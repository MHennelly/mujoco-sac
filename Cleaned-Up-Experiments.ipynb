{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-Mocap Simulation Efforts\n",
    "\n",
    "This notebook contains the work we've made since pivoting at the start of Week 9 towards simulating realistic gaits with non-mocap RL techniques.\n",
    "\n",
    "To give some context, the focus of these efforts was to determine how visually realistic the learned gaits through non-mocap methods would appear to be for different models. We also experimented with achieving more and more optimal trained agents, which lead to us shifting training from PPO to SAC as discussed in the project report. Below you will find both the scripts we wrote to train our agents and data/graphs collected from training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "# Gym provides all the training environments\n",
    "import gym\n",
    "\n",
    "# SAC used for all trained agents\n",
    "from stable_baselines.sac.policies import MlpPolicy\n",
    "from stable_baselines import SAC\n",
    "\n",
    "# Needed for the graphs displayed below\n",
    "%load_ext tensorboard\n",
    "\n",
    "# Needed for making GIFs of simulations\n",
    "import imageio\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task: Walk as far forward as possible without falling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f329133cdd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f329133cdd0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f329133cdd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f329133cdd0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3291d7da90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3291d7da90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3291d7da90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3291d7da90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3291d7d150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3291d7d150>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3291d7d150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3291d7d150>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f329133cdd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f329133cdd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f329133cdd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f329133cdd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f329133cdd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f329133cdd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f329133cdd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f329133cdd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f32bc20bc90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f32bc20bc90>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f32bc20bc90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f32bc20bc90>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f32bc3363d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f32bc3363d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f32bc3363d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f32bc3363d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f32bc1d8490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f32bc1d8490>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f32bc1d8490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f32bc1d8490>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f32bc34f190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f32bc34f190>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f32bc34f190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f32bc34f190>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f32bc1d8e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f32bc1d8e90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f32bc1d8e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f32bc1d8e90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f329395ee50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f329395ee50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f329395ee50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f329395ee50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f33d448a610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f33d448a610>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f33d448a610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f33d448a610>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f32bc302dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f32bc302dd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f32bc302dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f32bc302dd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3291d33dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3291d33dd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3291d33dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3291d33dd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f32bc34fa50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f32bc34fa50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f32bc34fa50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f32bc34fa50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f32bc133e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f32bc133e50>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f32bc133e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f32bc133e50>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f32939b3790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f32939b3790>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f32939b3790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f32939b3790>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f33402a9710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f33402a9710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f33402a9710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f33402a9710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f32bc133e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f32bc133e50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f32bc133e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f32bc133e50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3341d7d850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3341d7d850>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3341d7d850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3341d7d850>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3293942210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3293942210>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3293942210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3293942210>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f33402a9710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f33402a9710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f33402a9710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f33402a9710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f32bc336410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f32bc336410>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f32bc336410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f32bc336410>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f329386d710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f329386d710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f329386d710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f329386d710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3362cd9050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3362cd9050>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3362cd9050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3362cd9050>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f32bc336650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f32bc336650>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f32bc336650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f32bc336650>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    }
   ],
   "source": [
    "# DEFINE THE ENVIRONMENT/MODEL WITH TUNED PARAMETERS\n",
    "env = gym.make('Humanoid-v2')\n",
    "policy_kwargs = dict(layers=[256, 256])\n",
    "model = SAC(MlpPolicy, env, verbose=1, tensorboard_log=\"./sac_humanoid_walk_tensorboard/\", \n",
    "            policy_kwargs=policy_kwargs, buffer_size=1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 1.0125033  |\n",
      "| ent_coef_loss           | 0.06119744 |\n",
      "| entropy                 | 20.704313  |\n",
      "| episodes                | 10         |\n",
      "| fps                     | 97         |\n",
      "| mean 100 episode reward | 98.4       |\n",
      "| n_updates               | 80         |\n",
      "| policy_loss             | 22.465284  |\n",
      "| qf1_loss                | 11.124978  |\n",
      "| qf2_loss                | 8.203977   |\n",
      "| time_elapsed            | 1          |\n",
      "| total timesteps         | 179        |\n",
      "| value_loss              | 174.56766  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.9544133  |\n",
      "| ent_coef_loss           | -1.1572626 |\n",
      "| entropy                 | 20.403168  |\n",
      "| episodes                | 20         |\n",
      "| fps                     | 94         |\n",
      "| mean 100 episode reward | 108        |\n",
      "| n_updates               | 316        |\n",
      "| policy_loss             | -2.3990934 |\n",
      "| qf1_loss                | 0.51813656 |\n",
      "| qf2_loss                | 0.5467812  |\n",
      "| time_elapsed            | 4          |\n",
      "| total timesteps         | 415        |\n",
      "| value_loss              | 10.668219  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.8891577   |\n",
      "| ent_coef_loss           | -3.0752764  |\n",
      "| entropy                 | 21.700241   |\n",
      "| episodes                | 30          |\n",
      "| fps                     | 88          |\n",
      "| mean 100 episode reward | 107         |\n",
      "| n_updates               | 525         |\n",
      "| policy_loss             | -14.2423315 |\n",
      "| qf1_loss                | 0.70251644  |\n",
      "| qf2_loss                | 0.6889137   |\n",
      "| time_elapsed            | 7           |\n",
      "| total timesteps         | 624         |\n",
      "| value_loss              | 5.3352      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.8115706  |\n",
      "| ent_coef_loss           | -5.916248  |\n",
      "| entropy                 | 23.042986  |\n",
      "| episodes                | 40         |\n",
      "| fps                     | 88         |\n",
      "| mean 100 episode reward | 113        |\n",
      "| n_updates               | 794        |\n",
      "| policy_loss             | -29.005184 |\n",
      "| qf1_loss                | 1.2019413  |\n",
      "| qf2_loss                | 1.1649554  |\n",
      "| time_elapsed            | 10         |\n",
      "| total timesteps         | 893        |\n",
      "| value_loss              | 2.4184105  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.7393683  |\n",
      "| ent_coef_loss           | -8.613232  |\n",
      "| entropy                 | 22.716064  |\n",
      "| episodes                | 50         |\n",
      "| fps                     | 87         |\n",
      "| mean 100 episode reward | 119        |\n",
      "| n_updates               | 1076       |\n",
      "| policy_loss             | -40.725273 |\n",
      "| qf1_loss                | 3.622107   |\n",
      "| qf2_loss                | 3.279561   |\n",
      "| time_elapsed            | 13         |\n",
      "| total timesteps         | 1175       |\n",
      "| value_loss              | 4.5796423  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.6888414  |\n",
      "| ent_coef_loss           | -10.592568 |\n",
      "| entropy                 | 22.489193  |\n",
      "| episodes                | 60         |\n",
      "| fps                     | 86         |\n",
      "| mean 100 episode reward | 118        |\n",
      "| n_updates               | 1297       |\n",
      "| policy_loss             | -50.334282 |\n",
      "| qf1_loss                | 2.6979723  |\n",
      "| qf2_loss                | 2.7989557  |\n",
      "| time_elapsed            | 16         |\n",
      "| total timesteps         | 1396       |\n",
      "| value_loss              | 5.4930654  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.62427056 |\n",
      "| ent_coef_loss           | -13.403842 |\n",
      "| entropy                 | 22.108063  |\n",
      "| episodes                | 70         |\n",
      "| fps                     | 86         |\n",
      "| mean 100 episode reward | 123        |\n",
      "| n_updates               | 1611       |\n",
      "| policy_loss             | -62.88182  |\n",
      "| qf1_loss                | 4.1122417  |\n",
      "| qf2_loss                | 3.619776   |\n",
      "| time_elapsed            | 19         |\n",
      "| total timesteps         | 1710       |\n",
      "| value_loss              | 10.349296  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.56952125 |\n",
      "| ent_coef_loss           | -15.776991 |\n",
      "| entropy                 | 21.762817  |\n",
      "| episodes                | 80         |\n",
      "| fps                     | 86         |\n",
      "| mean 100 episode reward | 127        |\n",
      "| n_updates               | 1910       |\n",
      "| policy_loss             | -71.248245 |\n",
      "| qf1_loss                | 6.4287796  |\n",
      "| qf2_loss                | 7.911027   |\n",
      "| time_elapsed            | 23         |\n",
      "| total timesteps         | 2009       |\n",
      "| value_loss              | 20.334583  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.4767425  |\n",
      "| ent_coef_loss           | -18.844227 |\n",
      "| entropy                 | 20.878826  |\n",
      "| episodes                | 90         |\n",
      "| fps                     | 87         |\n",
      "| mean 100 episode reward | 150        |\n",
      "| n_updates               | 2529       |\n",
      "| policy_loss             | -92.92145  |\n",
      "| qf1_loss                | 9.190144   |\n",
      "| qf2_loss                | 7.6697125  |\n",
      "| time_elapsed            | 30         |\n",
      "| total timesteps         | 2628       |\n",
      "| value_loss              | 20.027836  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.40211478  |\n",
      "| ent_coef_loss           | -22.043222  |\n",
      "| entropy                 | 20.203209   |\n",
      "| episodes                | 100         |\n",
      "| fps                     | 87          |\n",
      "| mean 100 episode reward | 166         |\n",
      "| n_updates               | 3134        |\n",
      "| policy_loss             | -112.467896 |\n",
      "| qf1_loss                | 11.829196   |\n",
      "| qf2_loss                | 11.159112   |\n",
      "| time_elapsed            | 36          |\n",
      "| total timesteps         | 3233        |\n",
      "| value_loss              | 17.997143   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.33293605 |\n",
      "| ent_coef_loss           | -24.982601 |\n",
      "| entropy                 | 20.049065  |\n",
      "| episodes                | 110        |\n",
      "| fps                     | 87         |\n",
      "| mean 100 episode reward | 189        |\n",
      "| n_updates               | 3817       |\n",
      "| policy_loss             | -131.8073  |\n",
      "| qf1_loss                | 17.377613  |\n",
      "| qf2_loss                | 12.465757  |\n",
      "| time_elapsed            | 44         |\n",
      "| total timesteps         | 3916       |\n",
      "| value_loss              | 15.478849  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.29728726 |\n",
      "| ent_coef_loss           | -25.666069 |\n",
      "| entropy                 | 19.63733   |\n",
      "| episodes                | 120        |\n",
      "| fps                     | 87         |\n",
      "| mean 100 episode reward | 198        |\n",
      "| n_updates               | 4237       |\n",
      "| policy_loss             | -140.4714  |\n",
      "| qf1_loss                | 14.375568  |\n",
      "| qf2_loss                | 17.754604  |\n",
      "| time_elapsed            | 49         |\n",
      "| total timesteps         | 4336       |\n",
      "| value_loss              | 19.468287  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.2523827  |\n",
      "| ent_coef_loss           | -27.12737  |\n",
      "| entropy                 | 19.214508  |\n",
      "| episodes                | 130        |\n",
      "| fps                     | 87         |\n",
      "| mean 100 episode reward | 218        |\n",
      "| n_updates               | 4846       |\n",
      "| policy_loss             | -137.58263 |\n",
      "| qf1_loss                | 25.793324  |\n",
      "| qf2_loss                | 24.253765  |\n",
      "| time_elapsed            | 56         |\n",
      "| total timesteps         | 4945       |\n",
      "| value_loss              | 19.377977  |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.21295615 |\n",
      "| ent_coef_loss           | -29.209871 |\n",
      "| entropy                 | 18.89505   |\n",
      "| episodes                | 140        |\n",
      "| fps                     | 87         |\n",
      "| mean 100 episode reward | 238        |\n",
      "| n_updates               | 5479       |\n",
      "| policy_loss             | -156.94156 |\n",
      "| qf1_loss                | 16.031916  |\n",
      "| qf2_loss                | 12.033306  |\n",
      "| time_elapsed            | 63         |\n",
      "| total timesteps         | 5578       |\n",
      "| value_loss              | 33.884926  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.18249518 |\n",
      "| ent_coef_loss           | -32.414444 |\n",
      "| entropy                 | 18.825909  |\n",
      "| episodes                | 150        |\n",
      "| fps                     | 87         |\n",
      "| mean 100 episode reward | 252        |\n",
      "| n_updates               | 6042       |\n",
      "| policy_loss             | -162.18289 |\n",
      "| qf1_loss                | 30.098217  |\n",
      "| qf2_loss                | 38.950745  |\n",
      "| time_elapsed            | 70         |\n",
      "| total timesteps         | 6141       |\n",
      "| value_loss              | 22.57944   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.15254408 |\n",
      "| ent_coef_loss           | -27.628506 |\n",
      "| entropy                 | 18.200464  |\n",
      "| episodes                | 160        |\n",
      "| fps                     | 87         |\n",
      "| mean 100 episode reward | 277        |\n",
      "| n_updates               | 6704       |\n",
      "| policy_loss             | -154.98166 |\n",
      "| qf1_loss                | 18.055695  |\n",
      "| qf2_loss                | 24.94688   |\n",
      "| time_elapsed            | 77         |\n",
      "| total timesteps         | 6803       |\n",
      "| value_loss              | 22.368639  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.13118824 |\n",
      "| ent_coef_loss           | -30.602484 |\n",
      "| entropy                 | 18.01033   |\n",
      "| episodes                | 170        |\n",
      "| fps                     | 86         |\n",
      "| mean 100 episode reward | 292        |\n",
      "| n_updates               | 7286       |\n",
      "| policy_loss             | -166.12207 |\n",
      "| qf1_loss                | 21.22596   |\n",
      "| qf2_loss                | 22.273788  |\n",
      "| time_elapsed            | 84         |\n",
      "| total timesteps         | 7385       |\n",
      "| value_loss              | 26.313612  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.11490361 |\n",
      "| ent_coef_loss           | -29.836452 |\n",
      "| entropy                 | 17.558891  |\n",
      "| episodes                | 180        |\n",
      "| fps                     | 86         |\n",
      "| mean 100 episode reward | 304        |\n",
      "| n_updates               | 7790       |\n",
      "| policy_loss             | -166.04343 |\n",
      "| qf1_loss                | 18.31955   |\n",
      "| qf2_loss                | 14.394957  |\n",
      "| time_elapsed            | 91         |\n",
      "| total timesteps         | 7889       |\n",
      "| value_loss              | 16.28587   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.09793598 |\n",
      "| ent_coef_loss           | -27.269707 |\n",
      "| entropy                 | 17.354301  |\n",
      "| episodes                | 190        |\n",
      "| fps                     | 86         |\n",
      "| mean 100 episode reward | 305        |\n",
      "| n_updates               | 8430       |\n",
      "| policy_loss             | -177.32858 |\n",
      "| qf1_loss                | 13.253316  |\n",
      "| qf2_loss                | 17.871521  |\n",
      "| time_elapsed            | 98         |\n",
      "| total timesteps         | 8529       |\n",
      "| value_loss              | 15.269998  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.08384285 |\n",
      "| ent_coef_loss           | -28.546589 |\n",
      "| entropy                 | 17.259373  |\n",
      "| episodes                | 200        |\n",
      "| fps                     | 84         |\n",
      "| mean 100 episode reward | 305        |\n",
      "| n_updates               | 9062       |\n",
      "| policy_loss             | -181.84647 |\n",
      "| qf1_loss                | 20.222431  |\n",
      "| qf2_loss                | 18.010527  |\n",
      "| time_elapsed            | 107        |\n",
      "| total timesteps         | 9161       |\n",
      "| value_loss              | 19.043793  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.070702486 |\n",
      "| ent_coef_loss           | -24.564644  |\n",
      "| entropy                 | 16.905891   |\n",
      "| episodes                | 210         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 306         |\n",
      "| n_updates               | 9764        |\n",
      "| policy_loss             | -173.4393   |\n",
      "| qf1_loss                | 25.69077    |\n",
      "| qf2_loss                | 24.23481    |\n",
      "| time_elapsed            | 116         |\n",
      "| total timesteps         | 9863        |\n",
      "| value_loss              | 30.879848   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.06042513 |\n",
      "| ent_coef_loss           | -17.903103 |\n",
      "| entropy                 | 16.065002  |\n",
      "| episodes                | 220        |\n",
      "| fps                     | 85         |\n",
      "| mean 100 episode reward | 319        |\n",
      "| n_updates               | 10492      |\n",
      "| policy_loss             | -173.39142 |\n",
      "| qf1_loss                | 27.072964  |\n",
      "| qf2_loss                | 29.223164  |\n",
      "| time_elapsed            | 124        |\n",
      "| total timesteps         | 10591      |\n",
      "| value_loss              | 15.484298  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.052604783 |\n",
      "| ent_coef_loss           | -15.768726  |\n",
      "| entropy                 | 16.442316   |\n",
      "| episodes                | 230         |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 324         |\n",
      "| n_updates               | 11188       |\n",
      "| policy_loss             | -193.73581  |\n",
      "| qf1_loss                | 15.858789   |\n",
      "| qf2_loss                | 20.433746   |\n",
      "| time_elapsed            | 132         |\n",
      "| total timesteps         | 11287       |\n",
      "| value_loss              | 30.895166   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.04740392 |\n",
      "| ent_coef_loss           | -8.710045  |\n",
      "| entropy                 | 15.350883  |\n",
      "| episodes                | 240        |\n",
      "| fps                     | 85         |\n",
      "| mean 100 episode reward | 325        |\n",
      "| n_updates               | 11828      |\n",
      "| policy_loss             | -160.25937 |\n",
      "| qf1_loss                | 26.523512  |\n",
      "| qf2_loss                | 22.681032  |\n",
      "| time_elapsed            | 140        |\n",
      "| total timesteps         | 11927      |\n",
      "| value_loss              | 48.61867   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.042913496 |\n",
      "| ent_coef_loss           | -8.88969    |\n",
      "| entropy                 | 15.228067   |\n",
      "| episodes                | 250         |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 329         |\n",
      "| n_updates               | 12495       |\n",
      "| policy_loss             | -177.51395  |\n",
      "| qf1_loss                | 25.267555   |\n",
      "| qf2_loss                | 23.372738   |\n",
      "| time_elapsed            | 148         |\n",
      "| total timesteps         | 12594       |\n",
      "| value_loss              | 17.455212   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03895132 |\n",
      "| ent_coef_loss           | -1.9013168 |\n",
      "| entropy                 | 15.29756   |\n",
      "| episodes                | 260        |\n",
      "| fps                     | 85         |\n",
      "| mean 100 episode reward | 331        |\n",
      "| n_updates               | 13200      |\n",
      "| policy_loss             | -174.34492 |\n",
      "| qf1_loss                | 20.992893  |\n",
      "| qf2_loss                | 21.55784   |\n",
      "| time_elapsed            | 156        |\n",
      "| total timesteps         | 13299      |\n",
      "| value_loss              | 21.641598  |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.034614637 |\n",
      "| ent_coef_loss           | -8.215527   |\n",
      "| entropy                 | 15.240572   |\n",
      "| episodes                | 270         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 335         |\n",
      "| n_updates               | 13886       |\n",
      "| policy_loss             | -173.10144  |\n",
      "| qf1_loss                | 37.088688   |\n",
      "| qf2_loss                | 41.026405   |\n",
      "| time_elapsed            | 164         |\n",
      "| total timesteps         | 13985       |\n",
      "| value_loss              | 50.987045   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.033174377 |\n",
      "| ent_coef_loss           | -4.037989   |\n",
      "| entropy                 | 15.20296    |\n",
      "| episodes                | 280         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 342         |\n",
      "| n_updates               | 14538       |\n",
      "| policy_loss             | -161.33522  |\n",
      "| qf1_loss                | 30.464998   |\n",
      "| qf2_loss                | 31.075954   |\n",
      "| time_elapsed            | 172         |\n",
      "| total timesteps         | 14637       |\n",
      "| value_loss              | 26.430822   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.033046357 |\n",
      "| ent_coef_loss           | 4.510425    |\n",
      "| entropy                 | 14.817541   |\n",
      "| episodes                | 290         |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 341         |\n",
      "| n_updates               | 15176       |\n",
      "| policy_loss             | -148.55542  |\n",
      "| qf1_loss                | 26.26422    |\n",
      "| qf2_loss                | 28.17683    |\n",
      "| time_elapsed            | 179         |\n",
      "| total timesteps         | 15275       |\n",
      "| value_loss              | 26.110825   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.032739382 |\n",
      "| ent_coef_loss           | 2.7368808   |\n",
      "| entropy                 | 14.672256   |\n",
      "| episodes                | 300         |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 340         |\n",
      "| n_updates               | 15734       |\n",
      "| policy_loss             | -165.23859  |\n",
      "| qf1_loss                | 21.91856    |\n",
      "| qf2_loss                | 23.270452   |\n",
      "| time_elapsed            | 186         |\n",
      "| total timesteps         | 15833       |\n",
      "| value_loss              | 18.093607   |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| current_lr              | 0.0003       |\n",
      "| ent_coef                | 0.03208289   |\n",
      "| ent_coef_loss           | -0.095465064 |\n",
      "| entropy                 | 14.8334055   |\n",
      "| episodes                | 310          |\n",
      "| fps                     | 84           |\n",
      "| mean 100 episode reward | 341          |\n",
      "| n_updates               | 16402        |\n",
      "| policy_loss             | -180.74248   |\n",
      "| qf1_loss                | 29.932617    |\n",
      "| qf2_loss                | 24.77969     |\n",
      "| time_elapsed            | 194          |\n",
      "| total timesteps         | 16501        |\n",
      "| value_loss              | 41.195457    |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030630251 |\n",
      "| ent_coef_loss           | 1.0768744   |\n",
      "| entropy                 | 14.952648   |\n",
      "| episodes                | 320         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 341         |\n",
      "| n_updates               | 17054       |\n",
      "| policy_loss             | -168.07895  |\n",
      "| qf1_loss                | 23.649698   |\n",
      "| qf2_loss                | 28.791582   |\n",
      "| time_elapsed            | 201         |\n",
      "| total timesteps         | 17153       |\n",
      "| value_loss              | 19.426285   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031135954 |\n",
      "| ent_coef_loss           | 6.947121    |\n",
      "| entropy                 | 14.584168   |\n",
      "| episodes                | 330         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 341         |\n",
      "| n_updates               | 17725       |\n",
      "| policy_loss             | -162.26657  |\n",
      "| qf1_loss                | 25.703625   |\n",
      "| qf2_loss                | 18.435188   |\n",
      "| time_elapsed            | 210         |\n",
      "| total timesteps         | 17824       |\n",
      "| value_loss              | 43.311386   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.032728408 |\n",
      "| ent_coef_loss           | 3.390902    |\n",
      "| entropy                 | 14.676775   |\n",
      "| episodes                | 340         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 346         |\n",
      "| n_updates               | 18478       |\n",
      "| policy_loss             | -157.97499  |\n",
      "| qf1_loss                | 13.732407   |\n",
      "| qf2_loss                | 12.021284   |\n",
      "| time_elapsed            | 218         |\n",
      "| total timesteps         | 18577       |\n",
      "| value_loss              | 15.629811   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.030682   |\n",
      "| ent_coef_loss           | -4.1557207 |\n",
      "| entropy                 | 14.7995205 |\n",
      "| episodes                | 350        |\n",
      "| fps                     | 84         |\n",
      "| mean 100 episode reward | 348        |\n",
      "| n_updates               | 19131      |\n",
      "| policy_loss             | -161.29086 |\n",
      "| qf1_loss                | 21.738556  |\n",
      "| qf2_loss                | 15.610068  |\n",
      "| time_elapsed            | 226        |\n",
      "| total timesteps         | 19230      |\n",
      "| value_loss              | 10.056982  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028289106 |\n",
      "| ent_coef_loss           | 2.2079372   |\n",
      "| entropy                 | 14.547414   |\n",
      "| episodes                | 360         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 341         |\n",
      "| n_updates               | 19727       |\n",
      "| policy_loss             | -151.51096  |\n",
      "| qf1_loss                | 25.241892   |\n",
      "| qf2_loss                | 34.342102   |\n",
      "| time_elapsed            | 233         |\n",
      "| total timesteps         | 19826       |\n",
      "| value_loss              | 16.510027   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.026911765 |\n",
      "| ent_coef_loss           | 6.4005184   |\n",
      "| entropy                 | 14.2589245  |\n",
      "| episodes                | 370         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 345         |\n",
      "| n_updates               | 20508       |\n",
      "| policy_loss             | -147.1713   |\n",
      "| qf1_loss                | 10.796417   |\n",
      "| qf2_loss                | 12.395942   |\n",
      "| time_elapsed            | 242         |\n",
      "| total timesteps         | 20607       |\n",
      "| value_loss              | 13.097912   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028452838 |\n",
      "| ent_coef_loss           | -6.3728113  |\n",
      "| entropy                 | 14.955286   |\n",
      "| episodes                | 380         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 344         |\n",
      "| n_updates               | 21141       |\n",
      "| policy_loss             | -151.08305  |\n",
      "| qf1_loss                | 17.232067   |\n",
      "| qf2_loss                | 13.577698   |\n",
      "| time_elapsed            | 250         |\n",
      "| total timesteps         | 21240       |\n",
      "| value_loss              | 13.358202   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.027033307 |\n",
      "| ent_coef_loss           | 2.5431812   |\n",
      "| entropy                 | 14.47817    |\n",
      "| episodes                | 390         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 343         |\n",
      "| n_updates               | 21750       |\n",
      "| policy_loss             | -141.7665   |\n",
      "| qf1_loss                | 16.410782   |\n",
      "| qf2_loss                | 12.473917   |\n",
      "| time_elapsed            | 258         |\n",
      "| total timesteps         | 21849       |\n",
      "| value_loss              | 17.088127   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.026362928 |\n",
      "| ent_coef_loss           | -9.37888    |\n",
      "| entropy                 | 14.606434   |\n",
      "| episodes                | 400         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 357         |\n",
      "| n_updates               | 22589       |\n",
      "| policy_loss             | -135.58908  |\n",
      "| qf1_loss                | 12.199048   |\n",
      "| qf2_loss                | 15.35365    |\n",
      "| time_elapsed            | 268         |\n",
      "| total timesteps         | 22688       |\n",
      "| value_loss              | 30.521551   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.026057212 |\n",
      "| ent_coef_loss           | -1.4226665  |\n",
      "| entropy                 | 14.728348   |\n",
      "| episodes                | 410         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 362         |\n",
      "| n_updates               | 23342       |\n",
      "| policy_loss             | -153.4196   |\n",
      "| qf1_loss                | 12.087395   |\n",
      "| qf2_loss                | 18.09408    |\n",
      "| time_elapsed            | 277         |\n",
      "| total timesteps         | 23441       |\n",
      "| value_loss              | 12.881041   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.025476098 |\n",
      "| ent_coef_loss           | -3.3333855  |\n",
      "| entropy                 | 14.255647   |\n",
      "| episodes                | 420         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 370         |\n",
      "| n_updates               | 24198       |\n",
      "| policy_loss             | -141.0019   |\n",
      "| qf1_loss                | 21.4388     |\n",
      "| qf2_loss                | 21.200886   |\n",
      "| time_elapsed            | 287         |\n",
      "| total timesteps         | 24297       |\n",
      "| value_loss              | 24.233612   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.025081282 |\n",
      "| ent_coef_loss           | -3.0086808  |\n",
      "| entropy                 | 14.46191    |\n",
      "| episodes                | 430         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 371         |\n",
      "| n_updates               | 24853       |\n",
      "| policy_loss             | -140.43692  |\n",
      "| qf1_loss                | 11.198189   |\n",
      "| qf2_loss                | 13.508974   |\n",
      "| time_elapsed            | 294         |\n",
      "| total timesteps         | 24952       |\n",
      "| value_loss              | 12.402882   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.024374893 |\n",
      "| ent_coef_loss           | -6.769656   |\n",
      "| entropy                 | 14.556588   |\n",
      "| episodes                | 440         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 372         |\n",
      "| n_updates               | 25604       |\n",
      "| policy_loss             | -140.41684  |\n",
      "| qf1_loss                | 23.783472   |\n",
      "| qf2_loss                | 16.667923   |\n",
      "| time_elapsed            | 303         |\n",
      "| total timesteps         | 25703       |\n",
      "| value_loss              | 23.284893   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.024839826 |\n",
      "| ent_coef_loss           | 3.8391738   |\n",
      "| entropy                 | 14.650056   |\n",
      "| episodes                | 450         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 379         |\n",
      "| n_updates               | 26403       |\n",
      "| policy_loss             | -134.3405   |\n",
      "| qf1_loss                | 22.014538   |\n",
      "| qf2_loss                | 16.878626   |\n",
      "| time_elapsed            | 313         |\n",
      "| total timesteps         | 26502       |\n",
      "| value_loss              | 22.393276   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.024432033 |\n",
      "| ent_coef_loss           | 1.7038181   |\n",
      "| entropy                 | 14.481007   |\n",
      "| episodes                | 460         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 389         |\n",
      "| n_updates               | 27185       |\n",
      "| policy_loss             | -158.15817  |\n",
      "| qf1_loss                | 15.582773   |\n",
      "| qf2_loss                | 11.567409   |\n",
      "| time_elapsed            | 322         |\n",
      "| total timesteps         | 27284       |\n",
      "| value_loss              | 15.232784   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.023771655 |\n",
      "| ent_coef_loss           | 2.91747     |\n",
      "| entropy                 | 14.334192   |\n",
      "| episodes                | 470         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 390         |\n",
      "| n_updates               | 27939       |\n",
      "| policy_loss             | -151.45811  |\n",
      "| qf1_loss                | 10.378284   |\n",
      "| qf2_loss                | 9.888224    |\n",
      "| time_elapsed            | 331         |\n",
      "| total timesteps         | 28038       |\n",
      "| value_loss              | 11.279968   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.023334123 |\n",
      "| ent_coef_loss           | 2.179316    |\n",
      "| entropy                 | 14.710414   |\n",
      "| episodes                | 480         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 394         |\n",
      "| n_updates               | 28641       |\n",
      "| policy_loss             | -137.30954  |\n",
      "| qf1_loss                | 13.260685   |\n",
      "| qf2_loss                | 14.4116955  |\n",
      "| time_elapsed            | 339         |\n",
      "| total timesteps         | 28740       |\n",
      "| value_loss              | 16.230568   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.023894476 |\n",
      "| ent_coef_loss           | -4.435982   |\n",
      "| entropy                 | 14.357632   |\n",
      "| episodes                | 490         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 395         |\n",
      "| n_updates               | 29286       |\n",
      "| policy_loss             | -146.38998  |\n",
      "| qf1_loss                | 11.066259   |\n",
      "| qf2_loss                | 11.56292    |\n",
      "| time_elapsed            | 347         |\n",
      "| total timesteps         | 29385       |\n",
      "| value_loss              | 11.300538   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.025803056 |\n",
      "| ent_coef_loss           | 4.7244945   |\n",
      "| entropy                 | 14.69162    |\n",
      "| episodes                | 500         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 384         |\n",
      "| n_updates               | 29888       |\n",
      "| policy_loss             | -143.97833  |\n",
      "| qf1_loss                | 9.59837     |\n",
      "| qf2_loss                | 7.6874447   |\n",
      "| time_elapsed            | 354         |\n",
      "| total timesteps         | 29987       |\n",
      "| value_loss              | 8.179801    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02484245 |\n",
      "| ent_coef_loss           | -1.20201   |\n",
      "| entropy                 | 14.643574  |\n",
      "| episodes                | 510        |\n",
      "| fps                     | 84         |\n",
      "| mean 100 episode reward | 375        |\n",
      "| n_updates               | 30478      |\n",
      "| policy_loss             | -142.85545 |\n",
      "| qf1_loss                | 7.3137197  |\n",
      "| qf2_loss                | 8.174442   |\n",
      "| time_elapsed            | 361        |\n",
      "| total timesteps         | 30577      |\n",
      "| value_loss              | 11.880911  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02360865 |\n",
      "| ent_coef_loss           | 2.156072   |\n",
      "| entropy                 | 14.48136   |\n",
      "| episodes                | 520        |\n",
      "| fps                     | 84         |\n",
      "| mean 100 episode reward | 365        |\n",
      "| n_updates               | 31089      |\n",
      "| policy_loss             | -132.22705 |\n",
      "| qf1_loss                | 10.271678  |\n",
      "| qf2_loss                | 10.556091  |\n",
      "| time_elapsed            | 368        |\n",
      "| total timesteps         | 31188      |\n",
      "| value_loss              | 11.804316  |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02345964 |\n",
      "| ent_coef_loss           | 8.760165   |\n",
      "| entropy                 | 14.863079  |\n",
      "| episodes                | 530        |\n",
      "| fps                     | 84         |\n",
      "| mean 100 episode reward | 367        |\n",
      "| n_updates               | 31817      |\n",
      "| policy_loss             | -160.20456 |\n",
      "| qf1_loss                | 10.708256  |\n",
      "| qf2_loss                | 12.858675  |\n",
      "| time_elapsed            | 377        |\n",
      "| total timesteps         | 31916      |\n",
      "| value_loss              | 9.410799   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.022857789 |\n",
      "| ent_coef_loss           | -0.46138573 |\n",
      "| entropy                 | 14.51716    |\n",
      "| episodes                | 540         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 365         |\n",
      "| n_updates               | 32546       |\n",
      "| policy_loss             | -140.9625   |\n",
      "| qf1_loss                | 17.35345    |\n",
      "| qf2_loss                | 16.978088   |\n",
      "| time_elapsed            | 385         |\n",
      "| total timesteps         | 32645       |\n",
      "| value_loss              | 23.724155   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.022296865 |\n",
      "| ent_coef_loss           | 3.4612005   |\n",
      "| entropy                 | 13.8328285  |\n",
      "| episodes                | 550         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 358         |\n",
      "| n_updates               | 33215       |\n",
      "| policy_loss             | -144.33084  |\n",
      "| qf1_loss                | 10.985901   |\n",
      "| qf2_loss                | 10.531967   |\n",
      "| time_elapsed            | 393         |\n",
      "| total timesteps         | 33314       |\n",
      "| value_loss              | 5.656151    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02353079 |\n",
      "| ent_coef_loss           | -3.2424304 |\n",
      "| entropy                 | 14.646822  |\n",
      "| episodes                | 560        |\n",
      "| fps                     | 84         |\n",
      "| mean 100 episode reward | 359        |\n",
      "| n_updates               | 34031      |\n",
      "| policy_loss             | -150.36542 |\n",
      "| qf1_loss                | 12.026604  |\n",
      "| qf2_loss                | 19.674736  |\n",
      "| time_elapsed            | 403        |\n",
      "| total timesteps         | 34130      |\n",
      "| value_loss              | 13.71878   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02338927 |\n",
      "| ent_coef_loss           | 7.486129   |\n",
      "| entropy                 | 14.844045  |\n",
      "| episodes                | 570        |\n",
      "| fps                     | 84         |\n",
      "| mean 100 episode reward | 360        |\n",
      "| n_updates               | 34819      |\n",
      "| policy_loss             | -145.51083 |\n",
      "| qf1_loss                | 8.494654   |\n",
      "| qf2_loss                | 11.125505  |\n",
      "| time_elapsed            | 412        |\n",
      "| total timesteps         | 34918      |\n",
      "| value_loss              | 12.154156  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.022511456 |\n",
      "| ent_coef_loss           | -6.5699987  |\n",
      "| entropy                 | 14.67705    |\n",
      "| episodes                | 580         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 368         |\n",
      "| n_updates               | 35666       |\n",
      "| policy_loss             | -132.69957  |\n",
      "| qf1_loss                | 7.843907    |\n",
      "| qf2_loss                | 9.17316     |\n",
      "| time_elapsed            | 422         |\n",
      "| total timesteps         | 35765       |\n",
      "| value_loss              | 7.6894207   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.022647573 |\n",
      "| ent_coef_loss           | 7.490626    |\n",
      "| entropy                 | 14.6204815  |\n",
      "| episodes                | 590         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 374         |\n",
      "| n_updates               | 36412       |\n",
      "| policy_loss             | -144.29868  |\n",
      "| qf1_loss                | 12.541809   |\n",
      "| qf2_loss                | 10.643619   |\n",
      "| time_elapsed            | 431         |\n",
      "| total timesteps         | 36511       |\n",
      "| value_loss              | 11.571001   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02282266 |\n",
      "| ent_coef_loss           | 10.702605  |\n",
      "| entropy                 | 14.731488  |\n",
      "| episodes                | 600        |\n",
      "| fps                     | 84         |\n",
      "| mean 100 episode reward | 379        |\n",
      "| n_updates               | 37112      |\n",
      "| policy_loss             | -159.10071 |\n",
      "| qf1_loss                | 10.443103  |\n",
      "| qf2_loss                | 14.121983  |\n",
      "| time_elapsed            | 439        |\n",
      "| total timesteps         | 37211      |\n",
      "| value_loss              | 12.441357  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02349482 |\n",
      "| ent_coef_loss           | -2.9316096 |\n",
      "| entropy                 | 14.803289  |\n",
      "| episodes                | 610        |\n",
      "| fps                     | 84         |\n",
      "| mean 100 episode reward | 382        |\n",
      "| n_updates               | 37764      |\n",
      "| policy_loss             | -145.04208 |\n",
      "| qf1_loss                | 8.61368    |\n",
      "| qf2_loss                | 7.6837797  |\n",
      "| time_elapsed            | 447        |\n",
      "| total timesteps         | 37863      |\n",
      "| value_loss              | 7.9445267  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.021718258 |\n",
      "| ent_coef_loss           | 10.10428    |\n",
      "| entropy                 | 14.138486   |\n",
      "| episodes                | 620         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 391         |\n",
      "| n_updates               | 38549       |\n",
      "| policy_loss             | -130.62341  |\n",
      "| qf1_loss                | 8.182379    |\n",
      "| qf2_loss                | 11.732786   |\n",
      "| time_elapsed            | 456         |\n",
      "| total timesteps         | 38648       |\n",
      "| value_loss              | 6.1676407   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.022029072 |\n",
      "| ent_coef_loss           | -3.0416088  |\n",
      "| entropy                 | 15.301498   |\n",
      "| episodes                | 630         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 398         |\n",
      "| n_updates               | 39387       |\n",
      "| policy_loss             | -142.19052  |\n",
      "| qf1_loss                | 8.336       |\n",
      "| qf2_loss                | 10.60507    |\n",
      "| time_elapsed            | 466         |\n",
      "| total timesteps         | 39486       |\n",
      "| value_loss              | 11.422369   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02108372 |\n",
      "| ent_coef_loss           | 2.343679   |\n",
      "| entropy                 | 14.73439   |\n",
      "| episodes                | 640        |\n",
      "| fps                     | 84         |\n",
      "| mean 100 episode reward | 406        |\n",
      "| n_updates               | 40244      |\n",
      "| policy_loss             | -151.48656 |\n",
      "| qf1_loss                | 7.950203   |\n",
      "| qf2_loss                | 6.763062   |\n",
      "| time_elapsed            | 476        |\n",
      "| total timesteps         | 40343      |\n",
      "| value_loss              | 8.29808    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.021089818 |\n",
      "| ent_coef_loss           | 6.626378    |\n",
      "| entropy                 | 13.822533   |\n",
      "| episodes                | 650         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 409         |\n",
      "| n_updates               | 40951       |\n",
      "| policy_loss             | -147.57472  |\n",
      "| qf1_loss                | 11.151835   |\n",
      "| qf2_loss                | 11.181138   |\n",
      "| time_elapsed            | 484         |\n",
      "| total timesteps         | 41050       |\n",
      "| value_loss              | 11.040905   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02111207 |\n",
      "| ent_coef_loss           | -3.9263606 |\n",
      "| entropy                 | 14.916639  |\n",
      "| episodes                | 660        |\n",
      "| fps                     | 84         |\n",
      "| mean 100 episode reward | 406        |\n",
      "| n_updates               | 41678      |\n",
      "| policy_loss             | -150.51184 |\n",
      "| qf1_loss                | 6.4043946  |\n",
      "| qf2_loss                | 8.534687   |\n",
      "| time_elapsed            | 493        |\n",
      "| total timesteps         | 41777      |\n",
      "| value_loss              | 5.54049    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.020920517 |\n",
      "| ent_coef_loss           | 6.5396233   |\n",
      "| entropy                 | 14.575903   |\n",
      "| episodes                | 670         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 402         |\n",
      "| n_updates               | 42379       |\n",
      "| policy_loss             | -139.5477   |\n",
      "| qf1_loss                | 9.526787    |\n",
      "| qf2_loss                | 9.901844    |\n",
      "| time_elapsed            | 501         |\n",
      "| total timesteps         | 42478       |\n",
      "| value_loss              | 6.900326    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.021471104 |\n",
      "| ent_coef_loss           | -5.0965166  |\n",
      "| entropy                 | 14.620501   |\n",
      "| episodes                | 680         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 398         |\n",
      "| n_updates               | 43156       |\n",
      "| policy_loss             | -128.18236  |\n",
      "| qf1_loss                | 12.367277   |\n",
      "| qf2_loss                | 12.123291   |\n",
      "| time_elapsed            | 510         |\n",
      "| total timesteps         | 43255       |\n",
      "| value_loss              | 16.25853    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.020990273 |\n",
      "| ent_coef_loss           | -7.5475397  |\n",
      "| entropy                 | 14.289497   |\n",
      "| episodes                | 690         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 396         |\n",
      "| n_updates               | 43881       |\n",
      "| policy_loss             | -148.11758  |\n",
      "| qf1_loss                | 10.557983   |\n",
      "| qf2_loss                | 8.748049    |\n",
      "| time_elapsed            | 519         |\n",
      "| total timesteps         | 43980       |\n",
      "| value_loss              | 8.38941     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.021351136 |\n",
      "| ent_coef_loss           | 3.0421622   |\n",
      "| entropy                 | 14.507201   |\n",
      "| episodes                | 700         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 404         |\n",
      "| n_updates               | 44719       |\n",
      "| policy_loss             | -145.95415  |\n",
      "| qf1_loss                | 6.7552137   |\n",
      "| qf2_loss                | 9.197535    |\n",
      "| time_elapsed            | 528         |\n",
      "| total timesteps         | 44818       |\n",
      "| value_loss              | 7.678665    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02042998 |\n",
      "| ent_coef_loss           | -3.766633  |\n",
      "| entropy                 | 14.946854  |\n",
      "| episodes                | 710        |\n",
      "| fps                     | 84         |\n",
      "| mean 100 episode reward | 408        |\n",
      "| n_updates               | 45443      |\n",
      "| policy_loss             | -133.09146 |\n",
      "| qf1_loss                | 7.8345213  |\n",
      "| qf2_loss                | 12.636549  |\n",
      "| time_elapsed            | 537        |\n",
      "| total timesteps         | 45542      |\n",
      "| value_loss              | 13.145618  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.020136172 |\n",
      "| ent_coef_loss           | -0.47509742 |\n",
      "| entropy                 | 14.486801   |\n",
      "| episodes                | 720         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 409         |\n",
      "| n_updates               | 46272       |\n",
      "| policy_loss             | -150.68243  |\n",
      "| qf1_loss                | 11.624931   |\n",
      "| qf2_loss                | 9.907316    |\n",
      "| time_elapsed            | 549         |\n",
      "| total timesteps         | 46371       |\n",
      "| value_loss              | 11.997977   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.019923778 |\n",
      "| ent_coef_loss           | -4.1080265  |\n",
      "| entropy                 | 15.171011   |\n",
      "| episodes                | 730         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 409         |\n",
      "| n_updates               | 47133       |\n",
      "| policy_loss             | -146.23218  |\n",
      "| qf1_loss                | 7.213092    |\n",
      "| qf2_loss                | 8.7460785   |\n",
      "| time_elapsed            | 559         |\n",
      "| total timesteps         | 47232       |\n",
      "| value_loss              | 7.111809    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.020990249 |\n",
      "| ent_coef_loss           | 5.5455523   |\n",
      "| entropy                 | 14.29958    |\n",
      "| episodes                | 740         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 412         |\n",
      "| n_updates               | 48069       |\n",
      "| policy_loss             | -134.2474   |\n",
      "| qf1_loss                | 8.928366    |\n",
      "| qf2_loss                | 7.5645275   |\n",
      "| time_elapsed            | 570         |\n",
      "| total timesteps         | 48168       |\n",
      "| value_loss              | 7.0399485   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.020371938 |\n",
      "| ent_coef_loss           | 2.5898635   |\n",
      "| entropy                 | 13.988668   |\n",
      "| episodes                | 750         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 416         |\n",
      "| n_updates               | 48872       |\n",
      "| policy_loss             | -153.96233  |\n",
      "| qf1_loss                | 11.34597    |\n",
      "| qf2_loss                | 11.370853   |\n",
      "| time_elapsed            | 580         |\n",
      "| total timesteps         | 48971       |\n",
      "| value_loss              | 13.663446   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02024594 |\n",
      "| ent_coef_loss           | -7.845292  |\n",
      "| entropy                 | 14.610966  |\n",
      "| episodes                | 760        |\n",
      "| fps                     | 84         |\n",
      "| mean 100 episode reward | 417        |\n",
      "| n_updates               | 49626      |\n",
      "| policy_loss             | -146.33258 |\n",
      "| qf1_loss                | 9.77622    |\n",
      "| qf2_loss                | 11.577167  |\n",
      "| time_elapsed            | 589        |\n",
      "| total timesteps         | 49725      |\n",
      "| value_loss              | 19.253288  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.021168187 |\n",
      "| ent_coef_loss           | -2.7607274  |\n",
      "| entropy                 | 14.221828   |\n",
      "| episodes                | 770         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 425         |\n",
      "| n_updates               | 50503       |\n",
      "| policy_loss             | -144.69568  |\n",
      "| qf1_loss                | 8.706518    |\n",
      "| qf2_loss                | 9.625148    |\n",
      "| time_elapsed            | 599         |\n",
      "| total timesteps         | 50602       |\n",
      "| value_loss              | 7.2458353   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02068694 |\n",
      "| ent_coef_loss           | 3.2789805  |\n",
      "| entropy                 | 14.33873   |\n",
      "| episodes                | 780        |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 422        |\n",
      "| n_updates               | 51250      |\n",
      "| policy_loss             | -147.58362 |\n",
      "| qf1_loss                | 10.634875  |\n",
      "| qf2_loss                | 9.856796   |\n",
      "| time_elapsed            | 613        |\n",
      "| total timesteps         | 51349      |\n",
      "| value_loss              | 8.175265   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.0195836  |\n",
      "| ent_coef_loss           | 5.817676   |\n",
      "| entropy                 | 14.099024  |\n",
      "| episodes                | 790        |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 428        |\n",
      "| n_updates               | 52117      |\n",
      "| policy_loss             | -156.18253 |\n",
      "| qf1_loss                | 9.894957   |\n",
      "| qf2_loss                | 11.857658  |\n",
      "| time_elapsed            | 624        |\n",
      "| total timesteps         | 52216      |\n",
      "| value_loss              | 6.3636813  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.01969059 |\n",
      "| ent_coef_loss           | -0.7623328 |\n",
      "| entropy                 | 14.413048  |\n",
      "| episodes                | 800        |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 418        |\n",
      "| n_updates               | 52814      |\n",
      "| policy_loss             | -128.5365  |\n",
      "| qf1_loss                | 5.6439743  |\n",
      "| qf2_loss                | 7.3846064  |\n",
      "| time_elapsed            | 632        |\n",
      "| total timesteps         | 52913      |\n",
      "| value_loss              | 5.9773965  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.01940481 |\n",
      "| ent_coef_loss           | -6.948046  |\n",
      "| entropy                 | 14.701941  |\n",
      "| episodes                | 810        |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 423        |\n",
      "| n_updates               | 53621      |\n",
      "| policy_loss             | -135.06918 |\n",
      "| qf1_loss                | 6.8755455  |\n",
      "| qf2_loss                | 9.041778   |\n",
      "| time_elapsed            | 641        |\n",
      "| total timesteps         | 53720      |\n",
      "| value_loss              | 6.38319    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.019667571 |\n",
      "| ent_coef_loss           | 1.2676356   |\n",
      "| entropy                 | 14.418239   |\n",
      "| episodes                | 820         |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 424         |\n",
      "| n_updates               | 54452       |\n",
      "| policy_loss             | -131.51016  |\n",
      "| qf1_loss                | 5.437169    |\n",
      "| qf2_loss                | 3.8791142   |\n",
      "| time_elapsed            | 651         |\n",
      "| total timesteps         | 54551       |\n",
      "| value_loss              | 7.4240627   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.019244567 |\n",
      "| ent_coef_loss           | 3.6681342   |\n",
      "| entropy                 | 14.634224   |\n",
      "| episodes                | 830         |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 428         |\n",
      "| n_updates               | 55383       |\n",
      "| policy_loss             | -150.36809  |\n",
      "| qf1_loss                | 9.589024    |\n",
      "| qf2_loss                | 6.4272738   |\n",
      "| time_elapsed            | 662         |\n",
      "| total timesteps         | 55482       |\n",
      "| value_loss              | 5.736169    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.019319737 |\n",
      "| ent_coef_loss           | -2.7570066  |\n",
      "| entropy                 | 13.8168125  |\n",
      "| episodes                | 840         |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 432         |\n",
      "| n_updates               | 56376       |\n",
      "| policy_loss             | -134.4628   |\n",
      "| qf1_loss                | 7.9675865   |\n",
      "| qf2_loss                | 8.315899    |\n",
      "| time_elapsed            | 675         |\n",
      "| total timesteps         | 56475       |\n",
      "| value_loss              | 7.7707148   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.01959799 |\n",
      "| ent_coef_loss           | -0.4833989 |\n",
      "| entropy                 | 14.275812  |\n",
      "| episodes                | 850        |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 431        |\n",
      "| n_updates               | 57216      |\n",
      "| policy_loss             | -147.86713 |\n",
      "| qf1_loss                | 10.926787  |\n",
      "| qf2_loss                | 7.646709   |\n",
      "| time_elapsed            | 685        |\n",
      "| total timesteps         | 57315      |\n",
      "| value_loss              | 7.7136984  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.01864925 |\n",
      "| ent_coef_loss           | -1.3180374 |\n",
      "| entropy                 | 13.702561  |\n",
      "| episodes                | 860        |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 431        |\n",
      "| n_updates               | 58020      |\n",
      "| policy_loss             | -149.28983 |\n",
      "| qf1_loss                | 6.313385   |\n",
      "| qf2_loss                | 10.708382  |\n",
      "| time_elapsed            | 695        |\n",
      "| total timesteps         | 58119      |\n",
      "| value_loss              | 8.079536   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.01936209 |\n",
      "| ent_coef_loss           | -1.9242351 |\n",
      "| entropy                 | 13.978514  |\n",
      "| episodes                | 870        |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 427        |\n",
      "| n_updates               | 58890      |\n",
      "| policy_loss             | -150.79245 |\n",
      "| qf1_loss                | 11.900009  |\n",
      "| qf2_loss                | 7.8115363  |\n",
      "| time_elapsed            | 707        |\n",
      "| total timesteps         | 58989      |\n",
      "| value_loss              | 5.8150787  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.020040609 |\n",
      "| ent_coef_loss           | -0.72536254 |\n",
      "| entropy                 | 14.881411   |\n",
      "| episodes                | 880         |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 438         |\n",
      "| n_updates               | 59853       |\n",
      "| policy_loss             | -127.50573  |\n",
      "| qf1_loss                | 5.578719    |\n",
      "| qf2_loss                | 6.1859097   |\n",
      "| time_elapsed            | 719         |\n",
      "| total timesteps         | 59952       |\n",
      "| value_loss              | 4.207038    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.019639658 |\n",
      "| ent_coef_loss           | -0.54431033 |\n",
      "| entropy                 | 14.224201   |\n",
      "| episodes                | 890         |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 435         |\n",
      "| n_updates               | 60636       |\n",
      "| policy_loss             | -144.66882  |\n",
      "| qf1_loss                | 13.039801   |\n",
      "| qf2_loss                | 8.913351    |\n",
      "| time_elapsed            | 730         |\n",
      "| total timesteps         | 60735       |\n",
      "| value_loss              | 6.100926    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.020635817 |\n",
      "| ent_coef_loss           | -5.002112   |\n",
      "| entropy                 | 14.36463    |\n",
      "| episodes                | 900         |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 447         |\n",
      "| n_updates               | 61570       |\n",
      "| policy_loss             | -162.51163  |\n",
      "| qf1_loss                | 6.796918    |\n",
      "| qf2_loss                | 7.3936095   |\n",
      "| time_elapsed            | 741         |\n",
      "| total timesteps         | 61669       |\n",
      "| value_loss              | 7.6544237   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.020377675 |\n",
      "| ent_coef_loss           | 3.161664    |\n",
      "| entropy                 | 14.710535   |\n",
      "| episodes                | 910         |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 454         |\n",
      "| n_updates               | 62564       |\n",
      "| policy_loss             | -151.06088  |\n",
      "| qf1_loss                | 6.883707    |\n",
      "| qf2_loss                | 8.568787    |\n",
      "| time_elapsed            | 753         |\n",
      "| total timesteps         | 62663       |\n",
      "| value_loss              | 9.175472    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.020037962 |\n",
      "| ent_coef_loss           | 6.1514173   |\n",
      "| entropy                 | 14.525033   |\n",
      "| episodes                | 920         |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 459         |\n",
      "| n_updates               | 63531       |\n",
      "| policy_loss             | -131.87897  |\n",
      "| qf1_loss                | 9.435118    |\n",
      "| qf2_loss                | 9.309918    |\n",
      "| time_elapsed            | 765         |\n",
      "| total timesteps         | 63630       |\n",
      "| value_loss              | 8.996816    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.019466816 |\n",
      "| ent_coef_loss           | 1.3782105   |\n",
      "| entropy                 | 14.206264   |\n",
      "| episodes                | 930         |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 456         |\n",
      "| n_updates               | 64450       |\n",
      "| policy_loss             | -139.76022  |\n",
      "| qf1_loss                | 9.988564    |\n",
      "| qf2_loss                | 8.125635    |\n",
      "| time_elapsed            | 777         |\n",
      "| total timesteps         | 64549       |\n",
      "| value_loss              | 7.5016785   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.019914428 |\n",
      "| ent_coef_loss           | 4.0951333   |\n",
      "| entropy                 | 13.956382   |\n",
      "| episodes                | 940         |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 456         |\n",
      "| n_updates               | 65516       |\n",
      "| policy_loss             | -168.15712  |\n",
      "| qf1_loss                | 12.784153   |\n",
      "| qf2_loss                | 13.348814   |\n",
      "| time_elapsed            | 791         |\n",
      "| total timesteps         | 65615       |\n",
      "| value_loss              | 8.36985     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.0202206  |\n",
      "| ent_coef_loss           | -4.384291  |\n",
      "| entropy                 | 14.392784  |\n",
      "| episodes                | 950        |\n",
      "| fps                     | 82         |\n",
      "| mean 100 episode reward | 452        |\n",
      "| n_updates               | 66331      |\n",
      "| policy_loss             | -141.09529 |\n",
      "| qf1_loss                | 9.096476   |\n",
      "| qf2_loss                | 9.376747   |\n",
      "| time_elapsed            | 802        |\n",
      "| total timesteps         | 66430      |\n",
      "| value_loss              | 5.338047   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.020388065 |\n",
      "| ent_coef_loss           | 12.876976   |\n",
      "| entropy                 | 14.192883   |\n",
      "| episodes                | 960         |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 459         |\n",
      "| n_updates               | 67297       |\n",
      "| policy_loss             | -143.29541  |\n",
      "| qf1_loss                | 9.485785    |\n",
      "| qf2_loss                | 7.6415634   |\n",
      "| time_elapsed            | 818         |\n",
      "| total timesteps         | 67396       |\n",
      "| value_loss              | 8.975731    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.020299915 |\n",
      "| ent_coef_loss           | 5.1260843   |\n",
      "| entropy                 | 14.311816   |\n",
      "| episodes                | 970         |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 460         |\n",
      "| n_updates               | 68146       |\n",
      "| policy_loss             | -161.39026  |\n",
      "| qf1_loss                | 9.248813    |\n",
      "| qf2_loss                | 10.127536   |\n",
      "| time_elapsed            | 828         |\n",
      "| total timesteps         | 68245       |\n",
      "| value_loss              | 6.772669    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.020285875 |\n",
      "| ent_coef_loss           | -2.2738657  |\n",
      "| entropy                 | 14.393362   |\n",
      "| episodes                | 980         |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 446         |\n",
      "| n_updates               | 68880       |\n",
      "| policy_loss             | -153.5069   |\n",
      "| qf1_loss                | 8.241764    |\n",
      "| qf2_loss                | 6.2833076   |\n",
      "| time_elapsed            | 837         |\n",
      "| total timesteps         | 68979       |\n",
      "| value_loss              | 6.5904493   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.019445283 |\n",
      "| ent_coef_loss           | -4.3819833  |\n",
      "| entropy                 | 14.282099   |\n",
      "| episodes                | 990         |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 445         |\n",
      "| n_updates               | 69723       |\n",
      "| policy_loss             | -165.75389  |\n",
      "| qf1_loss                | 10.440579   |\n",
      "| qf2_loss                | 8.6284685   |\n",
      "| time_elapsed            | 848         |\n",
      "| total timesteps         | 69822       |\n",
      "| value_loss              | 8.234003    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02016911 |\n",
      "| ent_coef_loss           | 1.444995   |\n",
      "| entropy                 | 14.641018  |\n",
      "| episodes                | 1000       |\n",
      "| fps                     | 82         |\n",
      "| mean 100 episode reward | 438        |\n",
      "| n_updates               | 70580      |\n",
      "| policy_loss             | -148.04758 |\n",
      "| qf1_loss                | 12.723666  |\n",
      "| qf2_loss                | 12.598084  |\n",
      "| time_elapsed            | 858        |\n",
      "| total timesteps         | 70679      |\n",
      "| value_loss              | 8.256583   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.019472698 |\n",
      "| ent_coef_loss           | -2.01864    |\n",
      "| entropy                 | 13.407592   |\n",
      "| episodes                | 1010        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 434         |\n",
      "| n_updates               | 71495       |\n",
      "| policy_loss             | -167.04565  |\n",
      "| qf1_loss                | 9.173526    |\n",
      "| qf2_loss                | 13.142884   |\n",
      "| time_elapsed            | 872         |\n",
      "| total timesteps         | 71594       |\n",
      "| value_loss              | 7.7036223   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.018894201 |\n",
      "| ent_coef_loss           | -6.400751   |\n",
      "| entropy                 | 13.799065   |\n",
      "| episodes                | 1020        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 427         |\n",
      "| n_updates               | 72349       |\n",
      "| policy_loss             | -179.30724  |\n",
      "| qf1_loss                | 11.114944   |\n",
      "| qf2_loss                | 10.904814   |\n",
      "| time_elapsed            | 886         |\n",
      "| total timesteps         | 72448       |\n",
      "| value_loss              | 9.4454975   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.019780466 |\n",
      "| ent_coef_loss           | -2.4265208  |\n",
      "| entropy                 | 13.929414   |\n",
      "| episodes                | 1030        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 425         |\n",
      "| n_updates               | 73233       |\n",
      "| policy_loss             | -157.38013  |\n",
      "| qf1_loss                | 14.341403   |\n",
      "| qf2_loss                | 11.321016   |\n",
      "| time_elapsed            | 899         |\n",
      "| total timesteps         | 73332       |\n",
      "| value_loss              | 6.7636046   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.019091163 |\n",
      "| ent_coef_loss           | 0.008064806 |\n",
      "| entropy                 | 14.268941   |\n",
      "| episodes                | 1040        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 417         |\n",
      "| n_updates               | 74093       |\n",
      "| policy_loss             | -166.13297  |\n",
      "| qf1_loss                | 7.3835287   |\n",
      "| qf2_loss                | 10.656995   |\n",
      "| time_elapsed            | 909         |\n",
      "| total timesteps         | 74192       |\n",
      "| value_loss              | 9.70038     |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.020101517 |\n",
      "| ent_coef_loss           | 3.1416376   |\n",
      "| entropy                 | 13.722512   |\n",
      "| episodes                | 1050        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 418         |\n",
      "| n_updates               | 74837       |\n",
      "| policy_loss             | -160.04816  |\n",
      "| qf1_loss                | 9.237646    |\n",
      "| qf2_loss                | 11.386145   |\n",
      "| time_elapsed            | 918         |\n",
      "| total timesteps         | 74936       |\n",
      "| value_loss              | 15.129594   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.020263908 |\n",
      "| ent_coef_loss           | 2.2702003   |\n",
      "| entropy                 | 13.851796   |\n",
      "| episodes                | 1060        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 419         |\n",
      "| n_updates               | 75808       |\n",
      "| policy_loss             | -153.09561  |\n",
      "| qf1_loss                | 9.10459     |\n",
      "| qf2_loss                | 9.326268    |\n",
      "| time_elapsed            | 930         |\n",
      "| total timesteps         | 75907       |\n",
      "| value_loss              | 8.952335    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.018977465 |\n",
      "| ent_coef_loss           | 4.540391    |\n",
      "| entropy                 | 13.738131   |\n",
      "| episodes                | 1070        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 422         |\n",
      "| n_updates               | 76702       |\n",
      "| policy_loss             | -160.51144  |\n",
      "| qf1_loss                | 6.2301426   |\n",
      "| qf2_loss                | 7.630122    |\n",
      "| time_elapsed            | 941         |\n",
      "| total timesteps         | 76801       |\n",
      "| value_loss              | 10.058994   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.018455049 |\n",
      "| ent_coef_loss           | 6.452741    |\n",
      "| entropy                 | 13.884153   |\n",
      "| episodes                | 1080        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 432         |\n",
      "| n_updates               | 77659       |\n",
      "| policy_loss             | -159.085    |\n",
      "| qf1_loss                | 9.090539    |\n",
      "| qf2_loss                | 11.675827   |\n",
      "| time_elapsed            | 953         |\n",
      "| total timesteps         | 77758       |\n",
      "| value_loss              | 12.978197   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.018242136 |\n",
      "| ent_coef_loss           | 4.324501    |\n",
      "| entropy                 | 13.685806   |\n",
      "| episodes                | 1090        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 442         |\n",
      "| n_updates               | 78660       |\n",
      "| policy_loss             | -145.54086  |\n",
      "| qf1_loss                | 11.954312   |\n",
      "| qf2_loss                | 9.516485    |\n",
      "| time_elapsed            | 965         |\n",
      "| total timesteps         | 78759       |\n",
      "| value_loss              | 10.9593525  |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.01865858 |\n",
      "| ent_coef_loss           | 8.101477   |\n",
      "| entropy                 | 13.803178  |\n",
      "| episodes                | 1100       |\n",
      "| fps                     | 81         |\n",
      "| mean 100 episode reward | 443        |\n",
      "| n_updates               | 79525      |\n",
      "| policy_loss             | -164.1921  |\n",
      "| qf1_loss                | 8.184504   |\n",
      "| qf2_loss                | 11.98036   |\n",
      "| time_elapsed            | 975        |\n",
      "| total timesteps         | 79624      |\n",
      "| value_loss              | 8.147497   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.018406838 |\n",
      "| ent_coef_loss           | -1.6056132  |\n",
      "| entropy                 | 14.273842   |\n",
      "| episodes                | 1110        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 443         |\n",
      "| n_updates               | 80428       |\n",
      "| policy_loss             | -162.25537  |\n",
      "| qf1_loss                | 7.3219795   |\n",
      "| qf2_loss                | 10.565304   |\n",
      "| time_elapsed            | 986         |\n",
      "| total timesteps         | 80527       |\n",
      "| value_loss              | 8.677317    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.018792924 |\n",
      "| ent_coef_loss           | -3.3364909  |\n",
      "| entropy                 | 13.586833   |\n",
      "| episodes                | 1120        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 454         |\n",
      "| n_updates               | 81541       |\n",
      "| policy_loss             | -154.0402   |\n",
      "| qf1_loss                | 12.788303   |\n",
      "| qf2_loss                | 7.0246325   |\n",
      "| time_elapsed            | 999         |\n",
      "| total timesteps         | 81640       |\n",
      "| value_loss              | 7.036372    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.019043848 |\n",
      "| ent_coef_loss           | 1.9503099   |\n",
      "| entropy                 | 14.307323   |\n",
      "| episodes                | 1130        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 455         |\n",
      "| n_updates               | 82478       |\n",
      "| policy_loss             | -154.3505   |\n",
      "| qf1_loss                | 9.928292    |\n",
      "| qf2_loss                | 14.025568   |\n",
      "| time_elapsed            | 1011        |\n",
      "| total timesteps         | 82577       |\n",
      "| value_loss              | 9.283243    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.019090977 |\n",
      "| ent_coef_loss           | -6.5883245  |\n",
      "| entropy                 | 14.030952   |\n",
      "| episodes                | 1140        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 449         |\n",
      "| n_updates               | 83245       |\n",
      "| policy_loss             | -156.98761  |\n",
      "| qf1_loss                | 6.3727865   |\n",
      "| qf2_loss                | 6.1309414   |\n",
      "| time_elapsed            | 1021        |\n",
      "| total timesteps         | 83344       |\n",
      "| value_loss              | 6.90069     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.018610328 |\n",
      "| ent_coef_loss           | -2.807592   |\n",
      "| entropy                 | 13.173039   |\n",
      "| episodes                | 1150        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 458         |\n",
      "| n_updates               | 84180       |\n",
      "| policy_loss             | -161.91728  |\n",
      "| qf1_loss                | 15.912395   |\n",
      "| qf2_loss                | 17.83324    |\n",
      "| time_elapsed            | 1033        |\n",
      "| total timesteps         | 84279       |\n",
      "| value_loss              | 11.182377   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.01980263 |\n",
      "| ent_coef_loss           | -4.456785  |\n",
      "| entropy                 | 14.431728  |\n",
      "| episodes                | 1160       |\n",
      "| fps                     | 81         |\n",
      "| mean 100 episode reward | 458        |\n",
      "| n_updates               | 85163      |\n",
      "| policy_loss             | -166.54892 |\n",
      "| qf1_loss                | 7.936171   |\n",
      "| qf2_loss                | 5.5473614  |\n",
      "| time_elapsed            | 1045       |\n",
      "| total timesteps         | 85262      |\n",
      "| value_loss              | 5.2485094  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.01890951 |\n",
      "| ent_coef_loss           | 1.2494016  |\n",
      "| entropy                 | 14.407334  |\n",
      "| episodes                | 1170       |\n",
      "| fps                     | 81         |\n",
      "| mean 100 episode reward | 461        |\n",
      "| n_updates               | 86097      |\n",
      "| policy_loss             | -159.3458  |\n",
      "| qf1_loss                | 9.695527   |\n",
      "| qf2_loss                | 8.851833   |\n",
      "| time_elapsed            | 1055       |\n",
      "| total timesteps         | 86196      |\n",
      "| value_loss              | 10.109938  |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.018651247 |\n",
      "| ent_coef_loss           | -4.556013   |\n",
      "| entropy                 | 14.131436   |\n",
      "| episodes                | 1180        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 475         |\n",
      "| n_updates               | 87279       |\n",
      "| policy_loss             | -157.82835  |\n",
      "| qf1_loss                | 12.037783   |\n",
      "| qf2_loss                | 9.379263    |\n",
      "| time_elapsed            | 1070        |\n",
      "| total timesteps         | 87378       |\n",
      "| value_loss              | 13.330234   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.01911511 |\n",
      "| ent_coef_loss           | -3.373487  |\n",
      "| entropy                 | 14.054893  |\n",
      "| episodes                | 1190       |\n",
      "| fps                     | 81         |\n",
      "| mean 100 episode reward | 469        |\n",
      "| n_updates               | 88131      |\n",
      "| policy_loss             | -144.96109 |\n",
      "| qf1_loss                | 8.279404   |\n",
      "| qf2_loss                | 9.92012    |\n",
      "| time_elapsed            | 1080       |\n",
      "| total timesteps         | 88230      |\n",
      "| value_loss              | 6.062558   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.019172447 |\n",
      "| ent_coef_loss           | 4.384152    |\n",
      "| entropy                 | 13.66209    |\n",
      "| episodes                | 1200        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 481         |\n",
      "| n_updates               | 89177       |\n",
      "| policy_loss             | -162.46893  |\n",
      "| qf1_loss                | 9.77994     |\n",
      "| qf2_loss                | 10.659842   |\n",
      "| time_elapsed            | 1092        |\n",
      "| total timesteps         | 89276       |\n",
      "| value_loss              | 6.946389    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.020010358 |\n",
      "| ent_coef_loss           | 1.6483922   |\n",
      "| entropy                 | 14.147065   |\n",
      "| episodes                | 1210        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 482         |\n",
      "| n_updates               | 90037       |\n",
      "| policy_loss             | -156.99489  |\n",
      "| qf1_loss                | 7.8851786   |\n",
      "| qf2_loss                | 7.605009    |\n",
      "| time_elapsed            | 1104        |\n",
      "| total timesteps         | 90136       |\n",
      "| value_loss              | 7.524032    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.019453032 |\n",
      "| ent_coef_loss           | 5.278385    |\n",
      "| entropy                 | 14.510665   |\n",
      "| episodes                | 1220        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 472         |\n",
      "| n_updates               | 90916       |\n",
      "| policy_loss             | -158.39407  |\n",
      "| qf1_loss                | 13.216995   |\n",
      "| qf2_loss                | 13.602888   |\n",
      "| time_elapsed            | 1116        |\n",
      "| total timesteps         | 91015       |\n",
      "| value_loss              | 6.732079    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.019953495 |\n",
      "| ent_coef_loss           | -1.8175408  |\n",
      "| entropy                 | 14.006584   |\n",
      "| episodes                | 1230        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 471         |\n",
      "| n_updates               | 91747       |\n",
      "| policy_loss             | -172.63396  |\n",
      "| qf1_loss                | 10.364583   |\n",
      "| qf2_loss                | 12.697238   |\n",
      "| time_elapsed            | 1126        |\n",
      "| total timesteps         | 91846       |\n",
      "| value_loss              | 7.7601004   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.019471463 |\n",
      "| ent_coef_loss           | 1.4123157   |\n",
      "| entropy                 | 13.718323   |\n",
      "| episodes                | 1240        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 480         |\n",
      "| n_updates               | 92623       |\n",
      "| policy_loss             | -170.48969  |\n",
      "| qf1_loss                | 9.74843     |\n",
      "| qf2_loss                | 7.178283    |\n",
      "| time_elapsed            | 1137        |\n",
      "| total timesteps         | 92722       |\n",
      "| value_loss              | 7.271837    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.019693965 |\n",
      "| ent_coef_loss           | -10.654989  |\n",
      "| entropy                 | 14.38703    |\n",
      "| episodes                | 1250        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 479         |\n",
      "| n_updates               | 93530       |\n",
      "| policy_loss             | -164.14626  |\n",
      "| qf1_loss                | 9.2001095   |\n",
      "| qf2_loss                | 6.8070436   |\n",
      "| time_elapsed            | 1148        |\n",
      "| total timesteps         | 93629       |\n",
      "| value_loss              | 6.5813837   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.019699328 |\n",
      "| ent_coef_loss           | -5.944031   |\n",
      "| entropy                 | 14.178559   |\n",
      "| episodes                | 1260        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 483         |\n",
      "| n_updates               | 94565       |\n",
      "| policy_loss             | -140.3081   |\n",
      "| qf1_loss                | 14.122512   |\n",
      "| qf2_loss                | 11.304325   |\n",
      "| time_elapsed            | 1161        |\n",
      "| total timesteps         | 94664       |\n",
      "| value_loss              | 6.122779    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.019902306 |\n",
      "| ent_coef_loss           | -0.704185   |\n",
      "| entropy                 | 14.375464   |\n",
      "| episodes                | 1270        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 483         |\n",
      "| n_updates               | 95481       |\n",
      "| policy_loss             | -144.07695  |\n",
      "| qf1_loss                | 8.776283    |\n",
      "| qf2_loss                | 8.511045    |\n",
      "| time_elapsed            | 1172        |\n",
      "| total timesteps         | 95580       |\n",
      "| value_loss              | 8.73132     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.019537207 |\n",
      "| ent_coef_loss           | -6.723821   |\n",
      "| entropy                 | 13.827469   |\n",
      "| episodes                | 1280        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 473         |\n",
      "| n_updates               | 96483       |\n",
      "| policy_loss             | -164.87112  |\n",
      "| qf1_loss                | 9.838817    |\n",
      "| qf2_loss                | 7.9658713   |\n",
      "| time_elapsed            | 1184        |\n",
      "| total timesteps         | 96582       |\n",
      "| value_loss              | 6.9604244   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02011356 |\n",
      "| ent_coef_loss           | 1.8521492  |\n",
      "| entropy                 | 14.5467205 |\n",
      "| episodes                | 1290       |\n",
      "| fps                     | 81         |\n",
      "| mean 100 episode reward | 470        |\n",
      "| n_updates               | 97279      |\n",
      "| policy_loss             | -162.0352  |\n",
      "| qf1_loss                | 8.517492   |\n",
      "| qf2_loss                | 7.8249917  |\n",
      "| time_elapsed            | 1193       |\n",
      "| total timesteps         | 97378      |\n",
      "| value_loss              | 7.3590755  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.019644829 |\n",
      "| ent_coef_loss           | 7.8747606   |\n",
      "| entropy                 | 14.077526   |\n",
      "| episodes                | 1300        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 462         |\n",
      "| n_updates               | 98140       |\n",
      "| policy_loss             | -144.51184  |\n",
      "| qf1_loss                | 8.866682    |\n",
      "| qf2_loss                | 10.491572   |\n",
      "| time_elapsed            | 1203        |\n",
      "| total timesteps         | 98239       |\n",
      "| value_loss              | 7.3805676   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.01961873 |\n",
      "| ent_coef_loss           | -1.9158077 |\n",
      "| entropy                 | 14.016521  |\n",
      "| episodes                | 1310       |\n",
      "| fps                     | 81         |\n",
      "| mean 100 episode reward | 469        |\n",
      "| n_updates               | 99210      |\n",
      "| policy_loss             | -165.45087 |\n",
      "| qf1_loss                | 8.1846285  |\n",
      "| qf2_loss                | 10.68044   |\n",
      "| time_elapsed            | 1216       |\n",
      "| total timesteps         | 99309      |\n",
      "| value_loss              | 6.167562   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.019552207 |\n",
      "| ent_coef_loss           | 7.219985    |\n",
      "| entropy                 | 14.475283   |\n",
      "| episodes                | 1320        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 480         |\n",
      "| n_updates               | 100298      |\n",
      "| policy_loss             | -162.76318  |\n",
      "| qf1_loss                | 11.94825    |\n",
      "| qf2_loss                | 11.7158985  |\n",
      "| time_elapsed            | 1229        |\n",
      "| total timesteps         | 100397      |\n",
      "| value_loss              | 11.764445   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.020506954 |\n",
      "| ent_coef_loss           | -9.659663   |\n",
      "| entropy                 | 14.105703   |\n",
      "| episodes                | 1330        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 499         |\n",
      "| n_updates               | 101572      |\n",
      "| policy_loss             | -160.88803  |\n",
      "| qf1_loss                | 11.687912   |\n",
      "| qf2_loss                | 7.802469    |\n",
      "| time_elapsed            | 1245        |\n",
      "| total timesteps         | 101671      |\n",
      "| value_loss              | 12.098127   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.01987485 |\n",
      "| ent_coef_loss           | 3.173627   |\n",
      "| entropy                 | 13.777264  |\n",
      "| episodes                | 1340       |\n",
      "| fps                     | 81         |\n",
      "| mean 100 episode reward | 502        |\n",
      "| n_updates               | 102580     |\n",
      "| policy_loss             | -165.7189  |\n",
      "| qf1_loss                | 11.963858  |\n",
      "| qf2_loss                | 7.3717537  |\n",
      "| time_elapsed            | 1259       |\n",
      "| total timesteps         | 102679     |\n",
      "| value_loss              | 9.684525   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.01969659 |\n",
      "| ent_coef_loss           | 0.5246248  |\n",
      "| entropy                 | 13.939337  |\n",
      "| episodes                | 1350       |\n",
      "| fps                     | 81         |\n",
      "| mean 100 episode reward | 507        |\n",
      "| n_updates               | 103618     |\n",
      "| policy_loss             | -155.5649  |\n",
      "| qf1_loss                | 9.57124    |\n",
      "| qf2_loss                | 12.114518  |\n",
      "| time_elapsed            | 1272       |\n",
      "| total timesteps         | 103717     |\n",
      "| value_loss              | 7.606074   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.01870827 |\n",
      "| ent_coef_loss           | 3.6053355  |\n",
      "| entropy                 | 13.982212  |\n",
      "| episodes                | 1360       |\n",
      "| fps                     | 81         |\n",
      "| mean 100 episode reward | 497        |\n",
      "| n_updates               | 104492     |\n",
      "| policy_loss             | -158.57    |\n",
      "| qf1_loss                | 10.718254  |\n",
      "| qf2_loss                | 10.809731  |\n",
      "| time_elapsed            | 1282       |\n",
      "| total timesteps         | 104591     |\n",
      "| value_loss              | 9.651854   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02076003 |\n",
      "| ent_coef_loss           | -4.501604  |\n",
      "| entropy                 | 14.171442  |\n",
      "| episodes                | 1370       |\n",
      "| fps                     | 81         |\n",
      "| mean 100 episode reward | 507        |\n",
      "| n_updates               | 105641     |\n",
      "| policy_loss             | -173.64966 |\n",
      "| qf1_loss                | 8.845429   |\n",
      "| qf2_loss                | 7.696664   |\n",
      "| time_elapsed            | 1295       |\n",
      "| total timesteps         | 105740     |\n",
      "| value_loss              | 6.283388   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02079948 |\n",
      "| ent_coef_loss           | -2.944419  |\n",
      "| entropy                 | 14.537357  |\n",
      "| episodes                | 1380       |\n",
      "| fps                     | 81         |\n",
      "| mean 100 episode reward | 508        |\n",
      "| n_updates               | 106701     |\n",
      "| policy_loss             | -154.24298 |\n",
      "| qf1_loss                | 12.86026   |\n",
      "| qf2_loss                | 12.183821  |\n",
      "| time_elapsed            | 1308       |\n",
      "| total timesteps         | 106800     |\n",
      "| value_loss              | 9.595011   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.020735068 |\n",
      "| ent_coef_loss           | 2.402624    |\n",
      "| entropy                 | 14.087012   |\n",
      "| episodes                | 1390        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 520         |\n",
      "| n_updates               | 107755      |\n",
      "| policy_loss             | -175.94824  |\n",
      "| qf1_loss                | 7.435195    |\n",
      "| qf2_loss                | 8.804233    |\n",
      "| time_elapsed            | 1320        |\n",
      "| total timesteps         | 107854      |\n",
      "| value_loss              | 4.893235    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02007394 |\n",
      "| ent_coef_loss           | -10.373407 |\n",
      "| entropy                 | 14.063377  |\n",
      "| episodes                | 1400       |\n",
      "| fps                     | 81         |\n",
      "| mean 100 episode reward | 533        |\n",
      "| n_updates               | 108875     |\n",
      "| policy_loss             | -161.54291 |\n",
      "| qf1_loss                | 9.472658   |\n",
      "| qf2_loss                | 10.721687  |\n",
      "| time_elapsed            | 1333       |\n",
      "| total timesteps         | 108974     |\n",
      "| value_loss              | 5.594591   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.02101689  |\n",
      "| ent_coef_loss           | 0.017517567 |\n",
      "| entropy                 | 14.585074   |\n",
      "| episodes                | 1410        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 533         |\n",
      "| n_updates               | 109906      |\n",
      "| policy_loss             | -156.76189  |\n",
      "| qf1_loss                | 15.009857   |\n",
      "| qf2_loss                | 15.162796   |\n",
      "| time_elapsed            | 1345        |\n",
      "| total timesteps         | 110005      |\n",
      "| value_loss              | 7.889426    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.0202999  |\n",
      "| ent_coef_loss           | -11.755862 |\n",
      "| entropy                 | 14.591982  |\n",
      "| episodes                | 1420       |\n",
      "| fps                     | 81         |\n",
      "| mean 100 episode reward | 527        |\n",
      "| n_updates               | 110874     |\n",
      "| policy_loss             | -160.04779 |\n",
      "| qf1_loss                | 9.515841   |\n",
      "| qf2_loss                | 11.012466  |\n",
      "| time_elapsed            | 1356       |\n",
      "| total timesteps         | 110973     |\n",
      "| value_loss              | 3.2405062  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02055168 |\n",
      "| ent_coef_loss           | -1.6632085 |\n",
      "| entropy                 | 13.859793  |\n",
      "| episodes                | 1430       |\n",
      "| fps                     | 81         |\n",
      "| mean 100 episode reward | 505        |\n",
      "| n_updates               | 111680     |\n",
      "| policy_loss             | -177.22444 |\n",
      "| qf1_loss                | 9.308351   |\n",
      "| qf2_loss                | 6.9932156  |\n",
      "| time_elapsed            | 1365       |\n",
      "| total timesteps         | 111779     |\n",
      "| value_loss              | 8.571508   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.020172188 |\n",
      "| ent_coef_loss           | -4.1439753  |\n",
      "| entropy                 | 14.109295   |\n",
      "| episodes                | 1440        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 511         |\n",
      "| n_updates               | 112782      |\n",
      "| policy_loss             | -167.24106  |\n",
      "| qf1_loss                | 9.847499    |\n",
      "| qf2_loss                | 8.819744    |\n",
      "| time_elapsed            | 1378        |\n",
      "| total timesteps         | 112881      |\n",
      "| value_loss              | 8.573309    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.020059645 |\n",
      "| ent_coef_loss           | 3.5800712   |\n",
      "| entropy                 | 14.011251   |\n",
      "| episodes                | 1450        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 515         |\n",
      "| n_updates               | 113908      |\n",
      "| policy_loss             | -155.04901  |\n",
      "| qf1_loss                | 11.946683   |\n",
      "| qf2_loss                | 13.213059   |\n",
      "| time_elapsed            | 1391        |\n",
      "| total timesteps         | 114007      |\n",
      "| value_loss              | 6.5918455   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.020872878 |\n",
      "| ent_coef_loss           | -2.6218219  |\n",
      "| entropy                 | 14.143831   |\n",
      "| episodes                | 1460        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 522         |\n",
      "| n_updates               | 114907      |\n",
      "| policy_loss             | -171.95856  |\n",
      "| qf1_loss                | 12.127285   |\n",
      "| qf2_loss                | 14.567734   |\n",
      "| time_elapsed            | 1402        |\n",
      "| total timesteps         | 115006      |\n",
      "| value_loss              | 11.234425   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.021203084 |\n",
      "| ent_coef_loss           | 4.3149724   |\n",
      "| entropy                 | 14.075466   |\n",
      "| episodes                | 1470        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 528         |\n",
      "| n_updates               | 116139      |\n",
      "| policy_loss             | -178.54718  |\n",
      "| qf1_loss                | 7.206277    |\n",
      "| qf2_loss                | 6.147005    |\n",
      "| time_elapsed            | 1416        |\n",
      "| total timesteps         | 116238      |\n",
      "| value_loss              | 6.6868916   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.021946501 |\n",
      "| ent_coef_loss           | 5.9899445   |\n",
      "| entropy                 | 13.949565   |\n",
      "| episodes                | 1480        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 523         |\n",
      "| n_updates               | 117014      |\n",
      "| policy_loss             | -181.16576  |\n",
      "| qf1_loss                | 10.657665   |\n",
      "| qf2_loss                | 5.7829847   |\n",
      "| time_elapsed            | 1426        |\n",
      "| total timesteps         | 117113      |\n",
      "| value_loss              | 8.2187195   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.021064099 |\n",
      "| ent_coef_loss           | 1.3776398   |\n",
      "| entropy                 | 14.148672   |\n",
      "| episodes                | 1490        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 524         |\n",
      "| n_updates               | 118074      |\n",
      "| policy_loss             | -156.37405  |\n",
      "| qf1_loss                | 7.7124386   |\n",
      "| qf2_loss                | 12.797891   |\n",
      "| time_elapsed            | 1438        |\n",
      "| total timesteps         | 118173      |\n",
      "| value_loss              | 10.711477   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.021042079 |\n",
      "| ent_coef_loss           | 1.463474    |\n",
      "| entropy                 | 14.152603   |\n",
      "| episodes                | 1500        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 526         |\n",
      "| n_updates               | 119232      |\n",
      "| policy_loss             | -169.2893   |\n",
      "| qf1_loss                | 10.142771   |\n",
      "| qf2_loss                | 11.451086   |\n",
      "| time_elapsed            | 1451        |\n",
      "| total timesteps         | 119331      |\n",
      "| value_loss              | 5.9522123   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.022807777 |\n",
      "| ent_coef_loss           | -6.65958    |\n",
      "| entropy                 | 14.895884   |\n",
      "| episodes                | 1510        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 528         |\n",
      "| n_updates               | 120314      |\n",
      "| policy_loss             | -154.7767   |\n",
      "| qf1_loss                | 9.818714    |\n",
      "| qf2_loss                | 10.230194   |\n",
      "| time_elapsed            | 1463        |\n",
      "| total timesteps         | 120413      |\n",
      "| value_loss              | 7.8683825   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.021609595 |\n",
      "| ent_coef_loss           | -1.0256782  |\n",
      "| entropy                 | 14.609728   |\n",
      "| episodes                | 1520        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 532         |\n",
      "| n_updates               | 121358      |\n",
      "| policy_loss             | -155.42122  |\n",
      "| qf1_loss                | 13.068403   |\n",
      "| qf2_loss                | 12.912933   |\n",
      "| time_elapsed            | 1475        |\n",
      "| total timesteps         | 121457      |\n",
      "| value_loss              | 13.66609    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02123921 |\n",
      "| ent_coef_loss           | 5.9780836  |\n",
      "| entropy                 | 14.775944  |\n",
      "| episodes                | 1530       |\n",
      "| fps                     | 82         |\n",
      "| mean 100 episode reward | 549        |\n",
      "| n_updates               | 122510     |\n",
      "| policy_loss             | -157.3099  |\n",
      "| qf1_loss                | 9.084165   |\n",
      "| qf2_loss                | 9.860333   |\n",
      "| time_elapsed            | 1487       |\n",
      "| total timesteps         | 122609     |\n",
      "| value_loss              | 7.94549    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.021899406 |\n",
      "| ent_coef_loss           | -4.4916735  |\n",
      "| entropy                 | 15.0327215  |\n",
      "| episodes                | 1540        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 569         |\n",
      "| n_updates               | 124050      |\n",
      "| policy_loss             | -163.76544  |\n",
      "| qf1_loss                | 13.833818   |\n",
      "| qf2_loss                | 13.718651   |\n",
      "| time_elapsed            | 1504        |\n",
      "| total timesteps         | 124149      |\n",
      "| value_loss              | 11.765288   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.021728875 |\n",
      "| ent_coef_loss           | 4.5610337   |\n",
      "| entropy                 | 14.066531   |\n",
      "| episodes                | 1550        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 572         |\n",
      "| n_updates               | 125269      |\n",
      "| policy_loss             | -171.3074   |\n",
      "| qf1_loss                | 10.666922   |\n",
      "| qf2_loss                | 9.287508    |\n",
      "| time_elapsed            | 1518        |\n",
      "| total timesteps         | 125368      |\n",
      "| value_loss              | 6.1683455   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.021745449 |\n",
      "| ent_coef_loss           | 1.8181372   |\n",
      "| entropy                 | 14.375391   |\n",
      "| episodes                | 1560        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 587         |\n",
      "| n_updates               | 126510      |\n",
      "| policy_loss             | -168.70786  |\n",
      "| qf1_loss                | 13.863511   |\n",
      "| qf2_loss                | 14.945701   |\n",
      "| time_elapsed            | 1532        |\n",
      "| total timesteps         | 126609      |\n",
      "| value_loss              | 7.958078    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.021854691 |\n",
      "| ent_coef_loss           | 10.252174   |\n",
      "| entropy                 | 14.087208   |\n",
      "| episodes                | 1570        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 584         |\n",
      "| n_updates               | 127696      |\n",
      "| policy_loss             | -174.08969  |\n",
      "| qf1_loss                | 11.697836   |\n",
      "| qf2_loss                | 11.466039   |\n",
      "| time_elapsed            | 1546        |\n",
      "| total timesteps         | 127795      |\n",
      "| value_loss              | 5.6389265   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.021884589 |\n",
      "| ent_coef_loss           | -4.7579403  |\n",
      "| entropy                 | 13.993997   |\n",
      "| episodes                | 1580        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 588         |\n",
      "| n_updates               | 128728      |\n",
      "| policy_loss             | -157.98367  |\n",
      "| qf1_loss                | 9.712808    |\n",
      "| qf2_loss                | 11.707916   |\n",
      "| time_elapsed            | 1559        |\n",
      "| total timesteps         | 128827      |\n",
      "| value_loss              | 13.161597   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.022240184 |\n",
      "| ent_coef_loss           | 5.8806376   |\n",
      "| entropy                 | 14.273108   |\n",
      "| episodes                | 1590        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 595         |\n",
      "| n_updates               | 129891      |\n",
      "| policy_loss             | -171.2031   |\n",
      "| qf1_loss                | 14.672164   |\n",
      "| qf2_loss                | 12.646503   |\n",
      "| time_elapsed            | 1574        |\n",
      "| total timesteps         | 129990      |\n",
      "| value_loss              | 11.513425   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.021577429 |\n",
      "| ent_coef_loss           | 3.2553544   |\n",
      "| entropy                 | 14.621109   |\n",
      "| episodes                | 1600        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 602         |\n",
      "| n_updates               | 131188      |\n",
      "| policy_loss             | -177.7374   |\n",
      "| qf1_loss                | 17.584394   |\n",
      "| qf2_loss                | 12.761179   |\n",
      "| time_elapsed            | 1588        |\n",
      "| total timesteps         | 131287      |\n",
      "| value_loss              | 10.828772   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.022635153 |\n",
      "| ent_coef_loss           | 9.692633    |\n",
      "| entropy                 | 14.568547   |\n",
      "| episodes                | 1610        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 595         |\n",
      "| n_updates               | 132129      |\n",
      "| policy_loss             | -168.3563   |\n",
      "| qf1_loss                | 21.695244   |\n",
      "| qf2_loss                | 14.938593   |\n",
      "| time_elapsed            | 1599        |\n",
      "| total timesteps         | 132228      |\n",
      "| value_loss              | 12.402203   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.021589387 |\n",
      "| ent_coef_loss           | -2.2470925  |\n",
      "| entropy                 | 14.238678   |\n",
      "| episodes                | 1620        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 602         |\n",
      "| n_updates               | 133359      |\n",
      "| policy_loss             | -162.7974   |\n",
      "| qf1_loss                | 9.830048    |\n",
      "| qf2_loss                | 16.237581   |\n",
      "| time_elapsed            | 1613        |\n",
      "| total timesteps         | 133458      |\n",
      "| value_loss              | 13.927931   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.021270279 |\n",
      "| ent_coef_loss           | -0.90941143 |\n",
      "| entropy                 | 14.386622   |\n",
      "| episodes                | 1630        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 600         |\n",
      "| n_updates               | 134483      |\n",
      "| policy_loss             | -194.61273  |\n",
      "| qf1_loss                | 18.946373   |\n",
      "| qf2_loss                | 15.20015    |\n",
      "| time_elapsed            | 1626        |\n",
      "| total timesteps         | 134582      |\n",
      "| value_loss              | 11.804801   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02182447 |\n",
      "| ent_coef_loss           | 0.82120514 |\n",
      "| entropy                 | 14.563338  |\n",
      "| episodes                | 1640       |\n",
      "| fps                     | 82         |\n",
      "| mean 100 episode reward | 604        |\n",
      "| n_updates               | 136030     |\n",
      "| policy_loss             | -166.21463 |\n",
      "| qf1_loss                | 9.059507   |\n",
      "| qf2_loss                | 11.588492  |\n",
      "| time_elapsed            | 1644       |\n",
      "| total timesteps         | 136129     |\n",
      "| value_loss              | 14.5263195 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.021357   |\n",
      "| ent_coef_loss           | -8.871094  |\n",
      "| entropy                 | 15.019145  |\n",
      "| episodes                | 1650       |\n",
      "| fps                     | 82         |\n",
      "| mean 100 episode reward | 599        |\n",
      "| n_updates               | 137112     |\n",
      "| policy_loss             | -152.64105 |\n",
      "| qf1_loss                | 8.054073   |\n",
      "| qf2_loss                | 12.275957  |\n",
      "| time_elapsed            | 1656       |\n",
      "| total timesteps         | 137211     |\n",
      "| value_loss              | 7.0633197  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.021794248 |\n",
      "| ent_coef_loss           | -5.617288   |\n",
      "| entropy                 | 14.064852   |\n",
      "| episodes                | 1660        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 598         |\n",
      "| n_updates               | 138391      |\n",
      "| policy_loss             | -189.6407   |\n",
      "| qf1_loss                | 10.484167   |\n",
      "| qf2_loss                | 11.303812   |\n",
      "| time_elapsed            | 1671        |\n",
      "| total timesteps         | 138490      |\n",
      "| value_loss              | 7.910592    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.022291964 |\n",
      "| ent_coef_loss           | 2.1733003   |\n",
      "| entropy                 | 13.848441   |\n",
      "| episodes                | 1670        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 617         |\n",
      "| n_updates               | 139941      |\n",
      "| policy_loss             | -173.31107  |\n",
      "| qf1_loss                | 15.579199   |\n",
      "| qf2_loss                | 17.763409   |\n",
      "| time_elapsed            | 1689        |\n",
      "| total timesteps         | 140040      |\n",
      "| value_loss              | 8.263042    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.022338465 |\n",
      "| ent_coef_loss           | -6.203889   |\n",
      "| entropy                 | 13.98444    |\n",
      "| episodes                | 1680        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 616         |\n",
      "| n_updates               | 140968      |\n",
      "| policy_loss             | -184.08441  |\n",
      "| qf1_loss                | 9.843754    |\n",
      "| qf2_loss                | 12.005376   |\n",
      "| time_elapsed            | 1701        |\n",
      "| total timesteps         | 141067      |\n",
      "| value_loss              | 8.859737    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.022625204 |\n",
      "| ent_coef_loss           | -1.0347106  |\n",
      "| entropy                 | 14.859694   |\n",
      "| episodes                | 1690        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 608         |\n",
      "| n_updates               | 142090      |\n",
      "| policy_loss             | -164.15967  |\n",
      "| qf1_loss                | 10.480379   |\n",
      "| qf2_loss                | 7.5341134   |\n",
      "| time_elapsed            | 1713        |\n",
      "| total timesteps         | 142189      |\n",
      "| value_loss              | 13.280217   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02267449 |\n",
      "| ent_coef_loss           | 2.6617682  |\n",
      "| entropy                 | 14.564955  |\n",
      "| episodes                | 1700       |\n",
      "| fps                     | 82         |\n",
      "| mean 100 episode reward | 603        |\n",
      "| n_updates               | 143355     |\n",
      "| policy_loss             | -172.85701 |\n",
      "| qf1_loss                | 12.463733  |\n",
      "| qf2_loss                | 20.294323  |\n",
      "| time_elapsed            | 1728       |\n",
      "| total timesteps         | 143454     |\n",
      "| value_loss              | 16.317646  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.023216456 |\n",
      "| ent_coef_loss           | -3.8325965  |\n",
      "| entropy                 | 14.862577   |\n",
      "| episodes                | 1710        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 628         |\n",
      "| n_updates               | 144780      |\n",
      "| policy_loss             | -163.7557   |\n",
      "| qf1_loss                | 8.5497875   |\n",
      "| qf2_loss                | 6.8346305   |\n",
      "| time_elapsed            | 1744        |\n",
      "| total timesteps         | 144879      |\n",
      "| value_loss              | 7.198472    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.023808347 |\n",
      "| ent_coef_loss           | -4.080044   |\n",
      "| entropy                 | 14.308163   |\n",
      "| episodes                | 1720        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 638         |\n",
      "| n_updates               | 146189      |\n",
      "| policy_loss             | -196.18576  |\n",
      "| qf1_loss                | 14.833855   |\n",
      "| qf2_loss                | 16.60403    |\n",
      "| time_elapsed            | 1761        |\n",
      "| total timesteps         | 146288      |\n",
      "| value_loss              | 12.076156   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02428391 |\n",
      "| ent_coef_loss           | -1.6918635 |\n",
      "| entropy                 | 14.286198  |\n",
      "| episodes                | 1730       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 646        |\n",
      "| n_updates               | 147424     |\n",
      "| policy_loss             | -171.10114 |\n",
      "| qf1_loss                | 7.4244633  |\n",
      "| qf2_loss                | 8.505354   |\n",
      "| time_elapsed            | 1775       |\n",
      "| total timesteps         | 147523     |\n",
      "| value_loss              | 5.346156   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.024304282 |\n",
      "| ent_coef_loss           | -3.4378052  |\n",
      "| entropy                 | 14.917103   |\n",
      "| episodes                | 1740        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 636         |\n",
      "| n_updates               | 148828      |\n",
      "| policy_loss             | -156.11064  |\n",
      "| qf1_loss                | 13.157606   |\n",
      "| qf2_loss                | 12.818549   |\n",
      "| time_elapsed            | 1792        |\n",
      "| total timesteps         | 148927      |\n",
      "| value_loss              | 8.430997    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.025140638 |\n",
      "| ent_coef_loss           | -2.3808205  |\n",
      "| entropy                 | 14.652432   |\n",
      "| episodes                | 1750        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 653         |\n",
      "| n_updates               | 150221      |\n",
      "| policy_loss             | -158.37564  |\n",
      "| qf1_loss                | 11.601957   |\n",
      "| qf2_loss                | 11.169577   |\n",
      "| time_elapsed            | 1810        |\n",
      "| total timesteps         | 150320      |\n",
      "| value_loss              | 10.587664   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.025730198 |\n",
      "| ent_coef_loss           | -4.635492   |\n",
      "| entropy                 | 14.306897   |\n",
      "| episodes                | 1760        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 652         |\n",
      "| n_updates               | 151463      |\n",
      "| policy_loss             | -169.49019  |\n",
      "| qf1_loss                | 15.09385    |\n",
      "| qf2_loss                | 10.629342   |\n",
      "| time_elapsed            | 1825        |\n",
      "| total timesteps         | 151562      |\n",
      "| value_loss              | 17.570911   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.024371916 |\n",
      "| ent_coef_loss           | -3.7028656  |\n",
      "| entropy                 | 14.349073   |\n",
      "| episodes                | 1770        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 628         |\n",
      "| n_updates               | 152568      |\n",
      "| policy_loss             | -175.13931  |\n",
      "| qf1_loss                | 9.980883    |\n",
      "| qf2_loss                | 15.489935   |\n",
      "| time_elapsed            | 1838        |\n",
      "| total timesteps         | 152667      |\n",
      "| value_loss              | 11.749472   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02423692 |\n",
      "| ent_coef_loss           | 1.0685169  |\n",
      "| entropy                 | 14.559077  |\n",
      "| episodes                | 1780       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 649        |\n",
      "| n_updates               | 154006     |\n",
      "| policy_loss             | -187.54701 |\n",
      "| qf1_loss                | 8.554914   |\n",
      "| qf2_loss                | 9.511713   |\n",
      "| time_elapsed            | 1855       |\n",
      "| total timesteps         | 154105     |\n",
      "| value_loss              | 12.582363  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.023833547 |\n",
      "| ent_coef_loss           | 1.3111792   |\n",
      "| entropy                 | 14.591619   |\n",
      "| episodes                | 1790        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 656         |\n",
      "| n_updates               | 155181      |\n",
      "| policy_loss             | -176.39186  |\n",
      "| qf1_loss                | 19.891645   |\n",
      "| qf2_loss                | 22.404968   |\n",
      "| time_elapsed            | 1869        |\n",
      "| total timesteps         | 155280      |\n",
      "| value_loss              | 11.556727   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.023821719 |\n",
      "| ent_coef_loss           | 0.944692    |\n",
      "| entropy                 | 13.998661   |\n",
      "| episodes                | 1800        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 652         |\n",
      "| n_updates               | 156333      |\n",
      "| policy_loss             | -186.3259   |\n",
      "| qf1_loss                | 9.8209505   |\n",
      "| qf2_loss                | 12.211185   |\n",
      "| time_elapsed            | 1883        |\n",
      "| total timesteps         | 156432      |\n",
      "| value_loss              | 8.321795    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.023871932 |\n",
      "| ent_coef_loss           | 2.2623959   |\n",
      "| entropy                 | 13.762995   |\n",
      "| episodes                | 1810        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 651         |\n",
      "| n_updates               | 157724      |\n",
      "| policy_loss             | -198.53708  |\n",
      "| qf1_loss                | 12.144512   |\n",
      "| qf2_loss                | 11.9616995  |\n",
      "| time_elapsed            | 1901        |\n",
      "| total timesteps         | 157823      |\n",
      "| value_loss              | 11.796014   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02481393 |\n",
      "| ent_coef_loss           | -1.5348933 |\n",
      "| entropy                 | 13.973993  |\n",
      "| episodes                | 1820       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 631        |\n",
      "| n_updates               | 158778     |\n",
      "| policy_loss             | -192.34988 |\n",
      "| qf1_loss                | 12.622112  |\n",
      "| qf2_loss                | 12.432493  |\n",
      "| time_elapsed            | 1913       |\n",
      "| total timesteps         | 158877     |\n",
      "| value_loss              | 13.617054  |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.025403362 |\n",
      "| ent_coef_loss           | 1.0383785   |\n",
      "| entropy                 | 14.67302    |\n",
      "| episodes                | 1830        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 635         |\n",
      "| n_updates               | 160096      |\n",
      "| policy_loss             | -188.39058  |\n",
      "| qf1_loss                | 10.775896   |\n",
      "| qf2_loss                | 10.491465   |\n",
      "| time_elapsed            | 1929        |\n",
      "| total timesteps         | 160195      |\n",
      "| value_loss              | 5.5978837   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.024729798 |\n",
      "| ent_coef_loss           | 7.954749    |\n",
      "| entropy                 | 14.163939   |\n",
      "| episodes                | 1840        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 635         |\n",
      "| n_updates               | 161503      |\n",
      "| policy_loss             | -166.97507  |\n",
      "| qf1_loss                | 14.64398    |\n",
      "| qf2_loss                | 12.842567   |\n",
      "| time_elapsed            | 1946        |\n",
      "| total timesteps         | 161602      |\n",
      "| value_loss              | 11.60369    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.025264785 |\n",
      "| ent_coef_loss           | -2.2920232  |\n",
      "| entropy                 | 14.336289   |\n",
      "| episodes                | 1850        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 633         |\n",
      "| n_updates               | 162940      |\n",
      "| policy_loss             | -178.58685  |\n",
      "| qf1_loss                | 13.826582   |\n",
      "| qf2_loss                | 10.61829    |\n",
      "| time_elapsed            | 1962        |\n",
      "| total timesteps         | 163039      |\n",
      "| value_loss              | 20.319279   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.024992991 |\n",
      "| ent_coef_loss           | -1.8404796  |\n",
      "| entropy                 | 14.453218   |\n",
      "| episodes                | 1860        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 639         |\n",
      "| n_updates               | 164311      |\n",
      "| policy_loss             | -171.207    |\n",
      "| qf1_loss                | 13.225038   |\n",
      "| qf2_loss                | 16.712923   |\n",
      "| time_elapsed            | 1978        |\n",
      "| total timesteps         | 164410      |\n",
      "| value_loss              | 22.500546   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02434814 |\n",
      "| ent_coef_loss           | 2.314576   |\n",
      "| entropy                 | 14.306799  |\n",
      "| episodes                | 1870       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 649        |\n",
      "| n_updates               | 165547     |\n",
      "| policy_loss             | -164.88684 |\n",
      "| qf1_loss                | 11.188612  |\n",
      "| qf2_loss                | 8.586008   |\n",
      "| time_elapsed            | 1993       |\n",
      "| total timesteps         | 165646     |\n",
      "| value_loss              | 11.230442  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.023572551 |\n",
      "| ent_coef_loss           | -0.17970908 |\n",
      "| entropy                 | 14.324713   |\n",
      "| episodes                | 1880        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 637         |\n",
      "| n_updates               | 166756      |\n",
      "| policy_loss             | -174.57736  |\n",
      "| qf1_loss                | 11.856771   |\n",
      "| qf2_loss                | 16.329735   |\n",
      "| time_elapsed            | 2007        |\n",
      "| total timesteps         | 166855      |\n",
      "| value_loss              | 11.181612   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.024529897 |\n",
      "| ent_coef_loss           | -3.6827514  |\n",
      "| entropy                 | 14.932859   |\n",
      "| episodes                | 1890        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 645         |\n",
      "| n_updates               | 168111      |\n",
      "| policy_loss             | -174.124    |\n",
      "| qf1_loss                | 11.218939   |\n",
      "| qf2_loss                | 10.310883   |\n",
      "| time_elapsed            | 2023        |\n",
      "| total timesteps         | 168210      |\n",
      "| value_loss              | 10.16668    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.025152065 |\n",
      "| ent_coef_loss           | -7.4432592  |\n",
      "| entropy                 | 15.198528   |\n",
      "| episodes                | 1900        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 648         |\n",
      "| n_updates               | 169287      |\n",
      "| policy_loss             | -168.68567  |\n",
      "| qf1_loss                | 10.542976   |\n",
      "| qf2_loss                | 11.355822   |\n",
      "| time_elapsed            | 2037        |\n",
      "| total timesteps         | 169386      |\n",
      "| value_loss              | 10.485597   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02501233 |\n",
      "| ent_coef_loss           | 6.641528   |\n",
      "| entropy                 | 14.282267  |\n",
      "| episodes                | 1910       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 648        |\n",
      "| n_updates               | 170689     |\n",
      "| policy_loss             | -182.4336  |\n",
      "| qf1_loss                | 14.736694  |\n",
      "| qf2_loss                | 13.272818  |\n",
      "| time_elapsed            | 2054       |\n",
      "| total timesteps         | 170788     |\n",
      "| value_loss              | 10.695801  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.025844492 |\n",
      "| ent_coef_loss           | -1.027495   |\n",
      "| entropy                 | 14.189255   |\n",
      "| episodes                | 1920        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 672         |\n",
      "| n_updates               | 172197      |\n",
      "| policy_loss             | -186.79543  |\n",
      "| qf1_loss                | 12.471725   |\n",
      "| qf2_loss                | 13.749929   |\n",
      "| time_elapsed            | 2071        |\n",
      "| total timesteps         | 172296      |\n",
      "| value_loss              | 14.284832   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.026717251 |\n",
      "| ent_coef_loss           | 7.3872232   |\n",
      "| entropy                 | 14.56212    |\n",
      "| episodes                | 1930        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 678         |\n",
      "| n_updates               | 173661      |\n",
      "| policy_loss             | -174.9939   |\n",
      "| qf1_loss                | 16.81496    |\n",
      "| qf2_loss                | 13.745334   |\n",
      "| time_elapsed            | 2089        |\n",
      "| total timesteps         | 173760      |\n",
      "| value_loss              | 11.70886    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02622491 |\n",
      "| ent_coef_loss           | 2.3274326  |\n",
      "| entropy                 | 14.339713  |\n",
      "| episodes                | 1940       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 675        |\n",
      "| n_updates               | 174973     |\n",
      "| policy_loss             | -177.04938 |\n",
      "| qf1_loss                | 26.542921  |\n",
      "| qf2_loss                | 17.266037  |\n",
      "| time_elapsed            | 2104       |\n",
      "| total timesteps         | 175072     |\n",
      "| value_loss              | 13.268026  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.026258895 |\n",
      "| ent_coef_loss           | -4.1575027  |\n",
      "| entropy                 | 14.548979   |\n",
      "| episodes                | 1950        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 681         |\n",
      "| n_updates               | 176443      |\n",
      "| policy_loss             | -176.3745   |\n",
      "| qf1_loss                | 13.157121   |\n",
      "| qf2_loss                | 15.952522   |\n",
      "| time_elapsed            | 2120        |\n",
      "| total timesteps         | 176542      |\n",
      "| value_loss              | 13.175455   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.024816705 |\n",
      "| ent_coef_loss           | 2.7036355   |\n",
      "| entropy                 | 14.360016   |\n",
      "| episodes                | 1960        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 688         |\n",
      "| n_updates               | 177917      |\n",
      "| policy_loss             | -198.94154  |\n",
      "| qf1_loss                | 10.875999   |\n",
      "| qf2_loss                | 10.9692955  |\n",
      "| time_elapsed            | 2136        |\n",
      "| total timesteps         | 178016      |\n",
      "| value_loss              | 8.991541    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02555347 |\n",
      "| ent_coef_loss           | -5.0055532 |\n",
      "| entropy                 | 14.194661  |\n",
      "| episodes                | 1970       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 687        |\n",
      "| n_updates               | 179123     |\n",
      "| policy_loss             | -192.05356 |\n",
      "| qf1_loss                | 16.922796  |\n",
      "| qf2_loss                | 16.911625  |\n",
      "| time_elapsed            | 2149       |\n",
      "| total timesteps         | 179222     |\n",
      "| value_loss              | 8.612157   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.025547463 |\n",
      "| ent_coef_loss           | 5.7502685   |\n",
      "| entropy                 | 13.937789   |\n",
      "| episodes                | 1980        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 695         |\n",
      "| n_updates               | 180430      |\n",
      "| policy_loss             | -171.60832  |\n",
      "| qf1_loss                | 15.652312   |\n",
      "| qf2_loss                | 11.493585   |\n",
      "| time_elapsed            | 2164        |\n",
      "| total timesteps         | 180529      |\n",
      "| value_loss              | 9.207185    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.025385974 |\n",
      "| ent_coef_loss           | 4.63295     |\n",
      "| entropy                 | 13.594534   |\n",
      "| episodes                | 1990        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 711         |\n",
      "| n_updates               | 182040      |\n",
      "| policy_loss             | -191.39334  |\n",
      "| qf1_loss                | 17.84109    |\n",
      "| qf2_loss                | 15.771383   |\n",
      "| time_elapsed            | 2184        |\n",
      "| total timesteps         | 182139      |\n",
      "| value_loss              | 14.927735   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.026399653 |\n",
      "| ent_coef_loss           | 3.0559974   |\n",
      "| entropy                 | 13.684661   |\n",
      "| episodes                | 2000        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 701         |\n",
      "| n_updates               | 183031      |\n",
      "| policy_loss             | -212.47702  |\n",
      "| qf1_loss                | 21.356895   |\n",
      "| qf2_loss                | 15.822674   |\n",
      "| time_elapsed            | 2196        |\n",
      "| total timesteps         | 183130      |\n",
      "| value_loss              | 11.880592   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.027161263 |\n",
      "| ent_coef_loss           | 0.26861334  |\n",
      "| entropy                 | 14.682964   |\n",
      "| episodes                | 2010        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 709         |\n",
      "| n_updates               | 184545      |\n",
      "| policy_loss             | -174.242    |\n",
      "| qf1_loss                | 18.304186   |\n",
      "| qf2_loss                | 16.666992   |\n",
      "| time_elapsed            | 2213        |\n",
      "| total timesteps         | 184644      |\n",
      "| value_loss              | 11.116484   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.027088076 |\n",
      "| ent_coef_loss           | 3.0961218   |\n",
      "| entropy                 | 14.1838     |\n",
      "| episodes                | 2020        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 701         |\n",
      "| n_updates               | 185848      |\n",
      "| policy_loss             | -191.34607  |\n",
      "| qf1_loss                | 13.660524   |\n",
      "| qf2_loss                | 22.304775   |\n",
      "| time_elapsed            | 2227        |\n",
      "| total timesteps         | 185947      |\n",
      "| value_loss              | 22.920544   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02781806 |\n",
      "| ent_coef_loss           | 10.943294  |\n",
      "| entropy                 | 13.718428  |\n",
      "| episodes                | 2030       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 682        |\n",
      "| n_updates               | 186901     |\n",
      "| policy_loss             | -199.95496 |\n",
      "| qf1_loss                | 21.530323  |\n",
      "| qf2_loss                | 20.733177  |\n",
      "| time_elapsed            | 2239       |\n",
      "| total timesteps         | 187000     |\n",
      "| value_loss              | 14.146317  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02667568 |\n",
      "| ent_coef_loss           | -1.3993138 |\n",
      "| entropy                 | 14.818403  |\n",
      "| episodes                | 2040       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 667        |\n",
      "| n_updates               | 187947     |\n",
      "| policy_loss             | -168.89767 |\n",
      "| qf1_loss                | 10.723822  |\n",
      "| qf2_loss                | 11.629926  |\n",
      "| time_elapsed            | 2251       |\n",
      "| total timesteps         | 188046     |\n",
      "| value_loss              | 11.51826   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.027575806 |\n",
      "| ent_coef_loss           | -6.060593   |\n",
      "| entropy                 | 14.926925   |\n",
      "| episodes                | 2050        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 672         |\n",
      "| n_updates               | 189529      |\n",
      "| policy_loss             | -191.0657   |\n",
      "| qf1_loss                | 15.686653   |\n",
      "| qf2_loss                | 14.625753   |\n",
      "| time_elapsed            | 2269        |\n",
      "| total timesteps         | 189628      |\n",
      "| value_loss              | 10.582542   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028243493 |\n",
      "| ent_coef_loss           | -2.7502122  |\n",
      "| entropy                 | 14.5097275  |\n",
      "| episodes                | 2060        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 677         |\n",
      "| n_updates               | 191129      |\n",
      "| policy_loss             | -170.4784   |\n",
      "| qf1_loss                | 16.76844    |\n",
      "| qf2_loss                | 14.905441   |\n",
      "| time_elapsed            | 2288        |\n",
      "| total timesteps         | 191228      |\n",
      "| value_loss              | 8.789458    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02747767 |\n",
      "| ent_coef_loss           | -19.500374 |\n",
      "| entropy                 | 14.683467  |\n",
      "| episodes                | 2070       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 692        |\n",
      "| n_updates               | 192749     |\n",
      "| policy_loss             | -191.64554 |\n",
      "| qf1_loss                | 12.119638  |\n",
      "| qf2_loss                | 12.337578  |\n",
      "| time_elapsed            | 2306       |\n",
      "| total timesteps         | 192848     |\n",
      "| value_loss              | 12.605509  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.027830478 |\n",
      "| ent_coef_loss           | -1.9017576  |\n",
      "| entropy                 | 14.043648   |\n",
      "| episodes                | 2080        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 698         |\n",
      "| n_updates               | 194194      |\n",
      "| policy_loss             | -193.29565  |\n",
      "| qf1_loss                | 10.393009   |\n",
      "| qf2_loss                | 12.986513   |\n",
      "| time_elapsed            | 2322        |\n",
      "| total timesteps         | 194293      |\n",
      "| value_loss              | 5.922474    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.027005613 |\n",
      "| ent_coef_loss           | 1.356554    |\n",
      "| entropy                 | 14.211111   |\n",
      "| episodes                | 2090        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 676         |\n",
      "| n_updates               | 195395      |\n",
      "| policy_loss             | -196.23822  |\n",
      "| qf1_loss                | 13.026674   |\n",
      "| qf2_loss                | 16.747437   |\n",
      "| time_elapsed            | 2336        |\n",
      "| total timesteps         | 195494      |\n",
      "| value_loss              | 8.841707    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.027444653 |\n",
      "| ent_coef_loss           | 1.7154655   |\n",
      "| entropy                 | 14.744289   |\n",
      "| episodes                | 2100        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 702         |\n",
      "| n_updates               | 196923      |\n",
      "| policy_loss             | -180.41713  |\n",
      "| qf1_loss                | 17.311127   |\n",
      "| qf2_loss                | 19.20626    |\n",
      "| time_elapsed            | 2354        |\n",
      "| total timesteps         | 197022      |\n",
      "| value_loss              | 22.800217   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028255805 |\n",
      "| ent_coef_loss           | 1.869623    |\n",
      "| entropy                 | 14.42283    |\n",
      "| episodes                | 2110        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 688         |\n",
      "| n_updates               | 198142      |\n",
      "| policy_loss             | -170.45383  |\n",
      "| qf1_loss                | 13.544975   |\n",
      "| qf2_loss                | 12.091161   |\n",
      "| time_elapsed            | 2367        |\n",
      "| total timesteps         | 198241      |\n",
      "| value_loss              | 8.757269    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028472062 |\n",
      "| ent_coef_loss           | 4.4339657   |\n",
      "| entropy                 | 14.0739565  |\n",
      "| episodes                | 2120        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 692         |\n",
      "| n_updates               | 199525      |\n",
      "| policy_loss             | -204.93597  |\n",
      "| qf1_loss                | 14.034366   |\n",
      "| qf2_loss                | 10.927919   |\n",
      "| time_elapsed            | 2384        |\n",
      "| total timesteps         | 199624      |\n",
      "| value_loss              | 9.207018    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02802882 |\n",
      "| ent_coef_loss           | 1.2319654  |\n",
      "| entropy                 | 14.243269  |\n",
      "| episodes                | 2130       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 714        |\n",
      "| n_updates               | 201030     |\n",
      "| policy_loss             | -193.89139 |\n",
      "| qf1_loss                | 18.914354  |\n",
      "| qf2_loss                | 10.415092  |\n",
      "| time_elapsed            | 2402       |\n",
      "| total timesteps         | 201129     |\n",
      "| value_loss              | 11.37945   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028506275 |\n",
      "| ent_coef_loss           | 5.672721    |\n",
      "| entropy                 | 14.217222   |\n",
      "| episodes                | 2140        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 750         |\n",
      "| n_updates               | 202806      |\n",
      "| policy_loss             | -199.30063  |\n",
      "| qf1_loss                | 30.105215   |\n",
      "| qf2_loss                | 26.846176   |\n",
      "| time_elapsed            | 2422        |\n",
      "| total timesteps         | 202905      |\n",
      "| value_loss              | 18.307844   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029172884 |\n",
      "| ent_coef_loss           | 4.811089    |\n",
      "| entropy                 | 14.595144   |\n",
      "| episodes                | 2150        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 754         |\n",
      "| n_updates               | 204441      |\n",
      "| policy_loss             | -206.39044  |\n",
      "| qf1_loss                | 11.450836   |\n",
      "| qf2_loss                | 12.268326   |\n",
      "| time_elapsed            | 2440        |\n",
      "| total timesteps         | 204540      |\n",
      "| value_loss              | 16.898537   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028470026 |\n",
      "| ent_coef_loss           | -8.729003   |\n",
      "| entropy                 | 14.788562   |\n",
      "| episodes                | 2160        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 749         |\n",
      "| n_updates               | 205927      |\n",
      "| policy_loss             | -202.04166  |\n",
      "| qf1_loss                | 18.546547   |\n",
      "| qf2_loss                | 20.01476    |\n",
      "| time_elapsed            | 2459        |\n",
      "| total timesteps         | 206026      |\n",
      "| value_loss              | 9.30625     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02847025 |\n",
      "| ent_coef_loss           | -4.462369  |\n",
      "| entropy                 | 14.683218  |\n",
      "| episodes                | 2170       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 735        |\n",
      "| n_updates               | 207231     |\n",
      "| policy_loss             | -196.43669 |\n",
      "| qf1_loss                | 14.5858555 |\n",
      "| qf2_loss                | 11.252096  |\n",
      "| time_elapsed            | 2475       |\n",
      "| total timesteps         | 207330     |\n",
      "| value_loss              | 14.946774  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028811708 |\n",
      "| ent_coef_loss           | -4.9174414  |\n",
      "| entropy                 | 14.550729   |\n",
      "| episodes                | 2180        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 727         |\n",
      "| n_updates               | 208586      |\n",
      "| policy_loss             | -198.08655  |\n",
      "| qf1_loss                | 11.707621   |\n",
      "| qf2_loss                | 13.665365   |\n",
      "| time_elapsed            | 2490        |\n",
      "| total timesteps         | 208685      |\n",
      "| value_loss              | 10.528481   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028363476 |\n",
      "| ent_coef_loss           | 2.7484283   |\n",
      "| entropy                 | 14.00968    |\n",
      "| episodes                | 2190        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 742         |\n",
      "| n_updates               | 210135      |\n",
      "| policy_loss             | -204.35968  |\n",
      "| qf1_loss                | 13.92291    |\n",
      "| qf2_loss                | 16.450375   |\n",
      "| time_elapsed            | 2507        |\n",
      "| total timesteps         | 210234      |\n",
      "| value_loss              | 6.0489473   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029345104 |\n",
      "| ent_coef_loss           | -7.9840713  |\n",
      "| entropy                 | 14.778465   |\n",
      "| episodes                | 2200        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 715         |\n",
      "| n_updates               | 211138      |\n",
      "| policy_loss             | -189.92307  |\n",
      "| qf1_loss                | 13.736845   |\n",
      "| qf2_loss                | 13.312      |\n",
      "| time_elapsed            | 2519        |\n",
      "| total timesteps         | 211237      |\n",
      "| value_loss              | 16.069508   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029400723 |\n",
      "| ent_coef_loss           | 6.5816574   |\n",
      "| entropy                 | 13.682611   |\n",
      "| episodes                | 2210        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 717         |\n",
      "| n_updates               | 212461      |\n",
      "| policy_loss             | -225.29996  |\n",
      "| qf1_loss                | 19.29541    |\n",
      "| qf2_loss                | 18.075382   |\n",
      "| time_elapsed            | 2534        |\n",
      "| total timesteps         | 212560      |\n",
      "| value_loss              | 23.380182   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028630137 |\n",
      "| ent_coef_loss           | 1.367549    |\n",
      "| entropy                 | 14.484201   |\n",
      "| episodes                | 2220        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 706         |\n",
      "| n_updates               | 213626      |\n",
      "| policy_loss             | -193.60297  |\n",
      "| qf1_loss                | 22.198212   |\n",
      "| qf2_loss                | 20.824247   |\n",
      "| time_elapsed            | 2547        |\n",
      "| total timesteps         | 213725      |\n",
      "| value_loss              | 8.71564     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029931005 |\n",
      "| ent_coef_loss           | -2.2275922  |\n",
      "| entropy                 | 14.862116   |\n",
      "| episodes                | 2230        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 728         |\n",
      "| n_updates               | 215495      |\n",
      "| policy_loss             | -190.44359  |\n",
      "| qf1_loss                | 18.796747   |\n",
      "| qf2_loss                | 16.176804   |\n",
      "| time_elapsed            | 2568        |\n",
      "| total timesteps         | 215594      |\n",
      "| value_loss              | 11.2231865  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029978378 |\n",
      "| ent_coef_loss           | -3.1240277  |\n",
      "| entropy                 | 14.222283   |\n",
      "| episodes                | 2240        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 712         |\n",
      "| n_updates               | 216934      |\n",
      "| policy_loss             | -202.60272  |\n",
      "| qf1_loss                | 30.26477    |\n",
      "| qf2_loss                | 23.617937   |\n",
      "| time_elapsed            | 2585        |\n",
      "| total timesteps         | 217033      |\n",
      "| value_loss              | 14.539797   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029891783 |\n",
      "| ent_coef_loss           | -1.6986125  |\n",
      "| entropy                 | 14.895342   |\n",
      "| episodes                | 2250        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 703         |\n",
      "| n_updates               | 218408      |\n",
      "| policy_loss             | -203.58427  |\n",
      "| qf1_loss                | 19.315155   |\n",
      "| qf2_loss                | 20.773777   |\n",
      "| time_elapsed            | 2604        |\n",
      "| total timesteps         | 218507      |\n",
      "| value_loss              | 14.031309   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030624768 |\n",
      "| ent_coef_loss           | -9.930386   |\n",
      "| entropy                 | 14.898289   |\n",
      "| episodes                | 2260        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 710         |\n",
      "| n_updates               | 220003      |\n",
      "| policy_loss             | -202.17464  |\n",
      "| qf1_loss                | 17.249542   |\n",
      "| qf2_loss                | 10.341377   |\n",
      "| time_elapsed            | 2621        |\n",
      "| total timesteps         | 220102      |\n",
      "| value_loss              | 9.886293    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030627973 |\n",
      "| ent_coef_loss           | 2.1574445   |\n",
      "| entropy                 | 13.746074   |\n",
      "| episodes                | 2270        |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 725         |\n",
      "| n_updates               | 221550      |\n",
      "| policy_loss             | -207.20677  |\n",
      "| qf1_loss                | 18.473686   |\n",
      "| qf2_loss                | 19.556282   |\n",
      "| time_elapsed            | 2638        |\n",
      "| total timesteps         | 221649      |\n",
      "| value_loss              | 21.330942   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030244274 |\n",
      "| ent_coef_loss           | -1.0537395  |\n",
      "| entropy                 | 14.82908    |\n",
      "| episodes                | 2280        |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 728         |\n",
      "| n_updates               | 222884      |\n",
      "| policy_loss             | -204.7322   |\n",
      "| qf1_loss                | 15.726856   |\n",
      "| qf2_loss                | 18.409979   |\n",
      "| time_elapsed            | 2653        |\n",
      "| total timesteps         | 222983      |\n",
      "| value_loss              | 12.535695   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031017147 |\n",
      "| ent_coef_loss           | 1.6126572   |\n",
      "| entropy                 | 14.289879   |\n",
      "| episodes                | 2290        |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 730         |\n",
      "| n_updates               | 224425      |\n",
      "| policy_loss             | -191.27449  |\n",
      "| qf1_loss                | 13.776123   |\n",
      "| qf2_loss                | 11.410454   |\n",
      "| time_elapsed            | 2670        |\n",
      "| total timesteps         | 224524      |\n",
      "| value_loss              | 19.463537   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03154635 |\n",
      "| ent_coef_loss           | 10.361381  |\n",
      "| entropy                 | 14.272766  |\n",
      "| episodes                | 2300       |\n",
      "| fps                     | 84         |\n",
      "| mean 100 episode reward | 754        |\n",
      "| n_updates               | 225901     |\n",
      "| policy_loss             | -203.60127 |\n",
      "| qf1_loss                | 27.293266  |\n",
      "| qf2_loss                | 21.999287  |\n",
      "| time_elapsed            | 2685       |\n",
      "| total timesteps         | 226000     |\n",
      "| value_loss              | 9.676245   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.0310821  |\n",
      "| ent_coef_loss           | 1.768805   |\n",
      "| entropy                 | 14.539597  |\n",
      "| episodes                | 2310       |\n",
      "| fps                     | 84         |\n",
      "| mean 100 episode reward | 752        |\n",
      "| n_updates               | 227154     |\n",
      "| policy_loss             | -209.98457 |\n",
      "| qf1_loss                | 32.07435   |\n",
      "| qf2_loss                | 24.969383  |\n",
      "| time_elapsed            | 2698       |\n",
      "| total timesteps         | 227253     |\n",
      "| value_loss              | 13.245318  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030725878 |\n",
      "| ent_coef_loss           | -3.8751616  |\n",
      "| entropy                 | 15.19584    |\n",
      "| episodes                | 2320        |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 790         |\n",
      "| n_updates               | 229159      |\n",
      "| policy_loss             | -194.73636  |\n",
      "| qf1_loss                | 17.170021   |\n",
      "| qf2_loss                | 14.754725   |\n",
      "| time_elapsed            | 2719        |\n",
      "| total timesteps         | 229258      |\n",
      "| value_loss              | 5.9511986   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031184362 |\n",
      "| ent_coef_loss           | -2.227676   |\n",
      "| entropy                 | 14.653955   |\n",
      "| episodes                | 2330        |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 793         |\n",
      "| n_updates               | 231108      |\n",
      "| policy_loss             | -196.355    |\n",
      "| qf1_loss                | 10.599629   |\n",
      "| qf2_loss                | 9.957336    |\n",
      "| time_elapsed            | 2740        |\n",
      "| total timesteps         | 231207      |\n",
      "| value_loss              | 10.163292   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030060828 |\n",
      "| ent_coef_loss           | -1.2433388  |\n",
      "| entropy                 | 13.883796   |\n",
      "| episodes                | 2340        |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 799         |\n",
      "| n_updates               | 232735      |\n",
      "| policy_loss             | -219.7012   |\n",
      "| qf1_loss                | 23.122093   |\n",
      "| qf2_loss                | 29.898134   |\n",
      "| time_elapsed            | 2758        |\n",
      "| total timesteps         | 232834      |\n",
      "| value_loss              | 18.17745    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.032047678 |\n",
      "| ent_coef_loss           | -0.2857238  |\n",
      "| entropy                 | 14.773907   |\n",
      "| episodes                | 2350        |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 787         |\n",
      "| n_updates               | 233971      |\n",
      "| policy_loss             | -202.5552   |\n",
      "| qf1_loss                | 21.652813   |\n",
      "| qf2_loss                | 23.207275   |\n",
      "| time_elapsed            | 2771        |\n",
      "| total timesteps         | 234070      |\n",
      "| value_loss              | 19.748571   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031414926 |\n",
      "| ent_coef_loss           | 6.5624857   |\n",
      "| entropy                 | 13.967148   |\n",
      "| episodes                | 2360        |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 827         |\n",
      "| n_updates               | 236389      |\n",
      "| policy_loss             | -190.88489  |\n",
      "| qf1_loss                | 13.033174   |\n",
      "| qf2_loss                | 10.513069   |\n",
      "| time_elapsed            | 2797        |\n",
      "| total timesteps         | 236488      |\n",
      "| value_loss              | 16.958267   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031403366 |\n",
      "| ent_coef_loss           | -4.341761   |\n",
      "| entropy                 | 14.384861   |\n",
      "| episodes                | 2370        |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 842         |\n",
      "| n_updates               | 238292      |\n",
      "| policy_loss             | -192.4173   |\n",
      "| qf1_loss                | 13.127241   |\n",
      "| qf2_loss                | 16.467644   |\n",
      "| time_elapsed            | 2820        |\n",
      "| total timesteps         | 238391      |\n",
      "| value_loss              | 8.567742    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031915095 |\n",
      "| ent_coef_loss           | -4.9190674  |\n",
      "| entropy                 | 14.789514   |\n",
      "| episodes                | 2380        |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 852         |\n",
      "| n_updates               | 239874      |\n",
      "| policy_loss             | -197.3899   |\n",
      "| qf1_loss                | 15.338716   |\n",
      "| qf2_loss                | 19.163437   |\n",
      "| time_elapsed            | 2837        |\n",
      "| total timesteps         | 239973      |\n",
      "| value_loss              | 7.282838    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031346947 |\n",
      "| ent_coef_loss           | -8.642336   |\n",
      "| entropy                 | 14.901524   |\n",
      "| episodes                | 2390        |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 860         |\n",
      "| n_updates               | 241555      |\n",
      "| policy_loss             | -171.83282  |\n",
      "| qf1_loss                | 12.755266   |\n",
      "| qf2_loss                | 21.044754   |\n",
      "| time_elapsed            | 2854        |\n",
      "| total timesteps         | 241654      |\n",
      "| value_loss              | 14.78702    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031372234 |\n",
      "| ent_coef_loss           | -5.607807   |\n",
      "| entropy                 | 14.747271   |\n",
      "| episodes                | 2400        |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 859         |\n",
      "| n_updates               | 242995      |\n",
      "| policy_loss             | -200.78441  |\n",
      "| qf1_loss                | 20.239109   |\n",
      "| qf2_loss                | 25.179226   |\n",
      "| time_elapsed            | 2869        |\n",
      "| total timesteps         | 243094      |\n",
      "| value_loss              | 18.584345   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03192368 |\n",
      "| ent_coef_loss           | 4.000783   |\n",
      "| entropy                 | 14.7119255 |\n",
      "| episodes                | 2410       |\n",
      "| fps                     | 84         |\n",
      "| mean 100 episode reward | 858        |\n",
      "| n_updates               | 244198     |\n",
      "| policy_loss             | -187.74475 |\n",
      "| qf1_loss                | 14.708235  |\n",
      "| qf2_loss                | 22.002277  |\n",
      "| time_elapsed            | 2881       |\n",
      "| total timesteps         | 244297     |\n",
      "| value_loss              | 16.05232   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.032517   |\n",
      "| ent_coef_loss           | 4.272448   |\n",
      "| entropy                 | 14.20905   |\n",
      "| episodes                | 2420       |\n",
      "| fps                     | 84         |\n",
      "| mean 100 episode reward | 828        |\n",
      "| n_updates               | 245524     |\n",
      "| policy_loss             | -230.96089 |\n",
      "| qf1_loss                | 22.683088  |\n",
      "| qf2_loss                | 18.599293  |\n",
      "| time_elapsed            | 2895       |\n",
      "| total timesteps         | 245623     |\n",
      "| value_loss              | 11.0971985 |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.032218896 |\n",
      "| ent_coef_loss           | -0.6245457  |\n",
      "| entropy                 | 14.801079   |\n",
      "| episodes                | 2430        |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 845         |\n",
      "| n_updates               | 247793      |\n",
      "| policy_loss             | -190.83281  |\n",
      "| qf1_loss                | 17.567049   |\n",
      "| qf2_loss                | 15.043467   |\n",
      "| time_elapsed            | 2918        |\n",
      "| total timesteps         | 247892      |\n",
      "| value_loss              | 17.750378   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03298024 |\n",
      "| ent_coef_loss           | -7.8043084 |\n",
      "| entropy                 | 14.733273  |\n",
      "| episodes                | 2440       |\n",
      "| fps                     | 84         |\n",
      "| mean 100 episode reward | 850        |\n",
      "| n_updates               | 249462     |\n",
      "| policy_loss             | -212.86653 |\n",
      "| qf1_loss                | 20.049725  |\n",
      "| qf2_loss                | 25.134403  |\n",
      "| time_elapsed            | 2936       |\n",
      "| total timesteps         | 249561     |\n",
      "| value_loss              | 13.59548   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.032664005 |\n",
      "| ent_coef_loss           | -6.3482857  |\n",
      "| entropy                 | 14.556084   |\n",
      "| episodes                | 2450        |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 865         |\n",
      "| n_updates               | 250971      |\n",
      "| policy_loss             | -214.38638  |\n",
      "| qf1_loss                | 23.664124   |\n",
      "| qf2_loss                | 21.019106   |\n",
      "| time_elapsed            | 2951        |\n",
      "| total timesteps         | 251070      |\n",
      "| value_loss              | 10.009308   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03279208 |\n",
      "| ent_coef_loss           | -6.8391733 |\n",
      "| entropy                 | 14.50598   |\n",
      "| episodes                | 2460       |\n",
      "| fps                     | 85         |\n",
      "| mean 100 episode reward | 840        |\n",
      "| n_updates               | 252896     |\n",
      "| policy_loss             | -207.15073 |\n",
      "| qf1_loss                | 17.124123  |\n",
      "| qf2_loss                | 16.355843  |\n",
      "| time_elapsed            | 2972       |\n",
      "| total timesteps         | 252995     |\n",
      "| value_loss              | 12.478087  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.032974925 |\n",
      "| ent_coef_loss           | -9.028177   |\n",
      "| entropy                 | 14.859552   |\n",
      "| episodes                | 2470        |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 828         |\n",
      "| n_updates               | 254522      |\n",
      "| policy_loss             | -214.19159  |\n",
      "| qf1_loss                | 24.757595   |\n",
      "| qf2_loss                | 23.523624   |\n",
      "| time_elapsed            | 2991        |\n",
      "| total timesteps         | 254621      |\n",
      "| value_loss              | 13.049879   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03169588 |\n",
      "| ent_coef_loss           | 8.472141   |\n",
      "| entropy                 | 14.012999  |\n",
      "| episodes                | 2480       |\n",
      "| fps                     | 85         |\n",
      "| mean 100 episode reward | 845        |\n",
      "| n_updates               | 256431     |\n",
      "| policy_loss             | -206.37323 |\n",
      "| qf1_loss                | 14.906103  |\n",
      "| qf2_loss                | 16.658484  |\n",
      "| time_elapsed            | 3011       |\n",
      "| total timesteps         | 256530     |\n",
      "| value_loss              | 25.834759  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.034261048 |\n",
      "| ent_coef_loss           | 1.6934528   |\n",
      "| entropy                 | 14.779165   |\n",
      "| episodes                | 2490        |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 829         |\n",
      "| n_updates               | 257789      |\n",
      "| policy_loss             | -235.39273  |\n",
      "| qf1_loss                | 14.634723   |\n",
      "| qf2_loss                | 22.302074   |\n",
      "| time_elapsed            | 3027        |\n",
      "| total timesteps         | 257888      |\n",
      "| value_loss              | 18.339443   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.032511357 |\n",
      "| ent_coef_loss           | 0.22655153  |\n",
      "| entropy                 | 13.628399   |\n",
      "| episodes                | 2500        |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 838         |\n",
      "| n_updates               | 259483      |\n",
      "| policy_loss             | -209.65994  |\n",
      "| qf1_loss                | 20.560204   |\n",
      "| qf2_loss                | 22.072634   |\n",
      "| time_elapsed            | 3045        |\n",
      "| total timesteps         | 259582      |\n",
      "| value_loss              | 12.510516   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031121481 |\n",
      "| ent_coef_loss           | -3.620656   |\n",
      "| entropy                 | 14.6409855  |\n",
      "| episodes                | 2510        |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 903         |\n",
      "| n_updates               | 262010      |\n",
      "| policy_loss             | -204.04498  |\n",
      "| qf1_loss                | 17.549488   |\n",
      "| qf2_loss                | 23.06605    |\n",
      "| time_elapsed            | 3075        |\n",
      "| total timesteps         | 262109      |\n",
      "| value_loss              | 14.653355   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.032740194 |\n",
      "| ent_coef_loss           | -3.071032   |\n",
      "| entropy                 | 14.036766   |\n",
      "| episodes                | 2520        |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 936         |\n",
      "| n_updates               | 264049      |\n",
      "| policy_loss             | -203.24353  |\n",
      "| qf1_loss                | 22.914272   |\n",
      "| qf2_loss                | 18.540913   |\n",
      "| time_elapsed            | 3096        |\n",
      "| total timesteps         | 264148      |\n",
      "| value_loss              | 17.4897     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.032189965 |\n",
      "| ent_coef_loss           | 0.44049275  |\n",
      "| entropy                 | 13.859234   |\n",
      "| episodes                | 2530        |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 936         |\n",
      "| n_updates               | 266337      |\n",
      "| policy_loss             | -218.85466  |\n",
      "| qf1_loss                | 24.875494   |\n",
      "| qf2_loss                | 19.659363   |\n",
      "| time_elapsed            | 3120        |\n",
      "| total timesteps         | 266436      |\n",
      "| value_loss              | 15.573429   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03316908 |\n",
      "| ent_coef_loss           | 1.6169822  |\n",
      "| entropy                 | 14.271088  |\n",
      "| episodes                | 2540       |\n",
      "| fps                     | 85         |\n",
      "| mean 100 episode reward | 957        |\n",
      "| n_updates               | 268445     |\n",
      "| policy_loss             | -220.30917 |\n",
      "| qf1_loss                | 24.990728  |\n",
      "| qf2_loss                | 18.818764  |\n",
      "| time_elapsed            | 3142       |\n",
      "| total timesteps         | 268544     |\n",
      "| value_loss              | 11.520169  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.032159988 |\n",
      "| ent_coef_loss           | -1.7820938  |\n",
      "| entropy                 | 14.3030815  |\n",
      "| episodes                | 2550        |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 974         |\n",
      "| n_updates               | 270309      |\n",
      "| policy_loss             | -214.52289  |\n",
      "| qf1_loss                | 25.074203   |\n",
      "| qf2_loss                | 19.662752   |\n",
      "| time_elapsed            | 3161        |\n",
      "| total timesteps         | 270408      |\n",
      "| value_loss              | 9.517488    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03247468 |\n",
      "| ent_coef_loss           | 1.150799   |\n",
      "| entropy                 | 13.779242  |\n",
      "| episodes                | 2560       |\n",
      "| fps                     | 85         |\n",
      "| mean 100 episode reward | 1.03e+03   |\n",
      "| n_updates               | 273324     |\n",
      "| policy_loss             | -214.77759 |\n",
      "| qf1_loss                | 17.806011  |\n",
      "| qf2_loss                | 20.82716   |\n",
      "| time_elapsed            | 3192       |\n",
      "| total timesteps         | 273423     |\n",
      "| value_loss              | 9.587427   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03396496 |\n",
      "| ent_coef_loss           | -6.0377045 |\n",
      "| entropy                 | 15.28479   |\n",
      "| episodes                | 2570       |\n",
      "| fps                     | 85         |\n",
      "| mean 100 episode reward | 1.06e+03   |\n",
      "| n_updates               | 275561     |\n",
      "| policy_loss             | -230.72662 |\n",
      "| qf1_loss                | 16.250908  |\n",
      "| qf2_loss                | 18.265858  |\n",
      "| time_elapsed            | 3215       |\n",
      "| total timesteps         | 275660     |\n",
      "| value_loss              | 10.537747  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.033368852 |\n",
      "| ent_coef_loss           | -5.9048686  |\n",
      "| entropy                 | 13.954583   |\n",
      "| episodes                | 2580        |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 1.08e+03    |\n",
      "| n_updates               | 277807      |\n",
      "| policy_loss             | -219.43326  |\n",
      "| qf1_loss                | 17.276121   |\n",
      "| qf2_loss                | 16.295212   |\n",
      "| time_elapsed            | 3239        |\n",
      "| total timesteps         | 277906      |\n",
      "| value_loss              | 12.421591   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03416965 |\n",
      "| ent_coef_loss           | 3.6600697  |\n",
      "| entropy                 | 14.111429  |\n",
      "| episodes                | 2590       |\n",
      "| fps                     | 85         |\n",
      "| mean 100 episode reward | 1.12e+03   |\n",
      "| n_updates               | 279953     |\n",
      "| policy_loss             | -204.82489 |\n",
      "| qf1_loss                | 20.388615  |\n",
      "| qf2_loss                | 15.817951  |\n",
      "| time_elapsed            | 3263       |\n",
      "| total timesteps         | 280052     |\n",
      "| value_loss              | 21.417343  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.033244934 |\n",
      "| ent_coef_loss           | -5.771246   |\n",
      "| entropy                 | 14.617327   |\n",
      "| episodes                | 2600        |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 1.15e+03    |\n",
      "| n_updates               | 282121      |\n",
      "| policy_loss             | -204.91953  |\n",
      "| qf1_loss                | 22.628052   |\n",
      "| qf2_loss                | 20.136738   |\n",
      "| time_elapsed            | 3288        |\n",
      "| total timesteps         | 282220      |\n",
      "| value_loss              | 11.199917   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.033204462 |\n",
      "| ent_coef_loss           | -4.409906   |\n",
      "| entropy                 | 14.352977   |\n",
      "| episodes                | 2610        |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 1.14e+03    |\n",
      "| n_updates               | 284285      |\n",
      "| policy_loss             | -228.30515  |\n",
      "| qf1_loss                | 15.729067   |\n",
      "| qf2_loss                | 14.471083   |\n",
      "| time_elapsed            | 3310        |\n",
      "| total timesteps         | 284384      |\n",
      "| value_loss              | 15.70075    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03464734 |\n",
      "| ent_coef_loss           | 2.9685683  |\n",
      "| entropy                 | 13.7981    |\n",
      "| episodes                | 2620       |\n",
      "| fps                     | 85         |\n",
      "| mean 100 episode reward | 1.14e+03   |\n",
      "| n_updates               | 286279     |\n",
      "| policy_loss             | -230.94188 |\n",
      "| qf1_loss                | 45.080097  |\n",
      "| qf2_loss                | 25.467758  |\n",
      "| time_elapsed            | 3330       |\n",
      "| total timesteps         | 286378     |\n",
      "| value_loss              | 58.886726  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035411496 |\n",
      "| ent_coef_loss           | 3.7423148   |\n",
      "| entropy                 | 13.94529    |\n",
      "| episodes                | 2630        |\n",
      "| fps                     | 86          |\n",
      "| mean 100 episode reward | 1.12e+03    |\n",
      "| n_updates               | 288247      |\n",
      "| policy_loss             | -204.18893  |\n",
      "| qf1_loss                | 15.365349   |\n",
      "| qf2_loss                | 13.346051   |\n",
      "| time_elapsed            | 3351        |\n",
      "| total timesteps         | 288346      |\n",
      "| value_loss              | 14.806957   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.034905307 |\n",
      "| ent_coef_loss           | -2.560594   |\n",
      "| entropy                 | 14.517075   |\n",
      "| episodes                | 2640        |\n",
      "| fps                     | 86          |\n",
      "| mean 100 episode reward | 1.15e+03    |\n",
      "| n_updates               | 291079      |\n",
      "| policy_loss             | -229.22443  |\n",
      "| qf1_loss                | 24.806969   |\n",
      "| qf2_loss                | 26.414059   |\n",
      "| time_elapsed            | 3380        |\n",
      "| total timesteps         | 291178      |\n",
      "| value_loss              | 16.897404   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.03426623  |\n",
      "| ent_coef_loss           | -0.13562179 |\n",
      "| entropy                 | 14.237202   |\n",
      "| episodes                | 2650        |\n",
      "| fps                     | 86          |\n",
      "| mean 100 episode reward | 1.21e+03    |\n",
      "| n_updates               | 294137      |\n",
      "| policy_loss             | -247.68839  |\n",
      "| qf1_loss                | 18.853203   |\n",
      "| qf2_loss                | 13.486107   |\n",
      "| time_elapsed            | 3415        |\n",
      "| total timesteps         | 294236      |\n",
      "| value_loss              | 16.205482   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.034599066 |\n",
      "| ent_coef_loss           | 16.332607   |\n",
      "| entropy                 | 13.601641   |\n",
      "| episodes                | 2660        |\n",
      "| fps                     | 86          |\n",
      "| mean 100 episode reward | 1.2e+03     |\n",
      "| n_updates               | 296913      |\n",
      "| policy_loss             | -255.04776  |\n",
      "| qf1_loss                | 29.187513   |\n",
      "| qf2_loss                | 29.622807   |\n",
      "| time_elapsed            | 3445        |\n",
      "| total timesteps         | 297012      |\n",
      "| value_loss              | 11.357231   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.032544184 |\n",
      "| ent_coef_loss           | -10.303692  |\n",
      "| entropy                 | 14.269972   |\n",
      "| episodes                | 2670        |\n",
      "| fps                     | 86          |\n",
      "| mean 100 episode reward | 1.17e+03    |\n",
      "| n_updates               | 298703      |\n",
      "| policy_loss             | -220.15546  |\n",
      "| qf1_loss                | 28.391464   |\n",
      "| qf2_loss                | 35.22182    |\n",
      "| time_elapsed            | 3464        |\n",
      "| total timesteps         | 298802      |\n",
      "| value_loss              | 12.403453   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.033783626 |\n",
      "| ent_coef_loss           | -12.221984  |\n",
      "| entropy                 | 14.347954   |\n",
      "| episodes                | 2680        |\n",
      "| fps                     | 86          |\n",
      "| mean 100 episode reward | 1.18e+03    |\n",
      "| n_updates               | 301189      |\n",
      "| policy_loss             | -223.29439  |\n",
      "| qf1_loss                | 17.710976   |\n",
      "| qf2_loss                | 23.054068   |\n",
      "| time_elapsed            | 3489        |\n",
      "| total timesteps         | 301288      |\n",
      "| value_loss              | 13.968718   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.033843245 |\n",
      "| ent_coef_loss           | 4.2181816   |\n",
      "| entropy                 | 13.635207   |\n",
      "| episodes                | 2690        |\n",
      "| fps                     | 86          |\n",
      "| mean 100 episode reward | 1.19e+03    |\n",
      "| n_updates               | 303552      |\n",
      "| policy_loss             | -220.97488  |\n",
      "| qf1_loss                | 18.861025   |\n",
      "| qf2_loss                | 21.315392   |\n",
      "| time_elapsed            | 3519        |\n",
      "| total timesteps         | 303651      |\n",
      "| value_loss              | 10.559311   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035186935 |\n",
      "| ent_coef_loss           | 5.887736    |\n",
      "| entropy                 | 14.3312435  |\n",
      "| episodes                | 2700        |\n",
      "| fps                     | 86          |\n",
      "| mean 100 episode reward | 1.2e+03     |\n",
      "| n_updates               | 305842      |\n",
      "| policy_loss             | -211.78476  |\n",
      "| qf1_loss                | 26.968607   |\n",
      "| qf2_loss                | 31.854652   |\n",
      "| time_elapsed            | 3549        |\n",
      "| total timesteps         | 305941      |\n",
      "| value_loss              | 45.0279     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.034045786 |\n",
      "| ent_coef_loss           | -11.472035  |\n",
      "| entropy                 | 14.692821   |\n",
      "| episodes                | 2710        |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 1.25e+03    |\n",
      "| n_updates               | 309027      |\n",
      "| policy_loss             | -209.50546  |\n",
      "| qf1_loss                | 16.537405   |\n",
      "| qf2_loss                | 14.720251   |\n",
      "| time_elapsed            | 3595        |\n",
      "| total timesteps         | 309126      |\n",
      "| value_loss              | 11.277486   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.034528576 |\n",
      "| ent_coef_loss           | -4.2728157  |\n",
      "| entropy                 | 14.306927   |\n",
      "| episodes                | 2720        |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 1.28e+03    |\n",
      "| n_updates               | 311481      |\n",
      "| policy_loss             | -251.03366  |\n",
      "| qf1_loss                | 27.327152   |\n",
      "| qf2_loss                | 26.424257   |\n",
      "| time_elapsed            | 3626        |\n",
      "| total timesteps         | 311580      |\n",
      "| value_loss              | 14.7596855  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.034049124 |\n",
      "| ent_coef_loss           | 2.4542994   |\n",
      "| entropy                 | 14.638479   |\n",
      "| episodes                | 2730        |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 1.3e+03     |\n",
      "| n_updates               | 314026      |\n",
      "| policy_loss             | -242.56622  |\n",
      "| qf1_loss                | 21.266342   |\n",
      "| qf2_loss                | 29.374266   |\n",
      "| time_elapsed            | 3660        |\n",
      "| total timesteps         | 314125      |\n",
      "| value_loss              | 12.878658   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035443347 |\n",
      "| ent_coef_loss           | 1.296416    |\n",
      "| entropy                 | 14.118126   |\n",
      "| episodes                | 2740        |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 1.31e+03    |\n",
      "| n_updates               | 316832      |\n",
      "| policy_loss             | -250.76245  |\n",
      "| qf1_loss                | 23.818066   |\n",
      "| qf2_loss                | 21.024256   |\n",
      "| time_elapsed            | 3695        |\n",
      "| total timesteps         | 316931      |\n",
      "| value_loss              | 10.731155   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03451925 |\n",
      "| ent_coef_loss           | -6.885414  |\n",
      "| entropy                 | 14.260357  |\n",
      "| episodes                | 2750       |\n",
      "| fps                     | 85         |\n",
      "| mean 100 episode reward | 1.3e+03    |\n",
      "| n_updates               | 319721     |\n",
      "| policy_loss             | -228.64653 |\n",
      "| qf1_loss                | 20.393555  |\n",
      "| qf2_loss                | 22.954681  |\n",
      "| time_elapsed            | 3733       |\n",
      "| total timesteps         | 319820     |\n",
      "| value_loss              | 16.171204  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.0349224  |\n",
      "| ent_coef_loss           | -5.019112  |\n",
      "| entropy                 | 14.572037  |\n",
      "| episodes                | 2760       |\n",
      "| fps                     | 85         |\n",
      "| mean 100 episode reward | 1.29e+03   |\n",
      "| n_updates               | 322215     |\n",
      "| policy_loss             | -265.51788 |\n",
      "| qf1_loss                | 16.92776   |\n",
      "| qf2_loss                | 15.26357   |\n",
      "| time_elapsed            | 3766       |\n",
      "| total timesteps         | 322314     |\n",
      "| value_loss              | 14.633429  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03574328 |\n",
      "| ent_coef_loss           | 5.0928965  |\n",
      "| entropy                 | 14.372396  |\n",
      "| episodes                | 2770       |\n",
      "| fps                     | 85         |\n",
      "| mean 100 episode reward | 1.36e+03   |\n",
      "| n_updates               | 325454     |\n",
      "| policy_loss             | -231.88821 |\n",
      "| qf1_loss                | 19.032368  |\n",
      "| qf2_loss                | 18.973923  |\n",
      "| time_elapsed            | 3806       |\n",
      "| total timesteps         | 325553     |\n",
      "| value_loss              | 13.3431    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036019597 |\n",
      "| ent_coef_loss           | 2.086008    |\n",
      "| entropy                 | 14.448618   |\n",
      "| episodes                | 2780        |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 1.36e+03    |\n",
      "| n_updates               | 328004      |\n",
      "| policy_loss             | -227.6584   |\n",
      "| qf1_loss                | 29.545311   |\n",
      "| qf2_loss                | 36.73671    |\n",
      "| time_elapsed            | 3839        |\n",
      "| total timesteps         | 328103      |\n",
      "| value_loss              | 24.547993   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03334298 |\n",
      "| ent_coef_loss           | 5.9019065  |\n",
      "| entropy                 | 13.919022  |\n",
      "| episodes                | 2790       |\n",
      "| fps                     | 85         |\n",
      "| mean 100 episode reward | 1.37e+03   |\n",
      "| n_updates               | 330449     |\n",
      "| policy_loss             | -218.93591 |\n",
      "| qf1_loss                | 30.127491  |\n",
      "| qf2_loss                | 26.280111  |\n",
      "| time_elapsed            | 3873       |\n",
      "| total timesteps         | 330548     |\n",
      "| value_loss              | 22.197521  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.034523785 |\n",
      "| ent_coef_loss           | -4.0536857  |\n",
      "| entropy                 | 14.376237   |\n",
      "| episodes                | 2800        |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 1.34e+03    |\n",
      "| n_updates               | 332192      |\n",
      "| policy_loss             | -245.40897  |\n",
      "| qf1_loss                | 17.970995   |\n",
      "| qf2_loss                | 11.861379   |\n",
      "| time_elapsed            | 3895        |\n",
      "| total timesteps         | 332291      |\n",
      "| value_loss              | 36.458885   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03479983 |\n",
      "| ent_coef_loss           | -4.7279224 |\n",
      "| entropy                 | 14.335835  |\n",
      "| episodes                | 2810       |\n",
      "| fps                     | 85         |\n",
      "| mean 100 episode reward | 1.31e+03   |\n",
      "| n_updates               | 334870     |\n",
      "| policy_loss             | -213.58499 |\n",
      "| qf1_loss                | 34.661484  |\n",
      "| qf2_loss                | 20.744183  |\n",
      "| time_elapsed            | 3924       |\n",
      "| total timesteps         | 334969     |\n",
      "| value_loss              | 18.474987  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035209145 |\n",
      "| ent_coef_loss           | 4.1890206   |\n",
      "| entropy                 | 13.614674   |\n",
      "| episodes                | 2820        |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 1.32e+03    |\n",
      "| n_updates               | 337548      |\n",
      "| policy_loss             | -247.50044  |\n",
      "| qf1_loss                | 28.508299   |\n",
      "| qf2_loss                | 36.21926    |\n",
      "| time_elapsed            | 3952        |\n",
      "| total timesteps         | 337647      |\n",
      "| value_loss              | 24.89613    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.033804946 |\n",
      "| ent_coef_loss           | -4.6758747  |\n",
      "| entropy                 | 14.346809   |\n",
      "| episodes                | 2830        |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 1.34e+03    |\n",
      "| n_updates               | 340408      |\n",
      "| policy_loss             | -234.64548  |\n",
      "| qf1_loss                | 14.559048   |\n",
      "| qf2_loss                | 18.83892    |\n",
      "| time_elapsed            | 3982        |\n",
      "| total timesteps         | 340507      |\n",
      "| value_loss              | 15.494921   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.0359645  |\n",
      "| ent_coef_loss           | 4.170557   |\n",
      "| entropy                 | 14.245802  |\n",
      "| episodes                | 2840       |\n",
      "| fps                     | 85         |\n",
      "| mean 100 episode reward | 1.33e+03   |\n",
      "| n_updates               | 343035     |\n",
      "| policy_loss             | -271.62372 |\n",
      "| qf1_loss                | 22.113914  |\n",
      "| qf2_loss                | 33.202614  |\n",
      "| time_elapsed            | 4009       |\n",
      "| total timesteps         | 343134     |\n",
      "| value_loss              | 23.136925  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.034556594 |\n",
      "| ent_coef_loss           | -0.6875967  |\n",
      "| entropy                 | 14.108434   |\n",
      "| episodes                | 2850        |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 1.36e+03    |\n",
      "| n_updates               | 346486      |\n",
      "| policy_loss             | -225.6761   |\n",
      "| qf1_loss                | 19.449348   |\n",
      "| qf2_loss                | 18.701273   |\n",
      "| time_elapsed            | 4044        |\n",
      "| total timesteps         | 346585      |\n",
      "| value_loss              | 15.877823   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035687864 |\n",
      "| ent_coef_loss           | 8.318498    |\n",
      "| entropy                 | 13.253987   |\n",
      "| episodes                | 2860        |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 1.36e+03    |\n",
      "| n_updates               | 349085      |\n",
      "| policy_loss             | -272.80133  |\n",
      "| qf1_loss                | 27.232635   |\n",
      "| qf2_loss                | 23.936611   |\n",
      "| time_elapsed            | 4071        |\n",
      "| total timesteps         | 349184      |\n",
      "| value_loss              | 16.201168   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03544226 |\n",
      "| ent_coef_loss           | 2.3151364  |\n",
      "| entropy                 | 14.032547  |\n",
      "| episodes                | 2870       |\n",
      "| fps                     | 85         |\n",
      "| mean 100 episode reward | 1.32e+03   |\n",
      "| n_updates               | 351556     |\n",
      "| policy_loss             | -261.39484 |\n",
      "| qf1_loss                | 19.124615  |\n",
      "| qf2_loss                | 27.353382  |\n",
      "| time_elapsed            | 4097       |\n",
      "| total timesteps         | 351655     |\n",
      "| value_loss              | 11.358231  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.0356659  |\n",
      "| ent_coef_loss           | -1.3157396 |\n",
      "| entropy                 | 14.046041  |\n",
      "| episodes                | 2880       |\n",
      "| fps                     | 85         |\n",
      "| mean 100 episode reward | 1.34e+03   |\n",
      "| n_updates               | 354391     |\n",
      "| policy_loss             | -235.36436 |\n",
      "| qf1_loss                | 16.477362  |\n",
      "| qf2_loss                | 16.734568  |\n",
      "| time_elapsed            | 4126       |\n",
      "| total timesteps         | 354490     |\n",
      "| value_loss              | 12.674389  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.037399463 |\n",
      "| ent_coef_loss           | -15.9124    |\n",
      "| entropy                 | 15.190786   |\n",
      "| episodes                | 2890        |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 1.38e+03    |\n",
      "| n_updates               | 357462      |\n",
      "| policy_loss             | -240.8618   |\n",
      "| qf1_loss                | 21.4222     |\n",
      "| qf2_loss                | 22.727066   |\n",
      "| time_elapsed            | 4158        |\n",
      "| total timesteps         | 357561      |\n",
      "| value_loss              | 22.084003   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03527788 |\n",
      "| ent_coef_loss           | 4.313955   |\n",
      "| entropy                 | 14.219479  |\n",
      "| episodes                | 2900       |\n",
      "| fps                     | 86         |\n",
      "| mean 100 episode reward | 1.46e+03   |\n",
      "| n_updates               | 360880     |\n",
      "| policy_loss             | -244.93013 |\n",
      "| qf1_loss                | 26.793758  |\n",
      "| qf2_loss                | 22.710684  |\n",
      "| time_elapsed            | 4193       |\n",
      "| total timesteps         | 360979     |\n",
      "| value_loss              | 16.059952  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.034787558 |\n",
      "| ent_coef_loss           | -0.5971302  |\n",
      "| entropy                 | 13.902368   |\n",
      "| episodes                | 2910        |\n",
      "| fps                     | 86          |\n",
      "| mean 100 episode reward | 1.45e+03    |\n",
      "| n_updates               | 363330      |\n",
      "| policy_loss             | -278.96753  |\n",
      "| qf1_loss                | 18.385681   |\n",
      "| qf2_loss                | 19.23883    |\n",
      "| time_elapsed            | 4218        |\n",
      "| total timesteps         | 363429      |\n",
      "| value_loss              | 25.891155   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036203906 |\n",
      "| ent_coef_loss           | 2.1790977   |\n",
      "| entropy                 | 14.20002    |\n",
      "| episodes                | 2920        |\n",
      "| fps                     | 86          |\n",
      "| mean 100 episode reward | 1.47e+03    |\n",
      "| n_updates               | 366308      |\n",
      "| policy_loss             | -266.22943  |\n",
      "| qf1_loss                | 10.512178   |\n",
      "| qf2_loss                | 13.432165   |\n",
      "| time_elapsed            | 4249        |\n",
      "| total timesteps         | 366407      |\n",
      "| value_loss              | 19.23719    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036188725 |\n",
      "| ent_coef_loss           | -7.871543   |\n",
      "| entropy                 | 14.456811   |\n",
      "| episodes                | 2930        |\n",
      "| fps                     | 86          |\n",
      "| mean 100 episode reward | 1.45e+03    |\n",
      "| n_updates               | 368890      |\n",
      "| policy_loss             | -234.40787  |\n",
      "| qf1_loss                | 27.195326   |\n",
      "| qf2_loss                | 23.068588   |\n",
      "| time_elapsed            | 4276        |\n",
      "| total timesteps         | 368989      |\n",
      "| value_loss              | 11.444147   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035535645 |\n",
      "| ent_coef_loss           | 1.1345552   |\n",
      "| entropy                 | 14.014536   |\n",
      "| episodes                | 2940        |\n",
      "| fps                     | 86          |\n",
      "| mean 100 episode reward | 1.5e+03     |\n",
      "| n_updates               | 372489      |\n",
      "| policy_loss             | -262.8407   |\n",
      "| qf1_loss                | 24.209064   |\n",
      "| qf2_loss                | 21.318583   |\n",
      "| time_elapsed            | 4313        |\n",
      "| total timesteps         | 372588      |\n",
      "| value_loss              | 26.630486   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03546743 |\n",
      "| ent_coef_loss           | 2.1900826  |\n",
      "| entropy                 | 13.8145485 |\n",
      "| episodes                | 2950       |\n",
      "| fps                     | 86         |\n",
      "| mean 100 episode reward | 1.47e+03   |\n",
      "| n_updates               | 375130     |\n",
      "| policy_loss             | -266.07532 |\n",
      "| qf1_loss                | 38.165344  |\n",
      "| qf2_loss                | 31.82483   |\n",
      "| time_elapsed            | 4340       |\n",
      "| total timesteps         | 375229     |\n",
      "| value_loss              | 21.679955  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036591947 |\n",
      "| ent_coef_loss           | 4.2992673   |\n",
      "| entropy                 | 14.38721    |\n",
      "| episodes                | 2960        |\n",
      "| fps                     | 86          |\n",
      "| mean 100 episode reward | 1.45e+03    |\n",
      "| n_updates               | 377421      |\n",
      "| policy_loss             | -266.05396  |\n",
      "| qf1_loss                | 24.646019   |\n",
      "| qf2_loss                | 29.14925    |\n",
      "| time_elapsed            | 4364        |\n",
      "| total timesteps         | 377520      |\n",
      "| value_loss              | 15.000055   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035621412 |\n",
      "| ent_coef_loss           | 2.4118662   |\n",
      "| entropy                 | 13.872871   |\n",
      "| episodes                | 2970        |\n",
      "| fps                     | 86          |\n",
      "| mean 100 episode reward | 1.45e+03    |\n",
      "| n_updates               | 379890      |\n",
      "| policy_loss             | -249.63753  |\n",
      "| qf1_loss                | 46.289955   |\n",
      "| qf2_loss                | 38.49798    |\n",
      "| time_elapsed            | 4389        |\n",
      "| total timesteps         | 379989      |\n",
      "| value_loss              | 20.736452   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035701744 |\n",
      "| ent_coef_loss           | -11.830394  |\n",
      "| entropy                 | 14.526136   |\n",
      "| episodes                | 2980        |\n",
      "| fps                     | 86          |\n",
      "| mean 100 episode reward | 1.41e+03    |\n",
      "| n_updates               | 382057      |\n",
      "| policy_loss             | -266.3987   |\n",
      "| qf1_loss                | 21.178589   |\n",
      "| qf2_loss                | 28.248735   |\n",
      "| time_elapsed            | 4412        |\n",
      "| total timesteps         | 382156      |\n",
      "| value_loss              | 21.21868    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036817398 |\n",
      "| ent_coef_loss           | -2.8988767  |\n",
      "| entropy                 | 14.650793   |\n",
      "| episodes                | 2990        |\n",
      "| fps                     | 86          |\n",
      "| mean 100 episode reward | 1.45e+03    |\n",
      "| n_updates               | 385908      |\n",
      "| policy_loss             | -245.66144  |\n",
      "| qf1_loss                | 24.356163   |\n",
      "| qf2_loss                | 27.382185   |\n",
      "| time_elapsed            | 4451        |\n",
      "| total timesteps         | 386007      |\n",
      "| value_loss              | 21.146118   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03557991 |\n",
      "| ent_coef_loss           | 11.05124   |\n",
      "| entropy                 | 13.709602  |\n",
      "| episodes                | 3000       |\n",
      "| fps                     | 86         |\n",
      "| mean 100 episode reward | 1.42e+03   |\n",
      "| n_updates               | 388695     |\n",
      "| policy_loss             | -252.17758 |\n",
      "| qf1_loss                | 43.397682  |\n",
      "| qf2_loss                | 41.258636  |\n",
      "| time_elapsed            | 4480       |\n",
      "| total timesteps         | 388794     |\n",
      "| value_loss              | 39.501205  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035019908 |\n",
      "| ent_coef_loss           | -5.1553345  |\n",
      "| entropy                 | 13.97574    |\n",
      "| episodes                | 3010        |\n",
      "| fps                     | 86          |\n",
      "| mean 100 episode reward | 1.46e+03    |\n",
      "| n_updates               | 391903      |\n",
      "| policy_loss             | -279.3997   |\n",
      "| qf1_loss                | 16.622803   |\n",
      "| qf2_loss                | 18.859867   |\n",
      "| time_elapsed            | 4513        |\n",
      "| total timesteps         | 392002      |\n",
      "| value_loss              | 17.143492   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03516091 |\n",
      "| ent_coef_loss           | 4.1011167  |\n",
      "| entropy                 | 13.999865  |\n",
      "| episodes                | 3020       |\n",
      "| fps                     | 86         |\n",
      "| mean 100 episode reward | 1.45e+03   |\n",
      "| n_updates               | 394674     |\n",
      "| policy_loss             | -260.36853 |\n",
      "| qf1_loss                | 20.399239  |\n",
      "| qf2_loss                | 32.104214  |\n",
      "| time_elapsed            | 4541       |\n",
      "| total timesteps         | 394773     |\n",
      "| value_loss              | 31.492273  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036757685 |\n",
      "| ent_coef_loss           | -6.416581   |\n",
      "| entropy                 | 13.866131   |\n",
      "| episodes                | 3030        |\n",
      "| fps                     | 86          |\n",
      "| mean 100 episode reward | 1.47e+03    |\n",
      "| n_updates               | 397532      |\n",
      "| policy_loss             | -271.06213  |\n",
      "| qf1_loss                | 17.335743   |\n",
      "| qf2_loss                | 14.610231   |\n",
      "| time_elapsed            | 4571        |\n",
      "| total timesteps         | 397631      |\n",
      "| value_loss              | 13.245155   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.033969246 |\n",
      "| ent_coef_loss           | -2.0195885  |\n",
      "| entropy                 | 14.448246   |\n",
      "| episodes                | 3040        |\n",
      "| fps                     | 87          |\n",
      "| mean 100 episode reward | 1.44e+03    |\n",
      "| n_updates               | 400463      |\n",
      "| policy_loss             | -264.184    |\n",
      "| qf1_loss                | 14.678702   |\n",
      "| qf2_loss                | 17.2432     |\n",
      "| time_elapsed            | 4601        |\n",
      "| total timesteps         | 400562      |\n",
      "| value_loss              | 10.395016   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036458455 |\n",
      "| ent_coef_loss           | -0.7441914  |\n",
      "| entropy                 | 14.778381   |\n",
      "| episodes                | 3050        |\n",
      "| fps                     | 87          |\n",
      "| mean 100 episode reward | 1.51e+03    |\n",
      "| n_updates               | 404610      |\n",
      "| policy_loss             | -262.45834  |\n",
      "| qf1_loss                | 37.26213    |\n",
      "| qf2_loss                | 24.588411   |\n",
      "| time_elapsed            | 4643        |\n",
      "| total timesteps         | 404709      |\n",
      "| value_loss              | 22.679287   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03450198 |\n",
      "| ent_coef_loss           | 1.6437392  |\n",
      "| entropy                 | 13.888292  |\n",
      "| episodes                | 3060       |\n",
      "| fps                     | 87         |\n",
      "| mean 100 episode reward | 1.56e+03   |\n",
      "| n_updates               | 407864     |\n",
      "| policy_loss             | -240.77902 |\n",
      "| qf1_loss                | 25.487152  |\n",
      "| qf2_loss                | 28.80857   |\n",
      "| time_elapsed            | 4677       |\n",
      "| total timesteps         | 407963     |\n",
      "| value_loss              | 16.102144  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035842653 |\n",
      "| ent_coef_loss           | -13.896336  |\n",
      "| entropy                 | 14.401157   |\n",
      "| episodes                | 3070        |\n",
      "| fps                     | 87          |\n",
      "| mean 100 episode reward | 1.63e+03    |\n",
      "| n_updates               | 411640      |\n",
      "| policy_loss             | -267.6037   |\n",
      "| qf1_loss                | 30.665298   |\n",
      "| qf2_loss                | 22.124767   |\n",
      "| time_elapsed            | 4716        |\n",
      "| total timesteps         | 411739      |\n",
      "| value_loss              | 12.613925   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03697285 |\n",
      "| ent_coef_loss           | -4.5052214 |\n",
      "| entropy                 | 14.644793  |\n",
      "| episodes                | 3080       |\n",
      "| fps                     | 87         |\n",
      "| mean 100 episode reward | 1.69e+03   |\n",
      "| n_updates               | 414877     |\n",
      "| policy_loss             | -239.93    |\n",
      "| qf1_loss                | 24.728043  |\n",
      "| qf2_loss                | 23.252262  |\n",
      "| time_elapsed            | 4749       |\n",
      "| total timesteps         | 414976     |\n",
      "| value_loss              | 17.835152  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.037059188 |\n",
      "| ent_coef_loss           | 0.16613173  |\n",
      "| entropy                 | 14.280196   |\n",
      "| episodes                | 3090        |\n",
      "| fps                     | 87          |\n",
      "| mean 100 episode reward | 1.62e+03    |\n",
      "| n_updates               | 417362      |\n",
      "| policy_loss             | -274.7544   |\n",
      "| qf1_loss                | 24.873142   |\n",
      "| qf2_loss                | 28.246769   |\n",
      "| time_elapsed            | 4774        |\n",
      "| total timesteps         | 417461      |\n",
      "| value_loss              | 25.844715   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03626231 |\n",
      "| ent_coef_loss           | -2.0843368 |\n",
      "| entropy                 | 14.33119   |\n",
      "| episodes                | 3100       |\n",
      "| fps                     | 87         |\n",
      "| mean 100 episode reward | 1.64e+03   |\n",
      "| n_updates               | 420583     |\n",
      "| policy_loss             | -283.34845 |\n",
      "| qf1_loss                | 15.902502  |\n",
      "| qf2_loss                | 15.937313  |\n",
      "| time_elapsed            | 4808       |\n",
      "| total timesteps         | 420682     |\n",
      "| value_loss              | 12.873383  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.0364978  |\n",
      "| ent_coef_loss           | 0.7202244  |\n",
      "| entropy                 | 14.3160095 |\n",
      "| episodes                | 3110       |\n",
      "| fps                     | 87         |\n",
      "| mean 100 episode reward | 1.66e+03   |\n",
      "| n_updates               | 424255     |\n",
      "| policy_loss             | -282.98306 |\n",
      "| qf1_loss                | 27.047672  |\n",
      "| qf2_loss                | 20.782307  |\n",
      "| time_elapsed            | 4846       |\n",
      "| total timesteps         | 424354     |\n",
      "| value_loss              | 14.751756  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036959346 |\n",
      "| ent_coef_loss           | 2.1685243   |\n",
      "| entropy                 | 13.675584   |\n",
      "| episodes                | 3120        |\n",
      "| fps                     | 87          |\n",
      "| mean 100 episode reward | 1.64e+03    |\n",
      "| n_updates               | 426412      |\n",
      "| policy_loss             | -286.30136  |\n",
      "| qf1_loss                | 37.256756   |\n",
      "| qf2_loss                | 24.24198    |\n",
      "| time_elapsed            | 4867        |\n",
      "| total timesteps         | 426511      |\n",
      "| value_loss              | 17.485464   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035768785 |\n",
      "| ent_coef_loss           | 4.143008    |\n",
      "| entropy                 | 13.937021   |\n",
      "| episodes                | 3130        |\n",
      "| fps                     | 87          |\n",
      "| mean 100 episode reward | 1.69e+03    |\n",
      "| n_updates               | 430240      |\n",
      "| policy_loss             | -262.41327  |\n",
      "| qf1_loss                | 63.21901    |\n",
      "| qf2_loss                | 50.19799    |\n",
      "| time_elapsed            | 4907        |\n",
      "| total timesteps         | 430339      |\n",
      "| value_loss              | 43.217396   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03629561 |\n",
      "| ent_coef_loss           | 4.1929073  |\n",
      "| entropy                 | 14.20621   |\n",
      "| episodes                | 3140       |\n",
      "| fps                     | 87         |\n",
      "| mean 100 episode reward | 1.7e+03    |\n",
      "| n_updates               | 433405     |\n",
      "| policy_loss             | -269.48666 |\n",
      "| qf1_loss                | 32.38251   |\n",
      "| qf2_loss                | 35.36547   |\n",
      "| time_elapsed            | 4939       |\n",
      "| total timesteps         | 433504     |\n",
      "| value_loss              | 28.442936  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03659891 |\n",
      "| ent_coef_loss           | 3.5303354  |\n",
      "| entropy                 | 14.396297  |\n",
      "| episodes                | 3150       |\n",
      "| fps                     | 87         |\n",
      "| mean 100 episode reward | 1.65e+03   |\n",
      "| n_updates               | 436683     |\n",
      "| policy_loss             | -258.9734  |\n",
      "| qf1_loss                | 29.320137  |\n",
      "| qf2_loss                | 18.061218  |\n",
      "| time_elapsed            | 4973       |\n",
      "| total timesteps         | 436782     |\n",
      "| value_loss              | 15.152737  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036502752 |\n",
      "| ent_coef_loss           | 6.269856    |\n",
      "| entropy                 | 13.985421   |\n",
      "| episodes                | 3160        |\n",
      "| fps                     | 87          |\n",
      "| mean 100 episode reward | 1.67e+03    |\n",
      "| n_updates               | 440202      |\n",
      "| policy_loss             | -291.08835  |\n",
      "| qf1_loss                | 40.217354   |\n",
      "| qf2_loss                | 36.686966   |\n",
      "| time_elapsed            | 5009        |\n",
      "| total timesteps         | 440301      |\n",
      "| value_loss              | 19.504547   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036634047 |\n",
      "| ent_coef_loss           | -4.010417   |\n",
      "| entropy                 | 14.348999   |\n",
      "| episodes                | 3170        |\n",
      "| fps                     | 87          |\n",
      "| mean 100 episode reward | 1.61e+03    |\n",
      "| n_updates               | 442840      |\n",
      "| policy_loss             | -249.76491  |\n",
      "| qf1_loss                | 19.24148    |\n",
      "| qf2_loss                | 23.750559   |\n",
      "| time_elapsed            | 5036        |\n",
      "| total timesteps         | 442939      |\n",
      "| value_loss              | 17.29977    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035618287 |\n",
      "| ent_coef_loss           | 2.7916236   |\n",
      "| entropy                 | 14.32233    |\n",
      "| episodes                | 3180        |\n",
      "| fps                     | 88          |\n",
      "| mean 100 episode reward | 1.61e+03    |\n",
      "| n_updates               | 445966      |\n",
      "| policy_loss             | -266.41797  |\n",
      "| qf1_loss                | 29.68191    |\n",
      "| qf2_loss                | 29.956682   |\n",
      "| time_elapsed            | 5068        |\n",
      "| total timesteps         | 446065      |\n",
      "| value_loss              | 13.582044   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036730476 |\n",
      "| ent_coef_loss           | -0.59070086 |\n",
      "| entropy                 | 14.093685   |\n",
      "| episodes                | 3190        |\n",
      "| fps                     | 88          |\n",
      "| mean 100 episode reward | 1.61e+03    |\n",
      "| n_updates               | 448420      |\n",
      "| policy_loss             | -277.10123  |\n",
      "| qf1_loss                | 36.75096    |\n",
      "| qf2_loss                | 27.859465   |\n",
      "| time_elapsed            | 5093        |\n",
      "| total timesteps         | 448519      |\n",
      "| value_loss              | 31.603672   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035752844 |\n",
      "| ent_coef_loss           | 4.6272593   |\n",
      "| entropy                 | 14.015474   |\n",
      "| episodes                | 3200        |\n",
      "| fps                     | 88          |\n",
      "| mean 100 episode reward | 1.57e+03    |\n",
      "| n_updates               | 451013      |\n",
      "| policy_loss             | -257.2032   |\n",
      "| qf1_loss                | 28.820957   |\n",
      "| qf2_loss                | 30.104565   |\n",
      "| time_elapsed            | 5120        |\n",
      "| total timesteps         | 451112      |\n",
      "| value_loss              | 23.502928   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.03612297  |\n",
      "| ent_coef_loss           | -0.70642114 |\n",
      "| entropy                 | 13.933323   |\n",
      "| episodes                | 3210        |\n",
      "| fps                     | 88          |\n",
      "| mean 100 episode reward | 1.54e+03    |\n",
      "| n_updates               | 454000      |\n",
      "| policy_loss             | -288.7337   |\n",
      "| qf1_loss                | 31.402746   |\n",
      "| qf2_loss                | 39.623657   |\n",
      "| time_elapsed            | 5150        |\n",
      "| total timesteps         | 454099      |\n",
      "| value_loss              | 28.064095   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036087763 |\n",
      "| ent_coef_loss           | -2.4387102  |\n",
      "| entropy                 | 14.466444   |\n",
      "| episodes                | 3220        |\n",
      "| fps                     | 88          |\n",
      "| mean 100 episode reward | 1.61e+03    |\n",
      "| n_updates               | 457535      |\n",
      "| policy_loss             | -256.7561   |\n",
      "| qf1_loss                | 26.772812   |\n",
      "| qf2_loss                | 33.998222   |\n",
      "| time_elapsed            | 5187        |\n",
      "| total timesteps         | 457634      |\n",
      "| value_loss              | 21.037548   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035631962 |\n",
      "| ent_coef_loss           | -8.265778   |\n",
      "| entropy                 | 14.723995   |\n",
      "| episodes                | 3230        |\n",
      "| fps                     | 88          |\n",
      "| mean 100 episode reward | 1.59e+03    |\n",
      "| n_updates               | 461098      |\n",
      "| policy_loss             | -278.87183  |\n",
      "| qf1_loss                | 18.364628   |\n",
      "| qf2_loss                | 22.248426   |\n",
      "| time_elapsed            | 5224        |\n",
      "| total timesteps         | 461197      |\n",
      "| value_loss              | 9.309727    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03640184 |\n",
      "| ent_coef_loss           | 16.310787  |\n",
      "| entropy                 | 13.531922  |\n",
      "| episodes                | 3240       |\n",
      "| fps                     | 88         |\n",
      "| mean 100 episode reward | 1.58e+03   |\n",
      "| n_updates               | 463977     |\n",
      "| policy_loss             | -268.68542 |\n",
      "| qf1_loss                | 50.751724  |\n",
      "| qf2_loss                | 55.144867  |\n",
      "| time_elapsed            | 5254       |\n",
      "| total timesteps         | 464076     |\n",
      "| value_loss              | 26.344763  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03615773 |\n",
      "| ent_coef_loss           | -7.049009  |\n",
      "| entropy                 | 14.104278  |\n",
      "| episodes                | 3250       |\n",
      "| fps                     | 88         |\n",
      "| mean 100 episode reward | 1.58e+03   |\n",
      "| n_updates               | 467457     |\n",
      "| policy_loss             | -237.9208  |\n",
      "| qf1_loss                | 27.162855  |\n",
      "| qf2_loss                | 27.54255   |\n",
      "| time_elapsed            | 5290       |\n",
      "| total timesteps         | 467556     |\n",
      "| value_loss              | 22.72063   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.037483383 |\n",
      "| ent_coef_loss           | 1.0392596   |\n",
      "| entropy                 | 14.298502   |\n",
      "| episodes                | 3260        |\n",
      "| fps                     | 88          |\n",
      "| mean 100 episode reward | 1.62e+03    |\n",
      "| n_updates               | 471535      |\n",
      "| policy_loss             | -251.45934  |\n",
      "| qf1_loss                | 18.404839   |\n",
      "| qf2_loss                | 20.09607    |\n",
      "| time_elapsed            | 5332        |\n",
      "| total timesteps         | 471634      |\n",
      "| value_loss              | 21.696196   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035678267 |\n",
      "| ent_coef_loss           | 9.805456    |\n",
      "| entropy                 | 13.497698   |\n",
      "| episodes                | 3270        |\n",
      "| fps                     | 88          |\n",
      "| mean 100 episode reward | 1.62e+03    |\n",
      "| n_updates               | 474142      |\n",
      "| policy_loss             | -285.75345  |\n",
      "| qf1_loss                | 32.95546    |\n",
      "| qf2_loss                | 29.180332   |\n",
      "| time_elapsed            | 5359        |\n",
      "| total timesteps         | 474241      |\n",
      "| value_loss              | 29.411774   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03634601 |\n",
      "| ent_coef_loss           | -0.8967749 |\n",
      "| entropy                 | 14.137215  |\n",
      "| episodes                | 3280       |\n",
      "| fps                     | 88         |\n",
      "| mean 100 episode reward | 1.63e+03   |\n",
      "| n_updates               | 477553     |\n",
      "| policy_loss             | -286.98502 |\n",
      "| qf1_loss                | 23.982683  |\n",
      "| qf2_loss                | 17.069557  |\n",
      "| time_elapsed            | 5394       |\n",
      "| total timesteps         | 477652     |\n",
      "| value_loss              | 12.43185   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03569535 |\n",
      "| ent_coef_loss           | 0.18812072 |\n",
      "| entropy                 | 14.621686  |\n",
      "| episodes                | 3290       |\n",
      "| fps                     | 88         |\n",
      "| mean 100 episode reward | 1.65e+03   |\n",
      "| n_updates               | 480389     |\n",
      "| policy_loss             | -254.39264 |\n",
      "| qf1_loss                | 14.875053  |\n",
      "| qf2_loss                | 21.969162  |\n",
      "| time_elapsed            | 5423       |\n",
      "| total timesteps         | 480488     |\n",
      "| value_loss              | 21.524382  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036334947 |\n",
      "| ent_coef_loss           | -1.2164667  |\n",
      "| entropy                 | 14.690214   |\n",
      "| episodes                | 3300        |\n",
      "| fps                     | 88          |\n",
      "| mean 100 episode reward | 1.76e+03    |\n",
      "| n_updates               | 485029      |\n",
      "| policy_loss             | -273.37946  |\n",
      "| qf1_loss                | 14.060209   |\n",
      "| qf2_loss                | 16.444393   |\n",
      "| time_elapsed            | 5470        |\n",
      "| total timesteps         | 485128      |\n",
      "| value_loss              | 18.155079   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035903525 |\n",
      "| ent_coef_loss           | -2.1011937  |\n",
      "| entropy                 | 14.2814045  |\n",
      "| episodes                | 3310        |\n",
      "| fps                     | 88          |\n",
      "| mean 100 episode reward | 1.75e+03    |\n",
      "| n_updates               | 487735      |\n",
      "| policy_loss             | -303.90204  |\n",
      "| qf1_loss                | 26.616707   |\n",
      "| qf2_loss                | 19.623093   |\n",
      "| time_elapsed            | 5498        |\n",
      "| total timesteps         | 487834      |\n",
      "| value_loss              | 11.837278   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03693293 |\n",
      "| ent_coef_loss           | 0.24420476 |\n",
      "| entropy                 | 14.389158  |\n",
      "| episodes                | 3320       |\n",
      "| fps                     | 88         |\n",
      "| mean 100 episode reward | 1.76e+03   |\n",
      "| n_updates               | 491589     |\n",
      "| policy_loss             | -280.9631  |\n",
      "| qf1_loss                | 19.14418   |\n",
      "| qf2_loss                | 25.78307   |\n",
      "| time_elapsed            | 5538       |\n",
      "| total timesteps         | 491688     |\n",
      "| value_loss              | 18.504017  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036014576 |\n",
      "| ent_coef_loss           | 11.452261   |\n",
      "| entropy                 | 13.701049   |\n",
      "| episodes                | 3330        |\n",
      "| fps                     | 88          |\n",
      "| mean 100 episode reward | 1.71e+03    |\n",
      "| n_updates               | 494154      |\n",
      "| policy_loss             | -288.84607  |\n",
      "| qf1_loss                | 17.870056   |\n",
      "| qf2_loss                | 16.353445   |\n",
      "| time_elapsed            | 5565        |\n",
      "| total timesteps         | 494253      |\n",
      "| value_loss              | 22.60719    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03520015 |\n",
      "| ent_coef_loss           | -3.8023877 |\n",
      "| entropy                 | 14.444155  |\n",
      "| episodes                | 3340       |\n",
      "| fps                     | 88         |\n",
      "| mean 100 episode reward | 1.7e+03    |\n",
      "| n_updates               | 496964     |\n",
      "| policy_loss             | -277.25958 |\n",
      "| qf1_loss                | 22.517666  |\n",
      "| qf2_loss                | 27.904491  |\n",
      "| time_elapsed            | 5594       |\n",
      "| total timesteps         | 497063     |\n",
      "| value_loss              | 15.630865  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03712339 |\n",
      "| ent_coef_loss           | 8.669659   |\n",
      "| entropy                 | 14.063671  |\n",
      "| episodes                | 3350       |\n",
      "| fps                     | 88         |\n",
      "| mean 100 episode reward | 1.66e+03   |\n",
      "| n_updates               | 499506     |\n",
      "| policy_loss             | -288.43054 |\n",
      "| qf1_loss                | 26.99427   |\n",
      "| qf2_loss                | 30.992546  |\n",
      "| time_elapsed            | 5619       |\n",
      "| total timesteps         | 499605     |\n",
      "| value_loss              | 20.339994  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036286052 |\n",
      "| ent_coef_loss           | 2.5525692   |\n",
      "| entropy                 | 14.09613    |\n",
      "| episodes                | 3360        |\n",
      "| fps                     | 88          |\n",
      "| mean 100 episode reward | 1.72e+03    |\n",
      "| n_updates               | 504929      |\n",
      "| policy_loss             | -277.43646  |\n",
      "| qf1_loss                | 14.953323   |\n",
      "| qf2_loss                | 23.900517   |\n",
      "| time_elapsed            | 5675        |\n",
      "| total timesteps         | 505028      |\n",
      "| value_loss              | 13.822123   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.037801675 |\n",
      "| ent_coef_loss           | 17.157598   |\n",
      "| entropy                 | 13.440931   |\n",
      "| episodes                | 3370        |\n",
      "| fps                     | 89          |\n",
      "| mean 100 episode reward | 1.75e+03    |\n",
      "| n_updates               | 508012      |\n",
      "| policy_loss             | -257.8103   |\n",
      "| qf1_loss                | 32.635765   |\n",
      "| qf2_loss                | 36.326973   |\n",
      "| time_elapsed            | 5707        |\n",
      "| total timesteps         | 508111      |\n",
      "| value_loss              | 35.25757    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.037358325 |\n",
      "| ent_coef_loss           | 4.706766    |\n",
      "| entropy                 | 14.049862   |\n",
      "| episodes                | 3380        |\n",
      "| fps                     | 89          |\n",
      "| mean 100 episode reward | 1.72e+03    |\n",
      "| n_updates               | 510857      |\n",
      "| policy_loss             | -260.57605  |\n",
      "| qf1_loss                | 14.948355   |\n",
      "| qf2_loss                | 19.086346   |\n",
      "| time_elapsed            | 5736        |\n",
      "| total timesteps         | 510956      |\n",
      "| value_loss              | 17.57586    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036740165 |\n",
      "| ent_coef_loss           | 10.811926   |\n",
      "| entropy                 | 13.900652   |\n",
      "| episodes                | 3390        |\n",
      "| fps                     | 89          |\n",
      "| mean 100 episode reward | 1.72e+03    |\n",
      "| n_updates               | 513698      |\n",
      "| policy_loss             | -272.53268  |\n",
      "| qf1_loss                | 46.048904   |\n",
      "| qf2_loss                | 25.930641   |\n",
      "| time_elapsed            | 5767        |\n",
      "| total timesteps         | 513797      |\n",
      "| value_loss              | 20.413235   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03798117 |\n",
      "| ent_coef_loss           | -1.7176542 |\n",
      "| entropy                 | 14.184507  |\n",
      "| episodes                | 3400       |\n",
      "| fps                     | 89         |\n",
      "| mean 100 episode reward | 1.64e+03   |\n",
      "| n_updates               | 516691     |\n",
      "| policy_loss             | -266.2097  |\n",
      "| qf1_loss                | 22.163353  |\n",
      "| qf2_loss                | 35.998802  |\n",
      "| time_elapsed            | 5800       |\n",
      "| total timesteps         | 516790     |\n",
      "| value_loss              | 17.977825  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.038064975 |\n",
      "| ent_coef_loss           | 4.672869    |\n",
      "| entropy                 | 13.758293   |\n",
      "| episodes                | 3410        |\n",
      "| fps                     | 89          |\n",
      "| mean 100 episode reward | 1.65e+03    |\n",
      "| n_updates               | 519632      |\n",
      "| policy_loss             | -280.14648  |\n",
      "| qf1_loss                | 31.821291   |\n",
      "| qf2_loss                | 34.824135   |\n",
      "| time_elapsed            | 5832        |\n",
      "| total timesteps         | 519731      |\n",
      "| value_loss              | 20.629917   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03782354 |\n",
      "| ent_coef_loss           | 4.406988   |\n",
      "| entropy                 | 14.118959  |\n",
      "| episodes                | 3420       |\n",
      "| fps                     | 89         |\n",
      "| mean 100 episode reward | 1.64e+03   |\n",
      "| n_updates               | 523164     |\n",
      "| policy_loss             | -253.78455 |\n",
      "| qf1_loss                | 51.065258  |\n",
      "| qf2_loss                | 45.176662  |\n",
      "| time_elapsed            | 5870       |\n",
      "| total timesteps         | 523263     |\n",
      "| value_loss              | 18.28723   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03616186 |\n",
      "| ent_coef_loss           | 3.287141   |\n",
      "| entropy                 | 13.662535  |\n",
      "| episodes                | 3430       |\n",
      "| fps                     | 89         |\n",
      "| mean 100 episode reward | 1.68e+03   |\n",
      "| n_updates               | 526549     |\n",
      "| policy_loss             | -299.02612 |\n",
      "| qf1_loss                | 28.449562  |\n",
      "| qf2_loss                | 24.228495  |\n",
      "| time_elapsed            | 5908       |\n",
      "| total timesteps         | 526648     |\n",
      "| value_loss              | 14.478835  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035840612 |\n",
      "| ent_coef_loss           | 2.049385    |\n",
      "| entropy                 | 14.226403   |\n",
      "| episodes                | 3440        |\n",
      "| fps                     | 89          |\n",
      "| mean 100 episode reward | 1.66e+03    |\n",
      "| n_updates               | 528948      |\n",
      "| policy_loss             | -291.4486   |\n",
      "| qf1_loss                | 33.57301    |\n",
      "| qf2_loss                | 32.78794    |\n",
      "| time_elapsed            | 5936        |\n",
      "| total timesteps         | 529047      |\n",
      "| value_loss              | 19.197077   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03668676 |\n",
      "| ent_coef_loss           | 2.448213   |\n",
      "| entropy                 | 14.3508    |\n",
      "| episodes                | 3450       |\n",
      "| fps                     | 89         |\n",
      "| mean 100 episode reward | 1.71e+03   |\n",
      "| n_updates               | 532347     |\n",
      "| policy_loss             | -256.9474  |\n",
      "| qf1_loss                | 60.68061   |\n",
      "| qf2_loss                | 67.770584  |\n",
      "| time_elapsed            | 5974       |\n",
      "| total timesteps         | 532446     |\n",
      "| value_loss              | 14.698427  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.038639456 |\n",
      "| ent_coef_loss           | -4.7123957  |\n",
      "| entropy                 | 14.267347   |\n",
      "| episodes                | 3460        |\n",
      "| fps                     | 89          |\n",
      "| mean 100 episode reward | 1.61e+03    |\n",
      "| n_updates               | 535718      |\n",
      "| policy_loss             | -275.9572   |\n",
      "| qf1_loss                | 44.647354   |\n",
      "| qf2_loss                | 45.411728   |\n",
      "| time_elapsed            | 6009        |\n",
      "| total timesteps         | 535817      |\n",
      "| value_loss              | 22.821516   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.039359167 |\n",
      "| ent_coef_loss           | -18.72236   |\n",
      "| entropy                 | 14.998098   |\n",
      "| episodes                | 3470        |\n",
      "| fps                     | 89          |\n",
      "| mean 100 episode reward | 1.63e+03    |\n",
      "| n_updates               | 539295      |\n",
      "| policy_loss             | -269.7289   |\n",
      "| qf1_loss                | 25.49629    |\n",
      "| qf2_loss                | 24.445744   |\n",
      "| time_elapsed            | 6046        |\n",
      "| total timesteps         | 539394      |\n",
      "| value_loss              | 17.722755   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.037487894 |\n",
      "| ent_coef_loss           | -8.854601   |\n",
      "| entropy                 | 13.86476    |\n",
      "| episodes                | 3480        |\n",
      "| fps                     | 89          |\n",
      "| mean 100 episode reward | 1.64e+03    |\n",
      "| n_updates               | 542435      |\n",
      "| policy_loss             | -302.36456  |\n",
      "| qf1_loss                | 26.560936   |\n",
      "| qf2_loss                | 28.441517   |\n",
      "| time_elapsed            | 6078        |\n",
      "| total timesteps         | 542534      |\n",
      "| value_loss              | 24.290195   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.038279984 |\n",
      "| ent_coef_loss           | -8.162748   |\n",
      "| entropy                 | 14.329224   |\n",
      "| episodes                | 3490        |\n",
      "| fps                     | 89          |\n",
      "| mean 100 episode reward | 1.67e+03    |\n",
      "| n_updates               | 545744      |\n",
      "| policy_loss             | -281.8244   |\n",
      "| qf1_loss                | 18.83617    |\n",
      "| qf2_loss                | 17.360226   |\n",
      "| time_elapsed            | 6115        |\n",
      "| total timesteps         | 545843      |\n",
      "| value_loss              | 13.279575   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03797595 |\n",
      "| ent_coef_loss           | 1.5742347  |\n",
      "| entropy                 | 13.9104595 |\n",
      "| episodes                | 3500       |\n",
      "| fps                     | 89         |\n",
      "| mean 100 episode reward | 1.77e+03   |\n",
      "| n_updates               | 550800     |\n",
      "| policy_loss             | -299.26215 |\n",
      "| qf1_loss                | 50.424065  |\n",
      "| qf2_loss                | 36.567963  |\n",
      "| time_elapsed            | 6168       |\n",
      "| total timesteps         | 550899     |\n",
      "| value_loss              | 25.662146  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03733462 |\n",
      "| ent_coef_loss           | 8.043416   |\n",
      "| entropy                 | 14.246227  |\n",
      "| episodes                | 3510       |\n",
      "| fps                     | 89         |\n",
      "| mean 100 episode reward | 1.8e+03    |\n",
      "| n_updates               | 554114     |\n",
      "| policy_loss             | -266.0774  |\n",
      "| qf1_loss                | 24.444016  |\n",
      "| qf2_loss                | 29.060532  |\n",
      "| time_elapsed            | 6204       |\n",
      "| total timesteps         | 554213     |\n",
      "| value_loss              | 29.461397  |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036207758 |\n",
      "| ent_coef_loss           | -4.8840065  |\n",
      "| entropy                 | 14.272851   |\n",
      "| episodes                | 3520        |\n",
      "| fps                     | 89          |\n",
      "| mean 100 episode reward | 1.76e+03    |\n",
      "| n_updates               | 556902      |\n",
      "| policy_loss             | -278.7376   |\n",
      "| qf1_loss                | 23.210829   |\n",
      "| qf2_loss                | 24.893444   |\n",
      "| time_elapsed            | 6234        |\n",
      "| total timesteps         | 557001      |\n",
      "| value_loss              | 20.583055   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03762919 |\n",
      "| ent_coef_loss           | 9.801144   |\n",
      "| entropy                 | 13.823221  |\n",
      "| episodes                | 3530       |\n",
      "| fps                     | 89         |\n",
      "| mean 100 episode reward | 1.81e+03   |\n",
      "| n_updates               | 561210     |\n",
      "| policy_loss             | -261.12762 |\n",
      "| qf1_loss                | 25.795776  |\n",
      "| qf2_loss                | 21.745174  |\n",
      "| time_elapsed            | 6290       |\n",
      "| total timesteps         | 561309     |\n",
      "| value_loss              | 26.582214  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035433836 |\n",
      "| ent_coef_loss           | 6.1709166   |\n",
      "| entropy                 | 13.672492   |\n",
      "| episodes                | 3540        |\n",
      "| fps                     | 89          |\n",
      "| mean 100 episode reward | 1.82e+03    |\n",
      "| n_updates               | 563811      |\n",
      "| policy_loss             | -286.35568  |\n",
      "| qf1_loss                | 24.448502   |\n",
      "| qf2_loss                | 11.6170635  |\n",
      "| time_elapsed            | 6322        |\n",
      "| total timesteps         | 563910      |\n",
      "| value_loss              | 10.743255   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.037859302 |\n",
      "| ent_coef_loss           | 0.060370445 |\n",
      "| entropy                 | 14.119455   |\n",
      "| episodes                | 3550        |\n",
      "| fps                     | 89          |\n",
      "| mean 100 episode reward | 1.82e+03    |\n",
      "| n_updates               | 567120      |\n",
      "| policy_loss             | -293.65747  |\n",
      "| qf1_loss                | 18.40963    |\n",
      "| qf2_loss                | 34.150837   |\n",
      "| time_elapsed            | 6363        |\n",
      "| total timesteps         | 567219      |\n",
      "| value_loss              | 12.7762985  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036291882 |\n",
      "| ent_coef_loss           | -3.3447018  |\n",
      "| entropy                 | 14.489204   |\n",
      "| episodes                | 3560        |\n",
      "| fps                     | 89          |\n",
      "| mean 100 episode reward | 1.89e+03    |\n",
      "| n_updates               | 571855      |\n",
      "| policy_loss             | -263.62784  |\n",
      "| qf1_loss                | 20.565323   |\n",
      "| qf2_loss                | 12.911829   |\n",
      "| time_elapsed            | 6421        |\n",
      "| total timesteps         | 571954      |\n",
      "| value_loss              | 18.350136   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03732009 |\n",
      "| ent_coef_loss           | 6.599284   |\n",
      "| entropy                 | 13.549844  |\n",
      "| episodes                | 3570       |\n",
      "| fps                     | 88         |\n",
      "| mean 100 episode reward | 1.99e+03   |\n",
      "| n_updates               | 577244     |\n",
      "| policy_loss             | -295.6412  |\n",
      "| qf1_loss                | 38.867172  |\n",
      "| qf2_loss                | 34.96514   |\n",
      "| time_elapsed            | 6487       |\n",
      "| total timesteps         | 577343     |\n",
      "| value_loss              | 12.665121  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.039269052 |\n",
      "| ent_coef_loss           | -10.454092  |\n",
      "| entropy                 | 14.1930065  |\n",
      "| episodes                | 3580        |\n",
      "| fps                     | 88          |\n",
      "| mean 100 episode reward | 2.03e+03    |\n",
      "| n_updates               | 581188      |\n",
      "| policy_loss             | -322.7318   |\n",
      "| qf1_loss                | 19.668808   |\n",
      "| qf2_loss                | 18.263197   |\n",
      "| time_elapsed            | 6535        |\n",
      "| total timesteps         | 581287      |\n",
      "| value_loss              | 9.421879    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03712047 |\n",
      "| ent_coef_loss           | -2.084992  |\n",
      "| entropy                 | 14.147861  |\n",
      "| episodes                | 3590       |\n",
      "| fps                     | 88         |\n",
      "| mean 100 episode reward | 2.06e+03   |\n",
      "| n_updates               | 585145     |\n",
      "| policy_loss             | -297.63208 |\n",
      "| qf1_loss                | 30.605272  |\n",
      "| qf2_loss                | 24.286903  |\n",
      "| time_elapsed            | 6584       |\n",
      "| total timesteps         | 585244     |\n",
      "| value_loss              | 26.949387  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03743742 |\n",
      "| ent_coef_loss           | 11.597352  |\n",
      "| entropy                 | 13.995575  |\n",
      "| episodes                | 3600       |\n",
      "| fps                     | 88         |\n",
      "| mean 100 episode reward | 1.97e+03   |\n",
      "| n_updates               | 588253     |\n",
      "| policy_loss             | -273.4671  |\n",
      "| qf1_loss                | 33.287163  |\n",
      "| qf2_loss                | 34.52317   |\n",
      "| time_elapsed            | 6623       |\n",
      "| total timesteps         | 588352     |\n",
      "| value_loss              | 39.97649   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03672674 |\n",
      "| ent_coef_loss           | 2.9514475  |\n",
      "| entropy                 | 14.433139  |\n",
      "| episodes                | 3610       |\n",
      "| fps                     | 88         |\n",
      "| mean 100 episode reward | 1.98e+03   |\n",
      "| n_updates               | 591899     |\n",
      "| policy_loss             | -275.8884  |\n",
      "| qf1_loss                | 26.823431  |\n",
      "| qf2_loss                | 33.209835  |\n",
      "| time_elapsed            | 6667       |\n",
      "| total timesteps         | 591998     |\n",
      "| value_loss              | 14.449371  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.0373461  |\n",
      "| ent_coef_loss           | -7.277728  |\n",
      "| entropy                 | 14.854822  |\n",
      "| episodes                | 3620       |\n",
      "| fps                     | 88         |\n",
      "| mean 100 episode reward | 2.07e+03   |\n",
      "| n_updates               | 596404     |\n",
      "| policy_loss             | -314.13635 |\n",
      "| qf1_loss                | 18.160215  |\n",
      "| qf2_loss                | 18.042831  |\n",
      "| time_elapsed            | 6742       |\n",
      "| total timesteps         | 596503     |\n",
      "| value_loss              | 5.614299   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03760295 |\n",
      "| ent_coef_loss           | -1.802835  |\n",
      "| entropy                 | 14.295328  |\n",
      "| episodes                | 3630       |\n",
      "| fps                     | 88         |\n",
      "| mean 100 episode reward | 2.1e+03    |\n",
      "| n_updates               | 601177     |\n",
      "| policy_loss             | -296.2132  |\n",
      "| qf1_loss                | 23.848312  |\n",
      "| qf2_loss                | 34.023544  |\n",
      "| time_elapsed            | 6820       |\n",
      "| total timesteps         | 601276     |\n",
      "| value_loss              | 10.564877  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.038609866 |\n",
      "| ent_coef_loss           | -8.241882   |\n",
      "| entropy                 | 15.1482525  |\n",
      "| episodes                | 3640        |\n",
      "| fps                     | 88          |\n",
      "| mean 100 episode reward | 2.18e+03    |\n",
      "| n_updates               | 605406      |\n",
      "| policy_loss             | -257.07916  |\n",
      "| qf1_loss                | 22.820803   |\n",
      "| qf2_loss                | 26.434948   |\n",
      "| time_elapsed            | 6878        |\n",
      "| total timesteps         | 605505      |\n",
      "| value_loss              | 14.2429085  |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.037362065 |\n",
      "| ent_coef_loss           | 8.284481    |\n",
      "| entropy                 | 14.298344   |\n",
      "| episodes                | 3650        |\n",
      "| fps                     | 87          |\n",
      "| mean 100 episode reward | 2.31e+03    |\n",
      "| n_updates               | 611025      |\n",
      "| policy_loss             | -271.28485  |\n",
      "| qf1_loss                | 48.680904   |\n",
      "| qf2_loss                | 33.29479    |\n",
      "| time_elapsed            | 6952        |\n",
      "| total timesteps         | 611124      |\n",
      "| value_loss              | 25.339237   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036210943 |\n",
      "| ent_coef_loss           | 1.5827245   |\n",
      "| entropy                 | 13.685816   |\n",
      "| episodes                | 3660        |\n",
      "| fps                     | 87          |\n",
      "| mean 100 episode reward | 2.28e+03    |\n",
      "| n_updates               | 615216      |\n",
      "| policy_loss             | -285.7924   |\n",
      "| qf1_loss                | 29.174202   |\n",
      "| qf2_loss                | 24.658691   |\n",
      "| time_elapsed            | 7004        |\n",
      "| total timesteps         | 615315      |\n",
      "| value_loss              | 20.04131    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03644973 |\n",
      "| ent_coef_loss           | -1.2811264 |\n",
      "| entropy                 | 14.200801  |\n",
      "| episodes                | 3670       |\n",
      "| fps                     | 87         |\n",
      "| mean 100 episode reward | 2.24e+03   |\n",
      "| n_updates               | 619816     |\n",
      "| policy_loss             | -278.35535 |\n",
      "| qf1_loss                | 31.631298  |\n",
      "| qf2_loss                | 33.971455  |\n",
      "| time_elapsed            | 7060       |\n",
      "| total timesteps         | 619915     |\n",
      "| value_loss              | 34.88241   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03770013 |\n",
      "| ent_coef_loss           | 2.231055   |\n",
      "| entropy                 | 13.280018  |\n",
      "| episodes                | 3680       |\n",
      "| fps                     | 87         |\n",
      "| mean 100 episode reward | 2.29e+03   |\n",
      "| n_updates               | 624702     |\n",
      "| policy_loss             | -319.51773 |\n",
      "| qf1_loss                | 32.525345  |\n",
      "| qf2_loss                | 15.423413  |\n",
      "| time_elapsed            | 7117       |\n",
      "| total timesteps         | 624801     |\n",
      "| value_loss              | 22.348639  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.037336126 |\n",
      "| ent_coef_loss           | -8.843679   |\n",
      "| entropy                 | 14.899838   |\n",
      "| episodes                | 3690        |\n",
      "| fps                     | 87          |\n",
      "| mean 100 episode reward | 2.31e+03    |\n",
      "| n_updates               | 629052      |\n",
      "| policy_loss             | -316.7096   |\n",
      "| qf1_loss                | 19.671555   |\n",
      "| qf2_loss                | 18.145908   |\n",
      "| time_elapsed            | 7173        |\n",
      "| total timesteps         | 629151      |\n",
      "| value_loss              | 18.00035    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03784167 |\n",
      "| ent_coef_loss           | 1.2253237  |\n",
      "| entropy                 | 14.223976  |\n",
      "| episodes                | 3700       |\n",
      "| fps                     | 87         |\n",
      "| mean 100 episode reward | 2.37e+03   |\n",
      "| n_updates               | 633412     |\n",
      "| policy_loss             | -276.03284 |\n",
      "| qf1_loss                | 29.551838  |\n",
      "| qf2_loss                | 31.866371  |\n",
      "| time_elapsed            | 7234       |\n",
      "| total timesteps         | 633511     |\n",
      "| value_loss              | 11.862334  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.038100492 |\n",
      "| ent_coef_loss           | 2.048367    |\n",
      "| entropy                 | 15.032872   |\n",
      "| episodes                | 3710        |\n",
      "| fps                     | 87          |\n",
      "| mean 100 episode reward | 2.35e+03    |\n",
      "| n_updates               | 636524      |\n",
      "| policy_loss             | -280.8386   |\n",
      "| qf1_loss                | 28.185879   |\n",
      "| qf2_loss                | 34.37014    |\n",
      "| time_elapsed            | 7272        |\n",
      "| total timesteps         | 636623      |\n",
      "| value_loss              | 17.072426   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03706957 |\n",
      "| ent_coef_loss           | -10.749901 |\n",
      "| entropy                 | 14.394156  |\n",
      "| episodes                | 3720       |\n",
      "| fps                     | 87         |\n",
      "| mean 100 episode reward | 2.41e+03   |\n",
      "| n_updates               | 642213     |\n",
      "| policy_loss             | -296.5526  |\n",
      "| qf1_loss                | 21.19337   |\n",
      "| qf2_loss                | 22.358788  |\n",
      "| time_elapsed            | 7343       |\n",
      "| total timesteps         | 642312     |\n",
      "| value_loss              | 31.517042  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03749737 |\n",
      "| ent_coef_loss           | -8.343317  |\n",
      "| entropy                 | 14.793886  |\n",
      "| episodes                | 3730       |\n",
      "| fps                     | 87         |\n",
      "| mean 100 episode reward | 2.47e+03   |\n",
      "| n_updates               | 648173     |\n",
      "| policy_loss             | -310.8169  |\n",
      "| qf1_loss                | 16.837372  |\n",
      "| qf2_loss                | 20.79445   |\n",
      "| time_elapsed            | 7413       |\n",
      "| total timesteps         | 648272     |\n",
      "| value_loss              | 19.609964  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03661575 |\n",
      "| ent_coef_loss           | -3.0472689 |\n",
      "| entropy                 | 14.709182  |\n",
      "| episodes                | 3740       |\n",
      "| fps                     | 87         |\n",
      "| mean 100 episode reward | 2.47e+03   |\n",
      "| n_updates               | 652299     |\n",
      "| policy_loss             | -314.27734 |\n",
      "| qf1_loss                | 25.504204  |\n",
      "| qf2_loss                | 28.222939  |\n",
      "| time_elapsed            | 7466       |\n",
      "| total timesteps         | 652398     |\n",
      "| value_loss              | 36.589516  |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| current_lr              | 0.0003       |\n",
      "| ent_coef                | 0.03743046   |\n",
      "| ent_coef_loss           | -0.045946836 |\n",
      "| entropy                 | 14.09864     |\n",
      "| episodes                | 3750         |\n",
      "| fps                     | 87           |\n",
      "| mean 100 episode reward | 2.43e+03     |\n",
      "| n_updates               | 657239       |\n",
      "| policy_loss             | -298.74896   |\n",
      "| qf1_loss                | 15.740737    |\n",
      "| qf2_loss                | 20.654057    |\n",
      "| time_elapsed            | 7534         |\n",
      "| total timesteps         | 657338       |\n",
      "| value_loss              | 10.604107    |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.03946195  |\n",
      "| ent_coef_loss           | -0.20291066 |\n",
      "| entropy                 | 14.051177   |\n",
      "| episodes                | 3760        |\n",
      "| fps                     | 87          |\n",
      "| mean 100 episode reward | 2.45e+03    |\n",
      "| n_updates               | 661728      |\n",
      "| policy_loss             | -308.8475   |\n",
      "| qf1_loss                | 19.870317   |\n",
      "| qf2_loss                | 24.120811   |\n",
      "| time_elapsed            | 7593        |\n",
      "| total timesteps         | 661827      |\n",
      "| value_loss              | 17.994432   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.038462255 |\n",
      "| ent_coef_loss           | 0.13686919  |\n",
      "| entropy                 | 14.375844   |\n",
      "| episodes                | 3770        |\n",
      "| fps                     | 87          |\n",
      "| mean 100 episode reward | 2.5e+03     |\n",
      "| n_updates               | 667117      |\n",
      "| policy_loss             | -314.39624  |\n",
      "| qf1_loss                | 30.681213   |\n",
      "| qf2_loss                | 37.876614   |\n",
      "| time_elapsed            | 7664        |\n",
      "| total timesteps         | 667216      |\n",
      "| value_loss              | 23.392288   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.038632784 |\n",
      "| ent_coef_loss           | -1.827709   |\n",
      "| entropy                 | 14.673859   |\n",
      "| episodes                | 3780        |\n",
      "| fps                     | 86          |\n",
      "| mean 100 episode reward | 2.59e+03    |\n",
      "| n_updates               | 673564      |\n",
      "| policy_loss             | -286.11237  |\n",
      "| qf1_loss                | 29.005793   |\n",
      "| qf2_loss                | 16.245358   |\n",
      "| time_elapsed            | 7745        |\n",
      "| total timesteps         | 673663      |\n",
      "| value_loss              | 17.398264   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.0383379  |\n",
      "| ent_coef_loss           | -3.291133  |\n",
      "| entropy                 | 14.480913  |\n",
      "| episodes                | 3790       |\n",
      "| fps                     | 86         |\n",
      "| mean 100 episode reward | 2.67e+03   |\n",
      "| n_updates               | 679436     |\n",
      "| policy_loss             | -318.66202 |\n",
      "| qf1_loss                | 29.22526   |\n",
      "| qf2_loss                | 28.242807  |\n",
      "| time_elapsed            | 7820       |\n",
      "| total timesteps         | 679535     |\n",
      "| value_loss              | 20.069729  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03824025 |\n",
      "| ent_coef_loss           | 5.41446    |\n",
      "| entropy                 | 14.118678  |\n",
      "| episodes                | 3800       |\n",
      "| fps                     | 86         |\n",
      "| mean 100 episode reward | 2.77e+03   |\n",
      "| n_updates               | 685619     |\n",
      "| policy_loss             | -325.44647 |\n",
      "| qf1_loss                | 43.60328   |\n",
      "| qf2_loss                | 42.534805  |\n",
      "| time_elapsed            | 7899       |\n",
      "| total timesteps         | 685718     |\n",
      "| value_loss              | 26.27659   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036564738 |\n",
      "| ent_coef_loss           | -2.574391   |\n",
      "| entropy                 | 13.7508545  |\n",
      "| episodes                | 3810        |\n",
      "| fps                     | 86          |\n",
      "| mean 100 episode reward | 2.75e+03    |\n",
      "| n_updates               | 688261      |\n",
      "| policy_loss             | -300.9122   |\n",
      "| qf1_loss                | 30.539274   |\n",
      "| qf2_loss                | 22.240059   |\n",
      "| time_elapsed            | 7934        |\n",
      "| total timesteps         | 688360      |\n",
      "| value_loss              | 11.758034   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03719203 |\n",
      "| ent_coef_loss           | 4.8738346  |\n",
      "| entropy                 | 14.293314  |\n",
      "| episodes                | 3820       |\n",
      "| fps                     | 86         |\n",
      "| mean 100 episode reward | 2.72e+03   |\n",
      "| n_updates               | 693551     |\n",
      "| policy_loss             | -313.56815 |\n",
      "| qf1_loss                | 21.854458  |\n",
      "| qf2_loss                | 23.04597   |\n",
      "| time_elapsed            | 7995       |\n",
      "| total timesteps         | 693650     |\n",
      "| value_loss              | 13.809688  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03741283 |\n",
      "| ent_coef_loss           | 8.103493   |\n",
      "| entropy                 | 14.2149725 |\n",
      "| episodes                | 3830       |\n",
      "| fps                     | 86         |\n",
      "| mean 100 episode reward | 2.62e+03   |\n",
      "| n_updates               | 697673     |\n",
      "| policy_loss             | -348.15997 |\n",
      "| qf1_loss                | 30.508488  |\n",
      "| qf2_loss                | 27.922812  |\n",
      "| time_elapsed            | 8057       |\n",
      "| total timesteps         | 697772     |\n",
      "| value_loss              | 31.348644  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03679997 |\n",
      "| ent_coef_loss           | 1.8479757  |\n",
      "| entropy                 | 14.013671  |\n",
      "| episodes                | 3840       |\n",
      "| fps                     | 86         |\n",
      "| mean 100 episode reward | 2.69e+03   |\n",
      "| n_updates               | 703083     |\n",
      "| policy_loss             | -259.72705 |\n",
      "| qf1_loss                | 30.603804  |\n",
      "| qf2_loss                | 22.126795  |\n",
      "| time_elapsed            | 8132       |\n",
      "| total timesteps         | 703182     |\n",
      "| value_loss              | 35.63307   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.037142865 |\n",
      "| ent_coef_loss           | -3.1250398  |\n",
      "| entropy                 | 14.339994   |\n",
      "| episodes                | 3850        |\n",
      "| fps                     | 86          |\n",
      "| mean 100 episode reward | 2.73e+03    |\n",
      "| n_updates               | 709029      |\n",
      "| policy_loss             | -309.14502  |\n",
      "| qf1_loss                | 14.906836   |\n",
      "| qf2_loss                | 17.382893   |\n",
      "| time_elapsed            | 8227        |\n",
      "| total timesteps         | 709128      |\n",
      "| value_loss              | 16.169237   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035066452 |\n",
      "| ent_coef_loss           | -4.6883664  |\n",
      "| entropy                 | 14.4656515  |\n",
      "| episodes                | 3860        |\n",
      "| fps                     | 86          |\n",
      "| mean 100 episode reward | 2.82e+03    |\n",
      "| n_updates               | 715154      |\n",
      "| policy_loss             | -336.2807   |\n",
      "| qf1_loss                | 43.621143   |\n",
      "| qf2_loss                | 37.120968   |\n",
      "| time_elapsed            | 8316        |\n",
      "| total timesteps         | 715253      |\n",
      "| value_loss              | 26.73154    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.037350263 |\n",
      "| ent_coef_loss           | 3.5041776   |\n",
      "| entropy                 | 14.0865345  |\n",
      "| episodes                | 3870        |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 2.92e+03    |\n",
      "| n_updates               | 722445      |\n",
      "| policy_loss             | -294.5336   |\n",
      "| qf1_loss                | 30.8553     |\n",
      "| qf2_loss                | 24.772621   |\n",
      "| time_elapsed            | 8426        |\n",
      "| total timesteps         | 722544      |\n",
      "| value_loss              | 19.146692   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036554355 |\n",
      "| ent_coef_loss           | -3.4964576  |\n",
      "| entropy                 | 13.830366   |\n",
      "| episodes                | 3880        |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 2.76e+03    |\n",
      "| n_updates               | 725895      |\n",
      "| policy_loss             | -329.8266   |\n",
      "| qf1_loss                | 32.584084   |\n",
      "| qf2_loss                | 31.309864   |\n",
      "| time_elapsed            | 8480        |\n",
      "| total timesteps         | 725994      |\n",
      "| value_loss              | 16.576263   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035896335 |\n",
      "| ent_coef_loss           | -5.967346   |\n",
      "| entropy                 | 14.656326   |\n",
      "| episodes                | 3890        |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 2.68e+03    |\n",
      "| n_updates               | 730319      |\n",
      "| policy_loss             | -299.2425   |\n",
      "| qf1_loss                | 16.16975    |\n",
      "| qf2_loss                | 18.789106   |\n",
      "| time_elapsed            | 8550        |\n",
      "| total timesteps         | 730418      |\n",
      "| value_loss              | 15.22377    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036587443 |\n",
      "| ent_coef_loss           | 5.382058    |\n",
      "| entropy                 | 14.559313   |\n",
      "| episodes                | 3900        |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 2.71e+03    |\n",
      "| n_updates               | 737081      |\n",
      "| policy_loss             | -308.17456  |\n",
      "| qf1_loss                | 18.891628   |\n",
      "| qf2_loss                | 23.594255   |\n",
      "| time_elapsed            | 8655        |\n",
      "| total timesteps         | 737180      |\n",
      "| value_loss              | 17.822973   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03791237 |\n",
      "| ent_coef_loss           | -2.402586  |\n",
      "| entropy                 | 13.7119465 |\n",
      "| episodes                | 3910       |\n",
      "| fps                     | 85         |\n",
      "| mean 100 episode reward | 2.89e+03   |\n",
      "| n_updates               | 743331     |\n",
      "| policy_loss             | -331.50604 |\n",
      "| qf1_loss                | 39.811462  |\n",
      "| qf2_loss                | 53.046463  |\n",
      "| time_elapsed            | 8741       |\n",
      "| total timesteps         | 743430     |\n",
      "| value_loss              | 14.136328  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035781983 |\n",
      "| ent_coef_loss           | -0.16826773 |\n",
      "| entropy                 | 14.148108   |\n",
      "| episodes                | 3920        |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 2.84e+03    |\n",
      "| n_updates               | 747725      |\n",
      "| policy_loss             | -333.49866  |\n",
      "| qf1_loss                | 22.917295   |\n",
      "| qf2_loss                | 15.686949   |\n",
      "| time_elapsed            | 8805        |\n",
      "| total timesteps         | 747824      |\n",
      "| value_loss              | 11.087343   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.038435966 |\n",
      "| ent_coef_loss           | -11.208544  |\n",
      "| entropy                 | 14.649311   |\n",
      "| episodes                | 3930        |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 2.97e+03    |\n",
      "| n_updates               | 754084      |\n",
      "| policy_loss             | -341.40576  |\n",
      "| qf1_loss                | 20.36129    |\n",
      "| qf2_loss                | 12.288735   |\n",
      "| time_elapsed            | 8889        |\n",
      "| total timesteps         | 754183      |\n",
      "| value_loss              | 14.1324625  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.037238907 |\n",
      "| ent_coef_loss           | 16.529865   |\n",
      "| entropy                 | 14.61601    |\n",
      "| episodes                | 3940        |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 3e+03       |\n",
      "| n_updates               | 760000      |\n",
      "| policy_loss             | -330.21005  |\n",
      "| qf1_loss                | 29.940948   |\n",
      "| qf2_loss                | 29.994495   |\n",
      "| time_elapsed            | 8969        |\n",
      "| total timesteps         | 760099      |\n",
      "| value_loss              | 22.361202   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036125038 |\n",
      "| ent_coef_loss           | -2.1431563  |\n",
      "| entropy                 | 14.197622   |\n",
      "| episodes                | 3950        |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 2.99e+03    |\n",
      "| n_updates               | 765607      |\n",
      "| policy_loss             | -348.8032   |\n",
      "| qf1_loss                | 32.9769     |\n",
      "| qf2_loss                | 35.68528    |\n",
      "| time_elapsed            | 9040        |\n",
      "| total timesteps         | 765706      |\n",
      "| value_loss              | 17.894407   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03729103 |\n",
      "| ent_coef_loss           | 1.9851875  |\n",
      "| entropy                 | 13.785604  |\n",
      "| episodes                | 3960       |\n",
      "| fps                     | 84         |\n",
      "| mean 100 episode reward | 3.06e+03   |\n",
      "| n_updates               | 772997     |\n",
      "| policy_loss             | -320.4574  |\n",
      "| qf1_loss                | 21.313034  |\n",
      "| qf2_loss                | 27.72958   |\n",
      "| time_elapsed            | 9131       |\n",
      "| total timesteps         | 773096     |\n",
      "| value_loss              | 15.419067  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.038512286 |\n",
      "| ent_coef_loss           | 3.3452258   |\n",
      "| entropy                 | 14.349675   |\n",
      "| episodes                | 3970        |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 2.99e+03    |\n",
      "| n_updates               | 779039      |\n",
      "| policy_loss             | -302.4318   |\n",
      "| qf1_loss                | 34.637016   |\n",
      "| qf2_loss                | 38.66788    |\n",
      "| time_elapsed            | 9209        |\n",
      "| total timesteps         | 779138      |\n",
      "| value_loss              | 13.782836   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035339274 |\n",
      "| ent_coef_loss           | -10.275114  |\n",
      "| entropy                 | 14.767581   |\n",
      "| episodes                | 3980        |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 3.14e+03    |\n",
      "| n_updates               | 785293      |\n",
      "| policy_loss             | -320.99152  |\n",
      "| qf1_loss                | 31.377752   |\n",
      "| qf2_loss                | 19.90651    |\n",
      "| time_elapsed            | 9286        |\n",
      "| total timesteps         | 785392      |\n",
      "| value_loss              | 25.26191    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03677351 |\n",
      "| ent_coef_loss           | 4.0440483  |\n",
      "| entropy                 | 14.045564  |\n",
      "| episodes                | 3990       |\n",
      "| fps                     | 84         |\n",
      "| mean 100 episode reward | 3.22e+03   |\n",
      "| n_updates               | 791257     |\n",
      "| policy_loss             | -330.97516 |\n",
      "| qf1_loss                | 21.85663   |\n",
      "| qf2_loss                | 20.510578  |\n",
      "| time_elapsed            | 9361       |\n",
      "| total timesteps         | 791356     |\n",
      "| value_loss              | 17.309158  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035472862 |\n",
      "| ent_coef_loss           | -0.6049646  |\n",
      "| entropy                 | 13.980989   |\n",
      "| episodes                | 4000        |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 3.22e+03    |\n",
      "| n_updates               | 797908      |\n",
      "| policy_loss             | -328.6369   |\n",
      "| qf1_loss                | 28.952312   |\n",
      "| qf2_loss                | 32.969868   |\n",
      "| time_elapsed            | 9440        |\n",
      "| total timesteps         | 798007      |\n",
      "| value_loss              | 29.235407   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03740072 |\n",
      "| ent_coef_loss           | 0.6501343  |\n",
      "| entropy                 | 14.122322  |\n",
      "| episodes                | 4010       |\n",
      "| fps                     | 84         |\n",
      "| mean 100 episode reward | 3.22e+03   |\n",
      "| n_updates               | 804102     |\n",
      "| policy_loss             | -320.80255 |\n",
      "| qf1_loss                | 29.962032  |\n",
      "| qf2_loss                | 23.283682  |\n",
      "| time_elapsed            | 9527       |\n",
      "| total timesteps         | 804201     |\n",
      "| value_loss              | 18.053358  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03657279 |\n",
      "| ent_coef_loss           | 4.885437   |\n",
      "| entropy                 | 13.626011  |\n",
      "| episodes                | 4020       |\n",
      "| fps                     | 84         |\n",
      "| mean 100 episode reward | 3.38e+03   |\n",
      "| n_updates               | 811257     |\n",
      "| policy_loss             | -345.17422 |\n",
      "| qf1_loss                | 23.023365  |\n",
      "| qf2_loss                | 38.92733   |\n",
      "| time_elapsed            | 9625       |\n",
      "| total timesteps         | 811356     |\n",
      "| value_loss              | 19.116482  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036644407 |\n",
      "| ent_coef_loss           | 0.5565664   |\n",
      "| entropy                 | 14.524886   |\n",
      "| episodes                | 4030        |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 3.39e+03    |\n",
      "| n_updates               | 817905      |\n",
      "| policy_loss             | -306.34424  |\n",
      "| qf1_loss                | 35.556324   |\n",
      "| qf2_loss                | 37.74778    |\n",
      "| time_elapsed            | 9708        |\n",
      "| total timesteps         | 818004      |\n",
      "| value_loss              | 10.324268   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036069762 |\n",
      "| ent_coef_loss           | 1.3314829   |\n",
      "| entropy                 | 14.136479   |\n",
      "| episodes                | 4040        |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 3.38e+03    |\n",
      "| n_updates               | 823614      |\n",
      "| policy_loss             | -353.62585  |\n",
      "| qf1_loss                | 23.589272   |\n",
      "| qf2_loss                | 15.734314   |\n",
      "| time_elapsed            | 9790        |\n",
      "| total timesteps         | 823713      |\n",
      "| value_loss              | 10.930536   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036388386 |\n",
      "| ent_coef_loss           | 7.2973404   |\n",
      "| entropy                 | 14.12973    |\n",
      "| episodes                | 4050        |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 3.45e+03    |\n",
      "| n_updates               | 830432      |\n",
      "| policy_loss             | -317.44128  |\n",
      "| qf1_loss                | 33.673313   |\n",
      "| qf2_loss                | 33.144554   |\n",
      "| time_elapsed            | 9881        |\n",
      "| total timesteps         | 830531      |\n",
      "| value_loss              | 10.655596   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036290612 |\n",
      "| ent_coef_loss           | 1.7869183   |\n",
      "| entropy                 | 14.994562   |\n",
      "| episodes                | 4060        |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 3.43e+03    |\n",
      "| n_updates               | 837386      |\n",
      "| policy_loss             | -356.86035  |\n",
      "| qf1_loss                | 32.27346    |\n",
      "| qf2_loss                | 21.49914    |\n",
      "| time_elapsed            | 9955        |\n",
      "| total timesteps         | 837485      |\n",
      "| value_loss              | 18.363018   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03553115 |\n",
      "| ent_coef_loss           | -5.6320386 |\n",
      "| entropy                 | 14.659012  |\n",
      "| episodes                | 4070       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 3.5e+03    |\n",
      "| n_updates               | 844918     |\n",
      "| policy_loss             | -342.30188 |\n",
      "| qf1_loss                | 30.174273  |\n",
      "| qf2_loss                | 19.663193  |\n",
      "| time_elapsed            | 10063      |\n",
      "| total timesteps         | 845017     |\n",
      "| value_loss              | 14.232666  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035446238 |\n",
      "| ent_coef_loss           | 5.231277    |\n",
      "| entropy                 | 13.602005   |\n",
      "| episodes                | 4080        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.5e+03     |\n",
      "| n_updates               | 851151      |\n",
      "| policy_loss             | -312.4442   |\n",
      "| qf1_loss                | 45.39889    |\n",
      "| qf2_loss                | 44.759804   |\n",
      "| time_elapsed            | 10144       |\n",
      "| total timesteps         | 851250      |\n",
      "| value_loss              | 25.348228   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03575397 |\n",
      "| ent_coef_loss           | -4.8540773 |\n",
      "| entropy                 | 14.674082  |\n",
      "| episodes                | 4090       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 3.48e+03   |\n",
      "| n_updates               | 856707     |\n",
      "| policy_loss             | -339.4572  |\n",
      "| qf1_loss                | 20.46154   |\n",
      "| qf2_loss                | 21.031006  |\n",
      "| time_elapsed            | 10216      |\n",
      "| total timesteps         | 856806     |\n",
      "| value_loss              | 11.453663  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03531011 |\n",
      "| ent_coef_loss           | 5.5337133  |\n",
      "| entropy                 | 14.367708  |\n",
      "| episodes                | 4100       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 3.44e+03   |\n",
      "| n_updates               | 862590     |\n",
      "| policy_loss             | -324.66125 |\n",
      "| qf1_loss                | 22.342691  |\n",
      "| qf2_loss                | 23.2188    |\n",
      "| time_elapsed            | 10291      |\n",
      "| total timesteps         | 862689     |\n",
      "| value_loss              | 15.190661  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036289167 |\n",
      "| ent_coef_loss           | 3.3378546   |\n",
      "| entropy                 | 14.442972   |\n",
      "| episodes                | 4110        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.51e+03    |\n",
      "| n_updates               | 870090      |\n",
      "| policy_loss             | -338.50323  |\n",
      "| qf1_loss                | 31.647198   |\n",
      "| qf2_loss                | 23.334446   |\n",
      "| time_elapsed            | 10373       |\n",
      "| total timesteps         | 870189      |\n",
      "| value_loss              | 11.013388   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.034447633 |\n",
      "| ent_coef_loss           | -5.68703    |\n",
      "| entropy                 | 14.542567   |\n",
      "| episodes                | 4120        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.52e+03    |\n",
      "| n_updates               | 877360      |\n",
      "| policy_loss             | -349.18002  |\n",
      "| qf1_loss                | 11.854071   |\n",
      "| qf2_loss                | 13.814597   |\n",
      "| time_elapsed            | 10478       |\n",
      "| total timesteps         | 877459      |\n",
      "| value_loss              | 9.516912    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| current_lr              | 0.0003       |\n",
      "| ent_coef                | 0.03529303   |\n",
      "| ent_coef_loss           | -0.096857786 |\n",
      "| entropy                 | 14.244188    |\n",
      "| episodes                | 4130         |\n",
      "| fps                     | 83           |\n",
      "| mean 100 episode reward | 3.47e+03     |\n",
      "| n_updates               | 882997       |\n",
      "| policy_loss             | -345.01422   |\n",
      "| qf1_loss                | 20.014301    |\n",
      "| qf2_loss                | 25.085781    |\n",
      "| time_elapsed            | 10556        |\n",
      "| total timesteps         | 883096       |\n",
      "| value_loss              | 14.436989    |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03486921 |\n",
      "| ent_coef_loss           | -4.133052  |\n",
      "| entropy                 | 13.378304  |\n",
      "| episodes                | 4140       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 3.59e+03   |\n",
      "| n_updates               | 890836     |\n",
      "| policy_loss             | -357.1911  |\n",
      "| qf1_loss                | 29.096075  |\n",
      "| qf2_loss                | 32.280296  |\n",
      "| time_elapsed            | 10650      |\n",
      "| total timesteps         | 890935     |\n",
      "| value_loss              | 27.292053  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03784119 |\n",
      "| ent_coef_loss           | -2.1857116 |\n",
      "| entropy                 | 14.187202  |\n",
      "| episodes                | 4150       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 3.57e+03   |\n",
      "| n_updates               | 897418     |\n",
      "| policy_loss             | -357.3107  |\n",
      "| qf1_loss                | 41.86605   |\n",
      "| qf2_loss                | 33.918365  |\n",
      "| time_elapsed            | 10733      |\n",
      "| total timesteps         | 897517     |\n",
      "| value_loss              | 22.140594  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03478582 |\n",
      "| ent_coef_loss           | 2.096517   |\n",
      "| entropy                 | 14.430133  |\n",
      "| episodes                | 4160       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 3.57e+03   |\n",
      "| n_updates               | 904221     |\n",
      "| policy_loss             | -336.59534 |\n",
      "| qf1_loss                | 11.007869  |\n",
      "| qf2_loss                | 21.714344  |\n",
      "| time_elapsed            | 10816      |\n",
      "| total timesteps         | 904320     |\n",
      "| value_loss              | 17.018929  |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.0377008  |\n",
      "| ent_coef_loss           | 6.1839786  |\n",
      "| entropy                 | 14.493202  |\n",
      "| episodes                | 4170       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 3.59e+03   |\n",
      "| n_updates               | 912010     |\n",
      "| policy_loss             | -366.35202 |\n",
      "| qf1_loss                | 44.418144  |\n",
      "| qf2_loss                | 43.077236  |\n",
      "| time_elapsed            | 10905      |\n",
      "| total timesteps         | 912109     |\n",
      "| value_loss              | 10.091852  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035857476 |\n",
      "| ent_coef_loss           | -11.331043  |\n",
      "| entropy                 | 14.412275   |\n",
      "| episodes                | 4180        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.66e+03    |\n",
      "| n_updates               | 919442      |\n",
      "| policy_loss             | -363.95248  |\n",
      "| qf1_loss                | 25.15254    |\n",
      "| qf2_loss                | 18.99337    |\n",
      "| time_elapsed            | 11000       |\n",
      "| total timesteps         | 919541      |\n",
      "| value_loss              | 14.697247   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.033897024 |\n",
      "| ent_coef_loss           | 5.393432    |\n",
      "| entropy                 | 13.907408   |\n",
      "| episodes                | 4190        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.73e+03    |\n",
      "| n_updates               | 926303      |\n",
      "| policy_loss             | -284.23138  |\n",
      "| qf1_loss                | 49.421684   |\n",
      "| qf2_loss                | 34.560097   |\n",
      "| time_elapsed            | 11091       |\n",
      "| total timesteps         | 926402      |\n",
      "| value_loss              | 14.320995   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.033541955 |\n",
      "| ent_coef_loss           | -2.5277624  |\n",
      "| entropy                 | 13.925432   |\n",
      "| episodes                | 4200        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.76e+03    |\n",
      "| n_updates               | 932792      |\n",
      "| policy_loss             | -372.85065  |\n",
      "| qf1_loss                | 50.800056   |\n",
      "| qf2_loss                | 41.959686   |\n",
      "| time_elapsed            | 11160       |\n",
      "| total timesteps         | 932891      |\n",
      "| value_loss              | 12.66709    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.033238146 |\n",
      "| ent_coef_loss           | 6.785434    |\n",
      "| entropy                 | 14.159573   |\n",
      "| episodes                | 4210        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.81e+03    |\n",
      "| n_updates               | 941172      |\n",
      "| policy_loss             | -340.8406   |\n",
      "| qf1_loss                | 38.817      |\n",
      "| qf2_loss                | 27.241385   |\n",
      "| time_elapsed            | 11247       |\n",
      "| total timesteps         | 941271      |\n",
      "| value_loss              | 11.520916   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.033378106 |\n",
      "| ent_coef_loss           | -3.119216   |\n",
      "| entropy                 | 14.57606    |\n",
      "| episodes                | 4220        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.85e+03    |\n",
      "| n_updates               | 949128      |\n",
      "| policy_loss             | -369.44293  |\n",
      "| qf1_loss                | 41.41352    |\n",
      "| qf2_loss                | 35.932198   |\n",
      "| time_elapsed            | 11329       |\n",
      "| total timesteps         | 949227      |\n",
      "| value_loss              | 7.2777934   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03480182 |\n",
      "| ent_coef_loss           | 6.34517    |\n",
      "| entropy                 | 13.6602745 |\n",
      "| episodes                | 4230       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 3.91e+03   |\n",
      "| n_updates               | 956065     |\n",
      "| policy_loss             | -380.04926 |\n",
      "| qf1_loss                | 68.915184  |\n",
      "| qf2_loss                | 64.44243   |\n",
      "| time_elapsed            | 11401      |\n",
      "| total timesteps         | 956164     |\n",
      "| value_loss              | 27.911587  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035357606 |\n",
      "| ent_coef_loss           | -0.9245243  |\n",
      "| entropy                 | 14.751389   |\n",
      "| episodes                | 4240        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.82e+03    |\n",
      "| n_updates               | 962141      |\n",
      "| policy_loss             | -352.39148  |\n",
      "| qf1_loss                | 14.846949   |\n",
      "| qf2_loss                | 20.809095   |\n",
      "| time_elapsed            | 11463       |\n",
      "| total timesteps         | 962240      |\n",
      "| value_loss              | 7.5499043   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03552514 |\n",
      "| ent_coef_loss           | 1.6764315  |\n",
      "| entropy                 | 14.5095005 |\n",
      "| episodes                | 4250       |\n",
      "| fps                     | 84         |\n",
      "| mean 100 episode reward | 3.9e+03    |\n",
      "| n_updates               | 970103     |\n",
      "| policy_loss             | -372.7925  |\n",
      "| qf1_loss                | 21.069159  |\n",
      "| qf2_loss                | 17.211815  |\n",
      "| time_elapsed            | 11544      |\n",
      "| total timesteps         | 970202     |\n",
      "| value_loss              | 8.645994   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.034067426 |\n",
      "| ent_coef_loss           | -0.09060168 |\n",
      "| entropy                 | 14.253069   |\n",
      "| episodes                | 4260        |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 3.9e+03     |\n",
      "| n_updates               | 977021      |\n",
      "| policy_loss             | -378.60757  |\n",
      "| qf1_loss                | 11.436849   |\n",
      "| qf2_loss                | 12.113352   |\n",
      "| time_elapsed            | 11619       |\n",
      "| total timesteps         | 977120      |\n",
      "| value_loss              | 18.566349   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035565402 |\n",
      "| ent_coef_loss           | -1.4173925  |\n",
      "| entropy                 | 14.302273   |\n",
      "| episodes                | 4270        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.98e+03    |\n",
      "| n_updates               | 986242      |\n",
      "| policy_loss             | -361.52515  |\n",
      "| qf1_loss                | 46.4116     |\n",
      "| qf2_loss                | 34.49969    |\n",
      "| time_elapsed            | 11750       |\n",
      "| total timesteps         | 986341      |\n",
      "| value_loss              | 28.616951   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.03547112  |\n",
      "| ent_coef_loss           | 0.030967236 |\n",
      "| entropy                 | 13.7783375  |\n",
      "| episodes                | 4280        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 4.02e+03    |\n",
      "| n_updates               | 994609      |\n",
      "| policy_loss             | -337.5243   |\n",
      "| qf1_loss                | 54.106476   |\n",
      "| qf2_loss                | 47.91198    |\n",
      "| time_elapsed            | 11867       |\n",
      "| total timesteps         | 994708      |\n",
      "| value_loss              | 26.798306   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.032903314 |\n",
      "| ent_coef_loss           | -0.11307335 |\n",
      "| entropy                 | 13.7442875  |\n",
      "| episodes                | 4290        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.97e+03    |\n",
      "| n_updates               | 1000377     |\n",
      "| policy_loss             | -350.17722  |\n",
      "| qf1_loss                | 27.976124   |\n",
      "| qf2_loss                | 29.559675   |\n",
      "| time_elapsed            | 11942       |\n",
      "| total timesteps         | 1000476     |\n",
      "| value_loss              | 11.4160185  |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.032931622 |\n",
      "| ent_coef_loss           | 1.09899     |\n",
      "| entropy                 | 14.206955   |\n",
      "| episodes                | 4300        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.95e+03    |\n",
      "| n_updates               | 1006556     |\n",
      "| policy_loss             | -382.5041   |\n",
      "| qf1_loss                | 7.176057    |\n",
      "| qf2_loss                | 16.449078   |\n",
      "| time_elapsed            | 12024       |\n",
      "| total timesteps         | 1006655     |\n",
      "| value_loss              | 21.143557   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.034302782 |\n",
      "| ent_coef_loss           | -3.8168266  |\n",
      "| entropy                 | 15.025036   |\n",
      "| episodes                | 4310        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.83e+03    |\n",
      "| n_updates               | 1012898     |\n",
      "| policy_loss             | -356.48306  |\n",
      "| qf1_loss                | 14.166665   |\n",
      "| qf2_loss                | 16.072998   |\n",
      "| time_elapsed            | 12107       |\n",
      "| total timesteps         | 1012997     |\n",
      "| value_loss              | 24.009848   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.033293236 |\n",
      "| ent_coef_loss           | -8.272352   |\n",
      "| entropy                 | 14.706566   |\n",
      "| episodes                | 4320        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.83e+03    |\n",
      "| n_updates               | 1020711     |\n",
      "| policy_loss             | -360.49463  |\n",
      "| qf1_loss                | 17.52545    |\n",
      "| qf2_loss                | 16.122028   |\n",
      "| time_elapsed            | 12204       |\n",
      "| total timesteps         | 1020810     |\n",
      "| value_loss              | 10.417657   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.034554947 |\n",
      "| ent_coef_loss           | -12.647502  |\n",
      "| entropy                 | 14.909933   |\n",
      "| episodes                | 4330        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.91e+03    |\n",
      "| n_updates               | 1029171     |\n",
      "| policy_loss             | -355.53003  |\n",
      "| qf1_loss                | 20.959803   |\n",
      "| qf2_loss                | 16.790932   |\n",
      "| time_elapsed            | 12311       |\n",
      "| total timesteps         | 1029270     |\n",
      "| value_loss              | 6.65357     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03460372 |\n",
      "| ent_coef_loss           | -9.605457  |\n",
      "| entropy                 | 14.451521  |\n",
      "| episodes                | 4340       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 4e+03      |\n",
      "| n_updates               | 1037021    |\n",
      "| policy_loss             | -389.57248 |\n",
      "| qf1_loss                | 28.636484  |\n",
      "| qf2_loss                | 18.489033  |\n",
      "| time_elapsed            | 12414      |\n",
      "| total timesteps         | 1037120    |\n",
      "| value_loss              | 19.988565  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03150185 |\n",
      "| ent_coef_loss           | 2.9018626  |\n",
      "| entropy                 | 14.632143  |\n",
      "| episodes                | 4350       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 3.92e+03   |\n",
      "| n_updates               | 1043553    |\n",
      "| policy_loss             | -371.9613  |\n",
      "| qf1_loss                | 17.530245  |\n",
      "| qf2_loss                | 23.836336  |\n",
      "| time_elapsed            | 12496      |\n",
      "| total timesteps         | 1043652    |\n",
      "| value_loss              | 17.888193  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03441447 |\n",
      "| ent_coef_loss           | -3.1768863 |\n",
      "| entropy                 | 14.442696  |\n",
      "| episodes                | 4360       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 3.91e+03   |\n",
      "| n_updates               | 1050206    |\n",
      "| policy_loss             | -351.81738 |\n",
      "| qf1_loss                | 13.528103  |\n",
      "| qf2_loss                | 14.2046995 |\n",
      "| time_elapsed            | 12576      |\n",
      "| total timesteps         | 1050305    |\n",
      "| value_loss              | 19.654463  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.033006836 |\n",
      "| ent_coef_loss           | 2.7545643   |\n",
      "| entropy                 | 14.106201   |\n",
      "| episodes                | 4370        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.71e+03    |\n",
      "| n_updates               | 1055666     |\n",
      "| policy_loss             | -349.28433  |\n",
      "| qf1_loss                | 27.398228   |\n",
      "| qf2_loss                | 29.744295   |\n",
      "| time_elapsed            | 12648       |\n",
      "| total timesteps         | 1055765     |\n",
      "| value_loss              | 18.922153   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.032181595 |\n",
      "| ent_coef_loss           | 5.518394    |\n",
      "| entropy                 | 14.996433   |\n",
      "| episodes                | 4380        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.45e+03    |\n",
      "| n_updates               | 1059137     |\n",
      "| policy_loss             | -355.74164  |\n",
      "| qf1_loss                | 28.44062    |\n",
      "| qf2_loss                | 17.843678   |\n",
      "| time_elapsed            | 12692       |\n",
      "| total timesteps         | 1059236     |\n",
      "| value_loss              | 24.978493   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.032510668 |\n",
      "| ent_coef_loss           | 3.5990639   |\n",
      "| entropy                 | 14.599123   |\n",
      "| episodes                | 4390        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.41e+03    |\n",
      "| n_updates               | 1064094     |\n",
      "| policy_loss             | -389.8944   |\n",
      "| qf1_loss                | 25.919144   |\n",
      "| qf2_loss                | 22.97268    |\n",
      "| time_elapsed            | 12751       |\n",
      "| total timesteps         | 1064193     |\n",
      "| value_loss              | 13.895401   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.032058973 |\n",
      "| ent_coef_loss           | 0.80148196  |\n",
      "| entropy                 | 14.554829   |\n",
      "| episodes                | 4400        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.54e+03    |\n",
      "| n_updates               | 1072660     |\n",
      "| policy_loss             | -366.35413  |\n",
      "| qf1_loss                | 41.756977   |\n",
      "| qf2_loss                | 28.482029   |\n",
      "| time_elapsed            | 12851       |\n",
      "| total timesteps         | 1072759     |\n",
      "| value_loss              | 18.161125   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03290889 |\n",
      "| ent_coef_loss           | 1.5958023  |\n",
      "| entropy                 | 14.697247  |\n",
      "| episodes                | 4410       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 3.51e+03   |\n",
      "| n_updates               | 1078367    |\n",
      "| policy_loss             | -361.59894 |\n",
      "| qf1_loss                | 33.296005  |\n",
      "| qf2_loss                | 21.683685  |\n",
      "| time_elapsed            | 12921      |\n",
      "| total timesteps         | 1078466    |\n",
      "| value_loss              | 12.643597  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.032324363 |\n",
      "| ent_coef_loss           | 7.553064    |\n",
      "| entropy                 | 14.628891   |\n",
      "| episodes                | 4420        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.37e+03    |\n",
      "| n_updates               | 1083593     |\n",
      "| policy_loss             | -345.43225  |\n",
      "| qf1_loss                | 29.38131    |\n",
      "| qf2_loss                | 27.767475   |\n",
      "| time_elapsed            | 12986       |\n",
      "| total timesteps         | 1083692     |\n",
      "| value_loss              | 21.806248   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.0333493  |\n",
      "| ent_coef_loss           | 4.334362   |\n",
      "| entropy                 | 13.478243  |\n",
      "| episodes                | 4430       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 3.01e+03   |\n",
      "| n_updates               | 1085252    |\n",
      "| policy_loss             | -361.03802 |\n",
      "| qf1_loss                | 23.185667  |\n",
      "| qf2_loss                | 18.590303  |\n",
      "| time_elapsed            | 13005      |\n",
      "| total timesteps         | 1085351    |\n",
      "| value_loss              | 28.853842  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031090148 |\n",
      "| ent_coef_loss           | 1.4938004   |\n",
      "| entropy                 | 15.161728   |\n",
      "| episodes                | 4440        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 2.92e+03    |\n",
      "| n_updates               | 1091420     |\n",
      "| policy_loss             | -363.69705  |\n",
      "| qf1_loss                | 12.455484   |\n",
      "| qf2_loss                | 14.341899   |\n",
      "| time_elapsed            | 13084       |\n",
      "| total timesteps         | 1091519     |\n",
      "| value_loss              | 13.978033   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031995084 |\n",
      "| ent_coef_loss           | -12.700774  |\n",
      "| entropy                 | 15.202607   |\n",
      "| episodes                | 4450        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 2.98e+03    |\n",
      "| n_updates               | 1099075     |\n",
      "| policy_loss             | -381.50757  |\n",
      "| qf1_loss                | 10.045204   |\n",
      "| qf2_loss                | 18.41537    |\n",
      "| time_elapsed            | 13180       |\n",
      "| total timesteps         | 1099174     |\n",
      "| value_loss              | 13.985168   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031058224 |\n",
      "| ent_coef_loss           | -1.565969   |\n",
      "| entropy                 | 13.838335   |\n",
      "| episodes                | 4460        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 2.88e+03    |\n",
      "| n_updates               | 1104040     |\n",
      "| policy_loss             | -372.86377  |\n",
      "| qf1_loss                | 28.658297   |\n",
      "| qf2_loss                | 18.978382   |\n",
      "| time_elapsed            | 13239       |\n",
      "| total timesteps         | 1104139     |\n",
      "| value_loss              | 9.855945    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031131389 |\n",
      "| ent_coef_loss           | 0.7691045   |\n",
      "| entropy                 | 14.697379   |\n",
      "| episodes                | 4470        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 2.85e+03    |\n",
      "| n_updates               | 1108859     |\n",
      "| policy_loss             | -380.51733  |\n",
      "| qf1_loss                | 28.854286   |\n",
      "| qf2_loss                | 28.80836    |\n",
      "| time_elapsed            | 13306       |\n",
      "| total timesteps         | 1108958     |\n",
      "| value_loss              | 12.095278   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.033172794 |\n",
      "| ent_coef_loss           | -6.4446387  |\n",
      "| entropy                 | 14.691728   |\n",
      "| episodes                | 4480        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.09e+03    |\n",
      "| n_updates               | 1116927     |\n",
      "| policy_loss             | -361.24597  |\n",
      "| qf1_loss                | 14.524552   |\n",
      "| qf2_loss                | 20.069393   |\n",
      "| time_elapsed            | 13405       |\n",
      "| total timesteps         | 1117026     |\n",
      "| value_loss              | 12.331305   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02951711 |\n",
      "| ent_coef_loss           | 6.1249995  |\n",
      "| entropy                 | 14.76473   |\n",
      "| episodes                | 4490       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 3.21e+03   |\n",
      "| n_updates               | 1124135    |\n",
      "| policy_loss             | -379.51645 |\n",
      "| qf1_loss                | 19.543655  |\n",
      "| qf2_loss                | 22.282175  |\n",
      "| time_elapsed            | 13496      |\n",
      "| total timesteps         | 1124234    |\n",
      "| value_loss              | 15.378317  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029540913 |\n",
      "| ent_coef_loss           | -2.5711737  |\n",
      "| entropy                 | 14.698154   |\n",
      "| episodes                | 4500        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 2.96e+03    |\n",
      "| n_updates               | 1128105     |\n",
      "| policy_loss             | -392.9614   |\n",
      "| qf1_loss                | 18.98739    |\n",
      "| qf2_loss                | 28.508116   |\n",
      "| time_elapsed            | 13547       |\n",
      "| total timesteps         | 1128204     |\n",
      "| value_loss              | 8.356819    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030738635 |\n",
      "| ent_coef_loss           | -4.784898   |\n",
      "| entropy                 | 13.918833   |\n",
      "| episodes                | 4510        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.04e+03    |\n",
      "| n_updates               | 1135112     |\n",
      "| policy_loss             | -387.70862  |\n",
      "| qf1_loss                | 1344.8329   |\n",
      "| qf2_loss                | 1333.7152   |\n",
      "| time_elapsed            | 13634       |\n",
      "| total timesteps         | 1135211     |\n",
      "| value_loss              | 14.353847   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031426974 |\n",
      "| ent_coef_loss           | -11.122457  |\n",
      "| entropy                 | 14.803665   |\n",
      "| episodes                | 4520        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 2.93e+03    |\n",
      "| n_updates               | 1138104     |\n",
      "| policy_loss             | -386.53253  |\n",
      "| qf1_loss                | 23.097174   |\n",
      "| qf2_loss                | 26.831964   |\n",
      "| time_elapsed            | 13670       |\n",
      "| total timesteps         | 1138203     |\n",
      "| value_loss              | 7.7493997   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031910304 |\n",
      "| ent_coef_loss           | 0.59146285  |\n",
      "| entropy                 | 15.2082205  |\n",
      "| episodes                | 4530        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.25e+03    |\n",
      "| n_updates               | 1145729     |\n",
      "| policy_loss             | -380.32263  |\n",
      "| qf1_loss                | 18.968063   |\n",
      "| qf2_loss                | 23.850714   |\n",
      "| time_elapsed            | 13763       |\n",
      "| total timesteps         | 1145828     |\n",
      "| value_loss              | 17.122528   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030199766 |\n",
      "| ent_coef_loss           | 1.8795156   |\n",
      "| entropy                 | 14.18993    |\n",
      "| episodes                | 4540        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.3e+03     |\n",
      "| n_updates               | 1152902     |\n",
      "| policy_loss             | -402.8955   |\n",
      "| qf1_loss                | 10.030003   |\n",
      "| qf2_loss                | 8.887243    |\n",
      "| time_elapsed            | 13850       |\n",
      "| total timesteps         | 1153001     |\n",
      "| value_loss              | 12.448381   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029747069 |\n",
      "| ent_coef_loss           | 1.6373885   |\n",
      "| entropy                 | 14.494099   |\n",
      "| episodes                | 4550        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.24e+03    |\n",
      "| n_updates               | 1159499     |\n",
      "| policy_loss             | -408.25073  |\n",
      "| qf1_loss                | 13.062692   |\n",
      "| qf2_loss                | 11.91711    |\n",
      "| time_elapsed            | 13925       |\n",
      "| total timesteps         | 1159598     |\n",
      "| value_loss              | 7.4555006   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031548403 |\n",
      "| ent_coef_loss           | -8.923805   |\n",
      "| entropy                 | 15.036744   |\n",
      "| episodes                | 4560        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.22e+03    |\n",
      "| n_updates               | 1164006     |\n",
      "| policy_loss             | -389.75464  |\n",
      "| qf1_loss                | 13.231338   |\n",
      "| qf2_loss                | 9.818841    |\n",
      "| time_elapsed            | 13976       |\n",
      "| total timesteps         | 1164105     |\n",
      "| value_loss              | 8.287279    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030821295 |\n",
      "| ent_coef_loss           | -10.210688  |\n",
      "| entropy                 | 14.983618   |\n",
      "| episodes                | 4570        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.31e+03    |\n",
      "| n_updates               | 1170428     |\n",
      "| policy_loss             | -411.2095   |\n",
      "| qf1_loss                | 11.973644   |\n",
      "| qf2_loss                | 13.002394   |\n",
      "| time_elapsed            | 14049       |\n",
      "| total timesteps         | 1170527     |\n",
      "| value_loss              | 9.688807    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02959302 |\n",
      "| ent_coef_loss           | -9.292609  |\n",
      "| entropy                 | 14.048855  |\n",
      "| episodes                | 4580       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 3.2e+03    |\n",
      "| n_updates               | 1176462    |\n",
      "| policy_loss             | -415.39545 |\n",
      "| qf1_loss                | 8.5829525  |\n",
      "| qf2_loss                | 6.5559025  |\n",
      "| time_elapsed            | 14128      |\n",
      "| total timesteps         | 1176561    |\n",
      "| value_loss              | 5.378621   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03225463 |\n",
      "| ent_coef_loss           | -6.7015734 |\n",
      "| entropy                 | 15.152246  |\n",
      "| episodes                | 4590       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 3.11e+03   |\n",
      "| n_updates               | 1182181    |\n",
      "| policy_loss             | -396.4178  |\n",
      "| qf1_loss                | 17.321466  |\n",
      "| qf2_loss                | 20.005253  |\n",
      "| time_elapsed            | 14202      |\n",
      "| total timesteps         | 1182280    |\n",
      "| value_loss              | 9.0949335  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031463027 |\n",
      "| ent_coef_loss           | 0.6830143   |\n",
      "| entropy                 | 14.170125   |\n",
      "| episodes                | 4600        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.13e+03    |\n",
      "| n_updates               | 1186447     |\n",
      "| policy_loss             | -373.41452  |\n",
      "| qf1_loss                | 28.851109   |\n",
      "| qf2_loss                | 39.68699    |\n",
      "| time_elapsed            | 14255       |\n",
      "| total timesteps         | 1186546     |\n",
      "| value_loss              | 17.404713   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029453875 |\n",
      "| ent_coef_loss           | 0.5215547   |\n",
      "| entropy                 | 13.961468   |\n",
      "| episodes                | 4610        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.07e+03    |\n",
      "| n_updates               | 1192571     |\n",
      "| policy_loss             | -385.91235  |\n",
      "| qf1_loss                | 21.159086   |\n",
      "| qf2_loss                | 17.74789    |\n",
      "| time_elapsed            | 14329       |\n",
      "| total timesteps         | 1192670     |\n",
      "| value_loss              | 17.43459    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030518468 |\n",
      "| ent_coef_loss           | 7.055725    |\n",
      "| entropy                 | 14.072962   |\n",
      "| episodes                | 4620        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.22e+03    |\n",
      "| n_updates               | 1198409     |\n",
      "| policy_loss             | -381.02246  |\n",
      "| qf1_loss                | 32.763607   |\n",
      "| qf2_loss                | 24.018454   |\n",
      "| time_elapsed            | 14401       |\n",
      "| total timesteps         | 1198508     |\n",
      "| value_loss              | 21.37151    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029942326 |\n",
      "| ent_coef_loss           | -0.71948385 |\n",
      "| entropy                 | 14.645064   |\n",
      "| episodes                | 4630        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.17e+03    |\n",
      "| n_updates               | 1205258     |\n",
      "| policy_loss             | -416.12628  |\n",
      "| qf1_loss                | 22.227861   |\n",
      "| qf2_loss                | 20.928577   |\n",
      "| time_elapsed            | 14486       |\n",
      "| total timesteps         | 1205357     |\n",
      "| value_loss              | 7.4274874   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.033069003 |\n",
      "| ent_coef_loss           | 0.73905694  |\n",
      "| entropy                 | 14.635466   |\n",
      "| episodes                | 4640        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.17e+03    |\n",
      "| n_updates               | 1212470     |\n",
      "| policy_loss             | -375.70654  |\n",
      "| qf1_loss                | 23.235065   |\n",
      "| qf2_loss                | 17.564278   |\n",
      "| time_elapsed            | 14569       |\n",
      "| total timesteps         | 1212569     |\n",
      "| value_loss              | 24.109272   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03364777 |\n",
      "| ent_coef_loss           | 5.562018   |\n",
      "| entropy                 | 14.57645   |\n",
      "| episodes                | 4650       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 3.07e+03   |\n",
      "| n_updates               | 1217451    |\n",
      "| policy_loss             | -400.4463  |\n",
      "| qf1_loss                | 20.254246  |\n",
      "| qf2_loss                | 25.185192  |\n",
      "| time_elapsed            | 14632      |\n",
      "| total timesteps         | 1217550    |\n",
      "| value_loss              | 17.079546  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.032874055 |\n",
      "| ent_coef_loss           | -8.154174   |\n",
      "| entropy                 | 14.742957   |\n",
      "| episodes                | 4660        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.05e+03    |\n",
      "| n_updates               | 1221647     |\n",
      "| policy_loss             | -413.0006   |\n",
      "| qf1_loss                | 22.61298    |\n",
      "| qf2_loss                | 24.061157   |\n",
      "| time_elapsed            | 14682       |\n",
      "| total timesteps         | 1221746     |\n",
      "| value_loss              | 10.548319   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.032159083 |\n",
      "| ent_coef_loss           | -0.13305998 |\n",
      "| entropy                 | 15.000093   |\n",
      "| episodes                | 4670        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.16e+03    |\n",
      "| n_updates               | 1230173     |\n",
      "| policy_loss             | -382.76218  |\n",
      "| qf1_loss                | 42.8753     |\n",
      "| qf2_loss                | 36.09678    |\n",
      "| time_elapsed            | 14785       |\n",
      "| total timesteps         | 1230272     |\n",
      "| value_loss              | 19.875841   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030964842 |\n",
      "| ent_coef_loss           | -3.004755   |\n",
      "| entropy                 | 14.844395   |\n",
      "| episodes                | 4680        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.33e+03    |\n",
      "| n_updates               | 1239164     |\n",
      "| policy_loss             | -412.63144  |\n",
      "| qf1_loss                | 29.28577    |\n",
      "| qf2_loss                | 18.992268   |\n",
      "| time_elapsed            | 14890       |\n",
      "| total timesteps         | 1239263     |\n",
      "| value_loss              | 11.946696   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.027718937 |\n",
      "| ent_coef_loss           | -6.5352225  |\n",
      "| entropy                 | 13.675625   |\n",
      "| episodes                | 4690        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.5e+03     |\n",
      "| n_updates               | 1247948     |\n",
      "| policy_loss             | -413.52417  |\n",
      "| qf1_loss                | 18.187092   |\n",
      "| qf2_loss                | 26.71135    |\n",
      "| time_elapsed            | 14991       |\n",
      "| total timesteps         | 1248047     |\n",
      "| value_loss              | 17.072006   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028489698 |\n",
      "| ent_coef_loss           | -0.1266368  |\n",
      "| entropy                 | 13.98067    |\n",
      "| episodes                | 4700        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.56e+03    |\n",
      "| n_updates               | 1253213     |\n",
      "| policy_loss             | -409.32883  |\n",
      "| qf1_loss                | 34.713398   |\n",
      "| qf2_loss                | 32.901463   |\n",
      "| time_elapsed            | 15051       |\n",
      "| total timesteps         | 1253312     |\n",
      "| value_loss              | 23.807777   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029441807 |\n",
      "| ent_coef_loss           | 1.7717334   |\n",
      "| entropy                 | 13.64837    |\n",
      "| episodes                | 4710        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.72e+03    |\n",
      "| n_updates               | 1262075     |\n",
      "| policy_loss             | -398.41608  |\n",
      "| qf1_loss                | 11.597394   |\n",
      "| qf2_loss                | 19.534313   |\n",
      "| time_elapsed            | 15154       |\n",
      "| total timesteps         | 1262174     |\n",
      "| value_loss              | 22.947973   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.026796514 |\n",
      "| ent_coef_loss           | 2.550488    |\n",
      "| entropy                 | 13.381535   |\n",
      "| episodes                | 4720        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.88e+03    |\n",
      "| n_updates               | 1270872     |\n",
      "| policy_loss             | -392.32333  |\n",
      "| qf1_loss                | 26.702322   |\n",
      "| qf2_loss                | 11.449345   |\n",
      "| time_elapsed            | 15259       |\n",
      "| total timesteps         | 1270971     |\n",
      "| value_loss              | 14.80231    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030933443 |\n",
      "| ent_coef_loss           | 6.661243    |\n",
      "| entropy                 | 14.372118   |\n",
      "| episodes                | 4730        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.98e+03    |\n",
      "| n_updates               | 1279422     |\n",
      "| policy_loss             | -411.237    |\n",
      "| qf1_loss                | 16.606804   |\n",
      "| qf2_loss                | 22.055641   |\n",
      "| time_elapsed            | 15364       |\n",
      "| total timesteps         | 1279521     |\n",
      "| value_loss              | 9.861782    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031907335 |\n",
      "| ent_coef_loss           | -11.359731  |\n",
      "| entropy                 | 14.316734   |\n",
      "| episodes                | 4740        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.98e+03    |\n",
      "| n_updates               | 1286531     |\n",
      "| policy_loss             | -416.3676   |\n",
      "| qf1_loss                | 19.008774   |\n",
      "| qf2_loss                | 12.709184   |\n",
      "| time_elapsed            | 15447       |\n",
      "| total timesteps         | 1286630     |\n",
      "| value_loss              | 8.140703    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029769951 |\n",
      "| ent_coef_loss           | 3.136643    |\n",
      "| entropy                 | 13.930703   |\n",
      "| episodes                | 4750        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 4.07e+03    |\n",
      "| n_updates               | 1292916     |\n",
      "| policy_loss             | -404.84576  |\n",
      "| qf1_loss                | 22.470522   |\n",
      "| qf2_loss                | 14.496952   |\n",
      "| time_elapsed            | 15527       |\n",
      "| total timesteps         | 1293015     |\n",
      "| value_loss              | 19.842743   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.027657155 |\n",
      "| ent_coef_loss           | -0.01214695 |\n",
      "| entropy                 | 14.339914   |\n",
      "| episodes                | 4760        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 4.23e+03    |\n",
      "| n_updates               | 1299861     |\n",
      "| policy_loss             | -423.03564  |\n",
      "| qf1_loss                | 8.367517    |\n",
      "| qf2_loss                | 12.607267   |\n",
      "| time_elapsed            | 15615       |\n",
      "| total timesteps         | 1299960     |\n",
      "| value_loss              | 13.585474   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028665552 |\n",
      "| ent_coef_loss           | -16.622063  |\n",
      "| entropy                 | 15.076967   |\n",
      "| episodes                | 4770        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 4.25e+03    |\n",
      "| n_updates               | 1308522     |\n",
      "| policy_loss             | -430.65967  |\n",
      "| qf1_loss                | 12.273869   |\n",
      "| qf2_loss                | 17.513058   |\n",
      "| time_elapsed            | 15745       |\n",
      "| total timesteps         | 1308621     |\n",
      "| value_loss              | 9.429866    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.027520694 |\n",
      "| ent_coef_loss           | 5.310293    |\n",
      "| entropy                 | 13.978738   |\n",
      "| episodes                | 4780        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 4.17e+03    |\n",
      "| n_updates               | 1316176     |\n",
      "| policy_loss             | -407.5349   |\n",
      "| qf1_loss                | 46.211594   |\n",
      "| qf2_loss                | 25.86856    |\n",
      "| time_elapsed            | 15860       |\n",
      "| total timesteps         | 1316275     |\n",
      "| value_loss              | 11.591336   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029565172 |\n",
      "| ent_coef_loss           | 11.197067   |\n",
      "| entropy                 | 14.570263   |\n",
      "| episodes                | 4790        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 4.12e+03    |\n",
      "| n_updates               | 1324154     |\n",
      "| policy_loss             | -405.64154  |\n",
      "| qf1_loss                | 38.416294   |\n",
      "| qf2_loss                | 44.326347   |\n",
      "| time_elapsed            | 15980       |\n",
      "| total timesteps         | 1324253     |\n",
      "| value_loss              | 9.931402    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028929535 |\n",
      "| ent_coef_loss           | -1.3951993  |\n",
      "| entropy                 | 14.732822   |\n",
      "| episodes                | 4800        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 4.26e+03    |\n",
      "| n_updates               | 1332000     |\n",
      "| policy_loss             | -419.2256   |\n",
      "| qf1_loss                | 24.50227    |\n",
      "| qf2_loss                | 21.618652   |\n",
      "| time_elapsed            | 16096       |\n",
      "| total timesteps         | 1332099     |\n",
      "| value_loss              | 10.828849   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028687019 |\n",
      "| ent_coef_loss           | -20.90469   |\n",
      "| entropy                 | 15.090248   |\n",
      "| episodes                | 4810        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 4.23e+03    |\n",
      "| n_updates               | 1340467     |\n",
      "| policy_loss             | -411.88998  |\n",
      "| qf1_loss                | 16.849611   |\n",
      "| qf2_loss                | 27.782314   |\n",
      "| time_elapsed            | 16218       |\n",
      "| total timesteps         | 1340566     |\n",
      "| value_loss              | 9.6488085   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030893821 |\n",
      "| ent_coef_loss           | 2.0187287   |\n",
      "| entropy                 | 14.762737   |\n",
      "| episodes                | 4820        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 4.2e+03     |\n",
      "| n_updates               | 1348624     |\n",
      "| policy_loss             | -423.39713  |\n",
      "| qf1_loss                | 26.353664   |\n",
      "| qf2_loss                | 23.610834   |\n",
      "| time_elapsed            | 16347       |\n",
      "| total timesteps         | 1348723     |\n",
      "| value_loss              | 16.155067   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03088525 |\n",
      "| ent_coef_loss           | -12.652441 |\n",
      "| entropy                 | 15.114635  |\n",
      "| episodes                | 4830       |\n",
      "| fps                     | 82         |\n",
      "| mean 100 episode reward | 4.09e+03   |\n",
      "| n_updates               | 1355107    |\n",
      "| policy_loss             | -437.64008 |\n",
      "| qf1_loss                | 9.0941     |\n",
      "| qf2_loss                | 6.1550093  |\n",
      "| time_elapsed            | 16438      |\n",
      "| total timesteps         | 1355206    |\n",
      "| value_loss              | 5.134454   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028774878 |\n",
      "| ent_coef_loss           | 4.676939    |\n",
      "| entropy                 | 14.067465   |\n",
      "| episodes                | 4840        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 3.94e+03    |\n",
      "| n_updates               | 1359486     |\n",
      "| policy_loss             | -424.0244   |\n",
      "| qf1_loss                | 25.958145   |\n",
      "| qf2_loss                | 18.685772   |\n",
      "| time_elapsed            | 16503       |\n",
      "| total timesteps         | 1359585     |\n",
      "| value_loss              | 18.698809   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029911466 |\n",
      "| ent_coef_loss           | -3.8033762  |\n",
      "| entropy                 | 14.883317   |\n",
      "| episodes                | 4850        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 3.93e+03    |\n",
      "| n_updates               | 1365878     |\n",
      "| policy_loss             | -430.06647  |\n",
      "| qf1_loss                | 21.402185   |\n",
      "| qf2_loss                | 20.463718   |\n",
      "| time_elapsed            | 16594       |\n",
      "| total timesteps         | 1365977     |\n",
      "| value_loss              | 9.409874    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028558193 |\n",
      "| ent_coef_loss           | -9.994448   |\n",
      "| entropy                 | 14.88106    |\n",
      "| episodes                | 4860        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 4e+03       |\n",
      "| n_updates               | 1374183     |\n",
      "| policy_loss             | -428.07928  |\n",
      "| qf1_loss                | 34.5451     |\n",
      "| qf2_loss                | 22.205969   |\n",
      "| time_elapsed            | 16700       |\n",
      "| total timesteps         | 1374282     |\n",
      "| value_loss              | 7.284384    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029112602 |\n",
      "| ent_coef_loss           | -6.5640965  |\n",
      "| entropy                 | 15.105557   |\n",
      "| episodes                | 4870        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 3.91e+03    |\n",
      "| n_updates               | 1381444     |\n",
      "| policy_loss             | -425.3202   |\n",
      "| qf1_loss                | 26.853909   |\n",
      "| qf2_loss                | 22.113792   |\n",
      "| time_elapsed            | 16789       |\n",
      "| total timesteps         | 1381543     |\n",
      "| value_loss              | 14.009164   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02692172 |\n",
      "| ent_coef_loss           | -7.3967843 |\n",
      "| entropy                 | 14.212481  |\n",
      "| episodes                | 4880       |\n",
      "| fps                     | 82         |\n",
      "| mean 100 episode reward | 3.74e+03   |\n",
      "| n_updates               | 1385839    |\n",
      "| policy_loss             | -431.55548 |\n",
      "| qf1_loss                | 5.5338163  |\n",
      "| qf2_loss                | 8.810286   |\n",
      "| time_elapsed            | 16836      |\n",
      "| total timesteps         | 1385938    |\n",
      "| value_loss              | 5.3006477  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02931157 |\n",
      "| ent_coef_loss           | -1.9252799 |\n",
      "| entropy                 | 14.5298    |\n",
      "| episodes                | 4890       |\n",
      "| fps                     | 82         |\n",
      "| mean 100 episode reward | 3.64e+03   |\n",
      "| n_updates               | 1391861    |\n",
      "| policy_loss             | -419.99942 |\n",
      "| qf1_loss                | 22.158312  |\n",
      "| qf2_loss                | 11.051484  |\n",
      "| time_elapsed            | 16900      |\n",
      "| total timesteps         | 1391960    |\n",
      "| value_loss              | 13.393807  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030838408 |\n",
      "| ent_coef_loss           | -3.907464   |\n",
      "| entropy                 | 14.418226   |\n",
      "| episodes                | 4900        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 3.66e+03    |\n",
      "| n_updates               | 1400097     |\n",
      "| policy_loss             | -431.39227  |\n",
      "| qf1_loss                | 13.4305315  |\n",
      "| qf2_loss                | 10.371884   |\n",
      "| time_elapsed            | 16989       |\n",
      "| total timesteps         | 1400196     |\n",
      "| value_loss              | 16.101444   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031158194 |\n",
      "| ent_coef_loss           | 1.2638628   |\n",
      "| entropy                 | 14.5897045  |\n",
      "| episodes                | 4910        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 3.67e+03    |\n",
      "| n_updates               | 1408784     |\n",
      "| policy_loss             | -423.9497   |\n",
      "| qf1_loss                | 23.648445   |\n",
      "| qf2_loss                | 8.721216    |\n",
      "| time_elapsed            | 17101       |\n",
      "| total timesteps         | 1408883     |\n",
      "| value_loss              | 15.425955   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.027770698 |\n",
      "| ent_coef_loss           | 15.756151   |\n",
      "| entropy                 | 14.048111   |\n",
      "| episodes                | 4920        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 3.44e+03    |\n",
      "| n_updates               | 1412674     |\n",
      "| policy_loss             | -394.95367  |\n",
      "| qf1_loss                | 21.43163    |\n",
      "| qf2_loss                | 25.225151   |\n",
      "| time_elapsed            | 17164       |\n",
      "| total timesteps         | 1412773     |\n",
      "| value_loss              | 15.375331   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028234681 |\n",
      "| ent_coef_loss           | -2.0055163  |\n",
      "| entropy                 | 14.255329   |\n",
      "| episodes                | 4930        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 3.51e+03    |\n",
      "| n_updates               | 1420473     |\n",
      "| policy_loss             | -424.27484  |\n",
      "| qf1_loss                | 30.558456   |\n",
      "| qf2_loss                | 27.52766    |\n",
      "| time_elapsed            | 17275       |\n",
      "| total timesteps         | 1420572     |\n",
      "| value_loss              | 20.259993   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029355194 |\n",
      "| ent_coef_loss           | 7.2815824   |\n",
      "| entropy                 | 14.181046   |\n",
      "| episodes                | 4940        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 3.78e+03    |\n",
      "| n_updates               | 1429836     |\n",
      "| policy_loss             | -392.38025  |\n",
      "| qf1_loss                | 20.920248   |\n",
      "| qf2_loss                | 19.255953   |\n",
      "| time_elapsed            | 17413       |\n",
      "| total timesteps         | 1429935     |\n",
      "| value_loss              | 23.018696   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.027849646 |\n",
      "| ent_coef_loss           | 16.995588   |\n",
      "| entropy                 | 13.534981   |\n",
      "| episodes                | 4950        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 3.84e+03    |\n",
      "| n_updates               | 1437063     |\n",
      "| policy_loss             | -400.14398  |\n",
      "| qf1_loss                | 25.95176    |\n",
      "| qf2_loss                | 22.867792   |\n",
      "| time_elapsed            | 17536       |\n",
      "| total timesteps         | 1437162     |\n",
      "| value_loss              | 12.761326   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.027199231 |\n",
      "| ent_coef_loss           | 14.929903   |\n",
      "| entropy                 | 14.32896    |\n",
      "| episodes                | 4960        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 3.83e+03    |\n",
      "| n_updates               | 1444980     |\n",
      "| policy_loss             | -419.27258  |\n",
      "| qf1_loss                | 32.744484   |\n",
      "| qf2_loss                | 19.555525   |\n",
      "| time_elapsed            | 17642       |\n",
      "| total timesteps         | 1445079     |\n",
      "| value_loss              | 18.097229   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.027234135 |\n",
      "| ent_coef_loss           | -3.9067469  |\n",
      "| entropy                 | 14.973588   |\n",
      "| episodes                | 4970        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 3.92e+03    |\n",
      "| n_updates               | 1453741     |\n",
      "| policy_loss             | -440.89343  |\n",
      "| qf1_loss                | 22.24014    |\n",
      "| qf2_loss                | 9.356161    |\n",
      "| time_elapsed            | 17772       |\n",
      "| total timesteps         | 1453840     |\n",
      "| value_loss              | 20.158588   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.026237981 |\n",
      "| ent_coef_loss           | -3.8440397  |\n",
      "| entropy                 | 13.617139   |\n",
      "| episodes                | 4980        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 3.98e+03    |\n",
      "| n_updates               | 1459381     |\n",
      "| policy_loss             | -432.10052  |\n",
      "| qf1_loss                | 44.174377   |\n",
      "| qf2_loss                | 36.564972   |\n",
      "| time_elapsed            | 17861       |\n",
      "| total timesteps         | 1459480     |\n",
      "| value_loss              | 18.31028    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.027638612 |\n",
      "| ent_coef_loss           | 2.84926     |\n",
      "| entropy                 | 14.459934   |\n",
      "| episodes                | 4990        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 4.02e+03    |\n",
      "| n_updates               | 1466356     |\n",
      "| policy_loss             | -418.74445  |\n",
      "| qf1_loss                | 23.572346   |\n",
      "| qf2_loss                | 25.96753    |\n",
      "| time_elapsed            | 17972       |\n",
      "| total timesteps         | 1466455     |\n",
      "| value_loss              | 12.668266   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.027442526 |\n",
      "| ent_coef_loss           | -0.5155716  |\n",
      "| entropy                 | 14.503395   |\n",
      "| episodes                | 5000        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 3.92e+03    |\n",
      "| n_updates               | 1472489     |\n",
      "| policy_loss             | -411.71277  |\n",
      "| qf1_loss                | 26.638527   |\n",
      "| qf2_loss                | 23.403843   |\n",
      "| time_elapsed            | 18071       |\n",
      "| total timesteps         | 1472588     |\n",
      "| value_loss              | 15.264112   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.026165871 |\n",
      "| ent_coef_loss           | -5.325344   |\n",
      "| entropy                 | 14.978943   |\n",
      "| episodes                | 5010        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 3.77e+03    |\n",
      "| n_updates               | 1478462     |\n",
      "| policy_loss             | -415.24664  |\n",
      "| qf1_loss                | 12.881838   |\n",
      "| qf2_loss                | 4.7037215   |\n",
      "| time_elapsed            | 18168       |\n",
      "| total timesteps         | 1478561     |\n",
      "| value_loss              | 8.373249    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.027464284 |\n",
      "| ent_coef_loss           | -7.2669535  |\n",
      "| entropy                 | 15.035132   |\n",
      "| episodes                | 5020        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 4.05e+03    |\n",
      "| n_updates               | 1487358     |\n",
      "| policy_loss             | -443.85168  |\n",
      "| qf1_loss                | 24.539875   |\n",
      "| qf2_loss                | 21.570902   |\n",
      "| time_elapsed            | 18310       |\n",
      "| total timesteps         | 1487457     |\n",
      "| value_loss              | 7.863242    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.027783923 |\n",
      "| ent_coef_loss           | -3.3183503  |\n",
      "| entropy                 | 14.84368    |\n",
      "| episodes                | 5030        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 4.01e+03    |\n",
      "| n_updates               | 1494289     |\n",
      "| policy_loss             | -426.43997  |\n",
      "| qf1_loss                | 20.904154   |\n",
      "| qf2_loss                | 31.372118   |\n",
      "| time_elapsed            | 18391       |\n",
      "| total timesteps         | 1494388     |\n",
      "| value_loss              | 26.665436   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029119253 |\n",
      "| ent_coef_loss           | -7.978      |\n",
      "| entropy                 | 15.151413   |\n",
      "| episodes                | 5040        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 3.79e+03    |\n",
      "| n_updates               | 1499554     |\n",
      "| policy_loss             | -430.7598   |\n",
      "| qf1_loss                | 8.593088    |\n",
      "| qf2_loss                | 7.9533772   |\n",
      "| time_elapsed            | 18446       |\n",
      "| total timesteps         | 1499653     |\n",
      "| value_loss              | 12.704058   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028081415 |\n",
      "| ent_coef_loss           | -15.316221  |\n",
      "| entropy                 | 14.456032   |\n",
      "| episodes                | 5050        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 3.9e+03     |\n",
      "| n_updates               | 1508718     |\n",
      "| policy_loss             | -446.16928  |\n",
      "| qf1_loss                | 38.730827   |\n",
      "| qf2_loss                | 26.78573    |\n",
      "| time_elapsed            | 18544       |\n",
      "| total timesteps         | 1508817     |\n",
      "| value_loss              | 14.101718   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029235898 |\n",
      "| ent_coef_loss           | -15.363142  |\n",
      "| entropy                 | 15.053864   |\n",
      "| episodes                | 5060        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 3.93e+03    |\n",
      "| n_updates               | 1517052     |\n",
      "| policy_loss             | -438.28143  |\n",
      "| qf1_loss                | 14.718515   |\n",
      "| qf2_loss                | 18.477757   |\n",
      "| time_elapsed            | 18632       |\n",
      "| total timesteps         | 1517151     |\n",
      "| value_loss              | 11.116659   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.027795438 |\n",
      "| ent_coef_loss           | -1.6932344  |\n",
      "| entropy                 | 14.18121    |\n",
      "| episodes                | 5070        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 3.79e+03    |\n",
      "| n_updates               | 1523216     |\n",
      "| policy_loss             | -432.23566  |\n",
      "| qf1_loss                | 19.22658    |\n",
      "| qf2_loss                | 10.887161   |\n",
      "| time_elapsed            | 18698       |\n",
      "| total timesteps         | 1523315     |\n",
      "| value_loss              | 11.653297   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.027761528 |\n",
      "| ent_coef_loss           | -11.949507  |\n",
      "| entropy                 | 15.105493   |\n",
      "| episodes                | 5080        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 3.84e+03    |\n",
      "| n_updates               | 1529659     |\n",
      "| policy_loss             | -444.05518  |\n",
      "| qf1_loss                | 7.627598    |\n",
      "| qf2_loss                | 6.6715155   |\n",
      "| time_elapsed            | 18767       |\n",
      "| total timesteps         | 1529758     |\n",
      "| value_loss              | 5.973584    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.026431212 |\n",
      "| ent_coef_loss           | -10.720377  |\n",
      "| entropy                 | 14.92044    |\n",
      "| episodes                | 5090        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 3.99e+03    |\n",
      "| n_updates               | 1539058     |\n",
      "| policy_loss             | -435.13574  |\n",
      "| qf1_loss                | 13.92595    |\n",
      "| qf2_loss                | 10.586875   |\n",
      "| time_elapsed            | 18866       |\n",
      "| total timesteps         | 1539157     |\n",
      "| value_loss              | 17.578753   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031511717 |\n",
      "| ent_coef_loss           | 1.1926198   |\n",
      "| entropy                 | 14.710289   |\n",
      "| episodes                | 5100        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 4.02e+03    |\n",
      "| n_updates               | 1545821     |\n",
      "| policy_loss             | -433.6376   |\n",
      "| qf1_loss                | 16.388191   |\n",
      "| qf2_loss                | 12.994824   |\n",
      "| time_elapsed            | 18938       |\n",
      "| total timesteps         | 1545920     |\n",
      "| value_loss              | 13.033691   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.0276202  |\n",
      "| ent_coef_loss           | 0.82931113 |\n",
      "| entropy                 | 14.159228  |\n",
      "| episodes                | 5110       |\n",
      "| fps                     | 81         |\n",
      "| mean 100 episode reward | 4.09e+03   |\n",
      "| n_updates               | 1552852    |\n",
      "| policy_loss             | -436.51703 |\n",
      "| qf1_loss                | 11.983243  |\n",
      "| qf2_loss                | 17.111895  |\n",
      "| time_elapsed            | 19012      |\n",
      "| total timesteps         | 1552951    |\n",
      "| value_loss              | 5.8416967  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028448496 |\n",
      "| ent_coef_loss           | 13.600281   |\n",
      "| entropy                 | 14.679515   |\n",
      "| episodes                | 5120        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 4.1e+03     |\n",
      "| n_updates               | 1561936     |\n",
      "| policy_loss             | -413.52957  |\n",
      "| qf1_loss                | 19.35       |\n",
      "| qf2_loss                | 13.077816   |\n",
      "| time_elapsed            | 19109       |\n",
      "| total timesteps         | 1562035     |\n",
      "| value_loss              | 19.32266    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.0301353  |\n",
      "| ent_coef_loss           | -2.9950337 |\n",
      "| entropy                 | 14.352768  |\n",
      "| episodes                | 5130       |\n",
      "| fps                     | 81         |\n",
      "| mean 100 episode reward | 4.06e+03   |\n",
      "| n_updates               | 1568395    |\n",
      "| policy_loss             | -454.2911  |\n",
      "| qf1_loss                | 30.45112   |\n",
      "| qf2_loss                | 31.994534  |\n",
      "| time_elapsed            | 19177      |\n",
      "| total timesteps         | 1568494    |\n",
      "| value_loss              | 28.456514  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02739143 |\n",
      "| ent_coef_loss           | -3.9665508 |\n",
      "| entropy                 | 13.674968  |\n",
      "| episodes                | 5140       |\n",
      "| fps                     | 81         |\n",
      "| mean 100 episode reward | 4.19e+03   |\n",
      "| n_updates               | 1575735    |\n",
      "| policy_loss             | -413.25836 |\n",
      "| qf1_loss                | 19.962688  |\n",
      "| qf2_loss                | 23.36056   |\n",
      "| time_elapsed            | 19255      |\n",
      "| total timesteps         | 1575834    |\n",
      "| value_loss              | 23.764755  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030355772 |\n",
      "| ent_coef_loss           | -1.3496177  |\n",
      "| entropy                 | 14.580101   |\n",
      "| episodes                | 5150        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 4.07e+03    |\n",
      "| n_updates               | 1582716     |\n",
      "| policy_loss             | -435.61145  |\n",
      "| qf1_loss                | 27.70811    |\n",
      "| qf2_loss                | 24.352325   |\n",
      "| time_elapsed            | 19328       |\n",
      "| total timesteps         | 1582815     |\n",
      "| value_loss              | 9.4441805   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029162627 |\n",
      "| ent_coef_loss           | 2.6322558   |\n",
      "| entropy                 | 14.549913   |\n",
      "| episodes                | 5160        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 4.11e+03    |\n",
      "| n_updates               | 1591827     |\n",
      "| policy_loss             | -425.85724  |\n",
      "| qf1_loss                | 18.028362   |\n",
      "| qf2_loss                | 14.734481   |\n",
      "| time_elapsed            | 19425       |\n",
      "| total timesteps         | 1591926     |\n",
      "| value_loss              | 28.816761   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028674206 |\n",
      "| ent_coef_loss           | 5.8897862   |\n",
      "| entropy                 | 14.818251   |\n",
      "| episodes                | 5170        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 4.27e+03    |\n",
      "| n_updates               | 1600997     |\n",
      "| policy_loss             | -412.55637  |\n",
      "| qf1_loss                | 30.265223   |\n",
      "| qf2_loss                | 19.681135   |\n",
      "| time_elapsed            | 19522       |\n",
      "| total timesteps         | 1601096     |\n",
      "| value_loss              | 7.9886346   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031598084 |\n",
      "| ent_coef_loss           | 3.5222216   |\n",
      "| entropy                 | 14.168704   |\n",
      "| episodes                | 5180        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 4.42e+03    |\n",
      "| n_updates               | 1609954     |\n",
      "| policy_loss             | -431.9673   |\n",
      "| qf1_loss                | 40.96723    |\n",
      "| qf2_loss                | 21.241243   |\n",
      "| time_elapsed            | 19621       |\n",
      "| total timesteps         | 1610053     |\n",
      "| value_loss              | 20.294216   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028485378 |\n",
      "| ent_coef_loss           | -1.4538074  |\n",
      "| entropy                 | 14.535371   |\n",
      "| episodes                | 5190        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 4.35e+03    |\n",
      "| n_updates               | 1617990     |\n",
      "| policy_loss             | -424.69214  |\n",
      "| qf1_loss                | 13.636562   |\n",
      "| qf2_loss                | 14.962355   |\n",
      "| time_elapsed            | 19708       |\n",
      "| total timesteps         | 1618089     |\n",
      "| value_loss              | 20.31694    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028536223 |\n",
      "| ent_coef_loss           | 2.1669118   |\n",
      "| entropy                 | 14.326082   |\n",
      "| episodes                | 5200        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 4.36e+03    |\n",
      "| n_updates               | 1624792     |\n",
      "| policy_loss             | -429.1457   |\n",
      "| qf1_loss                | 15.3621855  |\n",
      "| qf2_loss                | 12.922678   |\n",
      "| time_elapsed            | 19780       |\n",
      "| total timesteps         | 1624891     |\n",
      "| value_loss              | 21.13757    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03022234 |\n",
      "| ent_coef_loss           | 7.232462   |\n",
      "| entropy                 | 13.993225  |\n",
      "| episodes                | 5210       |\n",
      "| fps                     | 82         |\n",
      "| mean 100 episode reward | 4.43e+03   |\n",
      "| n_updates               | 1633095    |\n",
      "| policy_loss             | -440.28934 |\n",
      "| qf1_loss                | 15.385001  |\n",
      "| qf2_loss                | 16.51794   |\n",
      "| time_elapsed            | 19869      |\n",
      "| total timesteps         | 1633194    |\n",
      "| value_loss              | 6.684456   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02793943 |\n",
      "| ent_coef_loss           | -3.0425763 |\n",
      "| entropy                 | 14.281975  |\n",
      "| episodes                | 5220       |\n",
      "| fps                     | 82         |\n",
      "| mean 100 episode reward | 4.25e+03   |\n",
      "| n_updates               | 1638874    |\n",
      "| policy_loss             | -431.43124 |\n",
      "| qf1_loss                | 6.030054   |\n",
      "| qf2_loss                | 15.032359  |\n",
      "| time_elapsed            | 19931      |\n",
      "| total timesteps         | 1638973    |\n",
      "| value_loss              | 11.195568  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028437505 |\n",
      "| ent_coef_loss           | 4.41158     |\n",
      "| entropy                 | 14.543958   |\n",
      "| episodes                | 5230        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 4.26e+03    |\n",
      "| n_updates               | 1645511     |\n",
      "| policy_loss             | -442.544    |\n",
      "| qf1_loss                | 19.019035   |\n",
      "| qf2_loss                | 54.390434   |\n",
      "| time_elapsed            | 20002       |\n",
      "| total timesteps         | 1645610     |\n",
      "| value_loss              | 23.705194   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028470298 |\n",
      "| ent_coef_loss           | 0.38507462  |\n",
      "| entropy                 | 14.941883   |\n",
      "| episodes                | 5240        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 4.18e+03    |\n",
      "| n_updates               | 1651271     |\n",
      "| policy_loss             | -437.38     |\n",
      "| qf1_loss                | 12.62315    |\n",
      "| qf2_loss                | 9.701993    |\n",
      "| time_elapsed            | 20063       |\n",
      "| total timesteps         | 1651370     |\n",
      "| value_loss              | 4.76409     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029036185 |\n",
      "| ent_coef_loss           | 3.8506784   |\n",
      "| entropy                 | 14.717987   |\n",
      "| episodes                | 5250        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 4.11e+03    |\n",
      "| n_updates               | 1656937     |\n",
      "| policy_loss             | -431.8553   |\n",
      "| qf1_loss                | 9.394657    |\n",
      "| qf2_loss                | 20.95409    |\n",
      "| time_elapsed            | 20123       |\n",
      "| total timesteps         | 1657036     |\n",
      "| value_loss              | 5.0079355   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.027322585 |\n",
      "| ent_coef_loss           | 9.422425    |\n",
      "| entropy                 | 13.355223   |\n",
      "| episodes                | 5260        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 4.07e+03    |\n",
      "| n_updates               | 1665283     |\n",
      "| policy_loss             | -421.4519   |\n",
      "| qf1_loss                | 8.137091    |\n",
      "| qf2_loss                | 15.678598   |\n",
      "| time_elapsed            | 20211       |\n",
      "| total timesteps         | 1665382     |\n",
      "| value_loss              | 9.288737    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028152412 |\n",
      "| ent_coef_loss           | -6.794527   |\n",
      "| entropy                 | 14.279665   |\n",
      "| episodes                | 5270        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 4e+03       |\n",
      "| n_updates               | 1673430     |\n",
      "| policy_loss             | -432.35165  |\n",
      "| qf1_loss                | 11.946665   |\n",
      "| qf2_loss                | 7.9017906   |\n",
      "| time_elapsed            | 20298       |\n",
      "| total timesteps         | 1673529     |\n",
      "| value_loss              | 8.249122    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.027855908 |\n",
      "| ent_coef_loss           | 9.666199    |\n",
      "| entropy                 | 13.751051   |\n",
      "| episodes                | 5280        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 3.86e+03    |\n",
      "| n_updates               | 1680050     |\n",
      "| policy_loss             | -417.6551   |\n",
      "| qf1_loss                | 11.557052   |\n",
      "| qf2_loss                | 23.009552   |\n",
      "| time_elapsed            | 20368       |\n",
      "| total timesteps         | 1680149     |\n",
      "| value_loss              | 21.974735   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.027753342 |\n",
      "| ent_coef_loss           | -3.477269   |\n",
      "| entropy                 | 14.266816   |\n",
      "| episodes                | 5290        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 3.86e+03    |\n",
      "| n_updates               | 1687935     |\n",
      "| policy_loss             | -432.45187  |\n",
      "| qf1_loss                | 11.663385   |\n",
      "| qf2_loss                | 25.817421   |\n",
      "| time_elapsed            | 20452       |\n",
      "| total timesteps         | 1688034     |\n",
      "| value_loss              | 8.901488    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.027218284 |\n",
      "| ent_coef_loss           | -12.695534  |\n",
      "| entropy                 | 14.531222   |\n",
      "| episodes                | 5300        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 3.95e+03    |\n",
      "| n_updates               | 1696388     |\n",
      "| policy_loss             | -442.1854   |\n",
      "| qf1_loss                | 39.010773   |\n",
      "| qf2_loss                | 37.700348   |\n",
      "| time_elapsed            | 20541       |\n",
      "| total timesteps         | 1696487     |\n",
      "| value_loss              | 10.010439   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.027425397 |\n",
      "| ent_coef_loss           | -3.522092   |\n",
      "| entropy                 | 14.715565   |\n",
      "| episodes                | 5310        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 3.89e+03    |\n",
      "| n_updates               | 1703649     |\n",
      "| policy_loss             | -419.81427  |\n",
      "| qf1_loss                | 18.584003   |\n",
      "| qf2_loss                | 15.464287   |\n",
      "| time_elapsed            | 20618       |\n",
      "| total timesteps         | 1703748     |\n",
      "| value_loss              | 7.7219276   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028719485 |\n",
      "| ent_coef_loss           | 4.491871    |\n",
      "| entropy                 | 14.895055   |\n",
      "| episodes                | 5320        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 3.84e+03    |\n",
      "| n_updates               | 1708712     |\n",
      "| policy_loss             | -429.49194  |\n",
      "| qf1_loss                | 40.51549    |\n",
      "| qf2_loss                | 16.647335   |\n",
      "| time_elapsed            | 20671       |\n",
      "| total timesteps         | 1708811     |\n",
      "| value_loss              | 9.501934    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029987907 |\n",
      "| ent_coef_loss           | -0.94289666 |\n",
      "| entropy                 | 14.423759   |\n",
      "| episodes                | 5330        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 3.84e+03    |\n",
      "| n_updates               | 1715251     |\n",
      "| policy_loss             | -439.30676  |\n",
      "| qf1_loss                | 11.228678   |\n",
      "| qf2_loss                | 12.767899   |\n",
      "| time_elapsed            | 20740       |\n",
      "| total timesteps         | 1715350     |\n",
      "| value_loss              | 3.6708817   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031042188 |\n",
      "| ent_coef_loss           | -1.7417643  |\n",
      "| entropy                 | 13.8299885  |\n",
      "| episodes                | 5340        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 3.76e+03    |\n",
      "| n_updates               | 1719784     |\n",
      "| policy_loss             | -420.516    |\n",
      "| qf1_loss                | 41.28412    |\n",
      "| qf2_loss                | 12.842125   |\n",
      "| time_elapsed            | 20789       |\n",
      "| total timesteps         | 1719883     |\n",
      "| value_loss              | 7.440008    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030456392 |\n",
      "| ent_coef_loss           | 7.4296513   |\n",
      "| entropy                 | 13.376277   |\n",
      "| episodes                | 5350        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 3.84e+03    |\n",
      "| n_updates               | 1727047     |\n",
      "| policy_loss             | -441.41824  |\n",
      "| qf1_loss                | 32.669914   |\n",
      "| qf2_loss                | 30.691265   |\n",
      "| time_elapsed            | 20866       |\n",
      "| total timesteps         | 1727146     |\n",
      "| value_loss              | 11.324757   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031069644 |\n",
      "| ent_coef_loss           | -7.999904   |\n",
      "| entropy                 | 14.075526   |\n",
      "| episodes                | 5360        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 3.62e+03    |\n",
      "| n_updates               | 1731351     |\n",
      "| policy_loss             | -437.6958   |\n",
      "| qf1_loss                | 692.12286   |\n",
      "| qf2_loss                | 585.5472    |\n",
      "| time_elapsed            | 20912       |\n",
      "| total timesteps         | 1731450     |\n",
      "| value_loss              | 19.124771   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03058573 |\n",
      "| ent_coef_loss           | 5.983846   |\n",
      "| entropy                 | 14.605041  |\n",
      "| episodes                | 5370       |\n",
      "| fps                     | 82         |\n",
      "| mean 100 episode reward | 3.65e+03   |\n",
      "| n_updates               | 1740049    |\n",
      "| policy_loss             | -429.3124  |\n",
      "| qf1_loss                | 15.6787815 |\n",
      "| qf2_loss                | 23.822819  |\n",
      "| time_elapsed            | 21008      |\n",
      "| total timesteps         | 1740148    |\n",
      "| value_loss              | 15.562279  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028879931 |\n",
      "| ent_coef_loss           | -2.9706044  |\n",
      "| entropy                 | 14.068977   |\n",
      "| episodes                | 5380        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 3.64e+03    |\n",
      "| n_updates               | 1746874     |\n",
      "| policy_loss             | -434.90973  |\n",
      "| qf1_loss                | 10.814505   |\n",
      "| qf2_loss                | 11.352846   |\n",
      "| time_elapsed            | 21089       |\n",
      "| total timesteps         | 1746973     |\n",
      "| value_loss              | 6.673716    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031185113 |\n",
      "| ent_coef_loss           | 4.209318    |\n",
      "| entropy                 | 14.542936   |\n",
      "| episodes                | 5390        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 3.61e+03    |\n",
      "| n_updates               | 1754325     |\n",
      "| policy_loss             | -413.54474  |\n",
      "| qf1_loss                | 18.529375   |\n",
      "| qf2_loss                | 21.071365   |\n",
      "| time_elapsed            | 21170       |\n",
      "| total timesteps         | 1754424     |\n",
      "| value_loss              | 19.512653   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03154698 |\n",
      "| ent_coef_loss           | 1.3215375  |\n",
      "| entropy                 | 14.085138  |\n",
      "| episodes                | 5400       |\n",
      "| fps                     | 82         |\n",
      "| mean 100 episode reward | 3.58e+03   |\n",
      "| n_updates               | 1762314    |\n",
      "| policy_loss             | -433.77612 |\n",
      "| qf1_loss                | 23.917633  |\n",
      "| qf2_loss                | 8.712568   |\n",
      "| time_elapsed            | 21254      |\n",
      "| total timesteps         | 1762413    |\n",
      "| value_loss              | 14.228395  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03164945 |\n",
      "| ent_coef_loss           | 7.3349843  |\n",
      "| entropy                 | 13.28759   |\n",
      "| episodes                | 5410       |\n",
      "| fps                     | 82         |\n",
      "| mean 100 episode reward | 3.66e+03   |\n",
      "| n_updates               | 1771157    |\n",
      "| policy_loss             | -429.00803 |\n",
      "| qf1_loss                | 13.114708  |\n",
      "| qf2_loss                | 16.532442  |\n",
      "| time_elapsed            | 21348      |\n",
      "| total timesteps         | 1771256    |\n",
      "| value_loss              | 15.664197  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028652295 |\n",
      "| ent_coef_loss           | -8.18576    |\n",
      "| entropy                 | 14.181464   |\n",
      "| episodes                | 5420        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.89e+03    |\n",
      "| n_updates               | 1780325     |\n",
      "| policy_loss             | -434.42188  |\n",
      "| qf1_loss                | 9.782009    |\n",
      "| qf2_loss                | 8.85445     |\n",
      "| time_elapsed            | 21445       |\n",
      "| total timesteps         | 1780424     |\n",
      "| value_loss              | 7.4326897   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028613793 |\n",
      "| ent_coef_loss           | -10.090923  |\n",
      "| entropy                 | 15.066849   |\n",
      "| episodes                | 5430        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.91e+03    |\n",
      "| n_updates               | 1787156     |\n",
      "| policy_loss             | -429.58423  |\n",
      "| qf1_loss                | 18.861523   |\n",
      "| qf2_loss                | 25.470991   |\n",
      "| time_elapsed            | 21517       |\n",
      "| total timesteps         | 1787255     |\n",
      "| value_loss              | 15.906436   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028113268 |\n",
      "| ent_coef_loss           | -11.499125  |\n",
      "| entropy                 | 15.18391    |\n",
      "| episodes                | 5440        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.97e+03    |\n",
      "| n_updates               | 1792879     |\n",
      "| policy_loss             | -442.67853  |\n",
      "| qf1_loss                | 6.723777    |\n",
      "| qf2_loss                | 5.531251    |\n",
      "| time_elapsed            | 21577       |\n",
      "| total timesteps         | 1792978     |\n",
      "| value_loss              | 3.072418    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030488817 |\n",
      "| ent_coef_loss           | -7.155197   |\n",
      "| entropy                 | 14.536329   |\n",
      "| episodes                | 5450        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.96e+03    |\n",
      "| n_updates               | 1800019     |\n",
      "| policy_loss             | -442.13687  |\n",
      "| qf1_loss                | 6.7421293   |\n",
      "| qf2_loss                | 15.982632   |\n",
      "| time_elapsed            | 21652       |\n",
      "| total timesteps         | 1800118     |\n",
      "| value_loss              | 12.982727   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029562375 |\n",
      "| ent_coef_loss           | -8.325622   |\n",
      "| entropy                 | 14.843882   |\n",
      "| episodes                | 5460        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 4.13e+03    |\n",
      "| n_updates               | 1807358     |\n",
      "| policy_loss             | -426.10474  |\n",
      "| qf1_loss                | 20.069084   |\n",
      "| qf2_loss                | 41.152805   |\n",
      "| time_elapsed            | 21729       |\n",
      "| total timesteps         | 1807457     |\n",
      "| value_loss              | 20.710087   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029370407 |\n",
      "| ent_coef_loss           | -0.60967827 |\n",
      "| entropy                 | 14.126799   |\n",
      "| episodes                | 5470        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.94e+03    |\n",
      "| n_updates               | 1812632     |\n",
      "| policy_loss             | -425.5194   |\n",
      "| qf1_loss                | 16.695164   |\n",
      "| qf2_loss                | 14.571318   |\n",
      "| time_elapsed            | 21784       |\n",
      "| total timesteps         | 1812731     |\n",
      "| value_loss              | 23.012783   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030695682 |\n",
      "| ent_coef_loss           | -0.45108318 |\n",
      "| entropy                 | 14.259212   |\n",
      "| episodes                | 5480        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.99e+03    |\n",
      "| n_updates               | 1820254     |\n",
      "| policy_loss             | -420.1197   |\n",
      "| qf1_loss                | 19.196781   |\n",
      "| qf2_loss                | 21.874556   |\n",
      "| time_elapsed            | 21864       |\n",
      "| total timesteps         | 1820353     |\n",
      "| value_loss              | 13.518612   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029180147 |\n",
      "| ent_coef_loss           | 2.1445749   |\n",
      "| entropy                 | 14.110508   |\n",
      "| episodes                | 5490        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 4.05e+03    |\n",
      "| n_updates               | 1828597     |\n",
      "| policy_loss             | -428.44223  |\n",
      "| qf1_loss                | 21.325165   |\n",
      "| qf2_loss                | 39.37571    |\n",
      "| time_elapsed            | 21952       |\n",
      "| total timesteps         | 1828696     |\n",
      "| value_loss              | 9.680168    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.027629368 |\n",
      "| ent_coef_loss           | -7.2829843  |\n",
      "| entropy                 | 13.940953   |\n",
      "| episodes                | 5500        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 4.09e+03    |\n",
      "| n_updates               | 1837269     |\n",
      "| policy_loss             | -428.14545  |\n",
      "| qf1_loss                | 33.593903   |\n",
      "| qf2_loss                | 21.794367   |\n",
      "| time_elapsed            | 22043       |\n",
      "| total timesteps         | 1837368     |\n",
      "| value_loss              | 9.649459    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030496495 |\n",
      "| ent_coef_loss           | 4.18402     |\n",
      "| entropy                 | 13.55598    |\n",
      "| episodes                | 5510        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 4.01e+03    |\n",
      "| n_updates               | 1844450     |\n",
      "| policy_loss             | -423.1313   |\n",
      "| qf1_loss                | 25.34929    |\n",
      "| qf2_loss                | 10.255416   |\n",
      "| time_elapsed            | 22119       |\n",
      "| total timesteps         | 1844549     |\n",
      "| value_loss              | 14.875849   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028803514 |\n",
      "| ent_coef_loss           | -7.855604   |\n",
      "| entropy                 | 14.273399   |\n",
      "| episodes                | 5520        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.95e+03    |\n",
      "| n_updates               | 1852347     |\n",
      "| policy_loss             | -429.52475  |\n",
      "| qf1_loss                | 19.6839     |\n",
      "| qf2_loss                | 10.089951   |\n",
      "| time_elapsed            | 22201       |\n",
      "| total timesteps         | 1852446     |\n",
      "| value_loss              | 12.083624   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029815149 |\n",
      "| ent_coef_loss           | -1.9189128  |\n",
      "| entropy                 | 14.302855   |\n",
      "| episodes                | 5530        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 4.04e+03    |\n",
      "| n_updates               | 1860823     |\n",
      "| policy_loss             | -424.88702  |\n",
      "| qf1_loss                | 40.043716   |\n",
      "| qf2_loss                | 35.19978    |\n",
      "| time_elapsed            | 22291       |\n",
      "| total timesteps         | 1860922     |\n",
      "| value_loss              | 22.743408   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.027763858 |\n",
      "| ent_coef_loss           | -3.9171305  |\n",
      "| entropy                 | 14.449324   |\n",
      "| episodes                | 5540        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 4.15e+03    |\n",
      "| n_updates               | 1868405     |\n",
      "| policy_loss             | -440.7514   |\n",
      "| qf1_loss                | 24.07923    |\n",
      "| qf2_loss                | 18.129671   |\n",
      "| time_elapsed            | 22370       |\n",
      "| total timesteps         | 1868504     |\n",
      "| value_loss              | 7.2116885   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029528625 |\n",
      "| ent_coef_loss           | -4.419806   |\n",
      "| entropy                 | 15.225439   |\n",
      "| episodes                | 5550        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 4.18e+03    |\n",
      "| n_updates               | 1875897     |\n",
      "| policy_loss             | -442.1637   |\n",
      "| qf1_loss                | 28.60773    |\n",
      "| qf2_loss                | 19.513805   |\n",
      "| time_elapsed            | 22449       |\n",
      "| total timesteps         | 1875996     |\n",
      "| value_loss              | 10.548169   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028221503 |\n",
      "| ent_coef_loss           | -10.916938  |\n",
      "| entropy                 | 14.177142   |\n",
      "| episodes                | 5560        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 4.14e+03    |\n",
      "| n_updates               | 1882467     |\n",
      "| policy_loss             | -442.74176  |\n",
      "| qf1_loss                | 13.910986   |\n",
      "| qf2_loss                | 17.798193   |\n",
      "| time_elapsed            | 22517       |\n",
      "| total timesteps         | 1882566     |\n",
      "| value_loss              | 17.756752   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02603171 |\n",
      "| ent_coef_loss           | -9.503414  |\n",
      "| entropy                 | 14.080562  |\n",
      "| episodes                | 5570       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 4.26e+03   |\n",
      "| n_updates               | 1889819    |\n",
      "| policy_loss             | -428.90692 |\n",
      "| qf1_loss                | 7.6489177  |\n",
      "| qf2_loss                | 7.8969893  |\n",
      "| time_elapsed            | 22594      |\n",
      "| total timesteps         | 1889918    |\n",
      "| value_loss              | 6.668939   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028879944 |\n",
      "| ent_coef_loss           | -0.22504735 |\n",
      "| entropy                 | 14.221369   |\n",
      "| episodes                | 5580        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 4.3e+03     |\n",
      "| n_updates               | 1898027     |\n",
      "| policy_loss             | -410.7528   |\n",
      "| qf1_loss                | 19.73468    |\n",
      "| qf2_loss                | 27.026783   |\n",
      "| time_elapsed            | 22680       |\n",
      "| total timesteps         | 1898126     |\n",
      "| value_loss              | 20.465288   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.033500884 |\n",
      "| ent_coef_loss           | -0.89444923 |\n",
      "| entropy                 | 14.575241   |\n",
      "| episodes                | 5590        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 4.37e+03    |\n",
      "| n_updates               | 1907462     |\n",
      "| policy_loss             | -420.22186  |\n",
      "| qf1_loss                | 13.195826   |\n",
      "| qf2_loss                | 13.10508    |\n",
      "| time_elapsed            | 22779       |\n",
      "| total timesteps         | 1907561     |\n",
      "| value_loss              | 9.700703    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02894218 |\n",
      "| ent_coef_loss           | -2.8412938 |\n",
      "| entropy                 | 15.157005  |\n",
      "| episodes                | 5600       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 4.37e+03   |\n",
      "| n_updates               | 1916039    |\n",
      "| policy_loss             | -436.90063 |\n",
      "| qf1_loss                | 15.057048  |\n",
      "| qf2_loss                | 10.85241   |\n",
      "| time_elapsed            | 22869      |\n",
      "| total timesteps         | 1916138    |\n",
      "| value_loss              | 7.080185   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031102566 |\n",
      "| ent_coef_loss           | 0.67548156  |\n",
      "| entropy                 | 14.139357   |\n",
      "| episodes                | 5610        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 4.44e+03    |\n",
      "| n_updates               | 1924708     |\n",
      "| policy_loss             | -429.21298  |\n",
      "| qf1_loss                | 26.468697   |\n",
      "| qf2_loss                | 17.65601    |\n",
      "| time_elapsed            | 22960       |\n",
      "| total timesteps         | 1924807     |\n",
      "| value_loss              | 17.503347   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028990516 |\n",
      "| ent_coef_loss           | -7.431856   |\n",
      "| entropy                 | 13.188656   |\n",
      "| episodes                | 5620        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 4.53e+03    |\n",
      "| n_updates               | 1934156     |\n",
      "| policy_loss             | -441.12164  |\n",
      "| qf1_loss                | 9.5643835   |\n",
      "| qf2_loss                | 25.313332   |\n",
      "| time_elapsed            | 23059       |\n",
      "| total timesteps         | 1934255     |\n",
      "| value_loss              | 9.598647    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02880492 |\n",
      "| ent_coef_loss           | 5.2177224  |\n",
      "| entropy                 | 13.771379  |\n",
      "| episodes                | 5630       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 4.45e+03   |\n",
      "| n_updates               | 1941060    |\n",
      "| policy_loss             | -422.13687 |\n",
      "| qf1_loss                | 38.41042   |\n",
      "| qf2_loss                | 47.033062  |\n",
      "| time_elapsed            | 23131      |\n",
      "| total timesteps         | 1941159    |\n",
      "| value_loss              | 26.353107  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028711453 |\n",
      "| ent_coef_loss           | -1.2713827  |\n",
      "| entropy                 | 14.925286   |\n",
      "| episodes                | 5640        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 4.47e+03    |\n",
      "| n_updates               | 1948985     |\n",
      "| policy_loss             | -432.74332  |\n",
      "| qf1_loss                | 11.217673   |\n",
      "| qf2_loss                | 8.852245    |\n",
      "| time_elapsed            | 23221       |\n",
      "| total timesteps         | 1949084     |\n",
      "| value_loss              | 15.504994   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02762309 |\n",
      "| ent_coef_loss           | 5.850043   |\n",
      "| entropy                 | 13.584929  |\n",
      "| episodes                | 5650       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 4.47e+03   |\n",
      "| n_updates               | 1956486    |\n",
      "| policy_loss             | -423.26508 |\n",
      "| qf1_loss                | 47.181435  |\n",
      "| qf2_loss                | 64.13574   |\n",
      "| time_elapsed            | 23302      |\n",
      "| total timesteps         | 1956585    |\n",
      "| value_loss              | 48.16774   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028777286 |\n",
      "| ent_coef_loss           | 0.32543445  |\n",
      "| entropy                 | 15.33695    |\n",
      "| episodes                | 5660        |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 4.59e+03    |\n",
      "| n_updates               | 1965112     |\n",
      "| policy_loss             | -416.77814  |\n",
      "| qf1_loss                | 17.94247    |\n",
      "| qf2_loss                | 12.484608   |\n",
      "| time_elapsed            | 23393       |\n",
      "| total timesteps         | 1965211     |\n",
      "| value_loss              | 9.431281    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029129695 |\n",
      "| ent_coef_loss           | 4.8580723   |\n",
      "| entropy                 | 14.034903   |\n",
      "| episodes                | 5670        |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 4.61e+03    |\n",
      "| n_updates               | 1972674     |\n",
      "| policy_loss             | -414.8836   |\n",
      "| qf1_loss                | 23.737051   |\n",
      "| qf2_loss                | 22.238724   |\n",
      "| time_elapsed            | 23473       |\n",
      "| total timesteps         | 1972773     |\n",
      "| value_loss              | 19.35762    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030003497 |\n",
      "| ent_coef_loss           | 2.3435738   |\n",
      "| entropy                 | 14.388626   |\n",
      "| episodes                | 5680        |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 4.65e+03    |\n",
      "| n_updates               | 1981671     |\n",
      "| policy_loss             | -434.27258  |\n",
      "| qf1_loss                | 15.241843   |\n",
      "| qf2_loss                | 11.215733   |\n",
      "| time_elapsed            | 23568       |\n",
      "| total timesteps         | 1981770     |\n",
      "| value_loss              | 26.884335   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03015129 |\n",
      "| ent_coef_loss           | 2.9091327  |\n",
      "| entropy                 | 13.506798  |\n",
      "| episodes                | 5690       |\n",
      "| fps                     | 84         |\n",
      "| mean 100 episode reward | 4.49e+03   |\n",
      "| n_updates               | 1988143    |\n",
      "| policy_loss             | -412.13266 |\n",
      "| qf1_loss                | 48.854237  |\n",
      "| qf2_loss                | 26.085539  |\n",
      "| time_elapsed            | 23636      |\n",
      "| total timesteps         | 1988242    |\n",
      "| value_loss              | 9.660484   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.026770646 |\n",
      "| ent_coef_loss           | -2.968498   |\n",
      "| entropy                 | 14.392847   |\n",
      "| episodes                | 5700        |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 4.48e+03    |\n",
      "| n_updates               | 1996352     |\n",
      "| policy_loss             | -435.9751   |\n",
      "| qf1_loss                | 30.240345   |\n",
      "| qf2_loss                | 50.42679    |\n",
      "| time_elapsed            | 23723       |\n",
      "| total timesteps         | 1996451     |\n",
      "| value_loss              | 24.18204    |\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# TRAIN THE MODEL\n",
    "model.learn(total_timesteps=int(2e6), log_interval=10)\n",
    "model.save(\"humanoid_2M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading a model without an environment, this model cannot be trained until it has a valid environment.\n",
      "WARNING:tensorflow:From /home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:191: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:200: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/stable_baselines/sac/sac.py:142: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/stable_baselines/common/input.py:25: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/stable_baselines/sac/policies.py:194: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2d6dce4f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2d6dce4f10>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2d6dce4f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2d6dce4f10>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:From /home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/stable_baselines/common/tf_layers.py:57: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From /home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d7417bb90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d7417bb90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d7417bb90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d7417bb90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6dd05090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6dd05090>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6dd05090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6dd05090>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6dce4f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6dce4f10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6dce4f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6dce4f10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6dce4f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6dce4f10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6dce4f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6dce4f10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From /home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/stable_baselines/sac/policies.py:216: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2d6c26f610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2d6c26f610>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2d6c26f610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2d6c26f610>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6c1ff990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6c1ff990>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6c1ff990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6c1ff990>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6c1ff810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6c1ff810>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6c1ff810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6c1ff810>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6c247410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6c247410>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6c247410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6c247410>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6c255290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6c255290>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6c255290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6c255290>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6c253510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6c253510>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6c253510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6c253510>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d911a0250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d911a0250>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d911a0250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d911a0250>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6c253190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6c253190>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6c253190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6c253190>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6debef10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6debef10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6debef10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6debef10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6c10a610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6c10a610>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6c10a610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6c10a610>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2d6c2c9d50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2d6c2c9d50>>: AttributeError: module 'gast' has no attribute 'Num'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2d6c2c9d50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2d6c2c9d50>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d7407ba50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d7407ba50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d7407ba50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d7407ba50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d7407ba50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d7407ba50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d7407ba50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d7407ba50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6debef10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6debef10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6debef10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6debef10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6dd05f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6dd05f10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6dd05f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6dd05f10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6dd05f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6dd05f10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6dd05f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6dd05f10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6dd05f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6dd05f10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6dd05f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6dd05f10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2d911a0250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2d911a0250>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2d911a0250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2d911a0250>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d911a00d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d911a00d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d911a00d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d911a00d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6c2bb710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6c2bb710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6c2bb710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6c2bb710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6dd05710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6dd05710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6dd05710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6dd05710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From /home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/stable_baselines/sac/sac.py:233: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/stable_baselines/sac/sac.py:296: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/stable_baselines/sac/sac.py:316: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "Creating window glfw\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3339: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# RUN THE SAVED MODEL\n",
    "env = gym.make('Humanoid-v2')\n",
    "model = SAC.load(\"humanoid_2M\")\n",
    "\n",
    "for _ in range(10):\n",
    "    obs = env.reset()\n",
    "    for _ in range(1000):\n",
    "        action, _states = model.predict(obs)\n",
    "        obs, rewards, dones, info = env.step(action)\n",
    "        env.render()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800\"\n",
       "            src=\"http://localhost:6006\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f849406fcd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid info file: '/tmp/.tensorboard-info/pid-38328.info'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/tensorboard/manager.py\", line 149, in _info_from_string\n",
      "    json_value = json.loads(info_string)\n",
      "  File \"/home/mike/anaconda3/envs/rl/lib/python3.7/json/__init__.py\", line 348, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/home/mike/anaconda3/envs/rl/lib/python3.7/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/home/mike/anaconda3/envs/rl/lib/python3.7/json/decoder.py\", line 355, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/tensorboard/manager.py\", line 316, in get_all\n",
      "    info = _info_from_string(contents)\n",
      "  File \"/home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/tensorboard/manager.py\", line 151, in _info_from_string\n",
      "    raise ValueError(\"invalid JSON: %r\" % (info_string,))\n",
      "ValueError: invalid JSON: ''\n"
     ]
    }
   ],
   "source": [
    "# DISPLAY THE RESULTS\n",
    "%tensorboard --logdir sac_humanoid_walk_tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task: Stand up from a flat beginning position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:191: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:200: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/stable_baselines/sac/sac.py:142: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/stable_baselines/common/input.py:25: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/stable_baselines/sac/policies.py:194: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8482bf8590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8482bf8590>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8482bf8590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8482bf8590>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:From /home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/stable_baselines/common/tf_layers.py:57: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From /home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8482bf8490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8482bf8490>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8482bf8490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8482bf8490>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f848ce911d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f848ce911d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f848ce911d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f848ce911d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f848ce914d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f848ce914d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f848ce914d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f848ce914d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f848ce914d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f848ce914d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f848ce914d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f848ce914d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From /home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/stable_baselines/sac/policies.py:216: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f848008c1d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f848008c1d0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f848008c1d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f848008c1d0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8480082510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8480082510>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8480082510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8480082510>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f84a8665ed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f84a8665ed0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f84a8665ed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f84a8665ed0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8482bf8c90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8482bf8c90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8482bf8c90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8482bf8c90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f84af4c1c10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f84af4c1c10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f84af4c1c10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f84af4c1c10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f84af4c1c10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f84af4c1c10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f84af4c1c10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f84af4c1c10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f848016df50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f848016df50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f848016df50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f848016df50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8482bf8490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8482bf8490>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8482bf8490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8482bf8490>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8468754650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8468754650>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8468754650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8468754650>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f84800e3ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f84800e3ad0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f84800e3ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f84800e3ad0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8480082390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8480082390>>: AttributeError: module 'gast' has no attribute 'Num'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8480082390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8480082390>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f848008c650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f848008c650>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f848008c650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f848008c650>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8480080ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8480080ad0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8480080ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8480080ad0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8468754650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8468754650>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8468754650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8468754650>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f84af4c1c10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f84af4c1c10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f84af4c1c10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f84af4c1c10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f84af4c1c10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f84af4c1c10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f84af4c1c10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f84af4c1c10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f84800e3410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f84800e3410>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f84800e3410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f84800e3410>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8480040210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8480040210>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8480040210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8480040210>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8482bf8490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8482bf8490>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8482bf8490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8482bf8490>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f848000aa50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f848000aa50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f848000aa50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f848000aa50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f848000a090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f848000a090>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f848000a090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f848000a090>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From /home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/stable_baselines/sac/sac.py:233: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/stable_baselines/sac/sac.py:296: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/stable_baselines/sac/sac.py:316: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DEFINE THE ENVIRONMENT/MODEL WITH TUNED PARAMETERS\n",
    "env = gym.make('HumanoidStandup-v2')\n",
    "policy_kwargs = dict(layers=[256, 256])\n",
    "model = SAC(MlpPolicy, env, verbose=1, tensorboard_log=\"./sac_humanoid_standup_tensorboard/\", \n",
    "            policy_kwargs=policy_kwargs, buffer_size=1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/stable_baselines/common/base_class.py:1143: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.3715919  |\n",
      "| ent_coef_loss           | 1.0368845  |\n",
      "| entropy                 | 15.556219  |\n",
      "| episodes                | 10         |\n",
      "| fps                     | 72         |\n",
      "| mean 100 episode reward | 7.06e+04   |\n",
      "| n_updates               | 8901       |\n",
      "| policy_loss             | -2343.0728 |\n",
      "| qf1_loss                | 442.96002  |\n",
      "| qf2_loss                | 353.17847  |\n",
      "| time_elapsed            | 123        |\n",
      "| total timesteps         | 9000       |\n",
      "| value_loss              | 398.77277  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.6711767  |\n",
      "| ent_coef_loss           | 0.33287117 |\n",
      "| entropy                 | 15.5787325 |\n",
      "| episodes                | 20         |\n",
      "| fps                     | 81         |\n",
      "| mean 100 episode reward | 7.52e+04   |\n",
      "| n_updates               | 18901      |\n",
      "| policy_loss             | -4535.7314 |\n",
      "| qf1_loss                | 2131.247   |\n",
      "| qf2_loss                | 1931.5359  |\n",
      "| time_elapsed            | 234        |\n",
      "| total timesteps         | 19000      |\n",
      "| value_loss              | 1357.7815  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.7404186  |\n",
      "| ent_coef_loss           | 0.23721056 |\n",
      "| entropy                 | 15.481803  |\n",
      "| episodes                | 30         |\n",
      "| fps                     | 81         |\n",
      "| mean 100 episode reward | 8.04e+04   |\n",
      "| n_updates               | 28901      |\n",
      "| policy_loss             | -5633.621  |\n",
      "| qf1_loss                | 4343.631   |\n",
      "| qf2_loss                | 4476.461   |\n",
      "| time_elapsed            | 354        |\n",
      "| total timesteps         | 29000      |\n",
      "| value_loss              | 5531.1274  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.7944754   |\n",
      "| ent_coef_loss           | -0.22849077 |\n",
      "| entropy                 | 15.390942   |\n",
      "| episodes                | 40          |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 7.88e+04    |\n",
      "| n_updates               | 38901       |\n",
      "| policy_loss             | -5579.257   |\n",
      "| qf1_loss                | 4988.739    |\n",
      "| qf2_loss                | 4873.195    |\n",
      "| time_elapsed            | 467         |\n",
      "| total timesteps         | 39000       |\n",
      "| value_loss              | 19163.492   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.91131836  |\n",
      "| ent_coef_loss           | -0.04836991 |\n",
      "| entropy                 | 15.470493   |\n",
      "| episodes                | 50          |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 8.14e+04    |\n",
      "| n_updates               | 48901       |\n",
      "| policy_loss             | -6489.4336  |\n",
      "| qf1_loss                | 3632.4878   |\n",
      "| qf2_loss                | 4756.6567   |\n",
      "| time_elapsed            | 580         |\n",
      "| total timesteps         | 49000       |\n",
      "| value_loss              | 4223.5454   |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| current_lr              | 0.0003       |\n",
      "| ent_coef                | 0.9530886    |\n",
      "| ent_coef_loss           | -0.023826616 |\n",
      "| entropy                 | 15.43108     |\n",
      "| episodes                | 60           |\n",
      "| fps                     | 85           |\n",
      "| mean 100 episode reward | 8.12e+04     |\n",
      "| n_updates               | 58901        |\n",
      "| policy_loss             | -6070.8677   |\n",
      "| qf1_loss                | 3748.1333    |\n",
      "| qf2_loss                | 4197.015     |\n",
      "| time_elapsed            | 691          |\n",
      "| total timesteps         | 59000        |\n",
      "| value_loss              | 4184.997     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.9649788   |\n",
      "| ent_coef_loss           | 0.024068503 |\n",
      "| entropy                 | 15.278772   |\n",
      "| episodes                | 70          |\n",
      "| fps                     | 86          |\n",
      "| mean 100 episode reward | 8.31e+04    |\n",
      "| n_updates               | 68901       |\n",
      "| policy_loss             | -6521.9233  |\n",
      "| qf1_loss                | 12351.469   |\n",
      "| qf2_loss                | 11843.029   |\n",
      "| time_elapsed            | 799         |\n",
      "| total timesteps         | 69000       |\n",
      "| value_loss              | 4399.708    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 1.0225247   |\n",
      "| ent_coef_loss           | 0.024960719 |\n",
      "| entropy                 | 15.667633   |\n",
      "| episodes                | 80          |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 8.42e+04    |\n",
      "| n_updates               | 78901       |\n",
      "| policy_loss             | -5683.203   |\n",
      "| qf1_loss                | 6198.789    |\n",
      "| qf2_loss                | 7304.7393   |\n",
      "| time_elapsed            | 921         |\n",
      "| total timesteps         | 79000       |\n",
      "| value_loss              | 3003.3955   |\n",
      "-----------------------------------------\n",
      "--------------------------------------------\n",
      "| current_lr              | 0.0003         |\n",
      "| ent_coef                | 0.98686564     |\n",
      "| ent_coef_loss           | -0.00066134706 |\n",
      "| entropy                 | 15.527781      |\n",
      "| episodes                | 90             |\n",
      "| fps                     | 84             |\n",
      "| mean 100 episode reward | 8.53e+04       |\n",
      "| n_updates               | 88901          |\n",
      "| policy_loss             | -6058.24       |\n",
      "| qf1_loss                | 4870.6367      |\n",
      "| qf2_loss                | 3866.6895      |\n",
      "| time_elapsed            | 1057           |\n",
      "| total timesteps         | 89000          |\n",
      "| value_loss              | 1884.6318      |\n",
      "--------------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 1.0891664   |\n",
      "| ent_coef_loss           | -0.06549576 |\n",
      "| entropy                 | 15.345516   |\n",
      "| episodes                | 100         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 8.79e+04    |\n",
      "| n_updates               | 98901       |\n",
      "| policy_loss             | -6226.6743  |\n",
      "| qf1_loss                | 9111.873    |\n",
      "| qf2_loss                | 7033.613    |\n",
      "| time_elapsed            | 1167        |\n",
      "| total timesteps         | 99000       |\n",
      "| value_loss              | 5335.1055   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 1.0957052   |\n",
      "| ent_coef_loss           | -0.09253874 |\n",
      "| entropy                 | 15.074825   |\n",
      "| episodes                | 110         |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 9.24e+04    |\n",
      "| n_updates               | 108901      |\n",
      "| policy_loss             | -7351.75    |\n",
      "| qf1_loss                | 5280.6294   |\n",
      "| qf2_loss                | 3541.3757   |\n",
      "| time_elapsed            | 1277        |\n",
      "| total timesteps         | 109000      |\n",
      "| value_loss              | 2052.3545   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 1.196986    |\n",
      "| ent_coef_loss           | -0.18047364 |\n",
      "| entropy                 | 15.492748   |\n",
      "| episodes                | 120         |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 9.44e+04    |\n",
      "| n_updates               | 118901      |\n",
      "| policy_loss             | -5767.5444  |\n",
      "| qf1_loss                | 6202.6396   |\n",
      "| qf2_loss                | 5878.749    |\n",
      "| time_elapsed            | 1389        |\n",
      "| total timesteps         | 119000      |\n",
      "| value_loss              | 2478.8616   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 1.225881   |\n",
      "| ent_coef_loss           | 0.38030902 |\n",
      "| entropy                 | 15.366411  |\n",
      "| episodes                | 130        |\n",
      "| fps                     | 86         |\n",
      "| mean 100 episode reward | 9.26e+04   |\n",
      "| n_updates               | 128901     |\n",
      "| policy_loss             | -6394.011  |\n",
      "| qf1_loss                | 4555.45    |\n",
      "| qf2_loss                | 3109.5334  |\n",
      "| time_elapsed            | 1497       |\n",
      "| total timesteps         | 129000     |\n",
      "| value_loss              | 1338.5935  |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| current_lr              | 0.0003       |\n",
      "| ent_coef                | 1.4051741    |\n",
      "| ent_coef_loss           | -0.039193362 |\n",
      "| entropy                 | 15.407162    |\n",
      "| episodes                | 140          |\n",
      "| fps                     | 86           |\n",
      "| mean 100 episode reward | 9.28e+04     |\n",
      "| n_updates               | 138901       |\n",
      "| policy_loss             | -6354.6416   |\n",
      "| qf1_loss                | 4315.1826    |\n",
      "| qf2_loss                | 4202.98      |\n",
      "| time_elapsed            | 1609         |\n",
      "| total timesteps         | 139000       |\n",
      "| value_loss              | 1714.8142    |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 1.3612244   |\n",
      "| ent_coef_loss           | -0.77041334 |\n",
      "| entropy                 | 15.614488   |\n",
      "| episodes                | 150         |\n",
      "| fps                     | 86          |\n",
      "| mean 100 episode reward | 9.18e+04    |\n",
      "| n_updates               | 148901      |\n",
      "| policy_loss             | -5624.4473  |\n",
      "| qf1_loss                | 7261.7246   |\n",
      "| qf2_loss                | 6434.4644   |\n",
      "| time_elapsed            | 1720        |\n",
      "| total timesteps         | 149000      |\n",
      "| value_loss              | 4290.797    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 1.4525279   |\n",
      "| ent_coef_loss           | -0.44756374 |\n",
      "| entropy                 | 15.046814   |\n",
      "| episodes                | 160         |\n",
      "| fps                     | 86          |\n",
      "| mean 100 episode reward | 9.33e+04    |\n",
      "| n_updates               | 158901      |\n",
      "| policy_loss             | -5848.4756  |\n",
      "| qf1_loss                | 5567.4395   |\n",
      "| qf2_loss                | 6816.104    |\n",
      "| time_elapsed            | 1839        |\n",
      "| total timesteps         | 159000      |\n",
      "| value_loss              | 9036.186    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 1.4254271   |\n",
      "| ent_coef_loss           | 0.073512405 |\n",
      "| entropy                 | 15.655062   |\n",
      "| episodes                | 170         |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 9.31e+04    |\n",
      "| n_updates               | 168901      |\n",
      "| policy_loss             | -5734.6846  |\n",
      "| qf1_loss                | 4598.5967   |\n",
      "| qf2_loss                | 3686.8398   |\n",
      "| time_elapsed            | 1967        |\n",
      "| total timesteps         | 169000      |\n",
      "| value_loss              | 3940.8193   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 1.4881016  |\n",
      "| ent_coef_loss           | -0.6972947 |\n",
      "| entropy                 | 15.368418  |\n",
      "| episodes                | 180        |\n",
      "| fps                     | 85         |\n",
      "| mean 100 episode reward | 9.35e+04   |\n",
      "| n_updates               | 178901     |\n",
      "| policy_loss             | -6119.011  |\n",
      "| qf1_loss                | 6139.709   |\n",
      "| qf2_loss                | 7125.1763  |\n",
      "| time_elapsed            | 2082       |\n",
      "| total timesteps         | 179000     |\n",
      "| value_loss              | 4351.254   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ent_coef                | 1.4632401 |\n",
      "| ent_coef_loss           | -0.293953 |\n",
      "| entropy                 | 15.251804 |\n",
      "| episodes                | 190       |\n",
      "| fps                     | 86        |\n",
      "| mean 100 episode reward | 9.32e+04  |\n",
      "| n_updates               | 188901    |\n",
      "| policy_loss             | -5906.917 |\n",
      "| qf1_loss                | 2745.4658 |\n",
      "| qf2_loss                | 2826.5186 |\n",
      "| time_elapsed            | 2192      |\n",
      "| total timesteps         | 189000    |\n",
      "| value_loss              | 2593.3535 |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 1.46479    |\n",
      "| ent_coef_loss           | 1.1488049  |\n",
      "| entropy                 | 15.894516  |\n",
      "| episodes                | 200        |\n",
      "| fps                     | 86         |\n",
      "| mean 100 episode reward | 9.16e+04   |\n",
      "| n_updates               | 198901     |\n",
      "| policy_loss             | -5370.4893 |\n",
      "| qf1_loss                | 5245.341   |\n",
      "| qf2_loss                | 4316.33    |\n",
      "| time_elapsed            | 2307       |\n",
      "| total timesteps         | 199000     |\n",
      "| value_loss              | 4588.7     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 1.45431    |\n",
      "| ent_coef_loss           | 0.35042897 |\n",
      "| entropy                 | 15.600214  |\n",
      "| episodes                | 210        |\n",
      "| fps                     | 86         |\n",
      "| mean 100 episode reward | 9.08e+04   |\n",
      "| n_updates               | 208901     |\n",
      "| policy_loss             | -5497.0444 |\n",
      "| qf1_loss                | 4328.709   |\n",
      "| qf2_loss                | 3337.8545  |\n",
      "| time_elapsed            | 2409       |\n",
      "| total timesteps         | 209000     |\n",
      "| value_loss              | 2112.594   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 1.4236577   |\n",
      "| ent_coef_loss           | -0.18473989 |\n",
      "| entropy                 | 15.571702   |\n",
      "| episodes                | 220         |\n",
      "| fps                     | 87          |\n",
      "| mean 100 episode reward | 9.57e+04    |\n",
      "| n_updates               | 218901      |\n",
      "| policy_loss             | -5692.118   |\n",
      "| qf1_loss                | 76824.82    |\n",
      "| qf2_loss                | 76432.836   |\n",
      "| time_elapsed            | 2512        |\n",
      "| total timesteps         | 219000      |\n",
      "| value_loss              | 1694.6729   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 1.4841927   |\n",
      "| ent_coef_loss           | -0.08256826 |\n",
      "| entropy                 | 15.51011    |\n",
      "| episodes                | 230         |\n",
      "| fps                     | 87          |\n",
      "| mean 100 episode reward | 1.03e+05    |\n",
      "| n_updates               | 228901      |\n",
      "| policy_loss             | -6387.3584  |\n",
      "| qf1_loss                | 3598.6226   |\n",
      "| qf2_loss                | 3752.0615   |\n",
      "| time_elapsed            | 2616        |\n",
      "| total timesteps         | 229000      |\n",
      "| value_loss              | 1914.3262   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 1.6294069   |\n",
      "| ent_coef_loss           | -0.46904534 |\n",
      "| entropy                 | 15.532251   |\n",
      "| episodes                | 240         |\n",
      "| fps                     | 87          |\n",
      "| mean 100 episode reward | 1.1e+05     |\n",
      "| n_updates               | 238901      |\n",
      "| policy_loss             | -6466.5195  |\n",
      "| qf1_loss                | 5721.165    |\n",
      "| qf2_loss                | 4080.1797   |\n",
      "| time_elapsed            | 2719        |\n",
      "| total timesteps         | 239000      |\n",
      "| value_loss              | 11112.541   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 1.6481155   |\n",
      "| ent_coef_loss           | 0.024832398 |\n",
      "| entropy                 | 15.933384   |\n",
      "| episodes                | 250         |\n",
      "| fps                     | 88          |\n",
      "| mean 100 episode reward | 1.16e+05    |\n",
      "| n_updates               | 248901      |\n",
      "| policy_loss             | -6675.761   |\n",
      "| qf1_loss                | 6264.2627   |\n",
      "| qf2_loss                | 5406.026    |\n",
      "| time_elapsed            | 2822        |\n",
      "| total timesteps         | 249000      |\n",
      "| value_loss              | 2980.9175   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ent_coef                | 1.6927533 |\n",
      "| ent_coef_loss           | 0.3556143 |\n",
      "| entropy                 | 15.700617 |\n",
      "| episodes                | 260       |\n",
      "| fps                     | 88        |\n",
      "| mean 100 episode reward | 1.21e+05  |\n",
      "| n_updates               | 258901    |\n",
      "| policy_loss             | -7074.794 |\n",
      "| qf1_loss                | 7467.92   |\n",
      "| qf2_loss                | 8068.957  |\n",
      "| time_elapsed            | 2924      |\n",
      "| total timesteps         | 259000    |\n",
      "| value_loss              | 5124.861  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ent_coef                | 1.7176265 |\n",
      "| ent_coef_loss           | 0.2770148 |\n",
      "| entropy                 | 15.528044 |\n",
      "| episodes                | 270       |\n",
      "| fps                     | 88        |\n",
      "| mean 100 episode reward | 1.27e+05  |\n",
      "| n_updates               | 268901    |\n",
      "| policy_loss             | -6951.084 |\n",
      "| qf1_loss                | 2420.5786 |\n",
      "| qf2_loss                | 2750.9927 |\n",
      "| time_elapsed            | 3026      |\n",
      "| total timesteps         | 269000    |\n",
      "| value_loss              | 2781.3853 |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 1.839571   |\n",
      "| ent_coef_loss           | 1.269854   |\n",
      "| entropy                 | 15.908634  |\n",
      "| episodes                | 280        |\n",
      "| fps                     | 89         |\n",
      "| mean 100 episode reward | 1.32e+05   |\n",
      "| n_updates               | 278901     |\n",
      "| policy_loss             | -6712.6787 |\n",
      "| qf1_loss                | 6110.341   |\n",
      "| qf2_loss                | 5758.587   |\n",
      "| time_elapsed            | 3129       |\n",
      "| total timesteps         | 279000     |\n",
      "| value_loss              | 3094.697   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 1.8300838  |\n",
      "| ent_coef_loss           | 0.25618315 |\n",
      "| entropy                 | 15.563644  |\n",
      "| episodes                | 290        |\n",
      "| fps                     | 89         |\n",
      "| mean 100 episode reward | 1.36e+05   |\n",
      "| n_updates               | 288901     |\n",
      "| policy_loss             | -7121.2373 |\n",
      "| qf1_loss                | 8082.711   |\n",
      "| qf2_loss                | 7022.163   |\n",
      "| time_elapsed            | 3231       |\n",
      "| total timesteps         | 289000     |\n",
      "| value_loss              | 15018.922  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 1.8458633  |\n",
      "| ent_coef_loss           | -1.3831553 |\n",
      "| entropy                 | 15.73999   |\n",
      "| episodes                | 300        |\n",
      "| fps                     | 89         |\n",
      "| mean 100 episode reward | 1.4e+05    |\n",
      "| n_updates               | 298901     |\n",
      "| policy_loss             | -8014.5874 |\n",
      "| qf1_loss                | 3175.9307  |\n",
      "| qf2_loss                | 3643.684   |\n",
      "| time_elapsed            | 3332       |\n",
      "| total timesteps         | 299000     |\n",
      "| value_loss              | 1777.47    |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ent_coef                | 1.7951214 |\n",
      "| ent_coef_loss           | 0.2646631 |\n",
      "| entropy                 | 15.602675 |\n",
      "| episodes                | 310       |\n",
      "| fps                     | 89        |\n",
      "| mean 100 episode reward | 1.45e+05  |\n",
      "| n_updates               | 308901    |\n",
      "| policy_loss             | -7485.061 |\n",
      "| qf1_loss                | 6156.746  |\n",
      "| qf2_loss                | 9013.345  |\n",
      "| time_elapsed            | 3434      |\n",
      "| total timesteps         | 309000    |\n",
      "| value_loss              | 2604.2085 |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| current_lr              | 0.0003       |\n",
      "| ent_coef                | 1.927651     |\n",
      "| ent_coef_loss           | -0.044488907 |\n",
      "| entropy                 | 15.761637    |\n",
      "| episodes                | 320          |\n",
      "| fps                     | 90           |\n",
      "| mean 100 episode reward | 1.47e+05     |\n",
      "| n_updates               | 318901       |\n",
      "| policy_loss             | -7570.6035   |\n",
      "| qf1_loss                | 4272.3584    |\n",
      "| qf2_loss                | 3760.8252    |\n",
      "| time_elapsed            | 3537         |\n",
      "| total timesteps         | 319000       |\n",
      "| value_loss              | 2722.4675    |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 1.986292   |\n",
      "| ent_coef_loss           | 1.071183   |\n",
      "| entropy                 | 15.858602  |\n",
      "| episodes                | 330        |\n",
      "| fps                     | 90         |\n",
      "| mean 100 episode reward | 1.47e+05   |\n",
      "| n_updates               | 328901     |\n",
      "| policy_loss             | -6640.6943 |\n",
      "| qf1_loss                | 5684.5127  |\n",
      "| qf2_loss                | 5434.205   |\n",
      "| time_elapsed            | 3639       |\n",
      "| total timesteps         | 329000     |\n",
      "| value_loss              | 3216.974   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 1.9474449  |\n",
      "| ent_coef_loss           | -0.7937011 |\n",
      "| entropy                 | 15.451495  |\n",
      "| episodes                | 340        |\n",
      "| fps                     | 90         |\n",
      "| mean 100 episode reward | 1.49e+05   |\n",
      "| n_updates               | 338901     |\n",
      "| policy_loss             | -7960.6724 |\n",
      "| qf1_loss                | 4336.3037  |\n",
      "| qf2_loss                | 3523.7341  |\n",
      "| time_elapsed            | 3742       |\n",
      "| total timesteps         | 339000     |\n",
      "| value_loss              | 2696.7705  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 2.131418    |\n",
      "| ent_coef_loss           | -0.47000718 |\n",
      "| entropy                 | 15.578976   |\n",
      "| episodes                | 350         |\n",
      "| fps                     | 90          |\n",
      "| mean 100 episode reward | 1.49e+05    |\n",
      "| n_updates               | 348901      |\n",
      "| policy_loss             | -8164.501   |\n",
      "| qf1_loss                | 8939.956    |\n",
      "| qf2_loss                | 9540.943    |\n",
      "| time_elapsed            | 3844        |\n",
      "| total timesteps         | 349000      |\n",
      "| value_loss              | 10919.555   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 2.1885989  |\n",
      "| ent_coef_loss           | 0.15647899 |\n",
      "| entropy                 | 15.514972  |\n",
      "| episodes                | 360        |\n",
      "| fps                     | 90         |\n",
      "| mean 100 episode reward | 1.5e+05    |\n",
      "| n_updates               | 358901     |\n",
      "| policy_loss             | -8059.3506 |\n",
      "| qf1_loss                | 4401.45    |\n",
      "| qf2_loss                | 3527.103   |\n",
      "| time_elapsed            | 3946       |\n",
      "| total timesteps         | 359000     |\n",
      "| value_loss              | 2485.9827  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 2.1038551   |\n",
      "| ent_coef_loss           | -0.41177452 |\n",
      "| entropy                 | 15.598106   |\n",
      "| episodes                | 370         |\n",
      "| fps                     | 91          |\n",
      "| mean 100 episode reward | 1.5e+05     |\n",
      "| n_updates               | 368901      |\n",
      "| policy_loss             | -7617.4346  |\n",
      "| qf1_loss                | 7026.7754   |\n",
      "| qf2_loss                | 5608.7285   |\n",
      "| time_elapsed            | 4048        |\n",
      "| total timesteps         | 369000      |\n",
      "| value_loss              | 5470.3037   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 2.1388962   |\n",
      "| ent_coef_loss           | -0.33245918 |\n",
      "| entropy                 | 15.297967   |\n",
      "| episodes                | 380         |\n",
      "| fps                     | 91          |\n",
      "| mean 100 episode reward | 1.5e+05     |\n",
      "| n_updates               | 378901      |\n",
      "| policy_loss             | -8784.496   |\n",
      "| qf1_loss                | 4565.6387   |\n",
      "| qf2_loss                | 4697.3594   |\n",
      "| time_elapsed            | 4136        |\n",
      "| total timesteps         | 379000      |\n",
      "| value_loss              | 1513.2709   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 2.1180196  |\n",
      "| ent_coef_loss           | -1.2850449 |\n",
      "| entropy                 | 15.361796  |\n",
      "| episodes                | 390        |\n",
      "| fps                     | 92         |\n",
      "| mean 100 episode reward | 1.51e+05   |\n",
      "| n_updates               | 388901     |\n",
      "| policy_loss             | -7847.2754 |\n",
      "| qf1_loss                | 5705.274   |\n",
      "| qf2_loss                | 5188.9766  |\n",
      "| time_elapsed            | 4221       |\n",
      "| total timesteps         | 389000     |\n",
      "| value_loss              | 8376.502   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 2.087814    |\n",
      "| ent_coef_loss           | -0.60857546 |\n",
      "| entropy                 | 15.318112   |\n",
      "| episodes                | 400         |\n",
      "| fps                     | 92          |\n",
      "| mean 100 episode reward | 1.51e+05    |\n",
      "| n_updates               | 398901      |\n",
      "| policy_loss             | -8032.5933  |\n",
      "| qf1_loss                | 3981.9363   |\n",
      "| qf2_loss                | 3850.0132   |\n",
      "| time_elapsed            | 4306        |\n",
      "| total timesteps         | 399000      |\n",
      "| value_loss              | 16118.218   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 2.18402    |\n",
      "| ent_coef_loss           | -0.7372904 |\n",
      "| entropy                 | 15.465591  |\n",
      "| episodes                | 410        |\n",
      "| fps                     | 93         |\n",
      "| mean 100 episode reward | 1.49e+05   |\n",
      "| n_updates               | 408901     |\n",
      "| policy_loss             | -8636.848  |\n",
      "| qf1_loss                | 3570.6475  |\n",
      "| qf2_loss                | 4647.761   |\n",
      "| time_elapsed            | 4391       |\n",
      "| total timesteps         | 409000     |\n",
      "| value_loss              | 7050.6826  |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ent_coef                | 2.2658424 |\n",
      "| ent_coef_loss           | -1.19572  |\n",
      "| entropy                 | 15.519917 |\n",
      "| episodes                | 420       |\n",
      "| fps                     | 93        |\n",
      "| mean 100 episode reward | 1.48e+05  |\n",
      "| n_updates               | 418901    |\n",
      "| policy_loss             | -7996.476 |\n",
      "| qf1_loss                | 3072.5742 |\n",
      "| qf2_loss                | 2928.7568 |\n",
      "| time_elapsed            | 4480      |\n",
      "| total timesteps         | 419000    |\n",
      "| value_loss              | 3175.725  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 2.2303016  |\n",
      "| ent_coef_loss           | -1.5060706 |\n",
      "| entropy                 | 15.416103  |\n",
      "| episodes                | 430        |\n",
      "| fps                     | 93         |\n",
      "| mean 100 episode reward | 1.48e+05   |\n",
      "| n_updates               | 428901     |\n",
      "| policy_loss             | -8015.4756 |\n",
      "| qf1_loss                | 3201.8767  |\n",
      "| qf2_loss                | 3340.6125  |\n",
      "| time_elapsed            | 4575       |\n",
      "| total timesteps         | 429000     |\n",
      "| value_loss              | 3583.2773  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 2.3346395  |\n",
      "| ent_coef_loss           | -1.4121429 |\n",
      "| entropy                 | 15.324377  |\n",
      "| episodes                | 440        |\n",
      "| fps                     | 94         |\n",
      "| mean 100 episode reward | 1.45e+05   |\n",
      "| n_updates               | 438901     |\n",
      "| policy_loss             | -8850.75   |\n",
      "| qf1_loss                | 7135.5244  |\n",
      "| qf2_loss                | 6539.604   |\n",
      "| time_elapsed            | 4665       |\n",
      "| total timesteps         | 439000     |\n",
      "| value_loss              | 4029.4338  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 2.2257576  |\n",
      "| ent_coef_loss           | 1.0970005  |\n",
      "| entropy                 | 15.463503  |\n",
      "| episodes                | 450        |\n",
      "| fps                     | 94         |\n",
      "| mean 100 episode reward | 1.46e+05   |\n",
      "| n_updates               | 448901     |\n",
      "| policy_loss             | -7839.9814 |\n",
      "| qf1_loss                | 3683.877   |\n",
      "| qf2_loss                | 3600.6182  |\n",
      "| time_elapsed            | 4754       |\n",
      "| total timesteps         | 449000     |\n",
      "| value_loss              | 3207.9463  |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ent_coef                | 2.3421578 |\n",
      "| ent_coef_loss           | 0.4590369 |\n",
      "| entropy                 | 15.693654 |\n",
      "| episodes                | 460       |\n",
      "| fps                     | 94        |\n",
      "| mean 100 episode reward | 1.45e+05  |\n",
      "| n_updates               | 458901    |\n",
      "| policy_loss             | -8425.426 |\n",
      "| qf1_loss                | 2857.8792 |\n",
      "| qf2_loss                | 3882.831  |\n",
      "| time_elapsed            | 4842      |\n",
      "| total timesteps         | 459000    |\n",
      "| value_loss              | 3137.755  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ent_coef                | 2.3146546 |\n",
      "| ent_coef_loss           | 1.4522946 |\n",
      "| entropy                 | 16.13715  |\n",
      "| episodes                | 470       |\n",
      "| fps                     | 95        |\n",
      "| mean 100 episode reward | 1.45e+05  |\n",
      "| n_updates               | 468901    |\n",
      "| policy_loss             | -8036.829 |\n",
      "| qf1_loss                | 4649.661  |\n",
      "| qf2_loss                | 3806.0654 |\n",
      "| time_elapsed            | 4933      |\n",
      "| total timesteps         | 469000    |\n",
      "| value_loss              | 5671.209  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 2.2816272  |\n",
      "| ent_coef_loss           | 0.40581593 |\n",
      "| entropy                 | 15.541644  |\n",
      "| episodes                | 480        |\n",
      "| fps                     | 95         |\n",
      "| mean 100 episode reward | 1.43e+05   |\n",
      "| n_updates               | 478901     |\n",
      "| policy_loss             | -8034.7666 |\n",
      "| qf1_loss                | 19208.027  |\n",
      "| qf2_loss                | 15189.404  |\n",
      "| time_elapsed            | 5024       |\n",
      "| total timesteps         | 479000     |\n",
      "| value_loss              | 4710.9873  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 2.3650136  |\n",
      "| ent_coef_loss           | 1.4572346  |\n",
      "| entropy                 | 15.600475  |\n",
      "| episodes                | 490        |\n",
      "| fps                     | 95         |\n",
      "| mean 100 episode reward | 1.43e+05   |\n",
      "| n_updates               | 488901     |\n",
      "| policy_loss             | -7785.7905 |\n",
      "| qf1_loss                | 2258.856   |\n",
      "| qf2_loss                | 3143.0315  |\n",
      "| time_elapsed            | 5112       |\n",
      "| total timesteps         | 489000     |\n",
      "| value_loss              | 6903.8643  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 2.3407176  |\n",
      "| ent_coef_loss           | -1.0068928 |\n",
      "| entropy                 | 15.2495985 |\n",
      "| episodes                | 500        |\n",
      "| fps                     | 95         |\n",
      "| mean 100 episode reward | 1.42e+05   |\n",
      "| n_updates               | 498901     |\n",
      "| policy_loss             | -8231.969  |\n",
      "| qf1_loss                | 5141.252   |\n",
      "| qf2_loss                | 7308.2856  |\n",
      "| time_elapsed            | 5203       |\n",
      "| total timesteps         | 499000     |\n",
      "| value_loss              | 7318.5664  |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ent_coef                | 2.2773495 |\n",
      "| ent_coef_loss           | 0.6399425 |\n",
      "| entropy                 | 15.563597 |\n",
      "| episodes                | 510       |\n",
      "| fps                     | 96        |\n",
      "| mean 100 episode reward | 1.42e+05  |\n",
      "| n_updates               | 508901    |\n",
      "| policy_loss             | -8298.111 |\n",
      "| qf1_loss                | 3216.2136 |\n",
      "| qf2_loss                | 4301.9604 |\n",
      "| time_elapsed            | 5292      |\n",
      "| total timesteps         | 509000    |\n",
      "| value_loss              | 6846.349  |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 2.2607813  |\n",
      "| ent_coef_loss           | 2.7545269  |\n",
      "| entropy                 | 15.811618  |\n",
      "| episodes                | 520        |\n",
      "| fps                     | 96         |\n",
      "| mean 100 episode reward | 1.41e+05   |\n",
      "| n_updates               | 518901     |\n",
      "| policy_loss             | -6584.0264 |\n",
      "| qf1_loss                | 7649.201   |\n",
      "| qf2_loss                | 5599.502   |\n",
      "| time_elapsed            | 5385       |\n",
      "| total timesteps         | 519000     |\n",
      "| value_loss              | 2988.1274  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 2.1665118   |\n",
      "| ent_coef_loss           | -0.91029817 |\n",
      "| entropy                 | 15.551452   |\n",
      "| episodes                | 530         |\n",
      "| fps                     | 96          |\n",
      "| mean 100 episode reward | 1.4e+05     |\n",
      "| n_updates               | 528901      |\n",
      "| policy_loss             | -9161.668   |\n",
      "| qf1_loss                | 3697.2214   |\n",
      "| qf2_loss                | 2474.9937   |\n",
      "| time_elapsed            | 5479        |\n",
      "| total timesteps         | 529000      |\n",
      "| value_loss              | 2210.936    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 2.297523   |\n",
      "| ent_coef_loss           | 0.40789625 |\n",
      "| entropy                 | 15.762787  |\n",
      "| episodes                | 540        |\n",
      "| fps                     | 96         |\n",
      "| mean 100 episode reward | 1.42e+05   |\n",
      "| n_updates               | 538901     |\n",
      "| policy_loss             | -8071.4404 |\n",
      "| qf1_loss                | 2630.8145  |\n",
      "| qf2_loss                | 3349.1628  |\n",
      "| time_elapsed            | 5567       |\n",
      "| total timesteps         | 539000     |\n",
      "| value_loss              | 6001.2627  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 2.1498013  |\n",
      "| ent_coef_loss           | 0.11069986 |\n",
      "| entropy                 | 15.789854  |\n",
      "| episodes                | 550        |\n",
      "| fps                     | 96         |\n",
      "| mean 100 episode reward | 1.4e+05    |\n",
      "| n_updates               | 548901     |\n",
      "| policy_loss             | -7953.102  |\n",
      "| qf1_loss                | 9747.395   |\n",
      "| qf2_loss                | 11291.76   |\n",
      "| time_elapsed            | 5659       |\n",
      "| total timesteps         | 549000     |\n",
      "| value_loss              | 6119.6143  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 2.1885672  |\n",
      "| ent_coef_loss           | 0.57135487 |\n",
      "| entropy                 | 15.493459  |\n",
      "| episodes                | 560        |\n",
      "| fps                     | 97         |\n",
      "| mean 100 episode reward | 1.39e+05   |\n",
      "| n_updates               | 558901     |\n",
      "| policy_loss             | -8110.797  |\n",
      "| qf1_loss                | 4898.084   |\n",
      "| qf2_loss                | 4347.2305  |\n",
      "| time_elapsed            | 5750       |\n",
      "| total timesteps         | 559000     |\n",
      "| value_loss              | 4522.1973  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 2.337096   |\n",
      "| ent_coef_loss           | -2.6239338 |\n",
      "| entropy                 | 15.222135  |\n",
      "| episodes                | 570        |\n",
      "| fps                     | 97         |\n",
      "| mean 100 episode reward | 1.38e+05   |\n",
      "| n_updates               | 568901     |\n",
      "| policy_loss             | -9270.887  |\n",
      "| qf1_loss                | 5110.6035  |\n",
      "| qf2_loss                | 4228.407   |\n",
      "| time_elapsed            | 5845       |\n",
      "| total timesteps         | 569000     |\n",
      "| value_loss              | 2228.4092  |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ent_coef                | 2.346545  |\n",
      "| ent_coef_loss           | 1.2507576 |\n",
      "| entropy                 | 15.799614 |\n",
      "| episodes                | 580       |\n",
      "| fps                     | 97        |\n",
      "| mean 100 episode reward | 1.39e+05  |\n",
      "| n_updates               | 578901    |\n",
      "| policy_loss             | -7980.61  |\n",
      "| qf1_loss                | 6763.8545 |\n",
      "| qf2_loss                | 8755.025  |\n",
      "| time_elapsed            | 5946      |\n",
      "| total timesteps         | 579000    |\n",
      "| value_loss              | 2945.5222 |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 2.3523672  |\n",
      "| ent_coef_loss           | -0.5272965 |\n",
      "| entropy                 | 15.766816  |\n",
      "| episodes                | 590        |\n",
      "| fps                     | 97         |\n",
      "| mean 100 episode reward | 1.42e+05   |\n",
      "| n_updates               | 588901     |\n",
      "| policy_loss             | -8590.156  |\n",
      "| qf1_loss                | 6950.9893  |\n",
      "| qf2_loss                | 8037.67    |\n",
      "| time_elapsed            | 6053       |\n",
      "| total timesteps         | 589000     |\n",
      "| value_loss              | 16757.328  |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ent_coef                | 2.2575858 |\n",
      "| ent_coef_loss           | 0.7475432 |\n",
      "| entropy                 | 15.69975  |\n",
      "| episodes                | 600       |\n",
      "| fps                     | 97        |\n",
      "| mean 100 episode reward | 1.42e+05  |\n",
      "| n_updates               | 598901    |\n",
      "| policy_loss             | -7965.629 |\n",
      "| qf1_loss                | 6220.5986 |\n",
      "| qf2_loss                | 7569.132  |\n",
      "| time_elapsed            | 6156      |\n",
      "| total timesteps         | 599000    |\n",
      "| value_loss              | 5832.627  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 2.3614     |\n",
      "| ent_coef_loss           | -1.3632882 |\n",
      "| entropy                 | 15.568834  |\n",
      "| episodes                | 610        |\n",
      "| fps                     | 97         |\n",
      "| mean 100 episode reward | 1.43e+05   |\n",
      "| n_updates               | 608901     |\n",
      "| policy_loss             | -9112.215  |\n",
      "| qf1_loss                | 2963.8887  |\n",
      "| qf2_loss                | 3167.2332  |\n",
      "| time_elapsed            | 6259       |\n",
      "| total timesteps         | 609000     |\n",
      "| value_loss              | 2915.2139  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 2.4355416  |\n",
      "| ent_coef_loss           | -1.9078997 |\n",
      "| entropy                 | 15.33614   |\n",
      "| episodes                | 620        |\n",
      "| fps                     | 97         |\n",
      "| mean 100 episode reward | 1.44e+05   |\n",
      "| n_updates               | 618901     |\n",
      "| policy_loss             | -9172.3125 |\n",
      "| qf1_loss                | 2486.9185  |\n",
      "| qf2_loss                | 3127.2263  |\n",
      "| time_elapsed            | 6361       |\n",
      "| total timesteps         | 619000     |\n",
      "| value_loss              | 2745.082   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 2.3093762  |\n",
      "| ent_coef_loss           | 0.46046516 |\n",
      "| entropy                 | 15.571526  |\n",
      "| episodes                | 630        |\n",
      "| fps                     | 97         |\n",
      "| mean 100 episode reward | 1.47e+05   |\n",
      "| n_updates               | 628901     |\n",
      "| policy_loss             | -8986.384  |\n",
      "| qf1_loss                | 2820.0757  |\n",
      "| qf2_loss                | 2843.894   |\n",
      "| time_elapsed            | 6470       |\n",
      "| total timesteps         | 629000     |\n",
      "| value_loss              | 3263.1206  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 2.4028764   |\n",
      "| ent_coef_loss           | -0.22216415 |\n",
      "| entropy                 | 15.63065    |\n",
      "| episodes                | 640         |\n",
      "| fps                     | 97          |\n",
      "| mean 100 episode reward | 1.46e+05    |\n",
      "| n_updates               | 638901      |\n",
      "| policy_loss             | -8701.143   |\n",
      "| qf1_loss                | 3124.1208   |\n",
      "| qf2_loss                | 2925.9097   |\n",
      "| time_elapsed            | 6567        |\n",
      "| total timesteps         | 639000      |\n",
      "| value_loss              | 4722.7715   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 2.3283195  |\n",
      "| ent_coef_loss           | 1.5224438  |\n",
      "| entropy                 | 16.009146  |\n",
      "| episodes                | 650        |\n",
      "| fps                     | 97         |\n",
      "| mean 100 episode reward | 1.45e+05   |\n",
      "| n_updates               | 648901     |\n",
      "| policy_loss             | -7867.6367 |\n",
      "| qf1_loss                | 6078.2007  |\n",
      "| qf2_loss                | 4890.5767  |\n",
      "| time_elapsed            | 6658       |\n",
      "| total timesteps         | 649000     |\n",
      "| value_loss              | 3982.6467  |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ent_coef                | 2.393159  |\n",
      "| ent_coef_loss           | 1.6408587 |\n",
      "| entropy                 | 16.02755  |\n",
      "| episodes                | 660       |\n",
      "| fps                     | 97        |\n",
      "| mean 100 episode reward | 1.44e+05  |\n",
      "| n_updates               | 658901    |\n",
      "| policy_loss             | -7912.341 |\n",
      "| qf1_loss                | 2124.6238 |\n",
      "| qf2_loss                | 3102.062  |\n",
      "| time_elapsed            | 6762      |\n",
      "| total timesteps         | 659000    |\n",
      "| value_loss              | 1159.8308 |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ent_coef                | 2.3733132 |\n",
      "| ent_coef_loss           | 1.1411531 |\n",
      "| entropy                 | 16.103508 |\n",
      "| episodes                | 670       |\n",
      "| fps                     | 97        |\n",
      "| mean 100 episode reward | 1.45e+05  |\n",
      "| n_updates               | 668901    |\n",
      "| policy_loss             | -8360.538 |\n",
      "| qf1_loss                | 6156.097  |\n",
      "| qf2_loss                | 5868.1123 |\n",
      "| time_elapsed            | 6869      |\n",
      "| total timesteps         | 669000    |\n",
      "| value_loss              | 7518.5186 |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 2.5087986   |\n",
      "| ent_coef_loss           | -0.32963252 |\n",
      "| entropy                 | 15.469124   |\n",
      "| episodes                | 680         |\n",
      "| fps                     | 97          |\n",
      "| mean 100 episode reward | 1.44e+05    |\n",
      "| n_updates               | 678901      |\n",
      "| policy_loss             | -8776.13    |\n",
      "| qf1_loss                | 5527.558    |\n",
      "| qf2_loss                | 5511.5156   |\n",
      "| time_elapsed            | 6968        |\n",
      "| total timesteps         | 679000      |\n",
      "| value_loss              | 1333.9973   |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ent_coef                | 2.4473622 |\n",
      "| ent_coef_loss           | 0.7438159 |\n",
      "| entropy                 | 15.714466 |\n",
      "| episodes                | 690       |\n",
      "| fps                     | 97        |\n",
      "| mean 100 episode reward | 1.41e+05  |\n",
      "| n_updates               | 688901    |\n",
      "| policy_loss             | -8937.191 |\n",
      "| qf1_loss                | 6451.718  |\n",
      "| qf2_loss                | 7335.1924 |\n",
      "| time_elapsed            | 7062      |\n",
      "| total timesteps         | 689000    |\n",
      "| value_loss              | 6074.0684 |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 2.3536127   |\n",
      "| ent_coef_loss           | -0.33797026 |\n",
      "| entropy                 | 15.560301   |\n",
      "| episodes                | 700         |\n",
      "| fps                     | 97          |\n",
      "| mean 100 episode reward | 1.41e+05    |\n",
      "| n_updates               | 698901      |\n",
      "| policy_loss             | -9100.805   |\n",
      "| qf1_loss                | 5487.1777   |\n",
      "| qf2_loss                | 3916.327    |\n",
      "| time_elapsed            | 7156        |\n",
      "| total timesteps         | 699000      |\n",
      "| value_loss              | 5892.77     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 2.4465003  |\n",
      "| ent_coef_loss           | 0.42572474 |\n",
      "| entropy                 | 15.803097  |\n",
      "| episodes                | 710        |\n",
      "| fps                     | 97         |\n",
      "| mean 100 episode reward | 1.4e+05    |\n",
      "| n_updates               | 708901     |\n",
      "| policy_loss             | -8264.719  |\n",
      "| qf1_loss                | 12469.53   |\n",
      "| qf2_loss                | 9970.836   |\n",
      "| time_elapsed            | 7252       |\n",
      "| total timesteps         | 709000     |\n",
      "| value_loss              | 27348.637  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 2.2582214  |\n",
      "| ent_coef_loss           | -1.2350993 |\n",
      "| entropy                 | 15.421896  |\n",
      "| episodes                | 720        |\n",
      "| fps                     | 97         |\n",
      "| mean 100 episode reward | 1.39e+05   |\n",
      "| n_updates               | 718901     |\n",
      "| policy_loss             | -8991.338  |\n",
      "| qf1_loss                | 12928.765  |\n",
      "| qf2_loss                | 9376.193   |\n",
      "| time_elapsed            | 7348       |\n",
      "| total timesteps         | 719000     |\n",
      "| value_loss              | 2213.3174  |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ent_coef                | 2.3068564 |\n",
      "| ent_coef_loss           | 0.5982135 |\n",
      "| entropy                 | 15.328814 |\n",
      "| episodes                | 730       |\n",
      "| fps                     | 97        |\n",
      "| mean 100 episode reward | 1.38e+05  |\n",
      "| n_updates               | 728901    |\n",
      "| policy_loss             | -8321.098 |\n",
      "| qf1_loss                | 5246.462  |\n",
      "| qf2_loss                | 4758.536  |\n",
      "| time_elapsed            | 7444      |\n",
      "| total timesteps         | 729000    |\n",
      "| value_loss              | 20319.422 |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 2.3389714  |\n",
      "| ent_coef_loss           | -1.5934186 |\n",
      "| entropy                 | 15.432899  |\n",
      "| episodes                | 740        |\n",
      "| fps                     | 98         |\n",
      "| mean 100 episode reward | 1.39e+05   |\n",
      "| n_updates               | 738901     |\n",
      "| policy_loss             | -9268.442  |\n",
      "| qf1_loss                | 3794.3223  |\n",
      "| qf2_loss                | 4812.772   |\n",
      "| time_elapsed            | 7539       |\n",
      "| total timesteps         | 739000     |\n",
      "| value_loss              | 14119.977  |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ent_coef                | 2.4337661 |\n",
      "| ent_coef_loss           | 2.2332907 |\n",
      "| entropy                 | 15.980951 |\n",
      "| episodes                | 750       |\n",
      "| fps                     | 98        |\n",
      "| mean 100 episode reward | 1.39e+05  |\n",
      "| n_updates               | 748901    |\n",
      "| policy_loss             | -8042.714 |\n",
      "| qf1_loss                | 5253.7676 |\n",
      "| qf2_loss                | 3968.6514 |\n",
      "| time_elapsed            | 7634      |\n",
      "| total timesteps         | 749000    |\n",
      "| value_loss              | 2586.606  |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 2.385858    |\n",
      "| ent_coef_loss           | -0.30607378 |\n",
      "| entropy                 | 15.462795   |\n",
      "| episodes                | 760         |\n",
      "| fps                     | 98          |\n",
      "| mean 100 episode reward | 1.41e+05    |\n",
      "| n_updates               | 758901      |\n",
      "| policy_loss             | -8942.684   |\n",
      "| qf1_loss                | 5836.1484   |\n",
      "| qf2_loss                | 6875.4194   |\n",
      "| time_elapsed            | 7723        |\n",
      "| total timesteps         | 759000      |\n",
      "| value_loss              | 3953.3848   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 2.419912    |\n",
      "| ent_coef_loss           | -0.04312125 |\n",
      "| entropy                 | 15.605934   |\n",
      "| episodes                | 770         |\n",
      "| fps                     | 98          |\n",
      "| mean 100 episode reward | 1.42e+05    |\n",
      "| n_updates               | 768901      |\n",
      "| policy_loss             | -9068.291   |\n",
      "| qf1_loss                | 6664.1255   |\n",
      "| qf2_loss                | 7896.37     |\n",
      "| time_elapsed            | 7812        |\n",
      "| total timesteps         | 769000      |\n",
      "| value_loss              | 4574.733    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ent_coef                | 2.5220249 |\n",
      "| ent_coef_loss           | 1.1993393 |\n",
      "| entropy                 | 15.567829 |\n",
      "| episodes                | 780       |\n",
      "| fps                     | 98        |\n",
      "| mean 100 episode reward | 1.45e+05  |\n",
      "| n_updates               | 778901    |\n",
      "| policy_loss             | -8949.959 |\n",
      "| qf1_loss                | 6014.1123 |\n",
      "| qf2_loss                | 4750.6313 |\n",
      "| time_elapsed            | 7904      |\n",
      "| total timesteps         | 779000    |\n",
      "| value_loss              | 2016.6792 |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ent_coef                | 2.455815  |\n",
      "| ent_coef_loss           | 0.9688494 |\n",
      "| entropy                 | 16.09497  |\n",
      "| episodes                | 790       |\n",
      "| fps                     | 98        |\n",
      "| mean 100 episode reward | 1.48e+05  |\n",
      "| n_updates               | 788901    |\n",
      "| policy_loss             | -8657.587 |\n",
      "| qf1_loss                | 5825.694  |\n",
      "| qf2_loss                | 4990.103  |\n",
      "| time_elapsed            | 7998      |\n",
      "| total timesteps         | 789000    |\n",
      "| value_loss              | 10280.586 |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ent_coef                | 2.4129612 |\n",
      "| ent_coef_loss           | 1.0709457 |\n",
      "| entropy                 | 15.874563 |\n",
      "| episodes                | 800       |\n",
      "| fps                     | 98        |\n",
      "| mean 100 episode reward | 1.5e+05   |\n",
      "| n_updates               | 798901    |\n",
      "| policy_loss             | -8313.928 |\n",
      "| qf1_loss                | 3446.544  |\n",
      "| qf2_loss                | 3818.7273 |\n",
      "| time_elapsed            | 8093      |\n",
      "| total timesteps         | 799000    |\n",
      "| value_loss              | 4151.706  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ent_coef                | 2.3890615 |\n",
      "| ent_coef_loss           | 1.0248075 |\n",
      "| entropy                 | 15.675501 |\n",
      "| episodes                | 810       |\n",
      "| fps                     | 98        |\n",
      "| mean 100 episode reward | 1.52e+05  |\n",
      "| n_updates               | 808901    |\n",
      "| policy_loss             | -8931.771 |\n",
      "| qf1_loss                | 3288.3564 |\n",
      "| qf2_loss                | 3820.1165 |\n",
      "| time_elapsed            | 8187      |\n",
      "| total timesteps         | 809000    |\n",
      "| value_loss              | 9094.092  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ent_coef                | 2.3044488 |\n",
      "| ent_coef_loss           | 0.1340186 |\n",
      "| entropy                 | 15.654638 |\n",
      "| episodes                | 820       |\n",
      "| fps                     | 98        |\n",
      "| mean 100 episode reward | 1.53e+05  |\n",
      "| n_updates               | 818901    |\n",
      "| policy_loss             | -8508.618 |\n",
      "| qf1_loss                | 9501.831  |\n",
      "| qf2_loss                | 9862.297  |\n",
      "| time_elapsed            | 8295      |\n",
      "| total timesteps         | 819000    |\n",
      "| value_loss              | 2423.4355 |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ent_coef                | 2.2879558 |\n",
      "| ent_coef_loss           | 2.2696052 |\n",
      "| entropy                 | 15.50673  |\n",
      "| episodes                | 830       |\n",
      "| fps                     | 98        |\n",
      "| mean 100 episode reward | 1.54e+05  |\n",
      "| n_updates               | 828901    |\n",
      "| policy_loss             | -8198.143 |\n",
      "| qf1_loss                | 5199.6123 |\n",
      "| qf2_loss                | 5928.495  |\n",
      "| time_elapsed            | 8400      |\n",
      "| total timesteps         | 829000    |\n",
      "| value_loss              | 5744.039  |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 2.2748652   |\n",
      "| ent_coef_loss           | -0.13203123 |\n",
      "| entropy                 | 15.50168    |\n",
      "| episodes                | 840         |\n",
      "| fps                     | 98          |\n",
      "| mean 100 episode reward | 1.55e+05    |\n",
      "| n_updates               | 838901      |\n",
      "| policy_loss             | -9209.795   |\n",
      "| qf1_loss                | 7126.806    |\n",
      "| qf2_loss                | 7548.2295   |\n",
      "| time_elapsed            | 8508        |\n",
      "| total timesteps         | 839000      |\n",
      "| value_loss              | 2666.0508   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 2.3191822   |\n",
      "| ent_coef_loss           | -0.13069353 |\n",
      "| entropy                 | 15.559565   |\n",
      "| episodes                | 850         |\n",
      "| fps                     | 98          |\n",
      "| mean 100 episode reward | 1.58e+05    |\n",
      "| n_updates               | 848901      |\n",
      "| policy_loss             | -9353.229   |\n",
      "| qf1_loss                | 2597.5642   |\n",
      "| qf2_loss                | 2270.4702   |\n",
      "| time_elapsed            | 8611        |\n",
      "| total timesteps         | 849000      |\n",
      "| value_loss              | 5399.58     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 2.2405674   |\n",
      "| ent_coef_loss           | -0.63187605 |\n",
      "| entropy                 | 15.489397   |\n",
      "| episodes                | 860         |\n",
      "| fps                     | 98          |\n",
      "| mean 100 episode reward | 1.58e+05    |\n",
      "| n_updates               | 858901      |\n",
      "| policy_loss             | -9572.227   |\n",
      "| qf1_loss                | 3417.7104   |\n",
      "| qf2_loss                | 2854.0747   |\n",
      "| time_elapsed            | 8720        |\n",
      "| total timesteps         | 859000      |\n",
      "| value_loss              | 11256.113   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 2.122598   |\n",
      "| ent_coef_loss           | 0.12753141 |\n",
      "| entropy                 | 15.430037  |\n",
      "| episodes                | 870        |\n",
      "| fps                     | 98         |\n",
      "| mean 100 episode reward | 1.59e+05   |\n",
      "| n_updates               | 868901     |\n",
      "| policy_loss             | -8980.504  |\n",
      "| qf1_loss                | 3453.216   |\n",
      "| qf2_loss                | 3747.662   |\n",
      "| time_elapsed            | 8824       |\n",
      "| total timesteps         | 869000     |\n",
      "| value_loss              | 4064.7136  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 2.231518   |\n",
      "| ent_coef_loss           | 0.31947374 |\n",
      "| entropy                 | 15.616237  |\n",
      "| episodes                | 880        |\n",
      "| fps                     | 98         |\n",
      "| mean 100 episode reward | 1.58e+05   |\n",
      "| n_updates               | 878901     |\n",
      "| policy_loss             | -8792.852  |\n",
      "| qf1_loss                | 3691.213   |\n",
      "| qf2_loss                | 4487.7153  |\n",
      "| time_elapsed            | 8926       |\n",
      "| total timesteps         | 879000     |\n",
      "| value_loss              | 2965.2727  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 2.192278   |\n",
      "| ent_coef_loss           | 0.73060215 |\n",
      "| entropy                 | 15.912444  |\n",
      "| episodes                | 890        |\n",
      "| fps                     | 98         |\n",
      "| mean 100 episode reward | 1.58e+05   |\n",
      "| n_updates               | 888901     |\n",
      "| policy_loss             | -8225.16   |\n",
      "| qf1_loss                | 9505.149   |\n",
      "| qf2_loss                | 6439.129   |\n",
      "| time_elapsed            | 9035       |\n",
      "| total timesteps         | 889000     |\n",
      "| value_loss              | 7808.1514  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 2.1810894  |\n",
      "| ent_coef_loss           | -1.0406718 |\n",
      "| entropy                 | 15.40332   |\n",
      "| episodes                | 900        |\n",
      "| fps                     | 98         |\n",
      "| mean 100 episode reward | 1.56e+05   |\n",
      "| n_updates               | 898901     |\n",
      "| policy_loss             | -9277.945  |\n",
      "| qf1_loss                | 3823.2734  |\n",
      "| qf2_loss                | 3405.4106  |\n",
      "| time_elapsed            | 9142       |\n",
      "| total timesteps         | 899000     |\n",
      "| value_loss              | 7802.8955  |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ent_coef                | 2.172137  |\n",
      "| ent_coef_loss           | 0.426723  |\n",
      "| entropy                 | 15.65718  |\n",
      "| episodes                | 910       |\n",
      "| fps                     | 98        |\n",
      "| mean 100 episode reward | 1.56e+05  |\n",
      "| n_updates               | 908901    |\n",
      "| policy_loss             | -9329.802 |\n",
      "| qf1_loss                | 3413.3872 |\n",
      "| qf2_loss                | 2334.5508 |\n",
      "| time_elapsed            | 9237      |\n",
      "| total timesteps         | 909000    |\n",
      "| value_loss              | 2104.6191 |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ent_coef                | 2.194371  |\n",
      "| ent_coef_loss           | 0.2804036 |\n",
      "| entropy                 | 15.9773   |\n",
      "| episodes                | 920       |\n",
      "| fps                     | 98        |\n",
      "| mean 100 episode reward | 1.56e+05  |\n",
      "| n_updates               | 918901    |\n",
      "| policy_loss             | -8873.125 |\n",
      "| qf1_loss                | 9740.721  |\n",
      "| qf2_loss                | 9977.609  |\n",
      "| time_elapsed            | 9330      |\n",
      "| total timesteps         | 919000    |\n",
      "| value_loss              | 6703.801  |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 2.1507056   |\n",
      "| ent_coef_loss           | -0.36733174 |\n",
      "| entropy                 | 15.607737   |\n",
      "| episodes                | 930         |\n",
      "| fps                     | 98          |\n",
      "| mean 100 episode reward | 1.55e+05    |\n",
      "| n_updates               | 928901      |\n",
      "| policy_loss             | -10024.865  |\n",
      "| qf1_loss                | 6736.288    |\n",
      "| qf2_loss                | 5638.041    |\n",
      "| time_elapsed            | 9425        |\n",
      "| total timesteps         | 929000      |\n",
      "| value_loss              | 12739.594   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 2.0953927  |\n",
      "| ent_coef_loss           | 0.37480545 |\n",
      "| entropy                 | 15.837961  |\n",
      "| episodes                | 940        |\n",
      "| fps                     | 98         |\n",
      "| mean 100 episode reward | 1.54e+05   |\n",
      "| n_updates               | 938901     |\n",
      "| policy_loss             | -9338.242  |\n",
      "| qf1_loss                | 3253.1545  |\n",
      "| qf2_loss                | 3777.2168  |\n",
      "| time_elapsed            | 9519       |\n",
      "| total timesteps         | 939000     |\n",
      "| value_loss              | 1633.9125  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 2.1508126   |\n",
      "| ent_coef_loss           | -0.27354044 |\n",
      "| entropy                 | 15.379955   |\n",
      "| episodes                | 950         |\n",
      "| fps                     | 98          |\n",
      "| mean 100 episode reward | 1.53e+05    |\n",
      "| n_updates               | 948901      |\n",
      "| policy_loss             | -9861.382   |\n",
      "| qf1_loss                | 5357.182    |\n",
      "| qf2_loss                | 4625.0283   |\n",
      "| time_elapsed            | 9617        |\n",
      "| total timesteps         | 949000      |\n",
      "| value_loss              | 3074.9116   |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ent_coef                | 2.1478212 |\n",
      "| ent_coef_loss           | -1.537013 |\n",
      "| entropy                 | 15.428844 |\n",
      "| episodes                | 960       |\n",
      "| fps                     | 98        |\n",
      "| mean 100 episode reward | 1.54e+05  |\n",
      "| n_updates               | 958901    |\n",
      "| policy_loss             | -9616.698 |\n",
      "| qf1_loss                | 4667.582  |\n",
      "| qf2_loss                | 4154.804  |\n",
      "| time_elapsed            | 9721      |\n",
      "| total timesteps         | 959000    |\n",
      "| value_loss              | 8061.953  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 2.2760522  |\n",
      "| ent_coef_loss           | -1.2010227 |\n",
      "| entropy                 | 15.60495   |\n",
      "| episodes                | 970        |\n",
      "| fps                     | 98         |\n",
      "| mean 100 episode reward | 1.54e+05   |\n",
      "| n_updates               | 968901     |\n",
      "| policy_loss             | -9625.975  |\n",
      "| qf1_loss                | 3060.6572  |\n",
      "| qf2_loss                | 2700.2998  |\n",
      "| time_elapsed            | 9812       |\n",
      "| total timesteps         | 969000     |\n",
      "| value_loss              | 1203.4148  |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ent_coef                | 2.2651913 |\n",
      "| ent_coef_loss           | 1.1200262 |\n",
      "| entropy                 | 15.738991 |\n",
      "| episodes                | 980       |\n",
      "| fps                     | 98        |\n",
      "| mean 100 episode reward | 1.52e+05  |\n",
      "| n_updates               | 978901    |\n",
      "| policy_loss             | -9300.424 |\n",
      "| qf1_loss                | 4789.3184 |\n",
      "| qf2_loss                | 4412.891  |\n",
      "| time_elapsed            | 9911      |\n",
      "| total timesteps         | 979000    |\n",
      "| value_loss              | 3278.073  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ent_coef                | 2.1556654 |\n",
      "| ent_coef_loss           | 1.4319508 |\n",
      "| entropy                 | 15.681154 |\n",
      "| episodes                | 990       |\n",
      "| fps                     | 98        |\n",
      "| mean 100 episode reward | 1.53e+05  |\n",
      "| n_updates               | 988901    |\n",
      "| policy_loss             | -8962.348 |\n",
      "| qf1_loss                | 4711.7773 |\n",
      "| qf2_loss                | 3088.4868 |\n",
      "| time_elapsed            | 10025     |\n",
      "| total timesteps         | 989000    |\n",
      "| value_loss              | 7138.6816 |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 2.1828842   |\n",
      "| ent_coef_loss           | -0.05977507 |\n",
      "| entropy                 | 15.536679   |\n",
      "| episodes                | 1000        |\n",
      "| fps                     | 98          |\n",
      "| mean 100 episode reward | 1.53e+05    |\n",
      "| n_updates               | 998901      |\n",
      "| policy_loss             | -9185.448   |\n",
      "| qf1_loss                | 2965.1357   |\n",
      "| qf2_loss                | 2912.8013   |\n",
      "| time_elapsed            | 10145       |\n",
      "| total timesteps         | 999000      |\n",
      "| value_loss              | 2449.7192   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 2.104691   |\n",
      "| ent_coef_loss           | -0.6032696 |\n",
      "| entropy                 | 15.702168  |\n",
      "| episodes                | 1010       |\n",
      "| fps                     | 98         |\n",
      "| mean 100 episode reward | 1.53e+05   |\n",
      "| n_updates               | 1008901    |\n",
      "| policy_loss             | -9473.277  |\n",
      "| qf1_loss                | 3772.7534  |\n",
      "| qf2_loss                | 3086.0654  |\n",
      "| time_elapsed            | 10252      |\n",
      "| total timesteps         | 1009000    |\n",
      "| value_loss              | 2623.773   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 2.1471112  |\n",
      "| ent_coef_loss           | -0.2461255 |\n",
      "| entropy                 | 15.644627  |\n",
      "| episodes                | 1020       |\n",
      "| fps                     | 98         |\n",
      "| mean 100 episode reward | 1.52e+05   |\n",
      "| n_updates               | 1018901    |\n",
      "| policy_loss             | -10003.838 |\n",
      "| qf1_loss                | 2726.6985  |\n",
      "| qf2_loss                | 1762.2701  |\n",
      "| time_elapsed            | 10348      |\n",
      "| total timesteps         | 1019000    |\n",
      "| value_loss              | 2755.7388  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 2.1996367   |\n",
      "| ent_coef_loss           | -0.87716484 |\n",
      "| entropy                 | 15.658747   |\n",
      "| episodes                | 1030        |\n",
      "| fps                     | 98          |\n",
      "| mean 100 episode reward | 1.52e+05    |\n",
      "| n_updates               | 1028901     |\n",
      "| policy_loss             | -9396.491   |\n",
      "| qf1_loss                | 4809.4194   |\n",
      "| qf2_loss                | 3524.8567   |\n",
      "| time_elapsed            | 10441       |\n",
      "| total timesteps         | 1029000     |\n",
      "| value_loss              | 5121.849    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ent_coef                | 2.1642926 |\n",
      "| ent_coef_loss           | 0.5707723 |\n",
      "| entropy                 | 15.905418 |\n",
      "| episodes                | 1040      |\n",
      "| fps                     | 98        |\n",
      "| mean 100 episode reward | 1.51e+05  |\n",
      "| n_updates               | 1038901   |\n",
      "| policy_loss             | -9475.475 |\n",
      "| qf1_loss                | 2041.2802 |\n",
      "| qf2_loss                | 2561.3955 |\n",
      "| time_elapsed            | 10533     |\n",
      "| total timesteps         | 1039000   |\n",
      "| value_loss              | 2303.6975 |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 2.022202    |\n",
      "| ent_coef_loss           | -0.34330335 |\n",
      "| entropy                 | 15.627279   |\n",
      "| episodes                | 1050        |\n",
      "| fps                     | 98          |\n",
      "| mean 100 episode reward | 1.5e+05     |\n",
      "| n_updates               | 1048901     |\n",
      "| policy_loss             | -9580.952   |\n",
      "| qf1_loss                | 2007.6986   |\n",
      "| qf2_loss                | 2181.465    |\n",
      "| time_elapsed            | 10625       |\n",
      "| total timesteps         | 1049000     |\n",
      "| value_loss              | 3733.559    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 2.14822    |\n",
      "| ent_coef_loss           | -1.0951278 |\n",
      "| entropy                 | 15.294878  |\n",
      "| episodes                | 1060       |\n",
      "| fps                     | 98         |\n",
      "| mean 100 episode reward | 1.48e+05   |\n",
      "| n_updates               | 1058901    |\n",
      "| policy_loss             | -9621.48   |\n",
      "| qf1_loss                | 888185.2   |\n",
      "| qf2_loss                | 884535.25  |\n",
      "| time_elapsed            | 10712      |\n",
      "| total timesteps         | 1059000    |\n",
      "| value_loss              | 2963.8423  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 2.0711029   |\n",
      "| ent_coef_loss           | -0.26813468 |\n",
      "| entropy                 | 15.625109   |\n",
      "| episodes                | 1070        |\n",
      "| fps                     | 98          |\n",
      "| mean 100 episode reward | 1.46e+05    |\n",
      "| n_updates               | 1068901     |\n",
      "| policy_loss             | -9597.273   |\n",
      "| qf1_loss                | 3566.1763   |\n",
      "| qf2_loss                | 5478.6714   |\n",
      "| time_elapsed            | 10804       |\n",
      "| total timesteps         | 1069000     |\n",
      "| value_loss              | 9271.995    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 1.9954821   |\n",
      "| ent_coef_loss           | 0.029183865 |\n",
      "| entropy                 | 15.874141   |\n",
      "| episodes                | 1080        |\n",
      "| fps                     | 99          |\n",
      "| mean 100 episode reward | 1.45e+05    |\n",
      "| n_updates               | 1078901     |\n",
      "| policy_loss             | -10159.307  |\n",
      "| qf1_loss                | 1159938.2   |\n",
      "| qf2_loss                | 1159917.8   |\n",
      "| time_elapsed            | 10892       |\n",
      "| total timesteps         | 1079000     |\n",
      "| value_loss              | 896.6221    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 2.0546162  |\n",
      "| ent_coef_loss           | -0.9241417 |\n",
      "| entropy                 | 15.525     |\n",
      "| episodes                | 1090       |\n",
      "| fps                     | 98         |\n",
      "| mean 100 episode reward | 1.44e+05   |\n",
      "| n_updates               | 1088901    |\n",
      "| policy_loss             | -10499.803 |\n",
      "| qf1_loss                | 2785.4255  |\n",
      "| qf2_loss                | 1637.0848  |\n",
      "| time_elapsed            | 11000      |\n",
      "| total timesteps         | 1089000    |\n",
      "| value_loss              | 1858.4717  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 2.0903556  |\n",
      "| ent_coef_loss           | -1.5037122 |\n",
      "| entropy                 | 15.619671  |\n",
      "| episodes                | 1100       |\n",
      "| fps                     | 98         |\n",
      "| mean 100 episode reward | 1.43e+05   |\n",
      "| n_updates               | 1098901    |\n",
      "| policy_loss             | -10454.547 |\n",
      "| qf1_loss                | 1083.6196  |\n",
      "| qf2_loss                | 2445.3962  |\n",
      "| time_elapsed            | 11133      |\n",
      "| total timesteps         | 1099000    |\n",
      "| value_loss              | 2065.481   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 2.0759947  |\n",
      "| ent_coef_loss           | 0.64371574 |\n",
      "| entropy                 | 15.762106  |\n",
      "| episodes                | 1110       |\n",
      "| fps                     | 98         |\n",
      "| mean 100 episode reward | 1.4e+05    |\n",
      "| n_updates               | 1108901    |\n",
      "| policy_loss             | -9230.903  |\n",
      "| qf1_loss                | 5607.5117  |\n",
      "| qf2_loss                | 5212.4653  |\n",
      "| time_elapsed            | 11265      |\n",
      "| total timesteps         | 1109000    |\n",
      "| value_loss              | 6720.9395  |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ent_coef                | 2.0053864 |\n",
      "| ent_coef_loss           | 0.2546615 |\n",
      "| entropy                 | 15.617168 |\n",
      "| episodes                | 1120      |\n",
      "| fps                     | 98        |\n",
      "| mean 100 episode reward | 1.39e+05  |\n",
      "| n_updates               | 1118901   |\n",
      "| policy_loss             | -9976.621 |\n",
      "| qf1_loss                | 4365.2705 |\n",
      "| qf2_loss                | 3777.6497 |\n",
      "| time_elapsed            | 11398     |\n",
      "| total timesteps         | 1119000   |\n",
      "| value_loss              | 2929.9895 |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 1.9258689  |\n",
      "| ent_coef_loss           | 0.77816683 |\n",
      "| entropy                 | 15.837186  |\n",
      "| episodes                | 1130       |\n",
      "| fps                     | 97         |\n",
      "| mean 100 episode reward | 1.37e+05   |\n",
      "| n_updates               | 1128901    |\n",
      "| policy_loss             | -9522.884  |\n",
      "| qf1_loss                | 3597.8726  |\n",
      "| qf2_loss                | 2751.6265  |\n",
      "| time_elapsed            | 11530      |\n",
      "| total timesteps         | 1129000    |\n",
      "| value_loss              | 2028.7756  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 1.9449637  |\n",
      "| ent_coef_loss           | 0.19142357 |\n",
      "| entropy                 | 15.684445  |\n",
      "| episodes                | 1140       |\n",
      "| fps                     | 97         |\n",
      "| mean 100 episode reward | 1.37e+05   |\n",
      "| n_updates               | 1138901    |\n",
      "| policy_loss             | -9926.931  |\n",
      "| qf1_loss                | 2018.6566  |\n",
      "| qf2_loss                | 2506.9082  |\n",
      "| time_elapsed            | 11667      |\n",
      "| total timesteps         | 1139000    |\n",
      "| value_loss              | 4307.8936  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 1.9260079  |\n",
      "| ent_coef_loss           | -1.2627846 |\n",
      "| entropy                 | 15.605373  |\n",
      "| episodes                | 1150       |\n",
      "| fps                     | 97         |\n",
      "| mean 100 episode reward | 1.37e+05   |\n",
      "| n_updates               | 1148901    |\n",
      "| policy_loss             | -10120.277 |\n",
      "| qf1_loss                | 4692.7075  |\n",
      "| qf2_loss                | 3720.645   |\n",
      "| time_elapsed            | 11803      |\n",
      "| total timesteps         | 1149000    |\n",
      "| value_loss              | 3263.9656  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 1.9710059  |\n",
      "| ent_coef_loss           | 0.44700882 |\n",
      "| entropy                 | 15.53034   |\n",
      "| episodes                | 1160       |\n",
      "| fps                     | 97         |\n",
      "| mean 100 episode reward | 1.38e+05   |\n",
      "| n_updates               | 1158901    |\n",
      "| policy_loss             | -9774.38   |\n",
      "| qf1_loss                | 10370.163  |\n",
      "| qf2_loss                | 2773.8223  |\n",
      "| time_elapsed            | 11941      |\n",
      "| total timesteps         | 1159000    |\n",
      "| value_loss              | 1619.2737  |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 1.9068447  |\n",
      "| ent_coef_loss           | 0.29938903 |\n",
      "| entropy                 | 15.713181  |\n",
      "| episodes                | 1170       |\n",
      "| fps                     | 96         |\n",
      "| mean 100 episode reward | 1.38e+05   |\n",
      "| n_updates               | 1168901    |\n",
      "| policy_loss             | -10270.888 |\n",
      "| qf1_loss                | 3755.1138  |\n",
      "| qf2_loss                | 4094.2969  |\n",
      "| time_elapsed            | 12077      |\n",
      "| total timesteps         | 1169000    |\n",
      "| value_loss              | 16629.781  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 1.9401389  |\n",
      "| ent_coef_loss           | 0.22921705 |\n",
      "| entropy                 | 15.548038  |\n",
      "| episodes                | 1180       |\n",
      "| fps                     | 96         |\n",
      "| mean 100 episode reward | 1.39e+05   |\n",
      "| n_updates               | 1178901    |\n",
      "| policy_loss             | -9972.702  |\n",
      "| qf1_loss                | 1932.8228  |\n",
      "| qf2_loss                | 1914.4211  |\n",
      "| time_elapsed            | 12213      |\n",
      "| total timesteps         | 1179000    |\n",
      "| value_loss              | 2504.9102  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 1.9589465  |\n",
      "| ent_coef_loss           | 0.8765145  |\n",
      "| entropy                 | 15.397324  |\n",
      "| episodes                | 1190       |\n",
      "| fps                     | 96         |\n",
      "| mean 100 episode reward | 1.37e+05   |\n",
      "| n_updates               | 1188901    |\n",
      "| policy_loss             | -10302.932 |\n",
      "| qf1_loss                | 3528.4058  |\n",
      "| qf2_loss                | 3405.5156  |\n",
      "| time_elapsed            | 12348      |\n",
      "| total timesteps         | 1189000    |\n",
      "| value_loss              | 3074.3242  |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ent_coef                | 1.9732008 |\n",
      "| ent_coef_loss           | 1.0101546 |\n",
      "| entropy                 | 15.681271 |\n",
      "| episodes                | 1200      |\n",
      "| fps                     | 96        |\n",
      "| mean 100 episode reward | 1.38e+05  |\n",
      "| n_updates               | 1198901   |\n",
      "| policy_loss             | -9808.305 |\n",
      "| qf1_loss                | 5749.45   |\n",
      "| qf2_loss                | 6176.9697 |\n",
      "| time_elapsed            | 12484     |\n",
      "| total timesteps         | 1199000   |\n",
      "| value_loss              | 2005.176  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 2.0643497  |\n",
      "| ent_coef_loss           | 0.7796253  |\n",
      "| entropy                 | 15.7528925 |\n",
      "| episodes                | 1210       |\n",
      "| fps                     | 95         |\n",
      "| mean 100 episode reward | 1.4e+05    |\n",
      "| n_updates               | 1208901    |\n",
      "| policy_loss             | -9495.109  |\n",
      "| qf1_loss                | 16675.023  |\n",
      "| qf2_loss                | 20512.344  |\n",
      "| time_elapsed            | 12618      |\n",
      "| total timesteps         | 1209000    |\n",
      "| value_loss              | 2557.825   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 2.023585    |\n",
      "| ent_coef_loss           | -0.05232592 |\n",
      "| entropy                 | 15.609257   |\n",
      "| episodes                | 1220        |\n",
      "| fps                     | 95          |\n",
      "| mean 100 episode reward | 1.39e+05    |\n",
      "| n_updates               | 1218901     |\n",
      "| policy_loss             | -10425.451  |\n",
      "| qf1_loss                | 4171.6426   |\n",
      "| qf2_loss                | 4700.8877   |\n",
      "| time_elapsed            | 12734       |\n",
      "| total timesteps         | 1219000     |\n",
      "| value_loss              | 3515.0178   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 1.945928   |\n",
      "| ent_coef_loss           | -0.8402026 |\n",
      "| entropy                 | 15.41841   |\n",
      "| episodes                | 1230       |\n",
      "| fps                     | 95         |\n",
      "| mean 100 episode reward | 1.41e+05   |\n",
      "| n_updates               | 1228901    |\n",
      "| policy_loss             | -9937.605  |\n",
      "| qf1_loss                | 6788.38    |\n",
      "| qf2_loss                | 12136.875  |\n",
      "| time_elapsed            | 12858      |\n",
      "| total timesteps         | 1229000    |\n",
      "| value_loss              | 9008.906   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 1.941707   |\n",
      "| ent_coef_loss           | -0.6602648 |\n",
      "| entropy                 | 15.448458  |\n",
      "| episodes                | 1240       |\n",
      "| fps                     | 95         |\n",
      "| mean 100 episode reward | 1.4e+05    |\n",
      "| n_updates               | 1238901    |\n",
      "| policy_loss             | -10349.183 |\n",
      "| qf1_loss                | 683.1839   |\n",
      "| qf2_loss                | 1018.6839  |\n",
      "| time_elapsed            | 12986      |\n",
      "| total timesteps         | 1239000    |\n",
      "| value_loss              | 2011.424   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 1.8705891  |\n",
      "| ent_coef_loss           | -0.2305351 |\n",
      "| entropy                 | 15.681429  |\n",
      "| episodes                | 1250       |\n",
      "| fps                     | 95         |\n",
      "| mean 100 episode reward | 1.41e+05   |\n",
      "| n_updates               | 1248901    |\n",
      "| policy_loss             | -10086.713 |\n",
      "| qf1_loss                | 5932.7803  |\n",
      "| qf2_loss                | 6013.452   |\n",
      "| time_elapsed            | 13117      |\n",
      "| total timesteps         | 1249000    |\n",
      "| value_loss              | 3418.0884  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 1.8207338   |\n",
      "| ent_coef_loss           | -0.34505486 |\n",
      "| entropy                 | 15.27408    |\n",
      "| episodes                | 1260        |\n",
      "| fps                     | 94          |\n",
      "| mean 100 episode reward | 1.4e+05     |\n",
      "| n_updates               | 1258901     |\n",
      "| policy_loss             | -10437.04   |\n",
      "| qf1_loss                | 4698.2666   |\n",
      "| qf2_loss                | 5124.555    |\n",
      "| time_elapsed            | 13253       |\n",
      "| total timesteps         | 1259000     |\n",
      "| value_loss              | 5806.8193   |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| current_lr              | 0.0003       |\n",
      "| ent_coef                | 1.8704863    |\n",
      "| ent_coef_loss           | -0.003010869 |\n",
      "| entropy                 | 15.8028965   |\n",
      "| episodes                | 1270         |\n",
      "| fps                     | 94           |\n",
      "| mean 100 episode reward | 1.41e+05     |\n",
      "| n_updates               | 1268901      |\n",
      "| policy_loss             | -9870.512    |\n",
      "| qf1_loss                | 3223.983     |\n",
      "| qf2_loss                | 3939.3308    |\n",
      "| time_elapsed            | 13387        |\n",
      "| total timesteps         | 1269000      |\n",
      "| value_loss              | 2133.074     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 1.8978828  |\n",
      "| ent_coef_loss           | -0.4064233 |\n",
      "| entropy                 | 15.312372  |\n",
      "| episodes                | 1280       |\n",
      "| fps                     | 94         |\n",
      "| mean 100 episode reward | 1.42e+05   |\n",
      "| n_updates               | 1278901    |\n",
      "| policy_loss             | -10751.176 |\n",
      "| qf1_loss                | 3760.8833  |\n",
      "| qf2_loss                | 3422.246   |\n",
      "| time_elapsed            | 13522      |\n",
      "| total timesteps         | 1279000    |\n",
      "| value_loss              | 3009.8345  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 1.8612374   |\n",
      "| ent_coef_loss           | -0.46157828 |\n",
      "| entropy                 | 15.517746   |\n",
      "| episodes                | 1290        |\n",
      "| fps                     | 94          |\n",
      "| mean 100 episode reward | 1.45e+05    |\n",
      "| n_updates               | 1288901     |\n",
      "| policy_loss             | -10710.576  |\n",
      "| qf1_loss                | 5881.019    |\n",
      "| qf2_loss                | 6850.398    |\n",
      "| time_elapsed            | 13658       |\n",
      "| total timesteps         | 1289000     |\n",
      "| value_loss              | 3401.9028   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 1.8575326  |\n",
      "| ent_coef_loss           | 0.77788186 |\n",
      "| entropy                 | 15.614166  |\n",
      "| episodes                | 1300       |\n",
      "| fps                     | 94         |\n",
      "| mean 100 episode reward | 1.45e+05   |\n",
      "| n_updates               | 1298901    |\n",
      "| policy_loss             | -9759.656  |\n",
      "| qf1_loss                | 2444.146   |\n",
      "| qf2_loss                | 3416.3289  |\n",
      "| time_elapsed            | 13793      |\n",
      "| total timesteps         | 1299000    |\n",
      "| value_loss              | 1825.6794  |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ent_coef                | 1.9406232 |\n",
      "| ent_coef_loss           | 0.9710504 |\n",
      "| entropy                 | 15.75221  |\n",
      "| episodes                | 1310      |\n",
      "| fps                     | 93        |\n",
      "| mean 100 episode reward | 1.44e+05  |\n",
      "| n_updates               | 1308901   |\n",
      "| policy_loss             | -9990.645 |\n",
      "| qf1_loss                | 3103.312  |\n",
      "| qf2_loss                | 3729.0332 |\n",
      "| time_elapsed            | 13929     |\n",
      "| total timesteps         | 1309000   |\n",
      "| value_loss              | 2421.6475 |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ent_coef                | 1.8941567 |\n",
      "| ent_coef_loss           | 0.2831088 |\n",
      "| entropy                 | 15.655504 |\n",
      "| episodes                | 1320      |\n",
      "| fps                     | 93        |\n",
      "| mean 100 episode reward | 1.47e+05  |\n",
      "| n_updates               | 1318901   |\n",
      "| policy_loss             | -9982.541 |\n",
      "| qf1_loss                | 15523.634 |\n",
      "| qf2_loss                | 17175.84  |\n",
      "| time_elapsed            | 14066     |\n",
      "| total timesteps         | 1319000   |\n",
      "| value_loss              | 38435.91  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 1.7625896  |\n",
      "| ent_coef_loss           | 0.37055254 |\n",
      "| entropy                 | 15.810011  |\n",
      "| episodes                | 1330       |\n",
      "| fps                     | 93         |\n",
      "| mean 100 episode reward | 1.47e+05   |\n",
      "| n_updates               | 1328901    |\n",
      "| policy_loss             | -10544.497 |\n",
      "| qf1_loss                | 2970.1118  |\n",
      "| qf2_loss                | 2096.0647  |\n",
      "| time_elapsed            | 14203      |\n",
      "| total timesteps         | 1329000    |\n",
      "| value_loss              | 1839.7212  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 1.8343297  |\n",
      "| ent_coef_loss           | 0.33371598 |\n",
      "| entropy                 | 15.512875  |\n",
      "| episodes                | 1340       |\n",
      "| fps                     | 93         |\n",
      "| mean 100 episode reward | 1.49e+05   |\n",
      "| n_updates               | 1338901    |\n",
      "| policy_loss             | -9937.691  |\n",
      "| qf1_loss                | 3622.1658  |\n",
      "| qf2_loss                | 5450.1494  |\n",
      "| time_elapsed            | 14323      |\n",
      "| total timesteps         | 1339000    |\n",
      "| value_loss              | 1559.6353  |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ent_coef                | 1.8338038 |\n",
      "| ent_coef_loss           | 0.5995709 |\n",
      "| entropy                 | 15.816168 |\n",
      "| episodes                | 1350      |\n",
      "| fps                     | 93        |\n",
      "| mean 100 episode reward | 1.49e+05  |\n",
      "| n_updates               | 1348901   |\n",
      "| policy_loss             | -9415.696 |\n",
      "| qf1_loss                | 334369.22 |\n",
      "| qf2_loss                | 336531.53 |\n",
      "| time_elapsed            | 14453     |\n",
      "| total timesteps         | 1349000   |\n",
      "| value_loss              | 2748.107  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 1.8903087  |\n",
      "| ent_coef_loss           | 0.04627496 |\n",
      "| entropy                 | 15.626709  |\n",
      "| episodes                | 1360       |\n",
      "| fps                     | 93         |\n",
      "| mean 100 episode reward | 1.49e+05   |\n",
      "| n_updates               | 1358901    |\n",
      "| policy_loss             | -9913.73   |\n",
      "| qf1_loss                | 3551.474   |\n",
      "| qf2_loss                | 3598.38    |\n",
      "| time_elapsed            | 14588      |\n",
      "| total timesteps         | 1359000    |\n",
      "| value_loss              | 1941.9668  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 1.8237873  |\n",
      "| ent_coef_loss           | 0.94757795 |\n",
      "| entropy                 | 15.982302  |\n",
      "| episodes                | 1370       |\n",
      "| fps                     | 92         |\n",
      "| mean 100 episode reward | 1.5e+05    |\n",
      "| n_updates               | 1368901    |\n",
      "| policy_loss             | -9842.799  |\n",
      "| qf1_loss                | 1762.2632  |\n",
      "| qf2_loss                | 1876.6929  |\n",
      "| time_elapsed            | 14723      |\n",
      "| total timesteps         | 1369000    |\n",
      "| value_loss              | 2525.0176  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 1.7376478  |\n",
      "| ent_coef_loss           | 0.5456923  |\n",
      "| entropy                 | 15.584031  |\n",
      "| episodes                | 1380       |\n",
      "| fps                     | 92         |\n",
      "| mean 100 episode reward | 1.49e+05   |\n",
      "| n_updates               | 1378901    |\n",
      "| policy_loss             | -10062.711 |\n",
      "| qf1_loss                | 4252.8022  |\n",
      "| qf2_loss                | 4055.537   |\n",
      "| time_elapsed            | 14856      |\n",
      "| total timesteps         | 1379000    |\n",
      "| value_loss              | 2440.2651  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 1.8215674  |\n",
      "| ent_coef_loss           | -0.6207092 |\n",
      "| entropy                 | 15.514265  |\n",
      "| episodes                | 1390       |\n",
      "| fps                     | 92         |\n",
      "| mean 100 episode reward | 1.48e+05   |\n",
      "| n_updates               | 1388901    |\n",
      "| policy_loss             | -10602.703 |\n",
      "| qf1_loss                | 3895.7886  |\n",
      "| qf2_loss                | 4227.363   |\n",
      "| time_elapsed            | 14992      |\n",
      "| total timesteps         | 1389000    |\n",
      "| value_loss              | 2840.928   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| current_lr              | 0.0003       |\n",
      "| ent_coef                | 1.6751511    |\n",
      "| ent_coef_loss           | -0.014582276 |\n",
      "| entropy                 | 15.371215    |\n",
      "| episodes                | 1400         |\n",
      "| fps                     | 92           |\n",
      "| mean 100 episode reward | 1.5e+05      |\n",
      "| n_updates               | 1398901      |\n",
      "| policy_loss             | -10680.652   |\n",
      "| qf1_loss                | 5699.848     |\n",
      "| qf2_loss                | 3308.873     |\n",
      "| time_elapsed            | 15130        |\n",
      "| total timesteps         | 1399000      |\n",
      "| value_loss              | 3743.8074    |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| current_lr              | 0.0003       |\n",
      "| ent_coef                | 1.8834409    |\n",
      "| ent_coef_loss           | -0.027180463 |\n",
      "| entropy                 | 15.399284    |\n",
      "| episodes                | 1410         |\n",
      "| fps                     | 92           |\n",
      "| mean 100 episode reward | 1.5e+05      |\n",
      "| n_updates               | 1408901      |\n",
      "| policy_loss             | -10873.204   |\n",
      "| qf1_loss                | 8770.048     |\n",
      "| qf2_loss                | 8195.265     |\n",
      "| time_elapsed            | 15269        |\n",
      "| total timesteps         | 1409000      |\n",
      "| value_loss              | 26319.36     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 1.9672306  |\n",
      "| ent_coef_loss           | -0.6077878 |\n",
      "| entropy                 | 15.516182  |\n",
      "| episodes                | 1420       |\n",
      "| fps                     | 92         |\n",
      "| mean 100 episode reward | 1.49e+05   |\n",
      "| n_updates               | 1418901    |\n",
      "| policy_loss             | -11137.221 |\n",
      "| qf1_loss                | 2137.7788  |\n",
      "| qf2_loss                | 2448.6064  |\n",
      "| time_elapsed            | 15410      |\n",
      "| total timesteps         | 1419000    |\n",
      "| value_loss              | 2856.7837  |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 1.8313683  |\n",
      "| ent_coef_loss           | -0.9769394 |\n",
      "| entropy                 | 15.614851  |\n",
      "| episodes                | 1430       |\n",
      "| fps                     | 91         |\n",
      "| mean 100 episode reward | 1.49e+05   |\n",
      "| n_updates               | 1428901    |\n",
      "| policy_loss             | -11195.943 |\n",
      "| qf1_loss                | 14824.107  |\n",
      "| qf2_loss                | 15692.216  |\n",
      "| time_elapsed            | 15549      |\n",
      "| total timesteps         | 1429000    |\n",
      "| value_loss              | 3839.421   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 1.969141   |\n",
      "| ent_coef_loss           | -0.7194666 |\n",
      "| entropy                 | 15.58927   |\n",
      "| episodes                | 1440       |\n",
      "| fps                     | 91         |\n",
      "| mean 100 episode reward | 1.48e+05   |\n",
      "| n_updates               | 1438901    |\n",
      "| policy_loss             | -10822.148 |\n",
      "| qf1_loss                | 3686.9148  |\n",
      "| qf2_loss                | 4781.499   |\n",
      "| time_elapsed            | 15686      |\n",
      "| total timesteps         | 1439000    |\n",
      "| value_loss              | 3300.046   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 1.7387072  |\n",
      "| ent_coef_loss           | 0.5787382  |\n",
      "| entropy                 | 15.649025  |\n",
      "| episodes                | 1450       |\n",
      "| fps                     | 91         |\n",
      "| mean 100 episode reward | 1.49e+05   |\n",
      "| n_updates               | 1448901    |\n",
      "| policy_loss             | -10754.791 |\n",
      "| qf1_loss                | 3108.275   |\n",
      "| qf2_loss                | 7484.3267  |\n",
      "| time_elapsed            | 15823      |\n",
      "| total timesteps         | 1449000    |\n",
      "| value_loss              | 1347.5109  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 1.7874339   |\n",
      "| ent_coef_loss           | -0.03302908 |\n",
      "| entropy                 | 15.700469   |\n",
      "| episodes                | 1460        |\n",
      "| fps                     | 91          |\n",
      "| mean 100 episode reward | 1.49e+05    |\n",
      "| n_updates               | 1458901     |\n",
      "| policy_loss             | -11402.02   |\n",
      "| qf1_loss                | 7378.5635   |\n",
      "| qf2_loss                | 5059.003    |\n",
      "| time_elapsed            | 15959       |\n",
      "| total timesteps         | 1459000     |\n",
      "| value_loss              | 2806.4927   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 1.7161144  |\n",
      "| ent_coef_loss           | 0.12492353 |\n",
      "| entropy                 | 15.706537  |\n",
      "| episodes                | 1470       |\n",
      "| fps                     | 91         |\n",
      "| mean 100 episode reward | 1.49e+05   |\n",
      "| n_updates               | 1468901    |\n",
      "| policy_loss             | -10690.744 |\n",
      "| qf1_loss                | 1289.1481  |\n",
      "| qf2_loss                | 2062.1987  |\n",
      "| time_elapsed            | 16097      |\n",
      "| total timesteps         | 1469000    |\n",
      "| value_loss              | 2503.008   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 1.6525941   |\n",
      "| ent_coef_loss           | -0.17551193 |\n",
      "| entropy                 | 15.383414   |\n",
      "| episodes                | 1480        |\n",
      "| fps                     | 91          |\n",
      "| mean 100 episode reward | 1.5e+05     |\n",
      "| n_updates               | 1478901     |\n",
      "| policy_loss             | -11011.203  |\n",
      "| qf1_loss                | 5095.7446   |\n",
      "| qf2_loss                | 5065.7065   |\n",
      "| time_elapsed            | 16226       |\n",
      "| total timesteps         | 1479000     |\n",
      "| value_loss              | 2496.6926   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 1.6998372  |\n",
      "| ent_coef_loss           | 0.32793462 |\n",
      "| entropy                 | 15.900585  |\n",
      "| episodes                | 1490       |\n",
      "| fps                     | 91         |\n",
      "| mean 100 episode reward | 1.49e+05   |\n",
      "| n_updates               | 1488901    |\n",
      "| policy_loss             | -11048.861 |\n",
      "| qf1_loss                | 880364.8   |\n",
      "| qf2_loss                | 876116.8   |\n",
      "| time_elapsed            | 16353      |\n",
      "| total timesteps         | 1489000    |\n",
      "| value_loss              | 4487.785   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 1.5919528  |\n",
      "| ent_coef_loss           | 0.5473548  |\n",
      "| entropy                 | 15.767726  |\n",
      "| episodes                | 1500       |\n",
      "| fps                     | 90         |\n",
      "| mean 100 episode reward | 1.47e+05   |\n",
      "| n_updates               | 1498901    |\n",
      "| policy_loss             | -10946.625 |\n",
      "| qf1_loss                | 7148.3066  |\n",
      "| qf2_loss                | 9765.656   |\n",
      "| time_elapsed            | 16484      |\n",
      "| total timesteps         | 1499000    |\n",
      "| value_loss              | 9476.377   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 1.71321    |\n",
      "| ent_coef_loss           | -0.445786  |\n",
      "| entropy                 | 15.830044  |\n",
      "| episodes                | 1510       |\n",
      "| fps                     | 90         |\n",
      "| mean 100 episode reward | 1.48e+05   |\n",
      "| n_updates               | 1508901    |\n",
      "| policy_loss             | -11379.262 |\n",
      "| qf1_loss                | 2427.5527  |\n",
      "| qf2_loss                | 3748.641   |\n",
      "| time_elapsed            | 16615      |\n",
      "| total timesteps         | 1509000    |\n",
      "| value_loss              | 2395.916   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 1.6779543  |\n",
      "| ent_coef_loss           | 0.26142085 |\n",
      "| entropy                 | 15.976305  |\n",
      "| episodes                | 1520       |\n",
      "| fps                     | 90         |\n",
      "| mean 100 episode reward | 1.49e+05   |\n",
      "| n_updates               | 1518901    |\n",
      "| policy_loss             | -11000.452 |\n",
      "| qf1_loss                | 2362.6277  |\n",
      "| qf2_loss                | 2160.673   |\n",
      "| time_elapsed            | 16748      |\n",
      "| total timesteps         | 1519000    |\n",
      "| value_loss              | 2009.2386  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 1.6178697   |\n",
      "| ent_coef_loss           | -0.49618667 |\n",
      "| entropy                 | 15.359494   |\n",
      "| episodes                | 1530        |\n",
      "| fps                     | 90          |\n",
      "| mean 100 episode reward | 1.49e+05    |\n",
      "| n_updates               | 1528901     |\n",
      "| policy_loss             | -10882.053  |\n",
      "| qf1_loss                | 4705.143    |\n",
      "| qf2_loss                | 2547.335    |\n",
      "| time_elapsed            | 16882       |\n",
      "| total timesteps         | 1529000     |\n",
      "| value_loss              | 2590.6758   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 1.6447748  |\n",
      "| ent_coef_loss           | 0.08396533 |\n",
      "| entropy                 | 15.506157  |\n",
      "| episodes                | 1540       |\n",
      "| fps                     | 90         |\n",
      "| mean 100 episode reward | 1.51e+05   |\n",
      "| n_updates               | 1538901    |\n",
      "| policy_loss             | -11291.348 |\n",
      "| qf1_loss                | 3292.0278  |\n",
      "| qf2_loss                | 5150.695   |\n",
      "| time_elapsed            | 17020      |\n",
      "| total timesteps         | 1539000    |\n",
      "| value_loss              | 6269.072   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 1.5731975  |\n",
      "| ent_coef_loss           | 0.5279958  |\n",
      "| entropy                 | 15.961511  |\n",
      "| episodes                | 1550       |\n",
      "| fps                     | 90         |\n",
      "| mean 100 episode reward | 1.49e+05   |\n",
      "| n_updates               | 1548901    |\n",
      "| policy_loss             | -10181.382 |\n",
      "| qf1_loss                | 4447.343   |\n",
      "| qf2_loss                | 3053.8625  |\n",
      "| time_elapsed            | 17158      |\n",
      "| total timesteps         | 1549000    |\n",
      "| value_loss              | 2436.3267  |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 1.557186   |\n",
      "| ent_coef_loss           | 0.12741923 |\n",
      "| entropy                 | 15.716351  |\n",
      "| episodes                | 1560       |\n",
      "| fps                     | 90         |\n",
      "| mean 100 episode reward | 1.5e+05    |\n",
      "| n_updates               | 1558901    |\n",
      "| policy_loss             | -11271.822 |\n",
      "| qf1_loss                | 3306.7148  |\n",
      "| qf2_loss                | 4424.1226  |\n",
      "| time_elapsed            | 17295      |\n",
      "| total timesteps         | 1559000    |\n",
      "| value_loss              | 6003.883   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 1.600663    |\n",
      "| ent_coef_loss           | -0.66401255 |\n",
      "| entropy                 | 15.624241   |\n",
      "| episodes                | 1570        |\n",
      "| fps                     | 89          |\n",
      "| mean 100 episode reward | 1.5e+05     |\n",
      "| n_updates               | 1568901     |\n",
      "| policy_loss             | -10893.352  |\n",
      "| qf1_loss                | 10206.268   |\n",
      "| qf2_loss                | 12141.107   |\n",
      "| time_elapsed            | 17433       |\n",
      "| total timesteps         | 1569000     |\n",
      "| value_loss              | 6689.2437   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 1.5785657   |\n",
      "| ent_coef_loss           | -0.35135815 |\n",
      "| entropy                 | 15.4909     |\n",
      "| episodes                | 1580        |\n",
      "| fps                     | 89          |\n",
      "| mean 100 episode reward | 1.5e+05     |\n",
      "| n_updates               | 1578901     |\n",
      "| policy_loss             | -11117.027  |\n",
      "| qf1_loss                | 3912.6362   |\n",
      "| qf2_loss                | 2730.7832   |\n",
      "| time_elapsed            | 17571       |\n",
      "| total timesteps         | 1579000     |\n",
      "| value_loss              | 2529.5454   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 1.6112864  |\n",
      "| ent_coef_loss           | 0.17994821 |\n",
      "| entropy                 | 15.836191  |\n",
      "| episodes                | 1590       |\n",
      "| fps                     | 89         |\n",
      "| mean 100 episode reward | 1.52e+05   |\n",
      "| n_updates               | 1588901    |\n",
      "| policy_loss             | -10756.249 |\n",
      "| qf1_loss                | 6426.43    |\n",
      "| qf2_loss                | 3493.6292  |\n",
      "| time_elapsed            | 17709      |\n",
      "| total timesteps         | 1589000    |\n",
      "| value_loss              | 4109.248   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 1.5715152  |\n",
      "| ent_coef_loss           | -0.9520732 |\n",
      "| entropy                 | 15.519347  |\n",
      "| episodes                | 1600       |\n",
      "| fps                     | 89         |\n",
      "| mean 100 episode reward | 1.52e+05   |\n",
      "| n_updates               | 1598901    |\n",
      "| policy_loss             | -11084.117 |\n",
      "| qf1_loss                | 7386.7036  |\n",
      "| qf2_loss                | 6101.3486  |\n",
      "| time_elapsed            | 17847      |\n",
      "| total timesteps         | 1599000    |\n",
      "| value_loss              | 1749.2156  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 1.4733583  |\n",
      "| ent_coef_loss           | 0.55656946 |\n",
      "| entropy                 | 15.397692  |\n",
      "| episodes                | 1610       |\n",
      "| fps                     | 89         |\n",
      "| mean 100 episode reward | 1.51e+05   |\n",
      "| n_updates               | 1608901    |\n",
      "| policy_loss             | -11306.723 |\n",
      "| qf1_loss                | 5554.7363  |\n",
      "| qf2_loss                | 5328.3267  |\n",
      "| time_elapsed            | 17986      |\n",
      "| total timesteps         | 1609000    |\n",
      "| value_loss              | 1653.0222  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 1.5871778  |\n",
      "| ent_coef_loss           | -1.1576238 |\n",
      "| entropy                 | 15.135103  |\n",
      "| episodes                | 1620       |\n",
      "| fps                     | 89         |\n",
      "| mean 100 episode reward | 1.51e+05   |\n",
      "| n_updates               | 1618901    |\n",
      "| policy_loss             | -12423.428 |\n",
      "| qf1_loss                | 2507.9946  |\n",
      "| qf2_loss                | 4023.267   |\n",
      "| time_elapsed            | 18123      |\n",
      "| total timesteps         | 1619000    |\n",
      "| value_loss              | 2900.9277  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 1.5504893   |\n",
      "| ent_coef_loss           | -0.08201769 |\n",
      "| entropy                 | 15.211212   |\n",
      "| episodes                | 1630        |\n",
      "| fps                     | 89          |\n",
      "| mean 100 episode reward | 1.51e+05    |\n",
      "| n_updates               | 1628901     |\n",
      "| policy_loss             | -11126.703  |\n",
      "| qf1_loss                | 3445.1606   |\n",
      "| qf2_loss                | 4766.9556   |\n",
      "| time_elapsed            | 18263       |\n",
      "| total timesteps         | 1629000     |\n",
      "| value_loss              | 4546.495    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 1.5625353  |\n",
      "| ent_coef_loss           | 0.74438053 |\n",
      "| entropy                 | 15.841591  |\n",
      "| episodes                | 1640       |\n",
      "| fps                     | 89         |\n",
      "| mean 100 episode reward | 1.51e+05   |\n",
      "| n_updates               | 1638901    |\n",
      "| policy_loss             | -10548.643 |\n",
      "| qf1_loss                | 3427.087   |\n",
      "| qf2_loss                | 3191.3696  |\n",
      "| time_elapsed            | 18401      |\n",
      "| total timesteps         | 1639000    |\n",
      "| value_loss              | 1043.761   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 1.5647057  |\n",
      "| ent_coef_loss           | -0.3308662 |\n",
      "| entropy                 | 15.523542  |\n",
      "| episodes                | 1650       |\n",
      "| fps                     | 88         |\n",
      "| mean 100 episode reward | 1.52e+05   |\n",
      "| n_updates               | 1648901    |\n",
      "| policy_loss             | -11750.062 |\n",
      "| qf1_loss                | 6118.2554  |\n",
      "| qf2_loss                | 5769.183   |\n",
      "| time_elapsed            | 18540      |\n",
      "| total timesteps         | 1649000    |\n",
      "| value_loss              | 14226.235  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 1.6410838   |\n",
      "| ent_coef_loss           | -0.15389723 |\n",
      "| entropy                 | 15.539633   |\n",
      "| episodes                | 1660        |\n",
      "| fps                     | 88          |\n",
      "| mean 100 episode reward | 1.5e+05     |\n",
      "| n_updates               | 1658901     |\n",
      "| policy_loss             | -11575.235  |\n",
      "| qf1_loss                | 4900.5215   |\n",
      "| qf2_loss                | 3301.881    |\n",
      "| time_elapsed            | 18672       |\n",
      "| total timesteps         | 1659000     |\n",
      "| value_loss              | 10223.484   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 1.5911765  |\n",
      "| ent_coef_loss           | 0.27794808 |\n",
      "| entropy                 | 15.260918  |\n",
      "| episodes                | 1670       |\n",
      "| fps                     | 88         |\n",
      "| mean 100 episode reward | 1.51e+05   |\n",
      "| n_updates               | 1668901    |\n",
      "| policy_loss             | -11554.803 |\n",
      "| qf1_loss                | 2456.673   |\n",
      "| qf2_loss                | 2683.5554  |\n",
      "| time_elapsed            | 18800      |\n",
      "| total timesteps         | 1669000    |\n",
      "| value_loss              | 1439.6176  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 1.6886855  |\n",
      "| ent_coef_loss           | -0.1867009 |\n",
      "| entropy                 | 15.503778  |\n",
      "| episodes                | 1680       |\n",
      "| fps                     | 88         |\n",
      "| mean 100 episode reward | 1.51e+05   |\n",
      "| n_updates               | 1678901    |\n",
      "| policy_loss             | -11062.151 |\n",
      "| qf1_loss                | 3033.5986  |\n",
      "| qf2_loss                | 1871.291   |\n",
      "| time_elapsed            | 18936      |\n",
      "| total timesteps         | 1679000    |\n",
      "| value_loss              | 9701.916   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 1.5058168   |\n",
      "| ent_coef_loss           | 0.103327096 |\n",
      "| entropy                 | 15.333528   |\n",
      "| episodes                | 1690        |\n",
      "| fps                     | 88          |\n",
      "| mean 100 episode reward | 1.5e+05     |\n",
      "| n_updates               | 1688901     |\n",
      "| policy_loss             | -11825.957  |\n",
      "| qf1_loss                | 1617.8252   |\n",
      "| qf2_loss                | 3976.5      |\n",
      "| time_elapsed            | 19073       |\n",
      "| total timesteps         | 1689000     |\n",
      "| value_loss              | 1023.39685  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 1.4823601   |\n",
      "| ent_coef_loss           | -0.64577895 |\n",
      "| entropy                 | 15.010998   |\n",
      "| episodes                | 1700        |\n",
      "| fps                     | 88          |\n",
      "| mean 100 episode reward | 1.51e+05    |\n",
      "| n_updates               | 1698901     |\n",
      "| policy_loss             | -11440.349  |\n",
      "| qf1_loss                | 199263.78   |\n",
      "| qf2_loss                | 204265.53   |\n",
      "| time_elapsed            | 19207       |\n",
      "| total timesteps         | 1699000     |\n",
      "| value_loss              | 2520.8362   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 1.5686605  |\n",
      "| ent_coef_loss           | -0.3199335 |\n",
      "| entropy                 | 15.656775  |\n",
      "| episodes                | 1710       |\n",
      "| fps                     | 88         |\n",
      "| mean 100 episode reward | 1.51e+05   |\n",
      "| n_updates               | 1708901    |\n",
      "| policy_loss             | -12137.703 |\n",
      "| qf1_loss                | 1737.405   |\n",
      "| qf2_loss                | 4563.0044  |\n",
      "| time_elapsed            | 19342      |\n",
      "| total timesteps         | 1709000    |\n",
      "| value_loss              | 1103.6644  |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| current_lr              | 0.0003       |\n",
      "| ent_coef                | 1.5111638    |\n",
      "| ent_coef_loss           | -0.114363134 |\n",
      "| entropy                 | 15.047401    |\n",
      "| episodes                | 1720         |\n",
      "| fps                     | 88           |\n",
      "| mean 100 episode reward | 1.52e+05     |\n",
      "| n_updates               | 1718901      |\n",
      "| policy_loss             | -11453.916   |\n",
      "| qf1_loss                | 6228.4814    |\n",
      "| qf2_loss                | 6199.271     |\n",
      "| time_elapsed            | 19479        |\n",
      "| total timesteps         | 1719000      |\n",
      "| value_loss              | 2081.8596    |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 1.602372    |\n",
      "| ent_coef_loss           | -0.16258289 |\n",
      "| entropy                 | 15.343887   |\n",
      "| episodes                | 1730        |\n",
      "| fps                     | 88          |\n",
      "| mean 100 episode reward | 1.52e+05    |\n",
      "| n_updates               | 1728901     |\n",
      "| policy_loss             | -11267.785  |\n",
      "| qf1_loss                | 3793.3206   |\n",
      "| qf2_loss                | 6392.034    |\n",
      "| time_elapsed            | 19614       |\n",
      "| total timesteps         | 1729000     |\n",
      "| value_loss              | 3106.7627   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 1.562849   |\n",
      "| ent_coef_loss           | -0.7131661 |\n",
      "| entropy                 | 15.139004  |\n",
      "| episodes                | 1740       |\n",
      "| fps                     | 88         |\n",
      "| mean 100 episode reward | 1.52e+05   |\n",
      "| n_updates               | 1738901    |\n",
      "| policy_loss             | -11509.518 |\n",
      "| qf1_loss                | 4297.2563  |\n",
      "| qf2_loss                | 4340.3555  |\n",
      "| time_elapsed            | 19750      |\n",
      "| total timesteps         | 1739000    |\n",
      "| value_loss              | 3203.1245  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 1.6544114  |\n",
      "| ent_coef_loss           | 0.23244657 |\n",
      "| entropy                 | 15.315518  |\n",
      "| episodes                | 1750       |\n",
      "| fps                     | 87         |\n",
      "| mean 100 episode reward | 1.52e+05   |\n",
      "| n_updates               | 1748901    |\n",
      "| policy_loss             | -11042.59  |\n",
      "| qf1_loss                | 7312.13    |\n",
      "| qf2_loss                | 8792.851   |\n",
      "| time_elapsed            | 19886      |\n",
      "| total timesteps         | 1749000    |\n",
      "| value_loss              | 2686.157   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 1.6119107   |\n",
      "| ent_coef_loss           | -0.08185962 |\n",
      "| entropy                 | 15.406922   |\n",
      "| episodes                | 1760        |\n",
      "| fps                     | 87          |\n",
      "| mean 100 episode reward | 1.52e+05    |\n",
      "| n_updates               | 1758901     |\n",
      "| policy_loss             | -10973.752  |\n",
      "| qf1_loss                | 2407.7966   |\n",
      "| qf2_loss                | 3563.1455   |\n",
      "| time_elapsed            | 20021       |\n",
      "| total timesteps         | 1759000     |\n",
      "| value_loss              | 2768.9077   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 1.6424135   |\n",
      "| ent_coef_loss           | -0.37188488 |\n",
      "| entropy                 | 15.237031   |\n",
      "| episodes                | 1770        |\n",
      "| fps                     | 87          |\n",
      "| mean 100 episode reward | 1.51e+05    |\n",
      "| n_updates               | 1768901     |\n",
      "| policy_loss             | -11786.411  |\n",
      "| qf1_loss                | 3338.5923   |\n",
      "| qf2_loss                | 2152.46     |\n",
      "| time_elapsed            | 20158       |\n",
      "| total timesteps         | 1769000     |\n",
      "| value_loss              | 9989.302    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 1.4813806  |\n",
      "| ent_coef_loss           | -0.5880659 |\n",
      "| entropy                 | 15.290028  |\n",
      "| episodes                | 1780       |\n",
      "| fps                     | 87         |\n",
      "| mean 100 episode reward | 1.52e+05   |\n",
      "| n_updates               | 1778901    |\n",
      "| policy_loss             | -11623.65  |\n",
      "| qf1_loss                | 5217.5776  |\n",
      "| qf2_loss                | 6551.5117  |\n",
      "| time_elapsed            | 20295      |\n",
      "| total timesteps         | 1779000    |\n",
      "| value_loss              | 4020.2236  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 1.4103283  |\n",
      "| ent_coef_loss           | 0.04287952 |\n",
      "| entropy                 | 15.622587  |\n",
      "| episodes                | 1790       |\n",
      "| fps                     | 87         |\n",
      "| mean 100 episode reward | 1.52e+05   |\n",
      "| n_updates               | 1788901    |\n",
      "| policy_loss             | -11699.777 |\n",
      "| qf1_loss                | 4636.4136  |\n",
      "| qf2_loss                | 3139.5085  |\n",
      "| time_elapsed            | 20432      |\n",
      "| total timesteps         | 1789000    |\n",
      "| value_loss              | 8551.986   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 1.4046597  |\n",
      "| ent_coef_loss           | 0.54130626 |\n",
      "| entropy                 | 15.564717  |\n",
      "| episodes                | 1800       |\n",
      "| fps                     | 87         |\n",
      "| mean 100 episode reward | 1.52e+05   |\n",
      "| n_updates               | 1798901    |\n",
      "| policy_loss             | -11239.207 |\n",
      "| qf1_loss                | 527264.3   |\n",
      "| qf2_loss                | 472792.88  |\n",
      "| time_elapsed            | 20569      |\n",
      "| total timesteps         | 1799000    |\n",
      "| value_loss              | 6211.754   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 1.4232253   |\n",
      "| ent_coef_loss           | -0.18266344 |\n",
      "| entropy                 | 15.534407   |\n",
      "| episodes                | 1810        |\n",
      "| fps                     | 87          |\n",
      "| mean 100 episode reward | 1.52e+05    |\n",
      "| n_updates               | 1808901     |\n",
      "| policy_loss             | -11943.469  |\n",
      "| qf1_loss                | 793298.06   |\n",
      "| qf2_loss                | 792122.44   |\n",
      "| time_elapsed            | 20697       |\n",
      "| total timesteps         | 1809000     |\n",
      "| value_loss              | 16643.238   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 1.5947533  |\n",
      "| ent_coef_loss           | 0.76190794 |\n",
      "| entropy                 | 15.687931  |\n",
      "| episodes                | 1820       |\n",
      "| fps                     | 87         |\n",
      "| mean 100 episode reward | 1.51e+05   |\n",
      "| n_updates               | 1818901    |\n",
      "| policy_loss             | -10754.713 |\n",
      "| qf1_loss                | 4571.4077  |\n",
      "| qf2_loss                | 3672.0876  |\n",
      "| time_elapsed            | 20820      |\n",
      "| total timesteps         | 1819000    |\n",
      "| value_loss              | 5044.863   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 1.4305136   |\n",
      "| ent_coef_loss           | -0.29501066 |\n",
      "| entropy                 | 15.180468   |\n",
      "| episodes                | 1830        |\n",
      "| fps                     | 87          |\n",
      "| mean 100 episode reward | 1.49e+05    |\n",
      "| n_updates               | 1828901     |\n",
      "| policy_loss             | -11735.308  |\n",
      "| qf1_loss                | 3055.1748   |\n",
      "| qf2_loss                | 2882.5835   |\n",
      "| time_elapsed            | 20951       |\n",
      "| total timesteps         | 1829000     |\n",
      "| value_loss              | 1461.8702   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 1.5001488  |\n",
      "| ent_coef_loss           | -0.3813914 |\n",
      "| entropy                 | 15.233388  |\n",
      "| episodes                | 1840       |\n",
      "| fps                     | 87         |\n",
      "| mean 100 episode reward | 1.49e+05   |\n",
      "| n_updates               | 1838901    |\n",
      "| policy_loss             | -11839.209 |\n",
      "| qf1_loss                | 5245.4487  |\n",
      "| qf2_loss                | 8290.078   |\n",
      "| time_elapsed            | 21083      |\n",
      "| total timesteps         | 1839000    |\n",
      "| value_loss              | 3626.188   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 1.4637035  |\n",
      "| ent_coef_loss           | 0.5924409  |\n",
      "| entropy                 | 15.337307  |\n",
      "| episodes                | 1850       |\n",
      "| fps                     | 87         |\n",
      "| mean 100 episode reward | 1.49e+05   |\n",
      "| n_updates               | 1848901    |\n",
      "| policy_loss             | -11624.682 |\n",
      "| qf1_loss                | 8655.905   |\n",
      "| qf2_loss                | 10197.171  |\n",
      "| time_elapsed            | 21215      |\n",
      "| total timesteps         | 1849000    |\n",
      "| value_loss              | 12984.576  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 1.5842624  |\n",
      "| ent_coef_loss           | 0.56306326 |\n",
      "| entropy                 | 15.512848  |\n",
      "| episodes                | 1860       |\n",
      "| fps                     | 87         |\n",
      "| mean 100 episode reward | 1.49e+05   |\n",
      "| n_updates               | 1858901    |\n",
      "| policy_loss             | -10631.303 |\n",
      "| qf1_loss                | 327082.94  |\n",
      "| qf2_loss                | 331607.38  |\n",
      "| time_elapsed            | 21348      |\n",
      "| total timesteps         | 1859000    |\n",
      "| value_loss              | 7155.7017  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 1.4869016   |\n",
      "| ent_coef_loss           | -0.21806364 |\n",
      "| entropy                 | 15.241399   |\n",
      "| episodes                | 1870        |\n",
      "| fps                     | 86          |\n",
      "| mean 100 episode reward | 1.48e+05    |\n",
      "| n_updates               | 1868901     |\n",
      "| policy_loss             | -11529.069  |\n",
      "| qf1_loss                | 3648.659    |\n",
      "| qf2_loss                | 2761.6013   |\n",
      "| time_elapsed            | 21484       |\n",
      "| total timesteps         | 1869000     |\n",
      "| value_loss              | 4557.467    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 1.4893486   |\n",
      "| ent_coef_loss           | -0.40587455 |\n",
      "| entropy                 | 14.907233   |\n",
      "| episodes                | 1880        |\n",
      "| fps                     | 86          |\n",
      "| mean 100 episode reward | 1.48e+05    |\n",
      "| n_updates               | 1878901     |\n",
      "| policy_loss             | -11346.536  |\n",
      "| qf1_loss                | 5006.6924   |\n",
      "| qf2_loss                | 4525.965    |\n",
      "| time_elapsed            | 21619       |\n",
      "| total timesteps         | 1879000     |\n",
      "| value_loss              | 2966.357    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| current_lr              | 0.0003       |\n",
      "| ent_coef                | 1.5455804    |\n",
      "| ent_coef_loss           | -0.007579945 |\n",
      "| entropy                 | 15.119096    |\n",
      "| episodes                | 1890         |\n",
      "| fps                     | 86           |\n",
      "| mean 100 episode reward | 1.46e+05     |\n",
      "| n_updates               | 1888901      |\n",
      "| policy_loss             | -11327.926   |\n",
      "| qf1_loss                | 1173784.4    |\n",
      "| qf2_loss                | 1163421.4    |\n",
      "| time_elapsed            | 21755        |\n",
      "| total timesteps         | 1889000      |\n",
      "| value_loss              | 3099.8796    |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 1.5219077  |\n",
      "| ent_coef_loss           | 0.7468622  |\n",
      "| entropy                 | 15.785664  |\n",
      "| episodes                | 1900       |\n",
      "| fps                     | 86         |\n",
      "| mean 100 episode reward | 1.44e+05   |\n",
      "| n_updates               | 1898901    |\n",
      "| policy_loss             | -11242.641 |\n",
      "| qf1_loss                | 3225.7544  |\n",
      "| qf2_loss                | 2855.379   |\n",
      "| time_elapsed            | 21892      |\n",
      "| total timesteps         | 1899000    |\n",
      "| value_loss              | 1483.0186  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 1.4586278  |\n",
      "| ent_coef_loss           | 0.4384889  |\n",
      "| entropy                 | 15.087818  |\n",
      "| episodes                | 1910       |\n",
      "| fps                     | 86         |\n",
      "| mean 100 episode reward | 1.44e+05   |\n",
      "| n_updates               | 1908901    |\n",
      "| policy_loss             | -11109.626 |\n",
      "| qf1_loss                | 2970.3806  |\n",
      "| qf2_loss                | 3135.6467  |\n",
      "| time_elapsed            | 22029      |\n",
      "| total timesteps         | 1909000    |\n",
      "| value_loss              | 2937.5862  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 1.4968691  |\n",
      "| ent_coef_loss           | 0.07742521 |\n",
      "| entropy                 | 15.413149  |\n",
      "| episodes                | 1920       |\n",
      "| fps                     | 86         |\n",
      "| mean 100 episode reward | 1.44e+05   |\n",
      "| n_updates               | 1918901    |\n",
      "| policy_loss             | -11065.801 |\n",
      "| qf1_loss                | 795138.94  |\n",
      "| qf2_loss                | 789492.56  |\n",
      "| time_elapsed            | 22165      |\n",
      "| total timesteps         | 1919000    |\n",
      "| value_loss              | 4805.8467  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 1.4708633  |\n",
      "| ent_coef_loss           | 0.27545452 |\n",
      "| entropy                 | 15.610234  |\n",
      "| episodes                | 1930       |\n",
      "| fps                     | 86         |\n",
      "| mean 100 episode reward | 1.43e+05   |\n",
      "| n_updates               | 1928901    |\n",
      "| policy_loss             | -10882.998 |\n",
      "| qf1_loss                | 8590.688   |\n",
      "| qf2_loss                | 5025.556   |\n",
      "| time_elapsed            | 22300      |\n",
      "| total timesteps         | 1929000    |\n",
      "| value_loss              | 6808.144   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 1.4423018  |\n",
      "| ent_coef_loss           | -0.306691  |\n",
      "| entropy                 | 15.022915  |\n",
      "| episodes                | 1940       |\n",
      "| fps                     | 86         |\n",
      "| mean 100 episode reward | 1.42e+05   |\n",
      "| n_updates               | 1938901    |\n",
      "| policy_loss             | -11220.809 |\n",
      "| qf1_loss                | 10823.998  |\n",
      "| qf2_loss                | 7742.5     |\n",
      "| time_elapsed            | 22437      |\n",
      "| total timesteps         | 1939000    |\n",
      "| value_loss              | 4751.829   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 1.4162301   |\n",
      "| ent_coef_loss           | -0.42532098 |\n",
      "| entropy                 | 15.131926   |\n",
      "| episodes                | 1950        |\n",
      "| fps                     | 86          |\n",
      "| mean 100 episode reward | 1.4e+05     |\n",
      "| n_updates               | 1948901     |\n",
      "| policy_loss             | -10583.88   |\n",
      "| qf1_loss                | 13646.451   |\n",
      "| qf2_loss                | 14953.252   |\n",
      "| time_elapsed            | 22581       |\n",
      "| total timesteps         | 1949000     |\n",
      "| value_loss              | 1646.2394   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 1.4350197   |\n",
      "| ent_coef_loss           | 0.009385414 |\n",
      "| entropy                 | 15.484546   |\n",
      "| episodes                | 1960        |\n",
      "| fps                     | 86          |\n",
      "| mean 100 episode reward | 1.39e+05    |\n",
      "| n_updates               | 1958901     |\n",
      "| policy_loss             | -11796.532  |\n",
      "| qf1_loss                | 11947.508   |\n",
      "| qf2_loss                | 7087.6455   |\n",
      "| time_elapsed            | 22721       |\n",
      "| total timesteps         | 1959000     |\n",
      "| value_loss              | 15343.564   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 1.3905433   |\n",
      "| ent_coef_loss           | -0.42797118 |\n",
      "| entropy                 | 14.9558735  |\n",
      "| episodes                | 1970        |\n",
      "| fps                     | 86          |\n",
      "| mean 100 episode reward | 1.39e+05    |\n",
      "| n_updates               | 1968901     |\n",
      "| policy_loss             | -11355.246  |\n",
      "| qf1_loss                | 6825.1436   |\n",
      "| qf2_loss                | 7003.1494   |\n",
      "| time_elapsed            | 22860       |\n",
      "| total timesteps         | 1969000     |\n",
      "| value_loss              | 2367.9934   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 1.4055364  |\n",
      "| ent_coef_loss           | -0.4428595 |\n",
      "| entropy                 | 15.330061  |\n",
      "| episodes                | 1980       |\n",
      "| fps                     | 86         |\n",
      "| mean 100 episode reward | 1.38e+05   |\n",
      "| n_updates               | 1978901    |\n",
      "| policy_loss             | -11046.305 |\n",
      "| qf1_loss                | 3851.2358  |\n",
      "| qf2_loss                | 2073.2598  |\n",
      "| time_elapsed            | 22992      |\n",
      "| total timesteps         | 1979000    |\n",
      "| value_loss              | 1111.2385  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 1.4566038  |\n",
      "| ent_coef_loss           | 0.41756004 |\n",
      "| entropy                 | 15.369508  |\n",
      "| episodes                | 1990       |\n",
      "| fps                     | 86         |\n",
      "| mean 100 episode reward | 1.39e+05   |\n",
      "| n_updates               | 1988901    |\n",
      "| policy_loss             | -11238.442 |\n",
      "| qf1_loss                | 4117.963   |\n",
      "| qf2_loss                | 2923.4775  |\n",
      "| time_elapsed            | 23121      |\n",
      "| total timesteps         | 1989000    |\n",
      "| value_loss              | 2675.851   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 1.4314209  |\n",
      "| ent_coef_loss           | 0.07377134 |\n",
      "| entropy                 | 15.310362  |\n",
      "| episodes                | 2000       |\n",
      "| fps                     | 85         |\n",
      "| mean 100 episode reward | 1.39e+05   |\n",
      "| n_updates               | 1998901    |\n",
      "| policy_loss             | -11296.195 |\n",
      "| qf1_loss                | 936878.9   |\n",
      "| qf2_loss                | 945627.6   |\n",
      "| time_elapsed            | 23254      |\n",
      "| total timesteps         | 1999000    |\n",
      "| value_loss              | 3110.1938  |\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# TRAIN THE MODEL\n",
    "model.learn(total_timesteps=int(2e6), log_interval=10)\n",
    "model.save(\"humanoid_standup_2M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gym' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ecd16610c515>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# RUN THE SAVED MODEL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'HumanoidStandup-v2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSAC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"humanoid_standup_2M\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gym' is not defined"
     ]
    }
   ],
   "source": [
    "# RUN THE SAVED MODEL\n",
    "env = gym.make('HumanoidStandup-v2')\n",
    "model = SAC.load(\"humanoid_standup_2M\")\n",
    "\n",
    "for _ in range(10):\n",
    "    obs = env.reset()\n",
    "    for _ in range(1000):\n",
    "        action, _states = model.predict(obs)\n",
    "        obs, rewards, dones, info = env.step(action)\n",
    "        env.render()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800\"\n",
       "            src=\"http://localhost:6008\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f849407f750>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# DISPLAY THE RESULTS\n",
    "%tensorboard --logdir sac_humanoid_standup_tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task: Teach a 'half-cheetah' a gait to run forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f849406fc10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f849406fc10>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f849406fc10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f849406fc10>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f84686da9d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f84686da9d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f84686da9d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f84686da9d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8494022f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8494022f10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8494022f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8494022f10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f849406fc10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f849406fc10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f849406fc10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f849406fc10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f849406fc10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f849406fc10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f849406fc10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f849406fc10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f848005cc90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f848005cc90>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f848005cc90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f848005cc90>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f848005c690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f848005c690>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f848005c690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f848005c690>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83bf758150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83bf758150>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83bf758150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83bf758150>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83c4400550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83c4400550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83c4400550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83c4400550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8520def6d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8520def6d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8520def6d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8520def6d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8520def6d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8520def6d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8520def6d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8520def6d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83c422d410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83c422d410>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83c422d410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83c422d410>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83bf7aadd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83bf7aadd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83bf7aadd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83bf7aadd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83bfcacbd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83bfcacbd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83bfcacbd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83bfcacbd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8468775350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8468775350>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8468775350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8468775350>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f83c4458b90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f83c4458b90>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f83c4458b90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f83c4458b90>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83c42d6a10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83c42d6a10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83c42d6a10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83c42d6a10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83c5e4b790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83c5e4b790>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83c5e4b790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83c5e4b790>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83c4458b90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83c4458b90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83c4458b90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83c4458b90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f84800e3a50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f84800e3a50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f84800e3a50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f84800e3a50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83c5d6fe90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83c5d6fe90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83c5d6fe90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83c5d6fe90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83bf758150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83bf758150>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83bf758150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83bf758150>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f83c4385250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f83c4385250>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f83c4385250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f83c4385250>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83bf758150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83bf758150>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83bf758150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83bf758150>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83bf758150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83bf758150>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83bf758150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83bf758150>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83c4385e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83c4385e90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83c4385e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83c4385e90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    }
   ],
   "source": [
    "# DEFINE THE ENVIRONMENT/MODEL WITH TUNED PARAMETERS\n",
    "env = gym.make('HalfCheetah-v2')\n",
    "policy_kwargs = dict(layers=[256, 256])\n",
    "model = SAC(MlpPolicy, env, verbose=1, tensorboard_log=\"./sac_half_cheetah_tensorboard/\", \n",
    "            policy_kwargs=policy_kwargs, buffer_size=1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.077221446 |\n",
      "| ent_coef_loss           | -14.443401  |\n",
      "| entropy                 | 7.252101    |\n",
      "| episodes                | 10          |\n",
      "| fps                     | 140         |\n",
      "| mean 100 episode reward | -272        |\n",
      "| n_updates               | 8901        |\n",
      "| policy_loss             | -24.813099  |\n",
      "| qf1_loss                | 1.0343223   |\n",
      "| qf2_loss                | 1.0283409   |\n",
      "| time_elapsed            | 63          |\n",
      "| total timesteps         | 9000        |\n",
      "| value_loss              | 0.6378672   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.008806796 |\n",
      "| ent_coef_loss           | 2.4678369   |\n",
      "| entropy                 | 2.3462186   |\n",
      "| episodes                | 20          |\n",
      "| fps                     | 129         |\n",
      "| mean 100 episode reward | -248        |\n",
      "| n_updates               | 18901       |\n",
      "| policy_loss             | -6.4548817  |\n",
      "| qf1_loss                | 0.32903108  |\n",
      "| qf2_loss                | 0.3764286   |\n",
      "| time_elapsed            | 147         |\n",
      "| total timesteps         | 19000       |\n",
      "| value_loss              | 0.24944901  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.020749796 |\n",
      "| ent_coef_loss           | 7.7533045   |\n",
      "| entropy                 | 4.088045    |\n",
      "| episodes                | 30          |\n",
      "| fps                     | 124         |\n",
      "| mean 100 episode reward | 34.1        |\n",
      "| n_updates               | 28901       |\n",
      "| policy_loss             | -8.892538   |\n",
      "| qf1_loss                | 0.55391926  |\n",
      "| qf2_loss                | 0.49188069  |\n",
      "| time_elapsed            | 232         |\n",
      "| total timesteps         | 29000       |\n",
      "| value_loss              | 0.37027717  |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.04565271 |\n",
      "| ent_coef_loss           | 0.49165785 |\n",
      "| entropy                 | 5.2425427  |\n",
      "| episodes                | 40         |\n",
      "| fps                     | 122        |\n",
      "| mean 100 episode reward | 400        |\n",
      "| n_updates               | 38901      |\n",
      "| policy_loss             | -35.236267 |\n",
      "| qf1_loss                | 1.2126328  |\n",
      "| qf2_loss                | 0.98295283 |\n",
      "| time_elapsed            | 317        |\n",
      "| total timesteps         | 39000      |\n",
      "| value_loss              | 0.563034   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.055459883 |\n",
      "| ent_coef_loss           | 1.0460848   |\n",
      "| entropy                 | 5.0930433   |\n",
      "| episodes                | 50          |\n",
      "| fps                     | 121         |\n",
      "| mean 100 episode reward | 696         |\n",
      "| n_updates               | 48901       |\n",
      "| policy_loss             | -51.18821   |\n",
      "| qf1_loss                | 1.5792068   |\n",
      "| qf2_loss                | 1.6124103   |\n",
      "| time_elapsed            | 403         |\n",
      "| total timesteps         | 49000       |\n",
      "| value_loss              | 1.3630123   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.06327943 |\n",
      "| ent_coef_loss           | -4.3275576 |\n",
      "| entropy                 | 4.987198   |\n",
      "| episodes                | 60         |\n",
      "| fps                     | 120        |\n",
      "| mean 100 episode reward | 779        |\n",
      "| n_updates               | 58901      |\n",
      "| policy_loss             | -62.714165 |\n",
      "| qf1_loss                | 2.5209944  |\n",
      "| qf2_loss                | 2.634844   |\n",
      "| time_elapsed            | 488        |\n",
      "| total timesteps         | 59000      |\n",
      "| value_loss              | 1.2162406  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.071278706 |\n",
      "| ent_coef_loss           | -0.2581749  |\n",
      "| entropy                 | 4.9621487   |\n",
      "| episodes                | 70          |\n",
      "| fps                     | 120         |\n",
      "| mean 100 episode reward | 974         |\n",
      "| n_updates               | 68901       |\n",
      "| policy_loss             | -68.34958   |\n",
      "| qf1_loss                | 4.131881    |\n",
      "| qf2_loss                | 4.1757426   |\n",
      "| time_elapsed            | 574         |\n",
      "| total timesteps         | 69000       |\n",
      "| value_loss              | 1.2135229   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.0761765  |\n",
      "| ent_coef_loss           | -2.1504931 |\n",
      "| entropy                 | 4.73773    |\n",
      "| episodes                | 80         |\n",
      "| fps                     | 119        |\n",
      "| mean 100 episode reward | 1.16e+03   |\n",
      "| n_updates               | 78901      |\n",
      "| policy_loss             | -94.58748  |\n",
      "| qf1_loss                | 2.505958   |\n",
      "| qf2_loss                | 3.0086555  |\n",
      "| time_elapsed            | 662        |\n",
      "| total timesteps         | 79000      |\n",
      "| value_loss              | 1.1526512  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.08110483  |\n",
      "| ent_coef_loss           | -0.51621306 |\n",
      "| entropy                 | 4.639325    |\n",
      "| episodes                | 90          |\n",
      "| fps                     | 118         |\n",
      "| mean 100 episode reward | 1.33e+03    |\n",
      "| n_updates               | 88901       |\n",
      "| policy_loss             | -109.84258  |\n",
      "| qf1_loss                | 4.461891    |\n",
      "| qf2_loss                | 5.0017166   |\n",
      "| time_elapsed            | 750         |\n",
      "| total timesteps         | 89000       |\n",
      "| value_loss              | 1.7972703   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.087464646 |\n",
      "| ent_coef_loss           | 0.568797    |\n",
      "| entropy                 | 4.7439294   |\n",
      "| episodes                | 100         |\n",
      "| fps                     | 118         |\n",
      "| mean 100 episode reward | 1.47e+03    |\n",
      "| n_updates               | 98901       |\n",
      "| policy_loss             | -105.44086  |\n",
      "| qf1_loss                | 3.3706157   |\n",
      "| qf2_loss                | 3.2434835   |\n",
      "| time_elapsed            | 838         |\n",
      "| total timesteps         | 99000       |\n",
      "| value_loss              | 4.9171305   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.094351776 |\n",
      "| ent_coef_loss           | 0.9788337   |\n",
      "| entropy                 | 5.0073047   |\n",
      "| episodes                | 110         |\n",
      "| fps                     | 117         |\n",
      "| mean 100 episode reward | 1.76e+03    |\n",
      "| n_updates               | 108901      |\n",
      "| policy_loss             | -124.64894  |\n",
      "| qf1_loss                | 3.1894133   |\n",
      "| qf2_loss                | 3.7454815   |\n",
      "| time_elapsed            | 925         |\n",
      "| total timesteps         | 109000      |\n",
      "| value_loss              | 1.5198317   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.09888382 |\n",
      "| ent_coef_loss           | 1.5129279  |\n",
      "| entropy                 | 4.91516    |\n",
      "| episodes                | 120        |\n",
      "| fps                     | 117        |\n",
      "| mean 100 episode reward | 2.1e+03    |\n",
      "| n_updates               | 118901     |\n",
      "| policy_loss             | -124.14511 |\n",
      "| qf1_loss                | 3.1628695  |\n",
      "| qf2_loss                | 4.2491584  |\n",
      "| time_elapsed            | 1012       |\n",
      "| total timesteps         | 119000     |\n",
      "| value_loss              | 14.628567  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.10830256 |\n",
      "| ent_coef_loss           | -0.5307988 |\n",
      "| entropy                 | 4.812949   |\n",
      "| episodes                | 130        |\n",
      "| fps                     | 117        |\n",
      "| mean 100 episode reward | 2.38e+03   |\n",
      "| n_updates               | 128901     |\n",
      "| policy_loss             | -138.65558 |\n",
      "| qf1_loss                | 4.0872355  |\n",
      "| qf2_loss                | 4.924633   |\n",
      "| time_elapsed            | 1100       |\n",
      "| total timesteps         | 129000     |\n",
      "| value_loss              | 1.7098209  |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.11372819 |\n",
      "| ent_coef_loss           | 0.27206975 |\n",
      "| entropy                 | 4.7157555  |\n",
      "| episodes                | 140        |\n",
      "| fps                     | 116        |\n",
      "| mean 100 episode reward | 2.55e+03   |\n",
      "| n_updates               | 138901     |\n",
      "| policy_loss             | -138.6146  |\n",
      "| qf1_loss                | 5.302787   |\n",
      "| qf2_loss                | 4.8246965  |\n",
      "| time_elapsed            | 1188       |\n",
      "| total timesteps         | 139000     |\n",
      "| value_loss              | 1.8993766  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.12157916 |\n",
      "| ent_coef_loss           | 0.435884   |\n",
      "| entropy                 | 4.7494674  |\n",
      "| episodes                | 150        |\n",
      "| fps                     | 116        |\n",
      "| mean 100 episode reward | 2.71e+03   |\n",
      "| n_updates               | 148901     |\n",
      "| policy_loss             | -142.35864 |\n",
      "| qf1_loss                | 9.792103   |\n",
      "| qf2_loss                | 11.721245  |\n",
      "| time_elapsed            | 1275       |\n",
      "| total timesteps         | 149000     |\n",
      "| value_loss              | 3.1859403  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.12943417 |\n",
      "| ent_coef_loss           | -0.5973025 |\n",
      "| entropy                 | 4.64315    |\n",
      "| episodes                | 160        |\n",
      "| fps                     | 116        |\n",
      "| mean 100 episode reward | 2.95e+03   |\n",
      "| n_updates               | 158901     |\n",
      "| policy_loss             | -159.05667 |\n",
      "| qf1_loss                | 7.901149   |\n",
      "| qf2_loss                | 5.755165   |\n",
      "| time_elapsed            | 1362       |\n",
      "| total timesteps         | 159000     |\n",
      "| value_loss              | 12.739649  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.13444701 |\n",
      "| ent_coef_loss           | -1.7446442 |\n",
      "| entropy                 | 4.9093404  |\n",
      "| episodes                | 170        |\n",
      "| fps                     | 116        |\n",
      "| mean 100 episode reward | 3.1e+03    |\n",
      "| n_updates               | 168901     |\n",
      "| policy_loss             | -157.28284 |\n",
      "| qf1_loss                | 4.747553   |\n",
      "| qf2_loss                | 5.0575924  |\n",
      "| time_elapsed            | 1450       |\n",
      "| total timesteps         | 169000     |\n",
      "| value_loss              | 2.4885397  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.13628243 |\n",
      "| ent_coef_loss           | 1.1924822  |\n",
      "| entropy                 | 4.620712   |\n",
      "| episodes                | 180        |\n",
      "| fps                     | 116        |\n",
      "| mean 100 episode reward | 3.23e+03   |\n",
      "| n_updates               | 178901     |\n",
      "| policy_loss             | -193.09158 |\n",
      "| qf1_loss                | 9.465883   |\n",
      "| qf2_loss                | 9.390654   |\n",
      "| time_elapsed            | 1538       |\n",
      "| total timesteps         | 179000     |\n",
      "| value_loss              | 2.4994497  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.13890468 |\n",
      "| ent_coef_loss           | 2.1831164  |\n",
      "| entropy                 | 4.746926   |\n",
      "| episodes                | 190        |\n",
      "| fps                     | 116        |\n",
      "| mean 100 episode reward | 3.35e+03   |\n",
      "| n_updates               | 188901     |\n",
      "| policy_loss             | -187.62767 |\n",
      "| qf1_loss                | 3.8523037  |\n",
      "| qf2_loss                | 4.7547345  |\n",
      "| time_elapsed            | 1624       |\n",
      "| total timesteps         | 189000     |\n",
      "| value_loss              | 4.6902514  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.14108868 |\n",
      "| ent_coef_loss           | 1.1187558  |\n",
      "| entropy                 | 4.8088913  |\n",
      "| episodes                | 200        |\n",
      "| fps                     | 116        |\n",
      "| mean 100 episode reward | 3.47e+03   |\n",
      "| n_updates               | 198901     |\n",
      "| policy_loss             | -174.39702 |\n",
      "| qf1_loss                | 5.4019003  |\n",
      "| qf2_loss                | 4.6106315  |\n",
      "| time_elapsed            | 1712       |\n",
      "| total timesteps         | 199000     |\n",
      "| value_loss              | 3.8925424  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.14924684 |\n",
      "| ent_coef_loss           | 0.26552325 |\n",
      "| entropy                 | 4.7165303  |\n",
      "| episodes                | 210        |\n",
      "| fps                     | 116        |\n",
      "| mean 100 episode reward | 3.58e+03   |\n",
      "| n_updates               | 208901     |\n",
      "| policy_loss             | -178.69104 |\n",
      "| qf1_loss                | 2.088265   |\n",
      "| qf2_loss                | 2.9804182  |\n",
      "| time_elapsed            | 1786       |\n",
      "| total timesteps         | 209000     |\n",
      "| value_loss              | 3.5383503  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.15610853 |\n",
      "| ent_coef_loss           | 0.53514886 |\n",
      "| entropy                 | 4.748247   |\n",
      "| episodes                | 220        |\n",
      "| fps                     | 117        |\n",
      "| mean 100 episode reward | 3.67e+03   |\n",
      "| n_updates               | 218901     |\n",
      "| policy_loss             | -194.95636 |\n",
      "| qf1_loss                | 390.74347  |\n",
      "| qf2_loss                | 376.55835  |\n",
      "| time_elapsed            | 1865       |\n",
      "| total timesteps         | 219000     |\n",
      "| value_loss              | 2.4508355  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.1524368  |\n",
      "| ent_coef_loss           | 1.103265   |\n",
      "| entropy                 | 4.533698   |\n",
      "| episodes                | 230        |\n",
      "| fps                     | 117        |\n",
      "| mean 100 episode reward | 3.75e+03   |\n",
      "| n_updates               | 228901     |\n",
      "| policy_loss             | -203.49924 |\n",
      "| qf1_loss                | 3.1257687  |\n",
      "| qf2_loss                | 2.8896146  |\n",
      "| time_elapsed            | 1947       |\n",
      "| total timesteps         | 229000     |\n",
      "| value_loss              | 1.6542895  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.15954024 |\n",
      "| ent_coef_loss           | -1.4118131 |\n",
      "| entropy                 | 4.6853     |\n",
      "| episodes                | 240        |\n",
      "| fps                     | 117        |\n",
      "| mean 100 episode reward | 3.83e+03   |\n",
      "| n_updates               | 238901     |\n",
      "| policy_loss             | -166.12564 |\n",
      "| qf1_loss                | 5.057184   |\n",
      "| qf2_loss                | 4.9134645  |\n",
      "| time_elapsed            | 2033       |\n",
      "| total timesteps         | 239000     |\n",
      "| value_loss              | 4.853557   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.15955403  |\n",
      "| ent_coef_loss           | 0.006831646 |\n",
      "| entropy                 | 4.706296    |\n",
      "| episodes                | 250         |\n",
      "| fps                     | 117         |\n",
      "| mean 100 episode reward | 3.92e+03    |\n",
      "| n_updates               | 248901      |\n",
      "| policy_loss             | -199.452    |\n",
      "| qf1_loss                | 5.780634    |\n",
      "| qf2_loss                | 5.0545483   |\n",
      "| time_elapsed            | 2119        |\n",
      "| total timesteps         | 249000      |\n",
      "| value_loss              | 3.953467    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.16757864 |\n",
      "| ent_coef_loss           | -1.8125063 |\n",
      "| entropy                 | 4.5924683  |\n",
      "| episodes                | 260        |\n",
      "| fps                     | 117        |\n",
      "| mean 100 episode reward | 4.01e+03   |\n",
      "| n_updates               | 258901     |\n",
      "| policy_loss             | -196.0169  |\n",
      "| qf1_loss                | 234.37537  |\n",
      "| qf2_loss                | 223.65094  |\n",
      "| time_elapsed            | 2206       |\n",
      "| total timesteps         | 259000     |\n",
      "| value_loss              | 4.443823   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.1666056  |\n",
      "| ent_coef_loss           | -2.0274417 |\n",
      "| entropy                 | 4.8376884  |\n",
      "| episodes                | 270        |\n",
      "| fps                     | 117        |\n",
      "| mean 100 episode reward | 4.1e+03    |\n",
      "| n_updates               | 268901     |\n",
      "| policy_loss             | -207.14598 |\n",
      "| qf1_loss                | 4.2153287  |\n",
      "| qf2_loss                | 3.653286   |\n",
      "| time_elapsed            | 2294       |\n",
      "| total timesteps         | 269000     |\n",
      "| value_loss              | 2.5439286  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.17522393 |\n",
      "| ent_coef_loss           | 1.4029466  |\n",
      "| entropy                 | 4.423843   |\n",
      "| episodes                | 280        |\n",
      "| fps                     | 117        |\n",
      "| mean 100 episode reward | 4.18e+03   |\n",
      "| n_updates               | 278901     |\n",
      "| policy_loss             | -212.47246 |\n",
      "| qf1_loss                | 8.529746   |\n",
      "| qf2_loss                | 10.352278  |\n",
      "| time_elapsed            | 2383       |\n",
      "| total timesteps         | 279000     |\n",
      "| value_loss              | 9.922506   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.17204379 |\n",
      "| ent_coef_loss           | -1.3507919 |\n",
      "| entropy                 | 4.5879164  |\n",
      "| episodes                | 290        |\n",
      "| fps                     | 116        |\n",
      "| mean 100 episode reward | 4.27e+03   |\n",
      "| n_updates               | 288901     |\n",
      "| policy_loss             | -199.03192 |\n",
      "| qf1_loss                | 7.915675   |\n",
      "| qf2_loss                | 6.214729   |\n",
      "| time_elapsed            | 2470       |\n",
      "| total timesteps         | 289000     |\n",
      "| value_loss              | 7.423883   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.16933554 |\n",
      "| ent_coef_loss           | 1.6704122  |\n",
      "| entropy                 | 4.598682   |\n",
      "| episodes                | 300        |\n",
      "| fps                     | 116        |\n",
      "| mean 100 episode reward | 4.34e+03   |\n",
      "| n_updates               | 298901     |\n",
      "| policy_loss             | -230.05698 |\n",
      "| qf1_loss                | 3.6126623  |\n",
      "| qf2_loss                | 4.2157116  |\n",
      "| time_elapsed            | 2558       |\n",
      "| total timesteps         | 299000     |\n",
      "| value_loss              | 3.492589   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.17121284 |\n",
      "| ent_coef_loss           | 0.39538705 |\n",
      "| entropy                 | 4.4538746  |\n",
      "| episodes                | 310        |\n",
      "| fps                     | 116        |\n",
      "| mean 100 episode reward | 4.42e+03   |\n",
      "| n_updates               | 308901     |\n",
      "| policy_loss             | -231.76239 |\n",
      "| qf1_loss                | 3.9821377  |\n",
      "| qf2_loss                | 7.8536463  |\n",
      "| time_elapsed            | 2645       |\n",
      "| total timesteps         | 309000     |\n",
      "| value_loss              | 2.67513    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.18000014  |\n",
      "| ent_coef_loss           | -0.05042845 |\n",
      "| entropy                 | 4.6289763   |\n",
      "| episodes                | 320         |\n",
      "| fps                     | 116         |\n",
      "| mean 100 episode reward | 4.51e+03    |\n",
      "| n_updates               | 318901      |\n",
      "| policy_loss             | -238.76097  |\n",
      "| qf1_loss                | 10.034946   |\n",
      "| qf2_loss                | 10.703129   |\n",
      "| time_elapsed            | 2732        |\n",
      "| total timesteps         | 319000      |\n",
      "| value_loss              | 4.8541665   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.1778807   |\n",
      "| ent_coef_loss           | -0.41169146 |\n",
      "| entropy                 | 4.4950595   |\n",
      "| episodes                | 330         |\n",
      "| fps                     | 116         |\n",
      "| mean 100 episode reward | 4.57e+03    |\n",
      "| n_updates               | 328901      |\n",
      "| policy_loss             | -241.90271  |\n",
      "| qf1_loss                | 5.0133076   |\n",
      "| qf2_loss                | 6.5399494   |\n",
      "| time_elapsed            | 2820        |\n",
      "| total timesteps         | 329000      |\n",
      "| value_loss              | 3.067514    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.18344823 |\n",
      "| ent_coef_loss           | -0.6681516 |\n",
      "| entropy                 | 4.4290414  |\n",
      "| episodes                | 340        |\n",
      "| fps                     | 116        |\n",
      "| mean 100 episode reward | 4.66e+03   |\n",
      "| n_updates               | 338901     |\n",
      "| policy_loss             | -244.27515 |\n",
      "| qf1_loss                | 4.738451   |\n",
      "| qf2_loss                | 5.2500005  |\n",
      "| time_elapsed            | 2908       |\n",
      "| total timesteps         | 339000     |\n",
      "| value_loss              | 3.34297    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.18572454 |\n",
      "| ent_coef_loss           | 1.5359707  |\n",
      "| entropy                 | 4.4410768  |\n",
      "| episodes                | 350        |\n",
      "| fps                     | 116        |\n",
      "| mean 100 episode reward | 4.72e+03   |\n",
      "| n_updates               | 348901     |\n",
      "| policy_loss             | -253.61703 |\n",
      "| qf1_loss                | 8.957721   |\n",
      "| qf2_loss                | 9.221123   |\n",
      "| time_elapsed            | 2995       |\n",
      "| total timesteps         | 349000     |\n",
      "| value_loss              | 24.453865  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.19016215 |\n",
      "| ent_coef_loss           | 0.65263313 |\n",
      "| entropy                 | 4.412428   |\n",
      "| episodes                | 360        |\n",
      "| fps                     | 116        |\n",
      "| mean 100 episode reward | 4.79e+03   |\n",
      "| n_updates               | 358901     |\n",
      "| policy_loss             | -249.07333 |\n",
      "| qf1_loss                | 6.4468203  |\n",
      "| qf2_loss                | 5.074888   |\n",
      "| time_elapsed            | 3083       |\n",
      "| total timesteps         | 359000     |\n",
      "| value_loss              | 10.763227  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.18158351 |\n",
      "| ent_coef_loss           | -0.6368257 |\n",
      "| entropy                 | 4.0108547  |\n",
      "| episodes                | 370        |\n",
      "| fps                     | 116        |\n",
      "| mean 100 episode reward | 4.86e+03   |\n",
      "| n_updates               | 368901     |\n",
      "| policy_loss             | -249.93942 |\n",
      "| qf1_loss                | 5.648311   |\n",
      "| qf2_loss                | 4.9633346  |\n",
      "| time_elapsed            | 3172       |\n",
      "| total timesteps         | 369000     |\n",
      "| value_loss              | 4.249179   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.1936311   |\n",
      "| ent_coef_loss           | -0.74210626 |\n",
      "| entropy                 | 4.2176676   |\n",
      "| episodes                | 380         |\n",
      "| fps                     | 116         |\n",
      "| mean 100 episode reward | 4.92e+03    |\n",
      "| n_updates               | 378901      |\n",
      "| policy_loss             | -250.35155  |\n",
      "| qf1_loss                | 695.97217   |\n",
      "| qf2_loss                | 686.39325   |\n",
      "| time_elapsed            | 3260        |\n",
      "| total timesteps         | 379000      |\n",
      "| value_loss              | 6.045664    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.1990149   |\n",
      "| ent_coef_loss           | -0.52872896 |\n",
      "| entropy                 | 4.181425    |\n",
      "| episodes                | 390         |\n",
      "| fps                     | 116         |\n",
      "| mean 100 episode reward | 4.99e+03    |\n",
      "| n_updates               | 388901      |\n",
      "| policy_loss             | -246.15741  |\n",
      "| qf1_loss                | 9.849817    |\n",
      "| qf2_loss                | 10.287395   |\n",
      "| time_elapsed            | 3347        |\n",
      "| total timesteps         | 389000      |\n",
      "| value_loss              | 7.126122    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.20595506 |\n",
      "| ent_coef_loss           | -0.3530137 |\n",
      "| entropy                 | 4.1294703  |\n",
      "| episodes                | 400        |\n",
      "| fps                     | 116        |\n",
      "| mean 100 episode reward | 5.06e+03   |\n",
      "| n_updates               | 398901     |\n",
      "| policy_loss             | -280.0982  |\n",
      "| qf1_loss                | 4.887869   |\n",
      "| qf2_loss                | 3.8393095  |\n",
      "| time_elapsed            | 3434       |\n",
      "| total timesteps         | 399000     |\n",
      "| value_loss              | 7.819539   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.19765525  |\n",
      "| ent_coef_loss           | -0.10280675 |\n",
      "| entropy                 | 4.1954246   |\n",
      "| episodes                | 410         |\n",
      "| fps                     | 116         |\n",
      "| mean 100 episode reward | 5.13e+03    |\n",
      "| n_updates               | 408901      |\n",
      "| policy_loss             | -257.8737   |\n",
      "| qf1_loss                | 5.0168242   |\n",
      "| qf2_loss                | 4.9815207   |\n",
      "| time_elapsed            | 3522        |\n",
      "| total timesteps         | 409000      |\n",
      "| value_loss              | 4.066249    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.20232497  |\n",
      "| ent_coef_loss           | -0.09067941 |\n",
      "| entropy                 | 4.2693186   |\n",
      "| episodes                | 420         |\n",
      "| fps                     | 116         |\n",
      "| mean 100 episode reward | 5.15e+03    |\n",
      "| n_updates               | 418901      |\n",
      "| policy_loss             | -242.29198  |\n",
      "| qf1_loss                | 9.475481    |\n",
      "| qf2_loss                | 6.255069    |\n",
      "| time_elapsed            | 3610        |\n",
      "| total timesteps         | 419000      |\n",
      "| value_loss              | 5.883255    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.20561127 |\n",
      "| ent_coef_loss           | -1.0448536 |\n",
      "| entropy                 | 4.157944   |\n",
      "| episodes                | 430        |\n",
      "| fps                     | 116        |\n",
      "| mean 100 episode reward | 5.22e+03   |\n",
      "| n_updates               | 428901     |\n",
      "| policy_loss             | -277.34122 |\n",
      "| qf1_loss                | 680.34564  |\n",
      "| qf2_loss                | 673.4343   |\n",
      "| time_elapsed            | 3696       |\n",
      "| total timesteps         | 429000     |\n",
      "| value_loss              | 4.6800504  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.20357728 |\n",
      "| ent_coef_loss           | 1.5090313  |\n",
      "| entropy                 | 4.2269335  |\n",
      "| episodes                | 440        |\n",
      "| fps                     | 116        |\n",
      "| mean 100 episode reward | 5.27e+03   |\n",
      "| n_updates               | 438901     |\n",
      "| policy_loss             | -272.99158 |\n",
      "| qf1_loss                | 7.541588   |\n",
      "| qf2_loss                | 9.350597   |\n",
      "| time_elapsed            | 3774       |\n",
      "| total timesteps         | 439000     |\n",
      "| value_loss              | 9.948174   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.20589891 |\n",
      "| ent_coef_loss           | -0.31672   |\n",
      "| entropy                 | 4.234193   |\n",
      "| episodes                | 450        |\n",
      "| fps                     | 116        |\n",
      "| mean 100 episode reward | 5.33e+03   |\n",
      "| n_updates               | 448901     |\n",
      "| policy_loss             | -288.10184 |\n",
      "| qf1_loss                | 5.3769517  |\n",
      "| qf2_loss                | 6.3446655  |\n",
      "| time_elapsed            | 3852       |\n",
      "| total timesteps         | 449000     |\n",
      "| value_loss              | 3.4470456  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.20692272 |\n",
      "| ent_coef_loss           | -1.0249691 |\n",
      "| entropy                 | 4.2289333  |\n",
      "| episodes                | 460        |\n",
      "| fps                     | 116        |\n",
      "| mean 100 episode reward | 5.38e+03   |\n",
      "| n_updates               | 458901     |\n",
      "| policy_loss             | -271.62216 |\n",
      "| qf1_loss                | 18.798685  |\n",
      "| qf2_loss                | 13.216194  |\n",
      "| time_elapsed            | 3933       |\n",
      "| total timesteps         | 459000     |\n",
      "| value_loss              | 11.436184  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.21931037 |\n",
      "| ent_coef_loss           | -0.4203467 |\n",
      "| entropy                 | 4.076505   |\n",
      "| episodes                | 470        |\n",
      "| fps                     | 116        |\n",
      "| mean 100 episode reward | 5.42e+03   |\n",
      "| n_updates               | 468901     |\n",
      "| policy_loss             | -282.68042 |\n",
      "| qf1_loss                | 4.7912774  |\n",
      "| qf2_loss                | 7.26404    |\n",
      "| time_elapsed            | 4015       |\n",
      "| total timesteps         | 469000     |\n",
      "| value_loss              | 3.494147   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.21853295  |\n",
      "| ent_coef_loss           | -0.42583317 |\n",
      "| entropy                 | 3.978663    |\n",
      "| episodes                | 480         |\n",
      "| fps                     | 116         |\n",
      "| mean 100 episode reward | 5.47e+03    |\n",
      "| n_updates               | 478901      |\n",
      "| policy_loss             | -276.89526  |\n",
      "| qf1_loss                | 8.030659    |\n",
      "| qf2_loss                | 8.532402    |\n",
      "| time_elapsed            | 4100        |\n",
      "| total timesteps         | 479000      |\n",
      "| value_loss              | 5.387796    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.21350156  |\n",
      "| ent_coef_loss           | -0.14698124 |\n",
      "| entropy                 | 4.137815    |\n",
      "| episodes                | 490         |\n",
      "| fps                     | 116         |\n",
      "| mean 100 episode reward | 5.52e+03    |\n",
      "| n_updates               | 488901      |\n",
      "| policy_loss             | -296.76804  |\n",
      "| qf1_loss                | 6.9131465   |\n",
      "| qf2_loss                | 8.113279    |\n",
      "| time_elapsed            | 4185        |\n",
      "| total timesteps         | 489000      |\n",
      "| value_loss              | 6.947297    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.21123491 |\n",
      "| ent_coef_loss           | -0.0160622 |\n",
      "| entropy                 | 3.933642   |\n",
      "| episodes                | 500        |\n",
      "| fps                     | 116        |\n",
      "| mean 100 episode reward | 5.56e+03   |\n",
      "| n_updates               | 498901     |\n",
      "| policy_loss             | -294.95813 |\n",
      "| qf1_loss                | 10.17613   |\n",
      "| qf2_loss                | 7.8733573  |\n",
      "| time_elapsed            | 4270       |\n",
      "| total timesteps         | 499000     |\n",
      "| value_loss              | 3.164618   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ent_coef                | 0.2133098 |\n",
      "| ent_coef_loss           | 0.6566955 |\n",
      "| entropy                 | 3.7732391 |\n",
      "| episodes                | 510       |\n",
      "| fps                     | 116       |\n",
      "| mean 100 episode reward | 5.61e+03  |\n",
      "| n_updates               | 508901    |\n",
      "| policy_loss             | -310.3016 |\n",
      "| qf1_loss                | 669.8706  |\n",
      "| qf2_loss                | 687.30255 |\n",
      "| time_elapsed            | 4356      |\n",
      "| total timesteps         | 509000    |\n",
      "| value_loss              | 10.246416 |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.22154693 |\n",
      "| ent_coef_loss           | 0.9992882  |\n",
      "| entropy                 | 4.02489    |\n",
      "| episodes                | 520        |\n",
      "| fps                     | 116        |\n",
      "| mean 100 episode reward | 5.69e+03   |\n",
      "| n_updates               | 518901     |\n",
      "| policy_loss             | -314.07397 |\n",
      "| qf1_loss                | 706.92834  |\n",
      "| qf2_loss                | 703.174    |\n",
      "| time_elapsed            | 4443       |\n",
      "| total timesteps         | 519000     |\n",
      "| value_loss              | 7.588249   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.21274956  |\n",
      "| ent_coef_loss           | -0.11725074 |\n",
      "| entropy                 | 4.0765986   |\n",
      "| episodes                | 530         |\n",
      "| fps                     | 116         |\n",
      "| mean 100 episode reward | 5.72e+03    |\n",
      "| n_updates               | 528901      |\n",
      "| policy_loss             | -302.44388  |\n",
      "| qf1_loss                | 12.612393   |\n",
      "| qf2_loss                | 10.928156   |\n",
      "| time_elapsed            | 4529        |\n",
      "| total timesteps         | 529000      |\n",
      "| value_loss              | 14.936206   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.22274983  |\n",
      "| ent_coef_loss           | -0.85880554 |\n",
      "| entropy                 | 3.9102178   |\n",
      "| episodes                | 540         |\n",
      "| fps                     | 116         |\n",
      "| mean 100 episode reward | 5.78e+03    |\n",
      "| n_updates               | 538901      |\n",
      "| policy_loss             | -307.80264  |\n",
      "| qf1_loss                | 8.276397    |\n",
      "| qf2_loss                | 5.2814627   |\n",
      "| time_elapsed            | 4616        |\n",
      "| total timesteps         | 539000      |\n",
      "| value_loss              | 5.8181186   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.21301109 |\n",
      "| ent_coef_loss           | 0.41803282 |\n",
      "| entropy                 | 3.8454838  |\n",
      "| episodes                | 550        |\n",
      "| fps                     | 116        |\n",
      "| mean 100 episode reward | 5.83e+03   |\n",
      "| n_updates               | 548901     |\n",
      "| policy_loss             | -305.8659  |\n",
      "| qf1_loss                | 5.810792   |\n",
      "| qf2_loss                | 7.502552   |\n",
      "| time_elapsed            | 4702       |\n",
      "| total timesteps         | 549000     |\n",
      "| value_loss              | 4.286009   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.21997218 |\n",
      "| ent_coef_loss           | 0.73233706 |\n",
      "| entropy                 | 4.0103235  |\n",
      "| episodes                | 560        |\n",
      "| fps                     | 116        |\n",
      "| mean 100 episode reward | 5.85e+03   |\n",
      "| n_updates               | 558901     |\n",
      "| policy_loss             | -310.9687  |\n",
      "| qf1_loss                | 12.521555  |\n",
      "| qf2_loss                | 11.359589  |\n",
      "| time_elapsed            | 4789       |\n",
      "| total timesteps         | 559000     |\n",
      "| value_loss              | 8.90848    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.22400905 |\n",
      "| ent_coef_loss           | -0.5625654 |\n",
      "| entropy                 | 3.6761563  |\n",
      "| episodes                | 570        |\n",
      "| fps                     | 116        |\n",
      "| mean 100 episode reward | 5.91e+03   |\n",
      "| n_updates               | 568901     |\n",
      "| policy_loss             | -304.1529  |\n",
      "| qf1_loss                | 10.625759  |\n",
      "| qf2_loss                | 14.034891  |\n",
      "| time_elapsed            | 4876       |\n",
      "| total timesteps         | 569000     |\n",
      "| value_loss              | 7.5279803  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.21689482 |\n",
      "| ent_coef_loss           | 0.9367639  |\n",
      "| entropy                 | 3.892157   |\n",
      "| episodes                | 580        |\n",
      "| fps                     | 116        |\n",
      "| mean 100 episode reward | 5.95e+03   |\n",
      "| n_updates               | 578901     |\n",
      "| policy_loss             | -313.43262 |\n",
      "| qf1_loss                | 11.262482  |\n",
      "| qf2_loss                | 8.271881   |\n",
      "| time_elapsed            | 4963       |\n",
      "| total timesteps         | 579000     |\n",
      "| value_loss              | 11.602114  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.22075135 |\n",
      "| ent_coef_loss           | 2.34161    |\n",
      "| entropy                 | 3.8797138  |\n",
      "| episodes                | 590        |\n",
      "| fps                     | 116        |\n",
      "| mean 100 episode reward | 5.99e+03   |\n",
      "| n_updates               | 588901     |\n",
      "| policy_loss             | -326.7036  |\n",
      "| qf1_loss                | 10.486444  |\n",
      "| qf2_loss                | 14.343296  |\n",
      "| time_elapsed            | 5051       |\n",
      "| total timesteps         | 589000     |\n",
      "| value_loss              | 6.9856176  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.21812046 |\n",
      "| ent_coef_loss           | -0.6530662 |\n",
      "| entropy                 | 3.7363782  |\n",
      "| episodes                | 600        |\n",
      "| fps                     | 116        |\n",
      "| mean 100 episode reward | 6.04e+03   |\n",
      "| n_updates               | 598901     |\n",
      "| policy_loss             | -308.35107 |\n",
      "| qf1_loss                | 9.289068   |\n",
      "| qf2_loss                | 7.993718   |\n",
      "| time_elapsed            | 5138       |\n",
      "| total timesteps         | 599000     |\n",
      "| value_loss              | 6.4013453  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.22212051 |\n",
      "| ent_coef_loss           | -1.752181  |\n",
      "| entropy                 | 3.678731   |\n",
      "| episodes                | 610        |\n",
      "| fps                     | 116        |\n",
      "| mean 100 episode reward | 6.09e+03   |\n",
      "| n_updates               | 608901     |\n",
      "| policy_loss             | -342.5683  |\n",
      "| qf1_loss                | 4.9524393  |\n",
      "| qf2_loss                | 6.524766   |\n",
      "| time_elapsed            | 5226       |\n",
      "| total timesteps         | 609000     |\n",
      "| value_loss              | 9.787001   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.23588814  |\n",
      "| ent_coef_loss           | -0.13196912 |\n",
      "| entropy                 | 3.9534109   |\n",
      "| episodes                | 620         |\n",
      "| fps                     | 116         |\n",
      "| mean 100 episode reward | 6.14e+03    |\n",
      "| n_updates               | 618901      |\n",
      "| policy_loss             | -341.20197  |\n",
      "| qf1_loss                | 1079.0736   |\n",
      "| qf2_loss                | 1091.6613   |\n",
      "| time_elapsed            | 5315        |\n",
      "| total timesteps         | 619000      |\n",
      "| value_loss              | 13.594158   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.22574455 |\n",
      "| ent_coef_loss           | 0.6272649  |\n",
      "| entropy                 | 3.892964   |\n",
      "| episodes                | 630        |\n",
      "| fps                     | 116        |\n",
      "| mean 100 episode reward | 6.21e+03   |\n",
      "| n_updates               | 628901     |\n",
      "| policy_loss             | -332.53833 |\n",
      "| qf1_loss                | 27.660152  |\n",
      "| qf2_loss                | 20.330254  |\n",
      "| time_elapsed            | 5403       |\n",
      "| total timesteps         | 629000     |\n",
      "| value_loss              | 35.489944  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.22912553 |\n",
      "| ent_coef_loss           | -0.4108129 |\n",
      "| entropy                 | 3.6716433  |\n",
      "| episodes                | 640        |\n",
      "| fps                     | 116        |\n",
      "| mean 100 episode reward | 6.27e+03   |\n",
      "| n_updates               | 638901     |\n",
      "| policy_loss             | -356.27704 |\n",
      "| qf1_loss                | 7.3188124  |\n",
      "| qf2_loss                | 7.020504   |\n",
      "| time_elapsed            | 5491       |\n",
      "| total timesteps         | 639000     |\n",
      "| value_loss              | 7.267532   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.2392429  |\n",
      "| ent_coef_loss           | 0.5125533  |\n",
      "| entropy                 | 4.0044365  |\n",
      "| episodes                | 650        |\n",
      "| fps                     | 116        |\n",
      "| mean 100 episode reward | 6.31e+03   |\n",
      "| n_updates               | 648901     |\n",
      "| policy_loss             | -349.27792 |\n",
      "| qf1_loss                | 8.718824   |\n",
      "| qf2_loss                | 9.128071   |\n",
      "| time_elapsed            | 5578       |\n",
      "| total timesteps         | 649000     |\n",
      "| value_loss              | 15.601921  |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.23914954 |\n",
      "| ent_coef_loss           | -1.7745585 |\n",
      "| entropy                 | 3.8151941  |\n",
      "| episodes                | 660        |\n",
      "| fps                     | 116        |\n",
      "| mean 100 episode reward | 6.37e+03   |\n",
      "| n_updates               | 658901     |\n",
      "| policy_loss             | -310.97134 |\n",
      "| qf1_loss                | 7.6171694  |\n",
      "| qf2_loss                | 7.878295   |\n",
      "| time_elapsed            | 5666       |\n",
      "| total timesteps         | 659000     |\n",
      "| value_loss              | 6.327052   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.23525985 |\n",
      "| ent_coef_loss           | -1.6328101 |\n",
      "| entropy                 | 3.6833758  |\n",
      "| episodes                | 670        |\n",
      "| fps                     | 116        |\n",
      "| mean 100 episode reward | 6.41e+03   |\n",
      "| n_updates               | 668901     |\n",
      "| policy_loss             | -351.04663 |\n",
      "| qf1_loss                | 6.873605   |\n",
      "| qf2_loss                | 6.0032725  |\n",
      "| time_elapsed            | 5754       |\n",
      "| total timesteps         | 669000     |\n",
      "| value_loss              | 5.609522   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.23606609  |\n",
      "| ent_coef_loss           | -0.06007144 |\n",
      "| entropy                 | 3.6374521   |\n",
      "| episodes                | 680         |\n",
      "| fps                     | 116         |\n",
      "| mean 100 episode reward | 6.47e+03    |\n",
      "| n_updates               | 678901      |\n",
      "| policy_loss             | -368.93246  |\n",
      "| qf1_loss                | 14.054255   |\n",
      "| qf2_loss                | 13.584103   |\n",
      "| time_elapsed            | 5842        |\n",
      "| total timesteps         | 679000      |\n",
      "| value_loss              | 5.33211     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.23669954  |\n",
      "| ent_coef_loss           | -0.57559466 |\n",
      "| entropy                 | 3.9393573   |\n",
      "| episodes                | 690         |\n",
      "| fps                     | 116         |\n",
      "| mean 100 episode reward | 6.52e+03    |\n",
      "| n_updates               | 688901      |\n",
      "| policy_loss             | -326.61182  |\n",
      "| qf1_loss                | 7.414       |\n",
      "| qf2_loss                | 10.511459   |\n",
      "| time_elapsed            | 5920        |\n",
      "| total timesteps         | 689000      |\n",
      "| value_loss              | 4.2679987   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.23825027 |\n",
      "| ent_coef_loss           | 0.46881124 |\n",
      "| entropy                 | 3.8368552  |\n",
      "| episodes                | 700        |\n",
      "| fps                     | 116        |\n",
      "| mean 100 episode reward | 6.56e+03   |\n",
      "| n_updates               | 698901     |\n",
      "| policy_loss             | -362.05032 |\n",
      "| qf1_loss                | 8.284275   |\n",
      "| qf2_loss                | 6.8938856  |\n",
      "| time_elapsed            | 5995       |\n",
      "| total timesteps         | 699000     |\n",
      "| value_loss              | 4.1523666  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.24810535 |\n",
      "| ent_coef_loss           | 0.45974272 |\n",
      "| entropy                 | 3.7443123  |\n",
      "| episodes                | 710        |\n",
      "| fps                     | 116        |\n",
      "| mean 100 episode reward | 6.61e+03   |\n",
      "| n_updates               | 708901     |\n",
      "| policy_loss             | -378.4781  |\n",
      "| qf1_loss                | 11.496852  |\n",
      "| qf2_loss                | 8.551304   |\n",
      "| time_elapsed            | 6081       |\n",
      "| total timesteps         | 709000     |\n",
      "| value_loss              | 7.573619   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.24437658 |\n",
      "| ent_coef_loss           | 0.14044997 |\n",
      "| entropy                 | 3.6245465  |\n",
      "| episodes                | 720        |\n",
      "| fps                     | 116        |\n",
      "| mean 100 episode reward | 6.65e+03   |\n",
      "| n_updates               | 718901     |\n",
      "| policy_loss             | -359.1908  |\n",
      "| qf1_loss                | 7.8282     |\n",
      "| qf2_loss                | 7.262209   |\n",
      "| time_elapsed            | 6167       |\n",
      "| total timesteps         | 719000     |\n",
      "| value_loss              | 4.018569   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.23850486  |\n",
      "| ent_coef_loss           | -0.39491898 |\n",
      "| entropy                 | 3.7761183   |\n",
      "| episodes                | 730         |\n",
      "| fps                     | 116         |\n",
      "| mean 100 episode reward | 6.69e+03    |\n",
      "| n_updates               | 728901      |\n",
      "| policy_loss             | -369.16705  |\n",
      "| qf1_loss                | 8.112718    |\n",
      "| qf2_loss                | 8.115872    |\n",
      "| time_elapsed            | 6254        |\n",
      "| total timesteps         | 729000      |\n",
      "| value_loss              | 12.726131   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.24702427  |\n",
      "| ent_coef_loss           | -0.11507684 |\n",
      "| entropy                 | 3.7718105   |\n",
      "| episodes                | 740         |\n",
      "| fps                     | 116         |\n",
      "| mean 100 episode reward | 6.73e+03    |\n",
      "| n_updates               | 738901      |\n",
      "| policy_loss             | -374.76376  |\n",
      "| qf1_loss                | 33.05066    |\n",
      "| qf2_loss                | 34.882076   |\n",
      "| time_elapsed            | 6341        |\n",
      "| total timesteps         | 739000      |\n",
      "| value_loss              | 11.955526   |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ent_coef                | 0.2469937 |\n",
      "| ent_coef_loss           | 0.2815336 |\n",
      "| entropy                 | 3.765708  |\n",
      "| episodes                | 750       |\n",
      "| fps                     | 116       |\n",
      "| mean 100 episode reward | 6.78e+03  |\n",
      "| n_updates               | 748901    |\n",
      "| policy_loss             | -370.4196 |\n",
      "| qf1_loss                | 308.39706 |\n",
      "| qf2_loss                | 326.86697 |\n",
      "| time_elapsed            | 6422      |\n",
      "| total timesteps         | 749000    |\n",
      "| value_loss              | 4.6300306 |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.24807093 |\n",
      "| ent_coef_loss           | 0.7206693  |\n",
      "| entropy                 | 3.753095   |\n",
      "| episodes                | 760        |\n",
      "| fps                     | 117        |\n",
      "| mean 100 episode reward | 6.78e+03   |\n",
      "| n_updates               | 758901     |\n",
      "| policy_loss             | -371.55908 |\n",
      "| qf1_loss                | 16.334898  |\n",
      "| qf2_loss                | 16.13718   |\n",
      "| time_elapsed            | 6480       |\n",
      "| total timesteps         | 759000     |\n",
      "| value_loss              | 8.949169   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.25514853  |\n",
      "| ent_coef_loss           | -0.46316737 |\n",
      "| entropy                 | 3.8722553   |\n",
      "| episodes                | 770         |\n",
      "| fps                     | 117         |\n",
      "| mean 100 episode reward | 6.82e+03    |\n",
      "| n_updates               | 768901      |\n",
      "| policy_loss             | -374.16144  |\n",
      "| qf1_loss                | 15.373367   |\n",
      "| qf2_loss                | 13.935305   |\n",
      "| time_elapsed            | 6537        |\n",
      "| total timesteps         | 769000      |\n",
      "| value_loss              | 12.531672   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.24401349 |\n",
      "| ent_coef_loss           | -0.4905346 |\n",
      "| entropy                 | 3.5994158  |\n",
      "| episodes                | 780        |\n",
      "| fps                     | 118        |\n",
      "| mean 100 episode reward | 6.87e+03   |\n",
      "| n_updates               | 778901     |\n",
      "| policy_loss             | -361.67877 |\n",
      "| qf1_loss                | 1620.0796  |\n",
      "| qf2_loss                | 1594.5358  |\n",
      "| time_elapsed            | 6597       |\n",
      "| total timesteps         | 779000     |\n",
      "| value_loss              | 6.4351187  |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.2469637  |\n",
      "| ent_coef_loss           | 0.06783904 |\n",
      "| entropy                 | 3.5799603  |\n",
      "| episodes                | 790        |\n",
      "| fps                     | 118        |\n",
      "| mean 100 episode reward | 6.9e+03    |\n",
      "| n_updates               | 788901     |\n",
      "| policy_loss             | -384.91708 |\n",
      "| qf1_loss                | 5.014874   |\n",
      "| qf2_loss                | 4.9691114  |\n",
      "| time_elapsed            | 6668       |\n",
      "| total timesteps         | 789000     |\n",
      "| value_loss              | 3.313375   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.23829132 |\n",
      "| ent_coef_loss           | 0.7514824  |\n",
      "| entropy                 | 3.5532546  |\n",
      "| episodes                | 800        |\n",
      "| fps                     | 118        |\n",
      "| mean 100 episode reward | 6.94e+03   |\n",
      "| n_updates               | 798901     |\n",
      "| policy_loss             | -383.18784 |\n",
      "| qf1_loss                | 5.93467    |\n",
      "| qf2_loss                | 7.0893583  |\n",
      "| time_elapsed            | 6729       |\n",
      "| total timesteps         | 799000     |\n",
      "| value_loss              | 30.694054  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.2591789  |\n",
      "| ent_coef_loss           | -0.6079962 |\n",
      "| entropy                 | 3.8062801  |\n",
      "| episodes                | 810        |\n",
      "| fps                     | 118        |\n",
      "| mean 100 episode reward | 6.98e+03   |\n",
      "| n_updates               | 808901     |\n",
      "| policy_loss             | -388.73053 |\n",
      "| qf1_loss                | 7.997101   |\n",
      "| qf2_loss                | 7.382489   |\n",
      "| time_elapsed            | 6815       |\n",
      "| total timesteps         | 809000     |\n",
      "| value_loss              | 5.5444336  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.2656075  |\n",
      "| ent_coef_loss           | 1.3952326  |\n",
      "| entropy                 | 3.69692    |\n",
      "| episodes                | 820        |\n",
      "| fps                     | 119        |\n",
      "| mean 100 episode reward | 7e+03      |\n",
      "| n_updates               | 818901     |\n",
      "| policy_loss             | -411.24063 |\n",
      "| qf1_loss                | 16.021172  |\n",
      "| qf2_loss                | 12.525834  |\n",
      "| time_elapsed            | 6865       |\n",
      "| total timesteps         | 819000     |\n",
      "| value_loss              | 13.966057  |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| current_lr              | 0.0003       |\n",
      "| ent_coef                | 0.25792024   |\n",
      "| ent_coef_loss           | 0.0011592507 |\n",
      "| entropy                 | 3.7138236    |\n",
      "| episodes                | 830          |\n",
      "| fps                     | 119          |\n",
      "| mean 100 episode reward | 7.03e+03     |\n",
      "| n_updates               | 828901       |\n",
      "| policy_loss             | -409.06177   |\n",
      "| qf1_loss                | 9.870047     |\n",
      "| qf2_loss                | 8.354747     |\n",
      "| time_elapsed            | 6937         |\n",
      "| total timesteps         | 829000       |\n",
      "| value_loss              | 8.894098     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.25275815 |\n",
      "| ent_coef_loss           | 0.5045009  |\n",
      "| entropy                 | 3.5888093  |\n",
      "| episodes                | 840        |\n",
      "| fps                     | 119        |\n",
      "| mean 100 episode reward | 7.07e+03   |\n",
      "| n_updates               | 838901     |\n",
      "| policy_loss             | -406.89172 |\n",
      "| qf1_loss                | 9.51251    |\n",
      "| qf2_loss                | 9.269475   |\n",
      "| time_elapsed            | 6992       |\n",
      "| total timesteps         | 839000     |\n",
      "| value_loss              | 7.7976446  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.25487372 |\n",
      "| ent_coef_loss           | -1.4479349 |\n",
      "| entropy                 | 3.7787814  |\n",
      "| episodes                | 850        |\n",
      "| fps                     | 120        |\n",
      "| mean 100 episode reward | 7.1e+03    |\n",
      "| n_updates               | 848901     |\n",
      "| policy_loss             | -381.48492 |\n",
      "| qf1_loss                | 21.298698  |\n",
      "| qf2_loss                | 41.109104  |\n",
      "| time_elapsed            | 7066       |\n",
      "| total timesteps         | 849000     |\n",
      "| value_loss              | 9.6936     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.26313406  |\n",
      "| ent_coef_loss           | -0.14795613 |\n",
      "| entropy                 | 3.7376328   |\n",
      "| episodes                | 860         |\n",
      "| fps                     | 120         |\n",
      "| mean 100 episode reward | 7.2e+03     |\n",
      "| n_updates               | 858901      |\n",
      "| policy_loss             | -389.13348  |\n",
      "| qf1_loss                | 8.499247    |\n",
      "| qf2_loss                | 8.240744    |\n",
      "| time_elapsed            | 7146        |\n",
      "| total timesteps         | 859000      |\n",
      "| value_loss              | 6.838166    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.25721687  |\n",
      "| ent_coef_loss           | -0.13593626 |\n",
      "| entropy                 | 3.6029384   |\n",
      "| episodes                | 870         |\n",
      "| fps                     | 120         |\n",
      "| mean 100 episode reward | 7.24e+03    |\n",
      "| n_updates               | 868901      |\n",
      "| policy_loss             | -401.553    |\n",
      "| qf1_loss                | 14.075688   |\n",
      "| qf2_loss                | 13.588421   |\n",
      "| time_elapsed            | 7217        |\n",
      "| total timesteps         | 869000      |\n",
      "| value_loss              | 5.1758194   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.26014328  |\n",
      "| ent_coef_loss           | -0.19972026 |\n",
      "| entropy                 | 3.5719018   |\n",
      "| episodes                | 880         |\n",
      "| fps                     | 120         |\n",
      "| mean 100 episode reward | 7.27e+03    |\n",
      "| n_updates               | 878901      |\n",
      "| policy_loss             | -421.1977   |\n",
      "| qf1_loss                | 11.339964   |\n",
      "| qf2_loss                | 19.460049   |\n",
      "| time_elapsed            | 7290        |\n",
      "| total timesteps         | 879000      |\n",
      "| value_loss              | 6.888515    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.26470935 |\n",
      "| ent_coef_loss           | 0.78697485 |\n",
      "| entropy                 | 3.8956766  |\n",
      "| episodes                | 890        |\n",
      "| fps                     | 120        |\n",
      "| mean 100 episode reward | 7.3e+03    |\n",
      "| n_updates               | 888901     |\n",
      "| policy_loss             | -400.31863 |\n",
      "| qf1_loss                | 9.875848   |\n",
      "| qf2_loss                | 9.915009   |\n",
      "| time_elapsed            | 7361       |\n",
      "| total timesteps         | 889000     |\n",
      "| value_loss              | 16.27804   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.26216787 |\n",
      "| ent_coef_loss           | 0.19669816 |\n",
      "| entropy                 | 3.5748901  |\n",
      "| episodes                | 900        |\n",
      "| fps                     | 121        |\n",
      "| mean 100 episode reward | 7.31e+03   |\n",
      "| n_updates               | 898901     |\n",
      "| policy_loss             | -421.47125 |\n",
      "| qf1_loss                | 12.267591  |\n",
      "| qf2_loss                | 7.729018   |\n",
      "| time_elapsed            | 7410       |\n",
      "| total timesteps         | 899000     |\n",
      "| value_loss              | 10.236274  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.2651383  |\n",
      "| ent_coef_loss           | -0.9641148 |\n",
      "| entropy                 | 3.7212725  |\n",
      "| episodes                | 910        |\n",
      "| fps                     | 121        |\n",
      "| mean 100 episode reward | 7.34e+03   |\n",
      "| n_updates               | 908901     |\n",
      "| policy_loss             | -397.32965 |\n",
      "| qf1_loss                | 8.900316   |\n",
      "| qf2_loss                | 8.513893   |\n",
      "| time_elapsed            | 7463       |\n",
      "| total timesteps         | 909000     |\n",
      "| value_loss              | 4.6622334  |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.26098192  |\n",
      "| ent_coef_loss           | -0.09729943 |\n",
      "| entropy                 | 3.5983539   |\n",
      "| episodes                | 920         |\n",
      "| fps                     | 121         |\n",
      "| mean 100 episode reward | 7.38e+03    |\n",
      "| n_updates               | 918901      |\n",
      "| policy_loss             | -413.13202  |\n",
      "| qf1_loss                | 8.9895115   |\n",
      "| qf2_loss                | 9.851972    |\n",
      "| time_elapsed            | 7534        |\n",
      "| total timesteps         | 919000      |\n",
      "| value_loss              | 8.999504    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.25953558 |\n",
      "| ent_coef_loss           | 0.6015084  |\n",
      "| entropy                 | 3.9452643  |\n",
      "| episodes                | 930        |\n",
      "| fps                     | 122        |\n",
      "| mean 100 episode reward | 7.4e+03    |\n",
      "| n_updates               | 928901     |\n",
      "| policy_loss             | -422.23312 |\n",
      "| qf1_loss                | 13.47487   |\n",
      "| qf2_loss                | 15.59698   |\n",
      "| time_elapsed            | 7603       |\n",
      "| total timesteps         | 929000     |\n",
      "| value_loss              | 15.951975  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.2700624  |\n",
      "| ent_coef_loss           | 0.42791992 |\n",
      "| entropy                 | 3.609848   |\n",
      "| episodes                | 940        |\n",
      "| fps                     | 122        |\n",
      "| mean 100 episode reward | 7.42e+03   |\n",
      "| n_updates               | 938901     |\n",
      "| policy_loss             | -383.643   |\n",
      "| qf1_loss                | 14.373938  |\n",
      "| qf2_loss                | 17.128687  |\n",
      "| time_elapsed            | 7670       |\n",
      "| total timesteps         | 939000     |\n",
      "| value_loss              | 24.709068  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.26137334  |\n",
      "| ent_coef_loss           | -0.44683218 |\n",
      "| entropy                 | 3.8058693   |\n",
      "| episodes                | 950         |\n",
      "| fps                     | 122         |\n",
      "| mean 100 episode reward | 7.45e+03    |\n",
      "| n_updates               | 948901      |\n",
      "| policy_loss             | -410.88818  |\n",
      "| qf1_loss                | 9.474088    |\n",
      "| qf2_loss                | 9.076273    |\n",
      "| time_elapsed            | 7756        |\n",
      "| total timesteps         | 949000      |\n",
      "| value_loss              | 4.821895    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.26442078  |\n",
      "| ent_coef_loss           | -0.27974355 |\n",
      "| entropy                 | 3.8667507   |\n",
      "| episodes                | 960         |\n",
      "| fps                     | 122         |\n",
      "| mean 100 episode reward | 7.48e+03    |\n",
      "| n_updates               | 958901      |\n",
      "| policy_loss             | -415.97858  |\n",
      "| qf1_loss                | 13.943115   |\n",
      "| qf2_loss                | 14.28779    |\n",
      "| time_elapsed            | 7828        |\n",
      "| total timesteps         | 959000      |\n",
      "| value_loss              | 13.792814   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.2707525  |\n",
      "| ent_coef_loss           | -1.633837  |\n",
      "| entropy                 | 3.533122   |\n",
      "| episodes                | 970        |\n",
      "| fps                     | 122        |\n",
      "| mean 100 episode reward | 7.49e+03   |\n",
      "| n_updates               | 968901     |\n",
      "| policy_loss             | -433.65845 |\n",
      "| qf1_loss                | 13.70405   |\n",
      "| qf2_loss                | 12.3452015 |\n",
      "| time_elapsed            | 7890       |\n",
      "| total timesteps         | 969000     |\n",
      "| value_loss              | 6.0912995  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.27379522 |\n",
      "| ent_coef_loss           | 0.79754746 |\n",
      "| entropy                 | 3.7606602  |\n",
      "| episodes                | 980        |\n",
      "| fps                     | 123        |\n",
      "| mean 100 episode reward | 7.52e+03   |\n",
      "| n_updates               | 978901     |\n",
      "| policy_loss             | -412.15033 |\n",
      "| qf1_loss                | 14.989685  |\n",
      "| qf2_loss                | 15.686741  |\n",
      "| time_elapsed            | 7950       |\n",
      "| total timesteps         | 979000     |\n",
      "| value_loss              | 9.272667   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.27656657 |\n",
      "| ent_coef_loss           | -0.8676035 |\n",
      "| entropy                 | 3.7979014  |\n",
      "| episodes                | 990        |\n",
      "| fps                     | 123        |\n",
      "| mean 100 episode reward | 7.56e+03   |\n",
      "| n_updates               | 988901     |\n",
      "| policy_loss             | -401.72354 |\n",
      "| qf1_loss                | 4.1779704  |\n",
      "| qf2_loss                | 4.620984   |\n",
      "| time_elapsed            | 8009       |\n",
      "| total timesteps         | 989000     |\n",
      "| value_loss              | 6.8147554  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.28105727 |\n",
      "| ent_coef_loss           | -0.5370693 |\n",
      "| entropy                 | 3.6918187  |\n",
      "| episodes                | 1000       |\n",
      "| fps                     | 123        |\n",
      "| mean 100 episode reward | 7.59e+03   |\n",
      "| n_updates               | 998901     |\n",
      "| policy_loss             | -423.13947 |\n",
      "| qf1_loss                | 5.478107   |\n",
      "| qf2_loss                | 4.6310143  |\n",
      "| time_elapsed            | 8073       |\n",
      "| total timesteps         | 999000     |\n",
      "| value_loss              | 6.1780987  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.27722132 |\n",
      "| ent_coef_loss           | 0.9624151  |\n",
      "| entropy                 | 3.8147745  |\n",
      "| episodes                | 1010       |\n",
      "| fps                     | 124        |\n",
      "| mean 100 episode reward | 7.62e+03   |\n",
      "| n_updates               | 1008901    |\n",
      "| policy_loss             | -437.1526  |\n",
      "| qf1_loss                | 10.058257  |\n",
      "| qf2_loss                | 9.103603   |\n",
      "| time_elapsed            | 8120       |\n",
      "| total timesteps         | 1009000    |\n",
      "| value_loss              | 12.739851  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.27458     |\n",
      "| ent_coef_loss           | -0.28441125 |\n",
      "| entropy                 | 3.5323598   |\n",
      "| episodes                | 1020        |\n",
      "| fps                     | 124         |\n",
      "| mean 100 episode reward | 7.65e+03    |\n",
      "| n_updates               | 1018901     |\n",
      "| policy_loss             | -454.5468   |\n",
      "| qf1_loss                | 8.934487    |\n",
      "| qf2_loss                | 10.990126   |\n",
      "| time_elapsed            | 8165        |\n",
      "| total timesteps         | 1019000     |\n",
      "| value_loss              | 7.0189095   |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| current_lr              | 0.0003       |\n",
      "| ent_coef                | 0.27795663   |\n",
      "| ent_coef_loss           | -0.043995477 |\n",
      "| entropy                 | 3.6431618    |\n",
      "| episodes                | 1030         |\n",
      "| fps                     | 125          |\n",
      "| mean 100 episode reward | 7.69e+03     |\n",
      "| n_updates               | 1028901      |\n",
      "| policy_loss             | -448.5846    |\n",
      "| qf1_loss                | 1604.6345    |\n",
      "| qf2_loss                | 1605.4454    |\n",
      "| time_elapsed            | 8211         |\n",
      "| total timesteps         | 1029000      |\n",
      "| value_loss              | 7.399518     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.27036396 |\n",
      "| ent_coef_loss           | 0.37236547 |\n",
      "| entropy                 | 3.4633756  |\n",
      "| episodes                | 1040       |\n",
      "| fps                     | 125        |\n",
      "| mean 100 episode reward | 7.71e+03   |\n",
      "| n_updates               | 1038901    |\n",
      "| policy_loss             | -442.3749  |\n",
      "| qf1_loss                | 8.743508   |\n",
      "| qf2_loss                | 9.026326   |\n",
      "| time_elapsed            | 8257       |\n",
      "| total timesteps         | 1039000    |\n",
      "| value_loss              | 4.4179473  |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.27570617  |\n",
      "| ent_coef_loss           | -0.56653106 |\n",
      "| entropy                 | 3.386214    |\n",
      "| episodes                | 1050        |\n",
      "| fps                     | 126         |\n",
      "| mean 100 episode reward | 7.73e+03    |\n",
      "| n_updates               | 1048901     |\n",
      "| policy_loss             | -441.01892  |\n",
      "| qf1_loss                | 9.481546    |\n",
      "| qf2_loss                | 8.1971445   |\n",
      "| time_elapsed            | 8303        |\n",
      "| total timesteps         | 1049000     |\n",
      "| value_loss              | 14.658192   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.28551394 |\n",
      "| ent_coef_loss           | 0.20260829 |\n",
      "| entropy                 | 3.8423157  |\n",
      "| episodes                | 1060       |\n",
      "| fps                     | 126        |\n",
      "| mean 100 episode reward | 7.75e+03   |\n",
      "| n_updates               | 1058901    |\n",
      "| policy_loss             | -446.62677 |\n",
      "| qf1_loss                | 13.155783  |\n",
      "| qf2_loss                | 10.25163   |\n",
      "| time_elapsed            | 8349       |\n",
      "| total timesteps         | 1059000    |\n",
      "| value_loss              | 5.5943193  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.27415302 |\n",
      "| ent_coef_loss           | -0.4509691 |\n",
      "| entropy                 | 3.5373566  |\n",
      "| episodes                | 1070       |\n",
      "| fps                     | 127        |\n",
      "| mean 100 episode reward | 7.78e+03   |\n",
      "| n_updates               | 1068901    |\n",
      "| policy_loss             | -446.43738 |\n",
      "| qf1_loss                | 11.055386  |\n",
      "| qf2_loss                | 11.110328  |\n",
      "| time_elapsed            | 8395       |\n",
      "| total timesteps         | 1069000    |\n",
      "| value_loss              | 8.30747    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.2727586  |\n",
      "| ent_coef_loss           | -0.287174  |\n",
      "| entropy                 | 3.402504   |\n",
      "| episodes                | 1080       |\n",
      "| fps                     | 127        |\n",
      "| mean 100 episode reward | 7.79e+03   |\n",
      "| n_updates               | 1078901    |\n",
      "| policy_loss             | -452.68115 |\n",
      "| qf1_loss                | 28.992207  |\n",
      "| qf2_loss                | 33.574726  |\n",
      "| time_elapsed            | 8441       |\n",
      "| total timesteps         | 1079000    |\n",
      "| value_loss              | 5.134123   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| current_lr              | 0.0003       |\n",
      "| ent_coef                | 0.27485272   |\n",
      "| ent_coef_loss           | -0.046890616 |\n",
      "| entropy                 | 3.5150268    |\n",
      "| episodes                | 1090         |\n",
      "| fps                     | 128          |\n",
      "| mean 100 episode reward | 7.74e+03     |\n",
      "| n_updates               | 1088901      |\n",
      "| policy_loss             | -465.99942   |\n",
      "| qf1_loss                | 17.858746    |\n",
      "| qf2_loss                | 15.894403    |\n",
      "| time_elapsed            | 8487         |\n",
      "| total timesteps         | 1089000      |\n",
      "| value_loss              | 13.722201    |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.2891451  |\n",
      "| ent_coef_loss           | -0.309095  |\n",
      "| entropy                 | 3.5685945  |\n",
      "| episodes                | 1100       |\n",
      "| fps                     | 128        |\n",
      "| mean 100 episode reward | 7.77e+03   |\n",
      "| n_updates               | 1098901    |\n",
      "| policy_loss             | -458.26715 |\n",
      "| qf1_loss                | 9.767321   |\n",
      "| qf2_loss                | 7.9058046  |\n",
      "| time_elapsed            | 8533       |\n",
      "| total timesteps         | 1099000    |\n",
      "| value_loss              | 8.14944    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.29686597 |\n",
      "| ent_coef_loss           | 0.8225728  |\n",
      "| entropy                 | 3.5146422  |\n",
      "| episodes                | 1110       |\n",
      "| fps                     | 129        |\n",
      "| mean 100 episode reward | 7.79e+03   |\n",
      "| n_updates               | 1108901    |\n",
      "| policy_loss             | -458.94165 |\n",
      "| qf1_loss                | 8.941888   |\n",
      "| qf2_loss                | 10.186729  |\n",
      "| time_elapsed            | 8578       |\n",
      "| total timesteps         | 1109000    |\n",
      "| value_loss              | 11.522617  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.29020697  |\n",
      "| ent_coef_loss           | -0.96374553 |\n",
      "| entropy                 | 3.5197291   |\n",
      "| episodes                | 1120        |\n",
      "| fps                     | 129         |\n",
      "| mean 100 episode reward | 7.81e+03    |\n",
      "| n_updates               | 1118901     |\n",
      "| policy_loss             | -469.38495  |\n",
      "| qf1_loss                | 8.524871    |\n",
      "| qf2_loss                | 9.08954     |\n",
      "| time_elapsed            | 8625        |\n",
      "| total timesteps         | 1119000     |\n",
      "| value_loss              | 12.578625   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.29823136 |\n",
      "| ent_coef_loss           | 0.25811455 |\n",
      "| entropy                 | 3.528523   |\n",
      "| episodes                | 1130       |\n",
      "| fps                     | 130        |\n",
      "| mean 100 episode reward | 7.83e+03   |\n",
      "| n_updates               | 1128901    |\n",
      "| policy_loss             | -480.07983 |\n",
      "| qf1_loss                | 7.996002   |\n",
      "| qf2_loss                | 9.289523   |\n",
      "| time_elapsed            | 8670       |\n",
      "| total timesteps         | 1129000    |\n",
      "| value_loss              | 6.8044176  |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| current_lr              | 0.0003       |\n",
      "| ent_coef                | 0.29502475   |\n",
      "| ent_coef_loss           | -0.057023898 |\n",
      "| entropy                 | 3.487853     |\n",
      "| episodes                | 1140         |\n",
      "| fps                     | 130          |\n",
      "| mean 100 episode reward | 7.85e+03     |\n",
      "| n_updates               | 1138901      |\n",
      "| policy_loss             | -477.89294   |\n",
      "| qf1_loss                | 6.4329815    |\n",
      "| qf2_loss                | 5.3072977    |\n",
      "| time_elapsed            | 8716         |\n",
      "| total timesteps         | 1139000      |\n",
      "| value_loss              | 3.6021326    |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| current_lr              | 0.0003       |\n",
      "| ent_coef                | 0.2918836    |\n",
      "| ent_coef_loss           | -0.028915003 |\n",
      "| entropy                 | 3.396719     |\n",
      "| episodes                | 1150         |\n",
      "| fps                     | 131          |\n",
      "| mean 100 episode reward | 7.88e+03     |\n",
      "| n_updates               | 1148901      |\n",
      "| policy_loss             | -476.08063   |\n",
      "| qf1_loss                | 9.229326     |\n",
      "| qf2_loss                | 9.365211     |\n",
      "| time_elapsed            | 8762         |\n",
      "| total timesteps         | 1149000      |\n",
      "| value_loss              | 10.74715     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.28486013  |\n",
      "| ent_coef_loss           | -0.62953395 |\n",
      "| entropy                 | 3.7964826   |\n",
      "| episodes                | 1160        |\n",
      "| fps                     | 131         |\n",
      "| mean 100 episode reward | 7.89e+03    |\n",
      "| n_updates               | 1158901     |\n",
      "| policy_loss             | -466.75797  |\n",
      "| qf1_loss                | 9.627989    |\n",
      "| qf2_loss                | 11.724861   |\n",
      "| time_elapsed            | 8808        |\n",
      "| total timesteps         | 1159000     |\n",
      "| value_loss              | 9.8680525   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.29095414 |\n",
      "| ent_coef_loss           | 0.55209607 |\n",
      "| entropy                 | 3.478273   |\n",
      "| episodes                | 1170       |\n",
      "| fps                     | 132        |\n",
      "| mean 100 episode reward | 7.92e+03   |\n",
      "| n_updates               | 1168901    |\n",
      "| policy_loss             | -483.76913 |\n",
      "| qf1_loss                | 8.691085   |\n",
      "| qf2_loss                | 8.067089   |\n",
      "| time_elapsed            | 8854       |\n",
      "| total timesteps         | 1169000    |\n",
      "| value_loss              | 5.5113583  |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.2894611  |\n",
      "| ent_coef_loss           | 0.8085526  |\n",
      "| entropy                 | 3.583008   |\n",
      "| episodes                | 1180       |\n",
      "| fps                     | 132        |\n",
      "| mean 100 episode reward | 7.94e+03   |\n",
      "| n_updates               | 1178901    |\n",
      "| policy_loss             | -480.35416 |\n",
      "| qf1_loss                | 8.563398   |\n",
      "| qf2_loss                | 10.009234  |\n",
      "| time_elapsed            | 8900       |\n",
      "| total timesteps         | 1179000    |\n",
      "| value_loss              | 6.2739034  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.29884812  |\n",
      "| ent_coef_loss           | -0.03197719 |\n",
      "| entropy                 | 3.67585     |\n",
      "| episodes                | 1190        |\n",
      "| fps                     | 132         |\n",
      "| mean 100 episode reward | 8.04e+03    |\n",
      "| n_updates               | 1188901     |\n",
      "| policy_loss             | -478.14697  |\n",
      "| qf1_loss                | 14.931753   |\n",
      "| qf2_loss                | 14.540443   |\n",
      "| time_elapsed            | 8946        |\n",
      "| total timesteps         | 1189000     |\n",
      "| value_loss              | 8.246157    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.28879982 |\n",
      "| ent_coef_loss           | -0.6977927 |\n",
      "| entropy                 | 3.5389857  |\n",
      "| episodes                | 1200       |\n",
      "| fps                     | 133        |\n",
      "| mean 100 episode reward | 8.07e+03   |\n",
      "| n_updates               | 1198901    |\n",
      "| policy_loss             | -482.6955  |\n",
      "| qf1_loss                | 15.893674  |\n",
      "| qf2_loss                | 20.713263  |\n",
      "| time_elapsed            | 8992       |\n",
      "| total timesteps         | 1199000    |\n",
      "| value_loss              | 16.926952  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.30889702 |\n",
      "| ent_coef_loss           | 0.5930707  |\n",
      "| entropy                 | 3.6004333  |\n",
      "| episodes                | 1210       |\n",
      "| fps                     | 133        |\n",
      "| mean 100 episode reward | 8.09e+03   |\n",
      "| n_updates               | 1208901    |\n",
      "| policy_loss             | -488.81708 |\n",
      "| qf1_loss                | 4.5782013  |\n",
      "| qf2_loss                | 3.8245757  |\n",
      "| time_elapsed            | 9038       |\n",
      "| total timesteps         | 1209000    |\n",
      "| value_loss              | 14.874996  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.30280733  |\n",
      "| ent_coef_loss           | 0.018580914 |\n",
      "| entropy                 | 3.6289663   |\n",
      "| episodes                | 1220        |\n",
      "| fps                     | 134         |\n",
      "| mean 100 episode reward | 8.13e+03    |\n",
      "| n_updates               | 1218901     |\n",
      "| policy_loss             | -495.4162   |\n",
      "| qf1_loss                | 10.855546   |\n",
      "| qf2_loss                | 11.076649   |\n",
      "| time_elapsed            | 9084        |\n",
      "| total timesteps         | 1219000     |\n",
      "| value_loss              | 12.834908   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.29264984 |\n",
      "| ent_coef_loss           | -0.8067752 |\n",
      "| entropy                 | 3.3529768  |\n",
      "| episodes                | 1230       |\n",
      "| fps                     | 134        |\n",
      "| mean 100 episode reward | 8.13e+03   |\n",
      "| n_updates               | 1228901    |\n",
      "| policy_loss             | -491.79483 |\n",
      "| qf1_loss                | 7.571417   |\n",
      "| qf2_loss                | 7.7706194  |\n",
      "| time_elapsed            | 9130       |\n",
      "| total timesteps         | 1229000    |\n",
      "| value_loss              | 5.756612   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.3032806   |\n",
      "| ent_coef_loss           | 0.027815819 |\n",
      "| entropy                 | 3.4864554   |\n",
      "| episodes                | 1240        |\n",
      "| fps                     | 135         |\n",
      "| mean 100 episode reward | 8.16e+03    |\n",
      "| n_updates               | 1238901     |\n",
      "| policy_loss             | -497.91565  |\n",
      "| qf1_loss                | 7.6152716   |\n",
      "| qf2_loss                | 9.569134    |\n",
      "| time_elapsed            | 9176        |\n",
      "| total timesteps         | 1239000     |\n",
      "| value_loss              | 6.7351437   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.29631597 |\n",
      "| ent_coef_loss           | 0.7118257  |\n",
      "| entropy                 | 3.5481634  |\n",
      "| episodes                | 1250       |\n",
      "| fps                     | 135        |\n",
      "| mean 100 episode reward | 8.19e+03   |\n",
      "| n_updates               | 1248901    |\n",
      "| policy_loss             | -495.65765 |\n",
      "| qf1_loss                | 14.537016  |\n",
      "| qf2_loss                | 12.929825  |\n",
      "| time_elapsed            | 9222       |\n",
      "| total timesteps         | 1249000    |\n",
      "| value_loss              | 5.8623676  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.29739207 |\n",
      "| ent_coef_loss           | -1.0709262 |\n",
      "| entropy                 | 3.446976   |\n",
      "| episodes                | 1260       |\n",
      "| fps                     | 135        |\n",
      "| mean 100 episode reward | 8.22e+03   |\n",
      "| n_updates               | 1258901    |\n",
      "| policy_loss             | -503.18912 |\n",
      "| qf1_loss                | 6.084904   |\n",
      "| qf2_loss                | 8.400905   |\n",
      "| time_elapsed            | 9268       |\n",
      "| total timesteps         | 1259000    |\n",
      "| value_loss              | 5.3468094  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.30134773 |\n",
      "| ent_coef_loss           | -0.409598  |\n",
      "| entropy                 | 3.286818   |\n",
      "| episodes                | 1270       |\n",
      "| fps                     | 136        |\n",
      "| mean 100 episode reward | 8.25e+03   |\n",
      "| n_updates               | 1268901    |\n",
      "| policy_loss             | -508.02548 |\n",
      "| qf1_loss                | 2118.3684  |\n",
      "| qf2_loss                | 2134.8662  |\n",
      "| time_elapsed            | 9314       |\n",
      "| total timesteps         | 1269000    |\n",
      "| value_loss              | 3.423235   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.2972233   |\n",
      "| ent_coef_loss           | 0.058683336 |\n",
      "| entropy                 | 3.4372537   |\n",
      "| episodes                | 1280        |\n",
      "| fps                     | 136         |\n",
      "| mean 100 episode reward | 8.28e+03    |\n",
      "| n_updates               | 1278901     |\n",
      "| policy_loss             | -517.7655   |\n",
      "| qf1_loss                | 10.282375   |\n",
      "| qf2_loss                | 10.283508   |\n",
      "| time_elapsed            | 9360        |\n",
      "| total timesteps         | 1279000     |\n",
      "| value_loss              | 15.153614   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.29170555 |\n",
      "| ent_coef_loss           | 1.1113397  |\n",
      "| entropy                 | 3.5434027  |\n",
      "| episodes                | 1290       |\n",
      "| fps                     | 137        |\n",
      "| mean 100 episode reward | 8.29e+03   |\n",
      "| n_updates               | 1288901    |\n",
      "| policy_loss             | -511.11777 |\n",
      "| qf1_loss                | 10.962927  |\n",
      "| qf2_loss                | 14.092555  |\n",
      "| time_elapsed            | 9406       |\n",
      "| total timesteps         | 1289000    |\n",
      "| value_loss              | 16.78822   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.3087724  |\n",
      "| ent_coef_loss           | 0.70242566 |\n",
      "| entropy                 | 3.7170243  |\n",
      "| episodes                | 1300       |\n",
      "| fps                     | 137        |\n",
      "| mean 100 episode reward | 8.31e+03   |\n",
      "| n_updates               | 1298901    |\n",
      "| policy_loss             | -524.0348  |\n",
      "| qf1_loss                | 8.702162   |\n",
      "| qf2_loss                | 9.889538   |\n",
      "| time_elapsed            | 9452       |\n",
      "| total timesteps         | 1299000    |\n",
      "| value_loss              | 15.276817  |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.31301606  |\n",
      "| ent_coef_loss           | 0.004200712 |\n",
      "| entropy                 | 3.5926807   |\n",
      "| episodes                | 1310        |\n",
      "| fps                     | 137         |\n",
      "| mean 100 episode reward | 8.33e+03    |\n",
      "| n_updates               | 1308901     |\n",
      "| policy_loss             | -514.7399   |\n",
      "| qf1_loss                | 12.634396   |\n",
      "| qf2_loss                | 13.119291   |\n",
      "| time_elapsed            | 9498        |\n",
      "| total timesteps         | 1309000     |\n",
      "| value_loss              | 8.983633    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.31938523  |\n",
      "| ent_coef_loss           | -0.26640242 |\n",
      "| entropy                 | 3.5472476   |\n",
      "| episodes                | 1320        |\n",
      "| fps                     | 138         |\n",
      "| mean 100 episode reward | 8.34e+03    |\n",
      "| n_updates               | 1318901     |\n",
      "| policy_loss             | -510.7678   |\n",
      "| qf1_loss                | 14.588062   |\n",
      "| qf2_loss                | 12.288324   |\n",
      "| time_elapsed            | 9544        |\n",
      "| total timesteps         | 1319000     |\n",
      "| value_loss              | 5.200228    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.31080464 |\n",
      "| ent_coef_loss           | -0.8662411 |\n",
      "| entropy                 | 3.6266553  |\n",
      "| episodes                | 1330       |\n",
      "| fps                     | 138        |\n",
      "| mean 100 episode reward | 8.39e+03   |\n",
      "| n_updates               | 1328901    |\n",
      "| policy_loss             | -519.6642  |\n",
      "| qf1_loss                | 11.120596  |\n",
      "| qf2_loss                | 9.87983    |\n",
      "| time_elapsed            | 9590       |\n",
      "| total timesteps         | 1329000    |\n",
      "| value_loss              | 5.786701   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.30475897  |\n",
      "| ent_coef_loss           | -0.38026437 |\n",
      "| entropy                 | 3.506475    |\n",
      "| episodes                | 1340        |\n",
      "| fps                     | 138         |\n",
      "| mean 100 episode reward | 8.42e+03    |\n",
      "| n_updates               | 1338901     |\n",
      "| policy_loss             | -529.052    |\n",
      "| qf1_loss                | 8.377886    |\n",
      "| qf2_loss                | 8.318222    |\n",
      "| time_elapsed            | 9636        |\n",
      "| total timesteps         | 1339000     |\n",
      "| value_loss              | 6.357415    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.30150384  |\n",
      "| ent_coef_loss           | -0.77962685 |\n",
      "| entropy                 | 3.3472342   |\n",
      "| episodes                | 1350        |\n",
      "| fps                     | 139         |\n",
      "| mean 100 episode reward | 8.45e+03    |\n",
      "| n_updates               | 1348901     |\n",
      "| policy_loss             | -526.0849   |\n",
      "| qf1_loss                | 7.177372    |\n",
      "| qf2_loss                | 8.899012    |\n",
      "| time_elapsed            | 9682        |\n",
      "| total timesteps         | 1349000     |\n",
      "| value_loss              | 5.069562    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.304029   |\n",
      "| ent_coef_loss           | 0.15137279 |\n",
      "| entropy                 | 3.5022993  |\n",
      "| episodes                | 1360       |\n",
      "| fps                     | 139        |\n",
      "| mean 100 episode reward | 8.47e+03   |\n",
      "| n_updates               | 1358901    |\n",
      "| policy_loss             | -526.6557  |\n",
      "| qf1_loss                | 8.289845   |\n",
      "| qf2_loss                | 10.230255  |\n",
      "| time_elapsed            | 9728       |\n",
      "| total timesteps         | 1359000    |\n",
      "| value_loss              | 5.09717    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.30154264 |\n",
      "| ent_coef_loss           | -1.1920388 |\n",
      "| entropy                 | 3.4656644  |\n",
      "| episodes                | 1370       |\n",
      "| fps                     | 140        |\n",
      "| mean 100 episode reward | 8.5e+03    |\n",
      "| n_updates               | 1368901    |\n",
      "| policy_loss             | -529.2952  |\n",
      "| qf1_loss                | 6.3420444  |\n",
      "| qf2_loss                | 6.1887045  |\n",
      "| time_elapsed            | 9774       |\n",
      "| total timesteps         | 1369000    |\n",
      "| value_loss              | 4.9005547  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.29478425 |\n",
      "| ent_coef_loss           | -0.6852217 |\n",
      "| entropy                 | 3.6881123  |\n",
      "| episodes                | 1380       |\n",
      "| fps                     | 140        |\n",
      "| mean 100 episode reward | 8.52e+03   |\n",
      "| n_updates               | 1378901    |\n",
      "| policy_loss             | -516.54333 |\n",
      "| qf1_loss                | 24.941526  |\n",
      "| qf2_loss                | 21.618439  |\n",
      "| time_elapsed            | 9820       |\n",
      "| total timesteps         | 1379000    |\n",
      "| value_loss              | 7.4439     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.3043779  |\n",
      "| ent_coef_loss           | 0.6987456  |\n",
      "| entropy                 | 3.657452   |\n",
      "| episodes                | 1390       |\n",
      "| fps                     | 140        |\n",
      "| mean 100 episode reward | 8.55e+03   |\n",
      "| n_updates               | 1388901    |\n",
      "| policy_loss             | -526.50684 |\n",
      "| qf1_loss                | 11.65321   |\n",
      "| qf2_loss                | 14.692097  |\n",
      "| time_elapsed            | 9866       |\n",
      "| total timesteps         | 1389000    |\n",
      "| value_loss              | 5.521297   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.310733    |\n",
      "| ent_coef_loss           | -0.81276745 |\n",
      "| entropy                 | 3.7158463   |\n",
      "| episodes                | 1400        |\n",
      "| fps                     | 141         |\n",
      "| mean 100 episode reward | 8.57e+03    |\n",
      "| n_updates               | 1398901     |\n",
      "| policy_loss             | -537.2434   |\n",
      "| qf1_loss                | 14.506818   |\n",
      "| qf2_loss                | 13.708663   |\n",
      "| time_elapsed            | 9912        |\n",
      "| total timesteps         | 1399000     |\n",
      "| value_loss              | 5.2608194   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.2979604  |\n",
      "| ent_coef_loss           | 0.17513473 |\n",
      "| entropy                 | 3.7579546  |\n",
      "| episodes                | 1410       |\n",
      "| fps                     | 141        |\n",
      "| mean 100 episode reward | 8.58e+03   |\n",
      "| n_updates               | 1408901    |\n",
      "| policy_loss             | -540.1615  |\n",
      "| qf1_loss                | 21.02921   |\n",
      "| qf2_loss                | 18.555508  |\n",
      "| time_elapsed            | 9958       |\n",
      "| total timesteps         | 1409000    |\n",
      "| value_loss              | 8.039067   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.30552286  |\n",
      "| ent_coef_loss           | -0.20139584 |\n",
      "| entropy                 | 3.4978545   |\n",
      "| episodes                | 1420        |\n",
      "| fps                     | 141         |\n",
      "| mean 100 episode reward | 8.6e+03     |\n",
      "| n_updates               | 1418901     |\n",
      "| policy_loss             | -551.5614   |\n",
      "| qf1_loss                | 7.8414717   |\n",
      "| qf2_loss                | 5.259335    |\n",
      "| time_elapsed            | 10004       |\n",
      "| total timesteps         | 1419000     |\n",
      "| value_loss              | 2.869193    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.29678756  |\n",
      "| ent_coef_loss           | -0.17883211 |\n",
      "| entropy                 | 3.6794393   |\n",
      "| episodes                | 1430        |\n",
      "| fps                     | 142         |\n",
      "| mean 100 episode reward | 8.62e+03    |\n",
      "| n_updates               | 1428901     |\n",
      "| policy_loss             | -538.66534  |\n",
      "| qf1_loss                | 30.762314   |\n",
      "| qf2_loss                | 28.659327   |\n",
      "| time_elapsed            | 10050       |\n",
      "| total timesteps         | 1429000     |\n",
      "| value_loss              | 9.1010685   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.30701265 |\n",
      "| ent_coef_loss           | 0.04527393 |\n",
      "| entropy                 | 3.558796   |\n",
      "| episodes                | 1440       |\n",
      "| fps                     | 142        |\n",
      "| mean 100 episode reward | 8.63e+03   |\n",
      "| n_updates               | 1438901    |\n",
      "| policy_loss             | -547.4515  |\n",
      "| qf1_loss                | 19.962313  |\n",
      "| qf2_loss                | 16.695143  |\n",
      "| time_elapsed            | 10096      |\n",
      "| total timesteps         | 1439000    |\n",
      "| value_loss              | 9.2088     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.29832816  |\n",
      "| ent_coef_loss           | -0.07800028 |\n",
      "| entropy                 | 3.544276    |\n",
      "| episodes                | 1450        |\n",
      "| fps                     | 142         |\n",
      "| mean 100 episode reward | 8.63e+03    |\n",
      "| n_updates               | 1448901     |\n",
      "| policy_loss             | -556.0835   |\n",
      "| qf1_loss                | 7.1472054   |\n",
      "| qf2_loss                | 4.656262    |\n",
      "| time_elapsed            | 10142       |\n",
      "| total timesteps         | 1449000     |\n",
      "| value_loss              | 8.940552    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.29643628 |\n",
      "| ent_coef_loss           | -1.0261447 |\n",
      "| entropy                 | 3.49335    |\n",
      "| episodes                | 1460       |\n",
      "| fps                     | 143        |\n",
      "| mean 100 episode reward | 8.64e+03   |\n",
      "| n_updates               | 1458901    |\n",
      "| policy_loss             | -550.82764 |\n",
      "| qf1_loss                | 10.700089  |\n",
      "| qf2_loss                | 9.586554   |\n",
      "| time_elapsed            | 10188      |\n",
      "| total timesteps         | 1459000    |\n",
      "| value_loss              | 7.494924   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.3024762   |\n",
      "| ent_coef_loss           | 0.008368701 |\n",
      "| entropy                 | 3.2351112   |\n",
      "| episodes                | 1470        |\n",
      "| fps                     | 143         |\n",
      "| mean 100 episode reward | 8.66e+03    |\n",
      "| n_updates               | 1468901     |\n",
      "| policy_loss             | -555.36456  |\n",
      "| qf1_loss                | 14.901381   |\n",
      "| qf2_loss                | 11.793291   |\n",
      "| time_elapsed            | 10234       |\n",
      "| total timesteps         | 1469000     |\n",
      "| value_loss              | 4.865732    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.30688834 |\n",
      "| ent_coef_loss           | -0.544436  |\n",
      "| entropy                 | 3.4336267  |\n",
      "| episodes                | 1480       |\n",
      "| fps                     | 143        |\n",
      "| mean 100 episode reward | 8.67e+03   |\n",
      "| n_updates               | 1478901    |\n",
      "| policy_loss             | -560.63306 |\n",
      "| qf1_loss                | 8.380518   |\n",
      "| qf2_loss                | 6.5855885  |\n",
      "| time_elapsed            | 10280      |\n",
      "| total timesteps         | 1479000    |\n",
      "| value_loss              | 5.2629337  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.2990488  |\n",
      "| ent_coef_loss           | 0.35094187 |\n",
      "| entropy                 | 3.310625   |\n",
      "| episodes                | 1490       |\n",
      "| fps                     | 144        |\n",
      "| mean 100 episode reward | 8.69e+03   |\n",
      "| n_updates               | 1488901    |\n",
      "| policy_loss             | -567.58624 |\n",
      "| qf1_loss                | 14.251785  |\n",
      "| qf2_loss                | 12.8269415 |\n",
      "| time_elapsed            | 10326      |\n",
      "| total timesteps         | 1489000    |\n",
      "| value_loss              | 9.190378   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ent_coef                | 0.2962523 |\n",
      "| ent_coef_loss           | 0.7930889 |\n",
      "| entropy                 | 3.267721  |\n",
      "| episodes                | 1500      |\n",
      "| fps                     | 144       |\n",
      "| mean 100 episode reward | 8.71e+03  |\n",
      "| n_updates               | 1498901   |\n",
      "| policy_loss             | -553.8087 |\n",
      "| qf1_loss                | 10.436032 |\n",
      "| qf2_loss                | 10.087584 |\n",
      "| time_elapsed            | 10372     |\n",
      "| total timesteps         | 1499000   |\n",
      "| value_loss              | 9.4828615 |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.29119208 |\n",
      "| ent_coef_loss           | 0.11873283 |\n",
      "| entropy                 | 3.2947764  |\n",
      "| episodes                | 1510       |\n",
      "| fps                     | 144        |\n",
      "| mean 100 episode reward | 8.74e+03   |\n",
      "| n_updates               | 1508901    |\n",
      "| policy_loss             | -573.53235 |\n",
      "| qf1_loss                | 7.9896     |\n",
      "| qf2_loss                | 6.214908   |\n",
      "| time_elapsed            | 10418      |\n",
      "| total timesteps         | 1509000    |\n",
      "| value_loss              | 7.7277026  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.29296798 |\n",
      "| ent_coef_loss           | -0.6732075 |\n",
      "| entropy                 | 3.1364708  |\n",
      "| episodes                | 1520       |\n",
      "| fps                     | 145        |\n",
      "| mean 100 episode reward | 8.76e+03   |\n",
      "| n_updates               | 1518901    |\n",
      "| policy_loss             | -560.04266 |\n",
      "| qf1_loss                | 13.589888  |\n",
      "| qf2_loss                | 9.849758   |\n",
      "| time_elapsed            | 10465      |\n",
      "| total timesteps         | 1519000    |\n",
      "| value_loss              | 6.4699287  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.2987177   |\n",
      "| ent_coef_loss           | -0.36439422 |\n",
      "| entropy                 | 3.6304376   |\n",
      "| episodes                | 1530        |\n",
      "| fps                     | 145         |\n",
      "| mean 100 episode reward | 8.76e+03    |\n",
      "| n_updates               | 1528901     |\n",
      "| policy_loss             | -568.34436  |\n",
      "| qf1_loss                | 20.357502   |\n",
      "| qf2_loss                | 20.493866   |\n",
      "| time_elapsed            | 10511       |\n",
      "| total timesteps         | 1529000     |\n",
      "| value_loss              | 6.6454606   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.28731138 |\n",
      "| ent_coef_loss           | 0.5500171  |\n",
      "| entropy                 | 3.4250662  |\n",
      "| episodes                | 1540       |\n",
      "| fps                     | 145        |\n",
      "| mean 100 episode reward | 8.77e+03   |\n",
      "| n_updates               | 1538901    |\n",
      "| policy_loss             | -576.87    |\n",
      "| qf1_loss                | 6.405927   |\n",
      "| qf2_loss                | 5.467066   |\n",
      "| time_elapsed            | 10557      |\n",
      "| total timesteps         | 1539000    |\n",
      "| value_loss              | 11.074772  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.3005652  |\n",
      "| ent_coef_loss           | 0.49117237 |\n",
      "| entropy                 | 3.3650858  |\n",
      "| episodes                | 1550       |\n",
      "| fps                     | 146        |\n",
      "| mean 100 episode reward | 8.78e+03   |\n",
      "| n_updates               | 1548901    |\n",
      "| policy_loss             | -583.402   |\n",
      "| qf1_loss                | 16.448391  |\n",
      "| qf2_loss                | 16.142838  |\n",
      "| time_elapsed            | 10603      |\n",
      "| total timesteps         | 1549000    |\n",
      "| value_loss              | 9.624909   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| current_lr              | 0.0003       |\n",
      "| ent_coef                | 0.29601797   |\n",
      "| ent_coef_loss           | -0.003970653 |\n",
      "| entropy                 | 3.1610146    |\n",
      "| episodes                | 1560         |\n",
      "| fps                     | 146          |\n",
      "| mean 100 episode reward | 8.76e+03     |\n",
      "| n_updates               | 1558901      |\n",
      "| policy_loss             | -582.8684    |\n",
      "| qf1_loss                | 10.280266    |\n",
      "| qf2_loss                | 8.314036     |\n",
      "| time_elapsed            | 10649        |\n",
      "| total timesteps         | 1559000      |\n",
      "| value_loss              | 3.9877434    |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| current_lr              | 0.0003       |\n",
      "| ent_coef                | 0.3130878    |\n",
      "| ent_coef_loss           | -0.041646063 |\n",
      "| entropy                 | 3.3418188    |\n",
      "| episodes                | 1570         |\n",
      "| fps                     | 146          |\n",
      "| mean 100 episode reward | 8.78e+03     |\n",
      "| n_updates               | 1568901      |\n",
      "| policy_loss             | -586.3829    |\n",
      "| qf1_loss                | 14.731262    |\n",
      "| qf2_loss                | 15.208574    |\n",
      "| time_elapsed            | 10695        |\n",
      "| total timesteps         | 1569000      |\n",
      "| value_loss              | 5.5885878    |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| current_lr              | 0.0003       |\n",
      "| ent_coef                | 0.30417985   |\n",
      "| ent_coef_loss           | 0.0064101815 |\n",
      "| entropy                 | 3.247941     |\n",
      "| episodes                | 1580         |\n",
      "| fps                     | 147          |\n",
      "| mean 100 episode reward | 8.79e+03     |\n",
      "| n_updates               | 1578901      |\n",
      "| policy_loss             | -584.06995   |\n",
      "| qf1_loss                | 12.6135      |\n",
      "| qf2_loss                | 12.179487    |\n",
      "| time_elapsed            | 10741        |\n",
      "| total timesteps         | 1579000      |\n",
      "| value_loss              | 7.2817097    |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| current_lr              | 0.0003       |\n",
      "| ent_coef                | 0.30574656   |\n",
      "| ent_coef_loss           | -0.016301006 |\n",
      "| entropy                 | 2.8086376    |\n",
      "| episodes                | 1590         |\n",
      "| fps                     | 147          |\n",
      "| mean 100 episode reward | 8.8e+03      |\n",
      "| n_updates               | 1588901      |\n",
      "| policy_loss             | -587.7634    |\n",
      "| qf1_loss                | 6.9793587    |\n",
      "| qf2_loss                | 6.0883512    |\n",
      "| time_elapsed            | 10787        |\n",
      "| total timesteps         | 1589000      |\n",
      "| value_loss              | 4.8329983    |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.30570024 |\n",
      "| ent_coef_loss           | 0.73032534 |\n",
      "| entropy                 | 3.1377096  |\n",
      "| episodes                | 1600       |\n",
      "| fps                     | 147        |\n",
      "| mean 100 episode reward | 8.81e+03   |\n",
      "| n_updates               | 1598901    |\n",
      "| policy_loss             | -585.8092  |\n",
      "| qf1_loss                | 8.282632   |\n",
      "| qf2_loss                | 6.4713774  |\n",
      "| time_elapsed            | 10833      |\n",
      "| total timesteps         | 1599000    |\n",
      "| value_loss              | 5.1859818  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.2915131   |\n",
      "| ent_coef_loss           | -0.19469962 |\n",
      "| entropy                 | 3.324233    |\n",
      "| episodes                | 1610        |\n",
      "| fps                     | 147         |\n",
      "| mean 100 episode reward | 8.81e+03    |\n",
      "| n_updates               | 1608901     |\n",
      "| policy_loss             | -583.157    |\n",
      "| qf1_loss                | 7.425446    |\n",
      "| qf2_loss                | 7.2522154   |\n",
      "| time_elapsed            | 10880       |\n",
      "| total timesteps         | 1609000     |\n",
      "| value_loss              | 34.08225    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.29968736 |\n",
      "| ent_coef_loss           | 0.12939756 |\n",
      "| entropy                 | 3.348184   |\n",
      "| episodes                | 1620       |\n",
      "| fps                     | 148        |\n",
      "| mean 100 episode reward | 8.82e+03   |\n",
      "| n_updates               | 1618901    |\n",
      "| policy_loss             | -591.2882  |\n",
      "| qf1_loss                | 9.123071   |\n",
      "| qf2_loss                | 10.093194  |\n",
      "| time_elapsed            | 10926      |\n",
      "| total timesteps         | 1619000    |\n",
      "| value_loss              | 5.5083284  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.29941657  |\n",
      "| ent_coef_loss           | -0.37998632 |\n",
      "| entropy                 | 2.996684    |\n",
      "| episodes                | 1630        |\n",
      "| fps                     | 148         |\n",
      "| mean 100 episode reward | 8.87e+03    |\n",
      "| n_updates               | 1628901     |\n",
      "| policy_loss             | -582.4955   |\n",
      "| qf1_loss                | 11.575678   |\n",
      "| qf2_loss                | 14.488449   |\n",
      "| time_elapsed            | 10972       |\n",
      "| total timesteps         | 1629000     |\n",
      "| value_loss              | 6.251073    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.30720928  |\n",
      "| ent_coef_loss           | -0.32994586 |\n",
      "| entropy                 | 3.269886    |\n",
      "| episodes                | 1640        |\n",
      "| fps                     | 148         |\n",
      "| mean 100 episode reward | 8.89e+03    |\n",
      "| n_updates               | 1638901     |\n",
      "| policy_loss             | -591.66846  |\n",
      "| qf1_loss                | 12.960937   |\n",
      "| qf2_loss                | 14.15976    |\n",
      "| time_elapsed            | 11018       |\n",
      "| total timesteps         | 1639000     |\n",
      "| value_loss              | 63.572556   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.29284915  |\n",
      "| ent_coef_loss           | -0.28055018 |\n",
      "| entropy                 | 3.0981665   |\n",
      "| episodes                | 1650        |\n",
      "| fps                     | 149         |\n",
      "| mean 100 episode reward | 8.92e+03    |\n",
      "| n_updates               | 1648901     |\n",
      "| policy_loss             | -595.03815  |\n",
      "| qf1_loss                | 8.665815    |\n",
      "| qf2_loss                | 8.886532    |\n",
      "| time_elapsed            | 11064       |\n",
      "| total timesteps         | 1649000     |\n",
      "| value_loss              | 3.7459393   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.29122925  |\n",
      "| ent_coef_loss           | -0.68421745 |\n",
      "| entropy                 | 2.9117427   |\n",
      "| episodes                | 1660        |\n",
      "| fps                     | 149         |\n",
      "| mean 100 episode reward | 8.96e+03    |\n",
      "| n_updates               | 1658901     |\n",
      "| policy_loss             | -593.1544   |\n",
      "| qf1_loss                | 2679.4697   |\n",
      "| qf2_loss                | 2655.0889   |\n",
      "| time_elapsed            | 11110       |\n",
      "| total timesteps         | 1659000     |\n",
      "| value_loss              | 4.0358925   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.3083761  |\n",
      "| ent_coef_loss           | -1.0543232 |\n",
      "| entropy                 | 3.4870007  |\n",
      "| episodes                | 1670       |\n",
      "| fps                     | 149        |\n",
      "| mean 100 episode reward | 8.92e+03   |\n",
      "| n_updates               | 1668901    |\n",
      "| policy_loss             | -596.81287 |\n",
      "| qf1_loss                | 9.622752   |\n",
      "| qf2_loss                | 8.4425745  |\n",
      "| time_elapsed            | 11156      |\n",
      "| total timesteps         | 1669000    |\n",
      "| value_loss              | 6.121993   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.3135276  |\n",
      "| ent_coef_loss           | 0.16329467 |\n",
      "| entropy                 | 3.0805478  |\n",
      "| episodes                | 1680       |\n",
      "| fps                     | 149        |\n",
      "| mean 100 episode reward | 8.94e+03   |\n",
      "| n_updates               | 1678901    |\n",
      "| policy_loss             | -611.3543  |\n",
      "| qf1_loss                | 9.795523   |\n",
      "| qf2_loss                | 9.457837   |\n",
      "| time_elapsed            | 11202      |\n",
      "| total timesteps         | 1679000    |\n",
      "| value_loss              | 4.042741   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ent_coef                | 0.3029784 |\n",
      "| ent_coef_loss           | 0.8498548 |\n",
      "| entropy                 | 3.3255749 |\n",
      "| episodes                | 1690      |\n",
      "| fps                     | 150       |\n",
      "| mean 100 episode reward | 8.96e+03  |\n",
      "| n_updates               | 1688901   |\n",
      "| policy_loss             | -609.5914 |\n",
      "| qf1_loss                | 5.164852  |\n",
      "| qf2_loss                | 6.4854403 |\n",
      "| time_elapsed            | 11248     |\n",
      "| total timesteps         | 1689000   |\n",
      "| value_loss              | 9.015166  |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.2908391  |\n",
      "| ent_coef_loss           | 0.26949155 |\n",
      "| entropy                 | 2.8601418  |\n",
      "| episodes                | 1700       |\n",
      "| fps                     | 150        |\n",
      "| mean 100 episode reward | 8.97e+03   |\n",
      "| n_updates               | 1698901    |\n",
      "| policy_loss             | -613.36017 |\n",
      "| qf1_loss                | 16.110405  |\n",
      "| qf2_loss                | 17.456562  |\n",
      "| time_elapsed            | 11295      |\n",
      "| total timesteps         | 1699000    |\n",
      "| value_loss              | 4.1771293  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.291767    |\n",
      "| ent_coef_loss           | -0.93605816 |\n",
      "| entropy                 | 3.1237197   |\n",
      "| episodes                | 1710        |\n",
      "| fps                     | 150         |\n",
      "| mean 100 episode reward | 8.99e+03    |\n",
      "| n_updates               | 1708901     |\n",
      "| policy_loss             | -617.4581   |\n",
      "| qf1_loss                | 5.099886    |\n",
      "| qf2_loss                | 6.058631    |\n",
      "| time_elapsed            | 11341       |\n",
      "| total timesteps         | 1709000     |\n",
      "| value_loss              | 62.72007    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.3171705   |\n",
      "| ent_coef_loss           | -0.39288563 |\n",
      "| entropy                 | 3.2091382   |\n",
      "| episodes                | 1720        |\n",
      "| fps                     | 150         |\n",
      "| mean 100 episode reward | 9.01e+03    |\n",
      "| n_updates               | 1718901     |\n",
      "| policy_loss             | -615.65576  |\n",
      "| qf1_loss                | 9.099936    |\n",
      "| qf2_loss                | 7.662863    |\n",
      "| time_elapsed            | 11387       |\n",
      "| total timesteps         | 1719000     |\n",
      "| value_loss              | 9.718582    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.30605072 |\n",
      "| ent_coef_loss           | -1.3261223 |\n",
      "| entropy                 | 2.8599453  |\n",
      "| episodes                | 1730       |\n",
      "| fps                     | 151        |\n",
      "| mean 100 episode reward | 9.02e+03   |\n",
      "| n_updates               | 1728901    |\n",
      "| policy_loss             | -619.172   |\n",
      "| qf1_loss                | 15.017219  |\n",
      "| qf2_loss                | 15.928135  |\n",
      "| time_elapsed            | 11433      |\n",
      "| total timesteps         | 1729000    |\n",
      "| value_loss              | 13.089742  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.30449688 |\n",
      "| ent_coef_loss           | 0.38029522 |\n",
      "| entropy                 | 3.0967107  |\n",
      "| episodes                | 1740       |\n",
      "| fps                     | 151        |\n",
      "| mean 100 episode reward | 9.04e+03   |\n",
      "| n_updates               | 1738901    |\n",
      "| policy_loss             | -620.1677  |\n",
      "| qf1_loss                | 15.473141  |\n",
      "| qf2_loss                | 17.391544  |\n",
      "| time_elapsed            | 11480      |\n",
      "| total timesteps         | 1739000    |\n",
      "| value_loss              | 22.264547  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.28868616  |\n",
      "| ent_coef_loss           | 0.123197354 |\n",
      "| entropy                 | 3.2029343   |\n",
      "| episodes                | 1750        |\n",
      "| fps                     | 151         |\n",
      "| mean 100 episode reward | 9.06e+03    |\n",
      "| n_updates               | 1748901     |\n",
      "| policy_loss             | -611.5468   |\n",
      "| qf1_loss                | 30.2891     |\n",
      "| qf2_loss                | 26.180103   |\n",
      "| time_elapsed            | 11526       |\n",
      "| total timesteps         | 1749000     |\n",
      "| value_loss              | 9.519304    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.28469658 |\n",
      "| ent_coef_loss           | 0.2865919  |\n",
      "| entropy                 | 3.0546198  |\n",
      "| episodes                | 1760       |\n",
      "| fps                     | 151        |\n",
      "| mean 100 episode reward | 9.08e+03   |\n",
      "| n_updates               | 1758901    |\n",
      "| policy_loss             | -602.9313  |\n",
      "| qf1_loss                | 14.070381  |\n",
      "| qf2_loss                | 17.529198  |\n",
      "| time_elapsed            | 11573      |\n",
      "| total timesteps         | 1759000    |\n",
      "| value_loss              | 10.403071  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.29297593 |\n",
      "| ent_coef_loss           | 0.3983432  |\n",
      "| entropy                 | 2.7941568  |\n",
      "| episodes                | 1770       |\n",
      "| fps                     | 152        |\n",
      "| mean 100 episode reward | 9.15e+03   |\n",
      "| n_updates               | 1768901    |\n",
      "| policy_loss             | -635.5403  |\n",
      "| qf1_loss                | 31.897612  |\n",
      "| qf2_loss                | 35.779     |\n",
      "| time_elapsed            | 11619      |\n",
      "| total timesteps         | 1769000    |\n",
      "| value_loss              | 8.50474    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.31322768 |\n",
      "| ent_coef_loss           | -0.0712914 |\n",
      "| entropy                 | 3.4472442  |\n",
      "| episodes                | 1780       |\n",
      "| fps                     | 152        |\n",
      "| mean 100 episode reward | 9.17e+03   |\n",
      "| n_updates               | 1778901    |\n",
      "| policy_loss             | -625.98517 |\n",
      "| qf1_loss                | 2980.434   |\n",
      "| qf2_loss                | 3054.0798  |\n",
      "| time_elapsed            | 11665      |\n",
      "| total timesteps         | 1779000    |\n",
      "| value_loss              | 3.1190486  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.3116536  |\n",
      "| ent_coef_loss           | 0.16073877 |\n",
      "| entropy                 | 3.239555   |\n",
      "| episodes                | 1790       |\n",
      "| fps                     | 152        |\n",
      "| mean 100 episode reward | 9.18e+03   |\n",
      "| n_updates               | 1788901    |\n",
      "| policy_loss             | -616.73267 |\n",
      "| qf1_loss                | 6.4141216  |\n",
      "| qf2_loss                | 8.423332   |\n",
      "| time_elapsed            | 11711      |\n",
      "| total timesteps         | 1789000    |\n",
      "| value_loss              | 4.923547   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.29849258 |\n",
      "| ent_coef_loss           | 0.30895454 |\n",
      "| entropy                 | 2.9929152  |\n",
      "| episodes                | 1800       |\n",
      "| fps                     | 153        |\n",
      "| mean 100 episode reward | 9.2e+03    |\n",
      "| n_updates               | 1798901    |\n",
      "| policy_loss             | -631.56665 |\n",
      "| qf1_loss                | 25.408371  |\n",
      "| qf2_loss                | 25.425886  |\n",
      "| time_elapsed            | 11757      |\n",
      "| total timesteps         | 1799000    |\n",
      "| value_loss              | 7.3563423  |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| current_lr              | 0.0003       |\n",
      "| ent_coef                | 0.31079665   |\n",
      "| ent_coef_loss           | -0.024986684 |\n",
      "| entropy                 | 3.5128155    |\n",
      "| episodes                | 1810         |\n",
      "| fps                     | 153          |\n",
      "| mean 100 episode reward | 9.21e+03     |\n",
      "| n_updates               | 1808901      |\n",
      "| policy_loss             | -608.326     |\n",
      "| qf1_loss                | 14.959851    |\n",
      "| qf2_loss                | 14.262895    |\n",
      "| time_elapsed            | 11804        |\n",
      "| total timesteps         | 1809000      |\n",
      "| value_loss              | 7.2207384    |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.3036914  |\n",
      "| ent_coef_loss           | 0.22993994 |\n",
      "| entropy                 | 2.9722576  |\n",
      "| episodes                | 1820       |\n",
      "| fps                     | 153        |\n",
      "| mean 100 episode reward | 9.22e+03   |\n",
      "| n_updates               | 1818901    |\n",
      "| policy_loss             | -637.979   |\n",
      "| qf1_loss                | 7.318526   |\n",
      "| qf2_loss                | 12.201225  |\n",
      "| time_elapsed            | 11850      |\n",
      "| total timesteps         | 1819000    |\n",
      "| value_loss              | 4.5367184  |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| current_lr              | 0.0003       |\n",
      "| ent_coef                | 0.3010143    |\n",
      "| ent_coef_loss           | -0.011362195 |\n",
      "| entropy                 | 2.9754748    |\n",
      "| episodes                | 1830         |\n",
      "| fps                     | 153          |\n",
      "| mean 100 episode reward | 9.21e+03     |\n",
      "| n_updates               | 1828901      |\n",
      "| policy_loss             | -631.98444   |\n",
      "| qf1_loss                | 7.879155     |\n",
      "| qf2_loss                | 9.104228     |\n",
      "| time_elapsed            | 11896        |\n",
      "| total timesteps         | 1829000      |\n",
      "| value_loss              | 5.62065      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.29990792  |\n",
      "| ent_coef_loss           | -0.51284146 |\n",
      "| entropy                 | 3.320032    |\n",
      "| episodes                | 1840        |\n",
      "| fps                     | 153         |\n",
      "| mean 100 episode reward | 9.14e+03    |\n",
      "| n_updates               | 1838901     |\n",
      "| policy_loss             | -647.3596   |\n",
      "| qf1_loss                | 6.4316006   |\n",
      "| qf2_loss                | 5.299656    |\n",
      "| time_elapsed            | 11942       |\n",
      "| total timesteps         | 1839000     |\n",
      "| value_loss              | 12.072182   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.3138584  |\n",
      "| ent_coef_loss           | 0.42630345 |\n",
      "| entropy                 | 3.2424345  |\n",
      "| episodes                | 1850       |\n",
      "| fps                     | 154        |\n",
      "| mean 100 episode reward | 9.14e+03   |\n",
      "| n_updates               | 1848901    |\n",
      "| policy_loss             | -626.42017 |\n",
      "| qf1_loss                | 21.476744  |\n",
      "| qf2_loss                | 16.054626  |\n",
      "| time_elapsed            | 11989      |\n",
      "| total timesteps         | 1849000    |\n",
      "| value_loss              | 5.6860876  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.30742955  |\n",
      "| ent_coef_loss           | -0.77457863 |\n",
      "| entropy                 | 3.1068254   |\n",
      "| episodes                | 1860        |\n",
      "| fps                     | 154         |\n",
      "| mean 100 episode reward | 9.16e+03    |\n",
      "| n_updates               | 1858901     |\n",
      "| policy_loss             | -639.12585  |\n",
      "| qf1_loss                | 16.906738   |\n",
      "| qf2_loss                | 19.730286   |\n",
      "| time_elapsed            | 12034       |\n",
      "| total timesteps         | 1859000     |\n",
      "| value_loss              | 7.0313354   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.30993304  |\n",
      "| ent_coef_loss           | -0.35381213 |\n",
      "| entropy                 | 3.1356893   |\n",
      "| episodes                | 1870        |\n",
      "| fps                     | 154         |\n",
      "| mean 100 episode reward | 9.05e+03    |\n",
      "| n_updates               | 1868901     |\n",
      "| policy_loss             | -641.5089   |\n",
      "| qf1_loss                | 9.195911    |\n",
      "| qf2_loss                | 7.599356    |\n",
      "| time_elapsed            | 12081       |\n",
      "| total timesteps         | 1869000     |\n",
      "| value_loss              | 3.8188992   |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| current_lr              | 0.0003        |\n",
      "| ent_coef                | 0.30161184    |\n",
      "| ent_coef_loss           | -0.0037227422 |\n",
      "| entropy                 | 3.1001914     |\n",
      "| episodes                | 1880          |\n",
      "| fps                     | 154           |\n",
      "| mean 100 episode reward | 9.06e+03      |\n",
      "| n_updates               | 1878901       |\n",
      "| policy_loss             | -630.04803    |\n",
      "| qf1_loss                | 10.480549     |\n",
      "| qf2_loss                | 13.438253     |\n",
      "| time_elapsed            | 12127         |\n",
      "| total timesteps         | 1879000       |\n",
      "| value_loss              | 9.906902      |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.30000123  |\n",
      "| ent_coef_loss           | -0.23811173 |\n",
      "| entropy                 | 3.1790195   |\n",
      "| episodes                | 1890        |\n",
      "| fps                     | 155         |\n",
      "| mean 100 episode reward | 9.07e+03    |\n",
      "| n_updates               | 1888901     |\n",
      "| policy_loss             | -634.6862   |\n",
      "| qf1_loss                | 6.9213963   |\n",
      "| qf2_loss                | 6.1134014   |\n",
      "| time_elapsed            | 12174       |\n",
      "| total timesteps         | 1889000     |\n",
      "| value_loss              | 8.844357    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.3011134  |\n",
      "| ent_coef_loss           | 0.13882676 |\n",
      "| entropy                 | 3.1451826  |\n",
      "| episodes                | 1900       |\n",
      "| fps                     | 155        |\n",
      "| mean 100 episode reward | 9.08e+03   |\n",
      "| n_updates               | 1898901    |\n",
      "| policy_loss             | -641.8856  |\n",
      "| qf1_loss                | 2959.4004  |\n",
      "| qf2_loss                | 3013.5461  |\n",
      "| time_elapsed            | 12221      |\n",
      "| total timesteps         | 1899000    |\n",
      "| value_loss              | 7.518177   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.30425385  |\n",
      "| ent_coef_loss           | -0.82451975 |\n",
      "| entropy                 | 3.3194554   |\n",
      "| episodes                | 1910        |\n",
      "| fps                     | 155         |\n",
      "| mean 100 episode reward | 9.06e+03    |\n",
      "| n_updates               | 1908901     |\n",
      "| policy_loss             | -647.15564  |\n",
      "| qf1_loss                | 4.283529    |\n",
      "| qf2_loss                | 4.062141    |\n",
      "| time_elapsed            | 12267       |\n",
      "| total timesteps         | 1909000     |\n",
      "| value_loss              | 8.88821     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| current_lr              | 0.0003       |\n",
      "| ent_coef                | 0.30452272   |\n",
      "| ent_coef_loss           | -0.046753705 |\n",
      "| entropy                 | 3.174369     |\n",
      "| episodes                | 1920         |\n",
      "| fps                     | 155          |\n",
      "| mean 100 episode reward | 9.06e+03     |\n",
      "| n_updates               | 1918901      |\n",
      "| policy_loss             | -647.7836    |\n",
      "| qf1_loss                | 5.4624386    |\n",
      "| qf2_loss                | 6.2030764    |\n",
      "| time_elapsed            | 12313        |\n",
      "| total timesteps         | 1919000      |\n",
      "| value_loss              | 3.7620487    |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.28634864 |\n",
      "| ent_coef_loss           | 0.84896934 |\n",
      "| entropy                 | 2.9409847  |\n",
      "| episodes                | 1930       |\n",
      "| fps                     | 156        |\n",
      "| mean 100 episode reward | 9.1e+03    |\n",
      "| n_updates               | 1928901    |\n",
      "| policy_loss             | -638.1626  |\n",
      "| qf1_loss                | 15.46255   |\n",
      "| qf2_loss                | 14.655041  |\n",
      "| time_elapsed            | 12359      |\n",
      "| total timesteps         | 1929000    |\n",
      "| value_loss              | 8.718565   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.30734527 |\n",
      "| ent_coef_loss           | -0.6915104 |\n",
      "| entropy                 | 3.1321526  |\n",
      "| episodes                | 1940       |\n",
      "| fps                     | 156        |\n",
      "| mean 100 episode reward | 9.2e+03    |\n",
      "| n_updates               | 1938901    |\n",
      "| policy_loss             | -643.1959  |\n",
      "| qf1_loss                | 10.293388  |\n",
      "| qf2_loss                | 12.284803  |\n",
      "| time_elapsed            | 12406      |\n",
      "| total timesteps         | 1939000    |\n",
      "| value_loss              | 3.7269166  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.28513366 |\n",
      "| ent_coef_loss           | 0.29422522 |\n",
      "| entropy                 | 2.9646814  |\n",
      "| episodes                | 1950       |\n",
      "| fps                     | 156        |\n",
      "| mean 100 episode reward | 9.12e+03   |\n",
      "| n_updates               | 1948901    |\n",
      "| policy_loss             | -650.449   |\n",
      "| qf1_loss                | 4.912199   |\n",
      "| qf2_loss                | 5.547001   |\n",
      "| time_elapsed            | 12452      |\n",
      "| total timesteps         | 1949000    |\n",
      "| value_loss              | 3.321894   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.30557287 |\n",
      "| ent_coef_loss           | -0.9800366 |\n",
      "| entropy                 | 3.0614514  |\n",
      "| episodes                | 1960       |\n",
      "| fps                     | 156        |\n",
      "| mean 100 episode reward | 9.04e+03   |\n",
      "| n_updates               | 1958901    |\n",
      "| policy_loss             | -630.0945  |\n",
      "| qf1_loss                | 10.675732  |\n",
      "| qf2_loss                | 8.599438   |\n",
      "| time_elapsed            | 12498      |\n",
      "| total timesteps         | 1959000    |\n",
      "| value_loss              | 23.52641   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.2999656  |\n",
      "| ent_coef_loss           | -0.6041733 |\n",
      "| entropy                 | 3.0724955  |\n",
      "| episodes                | 1970       |\n",
      "| fps                     | 156        |\n",
      "| mean 100 episode reward | 9.16e+03   |\n",
      "| n_updates               | 1968901    |\n",
      "| policy_loss             | -627.7543  |\n",
      "| qf1_loss                | 29.879383  |\n",
      "| qf2_loss                | 25.730846  |\n",
      "| time_elapsed            | 12544      |\n",
      "| total timesteps         | 1969000    |\n",
      "| value_loss              | 15.763958  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.29563823 |\n",
      "| ent_coef_loss           | 0.15029252 |\n",
      "| entropy                 | 2.962168   |\n",
      "| episodes                | 1980       |\n",
      "| fps                     | 157        |\n",
      "| mean 100 episode reward | 9.17e+03   |\n",
      "| n_updates               | 1978901    |\n",
      "| policy_loss             | -659.46936 |\n",
      "| qf1_loss                | 10.183796  |\n",
      "| qf2_loss                | 9.220213   |\n",
      "| time_elapsed            | 12591      |\n",
      "| total timesteps         | 1979000    |\n",
      "| value_loss              | 8.136299   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.2997128  |\n",
      "| ent_coef_loss           | -1.3853669 |\n",
      "| entropy                 | 2.7378695  |\n",
      "| episodes                | 1990       |\n",
      "| fps                     | 157        |\n",
      "| mean 100 episode reward | 9.14e+03   |\n",
      "| n_updates               | 1988901    |\n",
      "| policy_loss             | -648.27    |\n",
      "| qf1_loss                | 6.983547   |\n",
      "| qf2_loss                | 5.419393   |\n",
      "| time_elapsed            | 12637      |\n",
      "| total timesteps         | 1989000    |\n",
      "| value_loss              | 5.2426243  |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| current_lr              | 0.0003       |\n",
      "| ent_coef                | 0.3030828    |\n",
      "| ent_coef_loss           | -0.015578508 |\n",
      "| entropy                 | 3.0699353    |\n",
      "| episodes                | 2000         |\n",
      "| fps                     | 157          |\n",
      "| mean 100 episode reward | 9.15e+03     |\n",
      "| n_updates               | 1998901      |\n",
      "| policy_loss             | -658.75104   |\n",
      "| qf1_loss                | 13.456894    |\n",
      "| qf2_loss                | 13.221835    |\n",
      "| time_elapsed            | 12683        |\n",
      "| total timesteps         | 1999000      |\n",
      "| value_loss              | 15.865295    |\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# TRAIN THE MODEL\n",
    "model.learn(total_timesteps=int(2e6), log_interval=10)\n",
    "model.save(\"half_cheetah_2M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gym' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ecd16610c515>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# RUN THE SAVED MODEL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'HumanoidStandup-v2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSAC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"humanoid_standup_2M\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gym' is not defined"
     ]
    }
   ],
   "source": [
    "# RUN THE SAVED MODEL\n",
    "env = gym.make('HumanoidStandup-v2')\n",
    "model = SAC.load(\"humanoid_standup_2M\")\n",
    "\n",
    "for _ in range(10):\n",
    "    obs = env.reset()\n",
    "    for _ in range(1000):\n",
    "        action, _states = model.predict(obs)\n",
    "        obs, rewards, dones, info = env.step(action)\n",
    "        env.render()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800\"\n",
       "            src=\"http://localhost:6009\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f83b606c290>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# DISPLAY THE RESULTS\n",
    "%tensorboard --logdir sac_half_cheetah_tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task: Teach an 'ant-like' quadruped a gait to move forward "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f83cca6b350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f83cca6b350>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f83cca6b350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f83cca6b350>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83acb706d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83acb706d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83acb706d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83acb706d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83cca6b310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83cca6b310>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83cca6b310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83cca6b310>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83c5e50ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83c5e50ad0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83c5e50ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83c5e50ad0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83c5e50ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83c5e50ad0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83c5e50ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83c5e50ad0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f83ac1ed350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f83ac1ed350>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f83ac1ed350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f83ac1ed350>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83ac1cb790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83ac1cb790>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83ac1cb790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83ac1cb790>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83ac199f90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83ac199f90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83ac199f90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83ac199f90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83ac201250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83ac201250>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83ac201250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83ac201250>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83ac189510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83ac189510>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83ac189510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83ac189510>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83ac189510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83ac189510>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83ac189510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83ac189510>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83ac21a6d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83ac21a6d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83ac21a6d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83ac21a6d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83c4192e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83c4192e90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83c4192e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83c4192e90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83ac227950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83ac227950>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83ac227950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83ac227950>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83ac199910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83ac199910>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83ac199910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83ac199910>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f83ac1cb510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f83ac1cb510>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f83ac1cb510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f83ac1cb510>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83ac168d50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83ac168d50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83ac168d50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83ac168d50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83c4192e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83c4192e90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83c4192e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83c4192e90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83ac201050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83ac201050>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83ac201050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83ac201050>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83ac1e4ed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83ac1e4ed0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83ac1e4ed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83ac1e4ed0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83ac1e4ed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83ac1e4ed0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83ac1e4ed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83ac1e4ed0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83ac189510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83ac189510>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83ac189510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83ac189510>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f83ac21a6d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f83ac21a6d0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f83ac21a6d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f83ac21a6d0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83ac227850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83ac227850>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83ac227850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83ac227850>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83ac227850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83ac227850>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83ac227850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83ac227850>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83ac03fad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83ac03fad0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83ac03fad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f83ac03fad0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    }
   ],
   "source": [
    "# DEFINE THE ENVIRONMENT/MODEL WITH TUNED PARAMETERS\n",
    "env = gym.make('Ant-v2')\n",
    "policy_kwargs = dict(layers=[256, 256])\n",
    "model = SAC(MlpPolicy, env, verbose=1, tensorboard_log=\"./sac_ant_tensorboard/\", \n",
    "            policy_kwargs=policy_kwargs, buffer_size=1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.8762652  |\n",
      "| ent_coef_loss           | -1.7449486 |\n",
      "| entropy                 | 10.457512  |\n",
      "| episodes                | 10         |\n",
      "| fps                     | 173        |\n",
      "| mean 100 episode reward | -31.7      |\n",
      "| n_updates               | 434        |\n",
      "| policy_loss             | -11.647961 |\n",
      "| qf1_loss                | 0.68411374 |\n",
      "| qf2_loss                | 0.6303036  |\n",
      "| time_elapsed            | 3          |\n",
      "| total timesteps         | 533        |\n",
      "| value_loss              | 0.62523365 |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ent_coef                | 0.5049892 |\n",
      "| ent_coef_loss           | -8.557511 |\n",
      "| entropy                 | 9.990568  |\n",
      "| episodes                | 20        |\n",
      "| fps                     | 173       |\n",
      "| mean 100 episode reward | -63.8     |\n",
      "| n_updates               | 2286      |\n",
      "| policy_loss             | -25.51715 |\n",
      "| qf1_loss                | 1.732612  |\n",
      "| qf2_loss                | 1.7376511 |\n",
      "| time_elapsed            | 13        |\n",
      "| total timesteps         | 2385      |\n",
      "| value_loss              | 2.1058083 |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.23871425 |\n",
      "| ent_coef_loss           | -14.865235 |\n",
      "| entropy                 | 9.208945   |\n",
      "| episodes                | 30         |\n",
      "| fps                     | 178        |\n",
      "| mean 100 episode reward | -88.8      |\n",
      "| n_updates               | 4897       |\n",
      "| policy_loss             | -31.183266 |\n",
      "| qf1_loss                | 2.0354762  |\n",
      "| qf2_loss                | 2.4516916  |\n",
      "| time_elapsed            | 28         |\n",
      "| total timesteps         | 4996       |\n",
      "| value_loss              | 2.1367354  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.10991176 |\n",
      "| ent_coef_loss           | -20.02817  |\n",
      "| entropy                 | 7.5829916  |\n",
      "| episodes                | 40         |\n",
      "| fps                     | 177        |\n",
      "| mean 100 episode reward | -101       |\n",
      "| n_updates               | 7649       |\n",
      "| policy_loss             | -22.478119 |\n",
      "| qf1_loss                | 1.3583798  |\n",
      "| qf2_loss                | 1.2246356  |\n",
      "| time_elapsed            | 43         |\n",
      "| total timesteps         | 7748       |\n",
      "| value_loss              | 1.0815293  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.013933086 |\n",
      "| ent_coef_loss           | -3.6115158  |\n",
      "| entropy                 | -4.6261168  |\n",
      "| episodes                | 50          |\n",
      "| fps                     | 178         |\n",
      "| mean 100 episode reward | -67.1       |\n",
      "| n_updates               | 16154       |\n",
      "| policy_loss             | -5.0903244  |\n",
      "| qf1_loss                | 0.8528155   |\n",
      "| qf2_loss                | 0.745692    |\n",
      "| time_elapsed            | 91          |\n",
      "| total timesteps         | 16253       |\n",
      "| value_loss              | 0.25189304  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.016280582 |\n",
      "| ent_coef_loss           | -1.9001789  |\n",
      "| entropy                 | -5.560029   |\n",
      "| episodes                | 60          |\n",
      "| fps                     | 178         |\n",
      "| mean 100 episode reward | 38.8        |\n",
      "| n_updates               | 25254       |\n",
      "| policy_loss             | -17.985956  |\n",
      "| qf1_loss                | 0.28295195  |\n",
      "| qf2_loss                | 0.44508833  |\n",
      "| time_elapsed            | 141         |\n",
      "| total timesteps         | 25353       |\n",
      "| value_loss              | 0.31909484  |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02345984 |\n",
      "| ent_coef_loss           | 0.49849868 |\n",
      "| entropy                 | -5.2601204 |\n",
      "| episodes                | 70         |\n",
      "| fps                     | 178        |\n",
      "| mean 100 episode reward | 145        |\n",
      "| n_updates               | 35254      |\n",
      "| policy_loss             | -26.830198 |\n",
      "| qf1_loss                | 0.4180339  |\n",
      "| qf2_loss                | 0.59588265 |\n",
      "| time_elapsed            | 197        |\n",
      "| total timesteps         | 35353      |\n",
      "| value_loss              | 0.26696047 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02517023 |\n",
      "| ent_coef_loss           | 0.9368582  |\n",
      "| entropy                 | -5.7872934 |\n",
      "| episodes                | 80         |\n",
      "| fps                     | 178        |\n",
      "| mean 100 episode reward | 229        |\n",
      "| n_updates               | 45254      |\n",
      "| policy_loss             | -36.77546  |\n",
      "| qf1_loss                | 0.20708762 |\n",
      "| qf2_loss                | 0.29097316 |\n",
      "| time_elapsed            | 254        |\n",
      "| total timesteps         | 45353      |\n",
      "| value_loss              | 0.29894045 |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028456053 |\n",
      "| ent_coef_loss           | 2.6408887   |\n",
      "| entropy                 | -5.992591   |\n",
      "| episodes                | 90          |\n",
      "| fps                     | 178         |\n",
      "| mean 100 episode reward | 285         |\n",
      "| n_updates               | 54264       |\n",
      "| policy_loss             | -40.86168   |\n",
      "| qf1_loss                | 0.20502079  |\n",
      "| qf2_loss                | 0.21998797  |\n",
      "| time_elapsed            | 304         |\n",
      "| total timesteps         | 54363       |\n",
      "| value_loss              | 0.2640136   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028687121 |\n",
      "| ent_coef_loss           | 0.42725718  |\n",
      "| entropy                 | -5.895428   |\n",
      "| episodes                | 100         |\n",
      "| fps                     | 178         |\n",
      "| mean 100 episode reward | 331         |\n",
      "| n_updates               | 63298       |\n",
      "| policy_loss             | -44.29381   |\n",
      "| qf1_loss                | 0.23081999  |\n",
      "| qf2_loss                | 0.2584656   |\n",
      "| time_elapsed            | 354         |\n",
      "| total timesteps         | 63397       |\n",
      "| value_loss              | 0.21019217  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028801454 |\n",
      "| ent_coef_loss           | -1.2594972  |\n",
      "| entropy                 | -5.7091417  |\n",
      "| episodes                | 110         |\n",
      "| fps                     | 178         |\n",
      "| mean 100 episode reward | 412         |\n",
      "| n_updates               | 73298       |\n",
      "| policy_loss             | -47.344814  |\n",
      "| qf1_loss                | 0.22117668  |\n",
      "| qf2_loss                | 0.2719455   |\n",
      "| time_elapsed            | 411         |\n",
      "| total timesteps         | 73397       |\n",
      "| value_loss              | 0.10903709  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.027172456 |\n",
      "| ent_coef_loss           | -2.9020271  |\n",
      "| entropy                 | -5.3401175  |\n",
      "| episodes                | 120         |\n",
      "| fps                     | 178         |\n",
      "| mean 100 episode reward | 505         |\n",
      "| n_updates               | 83298       |\n",
      "| policy_loss             | -50.327633  |\n",
      "| qf1_loss                | 0.48838034  |\n",
      "| qf2_loss                | 0.48478723  |\n",
      "| time_elapsed            | 467         |\n",
      "| total timesteps         | 83397       |\n",
      "| value_loss              | 1.5551369   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03138068 |\n",
      "| ent_coef_loss           | 0.9564403  |\n",
      "| entropy                 | -6.6929245 |\n",
      "| episodes                | 130        |\n",
      "| fps                     | 175        |\n",
      "| mean 100 episode reward | 588        |\n",
      "| n_updates               | 93298      |\n",
      "| policy_loss             | -50.25231  |\n",
      "| qf1_loss                | 0.16315952 |\n",
      "| qf2_loss                | 0.13621141 |\n",
      "| time_elapsed            | 531        |\n",
      "| total timesteps         | 93397      |\n",
      "| value_loss              | 0.64218277 |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02634931 |\n",
      "| ent_coef_loss           | 2.0376205  |\n",
      "| entropy                 | -7.1995163 |\n",
      "| episodes                | 140        |\n",
      "| fps                     | 175        |\n",
      "| mean 100 episode reward | 682        |\n",
      "| n_updates               | 103298     |\n",
      "| policy_loss             | -51.559914 |\n",
      "| qf1_loss                | 0.14398588 |\n",
      "| qf2_loss                | 0.24547134 |\n",
      "| time_elapsed            | 589        |\n",
      "| total timesteps         | 103397     |\n",
      "| value_loss              | 0.4554339  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.024466086 |\n",
      "| ent_coef_loss           | 0.16651306  |\n",
      "| entropy                 | -7.0487623  |\n",
      "| episodes                | 150         |\n",
      "| fps                     | 175         |\n",
      "| mean 100 episode reward | 758         |\n",
      "| n_updates               | 113298      |\n",
      "| policy_loss             | -52.218685  |\n",
      "| qf1_loss                | 0.26647377  |\n",
      "| qf2_loss                | 0.15930264  |\n",
      "| time_elapsed            | 646         |\n",
      "| total timesteps         | 113397      |\n",
      "| value_loss              | 0.32056817  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.024243155 |\n",
      "| ent_coef_loss           | -0.83210695 |\n",
      "| entropy                 | -7.1223993  |\n",
      "| episodes                | 160         |\n",
      "| fps                     | 175         |\n",
      "| mean 100 episode reward | 785         |\n",
      "| n_updates               | 123298      |\n",
      "| policy_loss             | -55.530838  |\n",
      "| qf1_loss                | 0.08817291  |\n",
      "| qf2_loss                | 0.1076099   |\n",
      "| time_elapsed            | 704         |\n",
      "| total timesteps         | 123397      |\n",
      "| value_loss              | 0.13082093  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.022751689 |\n",
      "| ent_coef_loss           | 0.11441834  |\n",
      "| entropy                 | -6.958832   |\n",
      "| episodes                | 170         |\n",
      "| fps                     | 175         |\n",
      "| mean 100 episode reward | 790         |\n",
      "| n_updates               | 133298      |\n",
      "| policy_loss             | -54.811367  |\n",
      "| qf1_loss                | 26.291683   |\n",
      "| qf2_loss                | 26.603703   |\n",
      "| time_elapsed            | 760         |\n",
      "| total timesteps         | 133397      |\n",
      "| value_loss              | 0.3383686   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.021320991 |\n",
      "| ent_coef_loss           | -1.143746   |\n",
      "| entropy                 | -6.423214   |\n",
      "| episodes                | 180         |\n",
      "| fps                     | 175         |\n",
      "| mean 100 episode reward | 784         |\n",
      "| n_updates               | 143298      |\n",
      "| policy_loss             | -56.62624   |\n",
      "| qf1_loss                | 0.2724266   |\n",
      "| qf2_loss                | 0.20337453  |\n",
      "| time_elapsed            | 816         |\n",
      "| total timesteps         | 143397      |\n",
      "| value_loss              | 0.4500185   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.022216234 |\n",
      "| ent_coef_loss           | 1.4068013   |\n",
      "| entropy                 | -7.5008426  |\n",
      "| episodes                | 190         |\n",
      "| fps                     | 175         |\n",
      "| mean 100 episode reward | 794         |\n",
      "| n_updates               | 153298      |\n",
      "| policy_loss             | -58.194214  |\n",
      "| qf1_loss                | 0.17759803  |\n",
      "| qf2_loss                | 0.27258533  |\n",
      "| time_elapsed            | 871         |\n",
      "| total timesteps         | 153397      |\n",
      "| value_loss              | 0.15348503  |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02270695 |\n",
      "| ent_coef_loss           | -1.9285893 |\n",
      "| entropy                 | -6.450054  |\n",
      "| episodes                | 200        |\n",
      "| fps                     | 176        |\n",
      "| mean 100 episode reward | 802        |\n",
      "| n_updates               | 163298     |\n",
      "| policy_loss             | -57.459293 |\n",
      "| qf1_loss                | 0.3403867  |\n",
      "| qf2_loss                | 0.12248806 |\n",
      "| time_elapsed            | 928        |\n",
      "| total timesteps         | 163397     |\n",
      "| value_loss              | 0.21233128 |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.021627821 |\n",
      "| ent_coef_loss           | 0.924968    |\n",
      "| entropy                 | -6.9333735  |\n",
      "| episodes                | 210         |\n",
      "| fps                     | 176         |\n",
      "| mean 100 episode reward | 804         |\n",
      "| n_updates               | 173298      |\n",
      "| policy_loss             | -56.13018   |\n",
      "| qf1_loss                | 0.24878412  |\n",
      "| qf2_loss                | 0.24949522  |\n",
      "| time_elapsed            | 984         |\n",
      "| total timesteps         | 173397      |\n",
      "| value_loss              | 0.3769607   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.02263805  |\n",
      "| ent_coef_loss           | 0.48182464  |\n",
      "| entropy                 | -7.254526   |\n",
      "| episodes                | 220         |\n",
      "| fps                     | 176         |\n",
      "| mean 100 episode reward | 804         |\n",
      "| n_updates               | 183298      |\n",
      "| policy_loss             | -59.458435  |\n",
      "| qf1_loss                | 0.10091002  |\n",
      "| qf2_loss                | 0.081955545 |\n",
      "| time_elapsed            | 1039        |\n",
      "| total timesteps         | 183397      |\n",
      "| value_loss              | 0.070140496 |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.02010429  |\n",
      "| ent_coef_loss           | -0.38100123 |\n",
      "| entropy                 | -7.1429863  |\n",
      "| episodes                | 230         |\n",
      "| fps                     | 173         |\n",
      "| mean 100 episode reward | 818         |\n",
      "| n_updates               | 193298      |\n",
      "| policy_loss             | -59.448826  |\n",
      "| qf1_loss                | 30.287994   |\n",
      "| qf2_loss                | 30.469131   |\n",
      "| time_elapsed            | 1115        |\n",
      "| total timesteps         | 193397      |\n",
      "| value_loss              | 0.16231403  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.023035971 |\n",
      "| ent_coef_loss           | 0.50678486  |\n",
      "| entropy                 | -7.3988314  |\n",
      "| episodes                | 240         |\n",
      "| fps                     | 167         |\n",
      "| mean 100 episode reward | 820         |\n",
      "| n_updates               | 203298      |\n",
      "| policy_loss             | -57.41946   |\n",
      "| qf1_loss                | 0.18388015  |\n",
      "| qf2_loss                | 0.24769348  |\n",
      "| time_elapsed            | 1217        |\n",
      "| total timesteps         | 203397      |\n",
      "| value_loss              | 0.2473733   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.021155018 |\n",
      "| ent_coef_loss           | 2.0051508   |\n",
      "| entropy                 | -7.34321    |\n",
      "| episodes                | 250         |\n",
      "| fps                     | 164         |\n",
      "| mean 100 episode reward | 820         |\n",
      "| n_updates               | 213298      |\n",
      "| policy_loss             | -58.41212   |\n",
      "| qf1_loss                | 0.22065547  |\n",
      "| qf2_loss                | 0.20433041  |\n",
      "| time_elapsed            | 1299        |\n",
      "| total timesteps         | 213397      |\n",
      "| value_loss              | 1.0789438   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.020408541 |\n",
      "| ent_coef_loss           | 1.1170628   |\n",
      "| entropy                 | -7.154443   |\n",
      "| episodes                | 260         |\n",
      "| fps                     | 162         |\n",
      "| mean 100 episode reward | 812         |\n",
      "| n_updates               | 222309      |\n",
      "| policy_loss             | -59.922333  |\n",
      "| qf1_loss                | 0.20159048  |\n",
      "| qf2_loss                | 0.2276838   |\n",
      "| time_elapsed            | 1367        |\n",
      "| total timesteps         | 222408      |\n",
      "| value_loss              | 0.32822752  |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.022565303 |\n",
      "| ent_coef_loss           | -0.84279364 |\n",
      "| entropy                 | -7.0611334  |\n",
      "| episodes                | 270         |\n",
      "| fps                     | 162         |\n",
      "| mean 100 episode reward | 811         |\n",
      "| n_updates               | 232309      |\n",
      "| policy_loss             | -59.33068   |\n",
      "| qf1_loss                | 0.097729    |\n",
      "| qf2_loss                | 0.1413833   |\n",
      "| time_elapsed            | 1433        |\n",
      "| total timesteps         | 232408      |\n",
      "| value_loss              | 0.07457222  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.021144958 |\n",
      "| ent_coef_loss           | -0.0998075  |\n",
      "| entropy                 | -7.449244   |\n",
      "| episodes                | 280         |\n",
      "| fps                     | 160         |\n",
      "| mean 100 episode reward | 821         |\n",
      "| n_updates               | 242309      |\n",
      "| policy_loss             | -62.201     |\n",
      "| qf1_loss                | 0.09630823  |\n",
      "| qf2_loss                | 0.05210513  |\n",
      "| time_elapsed            | 1509        |\n",
      "| total timesteps         | 242408      |\n",
      "| value_loss              | 0.042445377 |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.018755892 |\n",
      "| ent_coef_loss           | 1.41397     |\n",
      "| entropy                 | -7.4792457  |\n",
      "| episodes                | 290         |\n",
      "| fps                     | 156         |\n",
      "| mean 100 episode reward | 822         |\n",
      "| n_updates               | 252309      |\n",
      "| policy_loss             | -61.08422   |\n",
      "| qf1_loss                | 0.04631305  |\n",
      "| qf2_loss                | 0.06465125  |\n",
      "| time_elapsed            | 1610        |\n",
      "| total timesteps         | 252408      |\n",
      "| value_loss              | 0.2039402   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.020811172 |\n",
      "| ent_coef_loss           | 1.0667683   |\n",
      "| entropy                 | -6.916648   |\n",
      "| episodes                | 300         |\n",
      "| fps                     | 155         |\n",
      "| mean 100 episode reward | 825         |\n",
      "| n_updates               | 262309      |\n",
      "| policy_loss             | -61.771446  |\n",
      "| qf1_loss                | 0.09553109  |\n",
      "| qf2_loss                | 0.10708694  |\n",
      "| time_elapsed            | 1688        |\n",
      "| total timesteps         | 262408      |\n",
      "| value_loss              | 0.16609624  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.019412579 |\n",
      "| ent_coef_loss           | -0.18829854 |\n",
      "| entropy                 | -7.3753033  |\n",
      "| episodes                | 310         |\n",
      "| fps                     | 151         |\n",
      "| mean 100 episode reward | 823         |\n",
      "| n_updates               | 272309      |\n",
      "| policy_loss             | -62.502243  |\n",
      "| qf1_loss                | 0.06386177  |\n",
      "| qf2_loss                | 0.1114389   |\n",
      "| time_elapsed            | 1796        |\n",
      "| total timesteps         | 272408      |\n",
      "| value_loss              | 0.07383185  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.019008815 |\n",
      "| ent_coef_loss           | -4.346862   |\n",
      "| entropy                 | -6.9049854  |\n",
      "| episodes                | 320         |\n",
      "| fps                     | 150         |\n",
      "| mean 100 episode reward | 810         |\n",
      "| n_updates               | 282309      |\n",
      "| policy_loss             | -62.663788  |\n",
      "| qf1_loss                | 0.10429671  |\n",
      "| qf2_loss                | 0.057646    |\n",
      "| time_elapsed            | 1873        |\n",
      "| total timesteps         | 282408      |\n",
      "| value_loss              | 0.043919913 |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.019628325 |\n",
      "| ent_coef_loss           | 0.28527826  |\n",
      "| entropy                 | -6.912508   |\n",
      "| episodes                | 330         |\n",
      "| fps                     | 149         |\n",
      "| mean 100 episode reward | 809         |\n",
      "| n_updates               | 292309      |\n",
      "| policy_loss             | -60.55362   |\n",
      "| qf1_loss                | 0.23699939  |\n",
      "| qf2_loss                | 0.111742646 |\n",
      "| time_elapsed            | 1957        |\n",
      "| total timesteps         | 292408      |\n",
      "| value_loss              | 0.18530844  |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| current_lr              | 0.0003       |\n",
      "| ent_coef                | 0.020438822  |\n",
      "| ent_coef_loss           | -0.013821781 |\n",
      "| entropy                 | -6.9036174   |\n",
      "| episodes                | 340          |\n",
      "| fps                     | 147          |\n",
      "| mean 100 episode reward | 811          |\n",
      "| n_updates               | 302309       |\n",
      "| policy_loss             | -61.9858     |\n",
      "| qf1_loss                | 0.2390621    |\n",
      "| qf2_loss                | 0.2779724    |\n",
      "| time_elapsed            | 2046         |\n",
      "| total timesteps         | 302408       |\n",
      "| value_loss              | 0.16278422   |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.017026331 |\n",
      "| ent_coef_loss           | -0.7796536  |\n",
      "| entropy                 | -7.0458155  |\n",
      "| episodes                | 350         |\n",
      "| fps                     | 147         |\n",
      "| mean 100 episode reward | 810         |\n",
      "| n_updates               | 312309      |\n",
      "| policy_loss             | -64.64967   |\n",
      "| qf1_loss                | 0.09575281  |\n",
      "| qf2_loss                | 0.13316369  |\n",
      "| time_elapsed            | 2123        |\n",
      "| total timesteps         | 312408      |\n",
      "| value_loss              | 0.1757834   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.020723445 |\n",
      "| ent_coef_loss           | -0.7664398  |\n",
      "| entropy                 | -7.128685   |\n",
      "| episodes                | 360         |\n",
      "| fps                     | 146         |\n",
      "| mean 100 episode reward | 815         |\n",
      "| n_updates               | 322309      |\n",
      "| policy_loss             | -64.714066  |\n",
      "| qf1_loss                | 0.071630836 |\n",
      "| qf2_loss                | 0.13981089  |\n",
      "| time_elapsed            | 2199        |\n",
      "| total timesteps         | 322408      |\n",
      "| value_loss              | 0.1887409   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.018003287 |\n",
      "| ent_coef_loss           | 1.2741524   |\n",
      "| entropy                 | -7.4232206  |\n",
      "| episodes                | 370         |\n",
      "| fps                     | 145         |\n",
      "| mean 100 episode reward | 805         |\n",
      "| n_updates               | 331425      |\n",
      "| policy_loss             | -63.354355  |\n",
      "| qf1_loss                | 0.059453182 |\n",
      "| qf2_loss                | 0.119810656 |\n",
      "| time_elapsed            | 2274        |\n",
      "| total timesteps         | 331524      |\n",
      "| value_loss              | 0.11144718  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.018632136 |\n",
      "| ent_coef_loss           | 0.4136889   |\n",
      "| entropy                 | -7.4815397  |\n",
      "| episodes                | 380         |\n",
      "| fps                     | 143         |\n",
      "| mean 100 episode reward | 777         |\n",
      "| n_updates               | 340447      |\n",
      "| policy_loss             | -63.57468   |\n",
      "| qf1_loss                | 0.19992244  |\n",
      "| qf2_loss                | 0.3194517   |\n",
      "| time_elapsed            | 2372        |\n",
      "| total timesteps         | 340546      |\n",
      "| value_loss              | 0.33472866  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.021280484 |\n",
      "| ent_coef_loss           | 0.090426326 |\n",
      "| entropy                 | -5.8488955  |\n",
      "| episodes                | 390         |\n",
      "| fps                     | 142         |\n",
      "| mean 100 episode reward | 771         |\n",
      "| n_updates               | 350083      |\n",
      "| policy_loss             | -60.04229   |\n",
      "| qf1_loss                | 0.1895269   |\n",
      "| qf2_loss                | 0.19832516  |\n",
      "| time_elapsed            | 2461        |\n",
      "| total timesteps         | 350182      |\n",
      "| value_loss              | 0.1875345   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.01909487 |\n",
      "| ent_coef_loss           | -1.9280887 |\n",
      "| entropy                 | -6.142432  |\n",
      "| episodes                | 400        |\n",
      "| fps                     | 141        |\n",
      "| mean 100 episode reward | 746        |\n",
      "| n_updates               | 359123     |\n",
      "| policy_loss             | -58.48872  |\n",
      "| qf1_loss                | 0.43674144 |\n",
      "| qf2_loss                | 0.7115279  |\n",
      "| time_elapsed            | 2530       |\n",
      "| total timesteps         | 359222     |\n",
      "| value_loss              | 1.074904   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.019410137 |\n",
      "| ent_coef_loss           | -0.39564288 |\n",
      "| entropy                 | -6.2117147  |\n",
      "| episodes                | 410         |\n",
      "| fps                     | 141         |\n",
      "| mean 100 episode reward | 733         |\n",
      "| n_updates               | 369123      |\n",
      "| policy_loss             | -59.076622  |\n",
      "| qf1_loss                | 0.13562667  |\n",
      "| qf2_loss                | 0.22206202  |\n",
      "| time_elapsed            | 2617        |\n",
      "| total timesteps         | 369222      |\n",
      "| value_loss              | 0.31054306  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.022762481 |\n",
      "| ent_coef_loss           | 6.9664598   |\n",
      "| entropy                 | -5.358307   |\n",
      "| episodes                | 420         |\n",
      "| fps                     | 139         |\n",
      "| mean 100 episode reward | 749         |\n",
      "| n_updates               | 378378      |\n",
      "| policy_loss             | -59.43238   |\n",
      "| qf1_loss                | 0.14240432  |\n",
      "| qf2_loss                | 0.21538256  |\n",
      "| time_elapsed            | 2716        |\n",
      "| total timesteps         | 378477      |\n",
      "| value_loss              | 0.3175642   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030878512 |\n",
      "| ent_coef_loss           | 1.539248    |\n",
      "| entropy                 | -4.7801747  |\n",
      "| episodes                | 430         |\n",
      "| fps                     | 138         |\n",
      "| mean 100 episode reward | 764         |\n",
      "| n_updates               | 388378      |\n",
      "| policy_loss             | -64.79367   |\n",
      "| qf1_loss                | 0.40071267  |\n",
      "| qf2_loss                | 0.2282697   |\n",
      "| time_elapsed            | 2804        |\n",
      "| total timesteps         | 388477      |\n",
      "| value_loss              | 0.09453677  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.025952097 |\n",
      "| ent_coef_loss           | 1.7533242   |\n",
      "| entropy                 | -5.163407   |\n",
      "| episodes                | 440         |\n",
      "| fps                     | 137         |\n",
      "| mean 100 episode reward | 762         |\n",
      "| n_updates               | 395838      |\n",
      "| policy_loss             | -70.19449   |\n",
      "| qf1_loss                | 0.73405945  |\n",
      "| qf2_loss                | 0.6273001   |\n",
      "| time_elapsed            | 2883        |\n",
      "| total timesteps         | 395937      |\n",
      "| value_loss              | 0.1747631   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031392816 |\n",
      "| ent_coef_loss           | 0.775282    |\n",
      "| entropy                 | -4.5457597  |\n",
      "| episodes                | 450         |\n",
      "| fps                     | 136         |\n",
      "| mean 100 episode reward | 776         |\n",
      "| n_updates               | 404514      |\n",
      "| policy_loss             | -68.44522   |\n",
      "| qf1_loss                | 0.17057079  |\n",
      "| qf2_loss                | 0.19806904  |\n",
      "| time_elapsed            | 2959        |\n",
      "| total timesteps         | 404613      |\n",
      "| value_loss              | 0.20361266  |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03392132 |\n",
      "| ent_coef_loss           | 1.4708143  |\n",
      "| entropy                 | -4.600854  |\n",
      "| episodes                | 460        |\n",
      "| fps                     | 136        |\n",
      "| mean 100 episode reward | 791        |\n",
      "| n_updates               | 414514     |\n",
      "| policy_loss             | -73.88336  |\n",
      "| qf1_loss                | 0.3473791  |\n",
      "| qf2_loss                | 0.4555592  |\n",
      "| time_elapsed            | 3035       |\n",
      "| total timesteps         | 414613     |\n",
      "| value_loss              | 0.79519373 |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031548735 |\n",
      "| ent_coef_loss           | 0.259171    |\n",
      "| entropy                 | -4.6268606  |\n",
      "| episodes                | 470         |\n",
      "| fps                     | 135         |\n",
      "| mean 100 episode reward | 846         |\n",
      "| n_updates               | 424514      |\n",
      "| policy_loss             | -76.2718    |\n",
      "| qf1_loss                | 0.40065938  |\n",
      "| qf2_loss                | 0.7115567   |\n",
      "| time_elapsed            | 3140        |\n",
      "| total timesteps         | 424613      |\n",
      "| value_loss              | 0.19064504  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030318413 |\n",
      "| ent_coef_loss           | 2.1099827   |\n",
      "| entropy                 | -5.1551123  |\n",
      "| episodes                | 480         |\n",
      "| fps                     | 134         |\n",
      "| mean 100 episode reward | 910         |\n",
      "| n_updates               | 433658      |\n",
      "| policy_loss             | -81.32152   |\n",
      "| qf1_loss                | 0.25826102  |\n",
      "| qf2_loss                | 0.27095076  |\n",
      "| time_elapsed            | 3215        |\n",
      "| total timesteps         | 433757      |\n",
      "| value_loss              | 0.13897988  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030304134 |\n",
      "| ent_coef_loss           | -2.2188659  |\n",
      "| entropy                 | -4.759556   |\n",
      "| episodes                | 490         |\n",
      "| fps                     | 134         |\n",
      "| mean 100 episode reward | 930         |\n",
      "| n_updates               | 442687      |\n",
      "| policy_loss             | -84.86357   |\n",
      "| qf1_loss                | 0.24012533  |\n",
      "| qf2_loss                | 0.1433438   |\n",
      "| time_elapsed            | 3291        |\n",
      "| total timesteps         | 442786      |\n",
      "| value_loss              | 0.3886211   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.037972398 |\n",
      "| ent_coef_loss           | 1.3521898   |\n",
      "| entropy                 | -4.6671686  |\n",
      "| episodes                | 500         |\n",
      "| fps                     | 134         |\n",
      "| mean 100 episode reward | 970         |\n",
      "| n_updates               | 451536      |\n",
      "| policy_loss             | -87.185165  |\n",
      "| qf1_loss                | 0.33652204  |\n",
      "| qf2_loss                | 0.33286828  |\n",
      "| time_elapsed            | 3356        |\n",
      "| total timesteps         | 451635      |\n",
      "| value_loss              | 0.2420104   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03254733 |\n",
      "| ent_coef_loss           | -1.9275746 |\n",
      "| entropy                 | -4.088972  |\n",
      "| episodes                | 510        |\n",
      "| fps                     | 134        |\n",
      "| mean 100 episode reward | 990        |\n",
      "| n_updates               | 458016     |\n",
      "| policy_loss             | -86.85097  |\n",
      "| qf1_loss                | 0.80545706 |\n",
      "| qf2_loss                | 1.797906   |\n",
      "| time_elapsed            | 3410       |\n",
      "| total timesteps         | 458115     |\n",
      "| value_loss              | 0.36290246 |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035343565 |\n",
      "| ent_coef_loss           | -1.2075051  |\n",
      "| entropy                 | -4.1569633  |\n",
      "| episodes                | 520         |\n",
      "| fps                     | 134         |\n",
      "| mean 100 episode reward | 1e+03       |\n",
      "| n_updates               | 465386      |\n",
      "| policy_loss             | -91.75066   |\n",
      "| qf1_loss                | 0.50648665  |\n",
      "| qf2_loss                | 0.32395032  |\n",
      "| time_elapsed            | 3457        |\n",
      "| total timesteps         | 465485      |\n",
      "| value_loss              | 0.49903265  |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02978763 |\n",
      "| ent_coef_loss           | 2.5704236  |\n",
      "| entropy                 | -5.3670225 |\n",
      "| episodes                | 530        |\n",
      "| fps                     | 133        |\n",
      "| mean 100 episode reward | 994        |\n",
      "| n_updates               | 472641     |\n",
      "| policy_loss             | -94.46759  |\n",
      "| qf1_loss                | 0.45229393 |\n",
      "| qf2_loss                | 0.3883754  |\n",
      "| time_elapsed            | 3534       |\n",
      "| total timesteps         | 472740     |\n",
      "| value_loss              | 0.45563853 |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.033340923 |\n",
      "| ent_coef_loss           | 0.4542747   |\n",
      "| entropy                 | -4.48419    |\n",
      "| episodes                | 540         |\n",
      "| fps                     | 133         |\n",
      "| mean 100 episode reward | 1.04e+03    |\n",
      "| n_updates               | 482641      |\n",
      "| policy_loss             | -91.71767   |\n",
      "| qf1_loss                | 0.5114111   |\n",
      "| qf2_loss                | 0.6372951   |\n",
      "| time_elapsed            | 3614        |\n",
      "| total timesteps         | 482740      |\n",
      "| value_loss              | 0.29064572  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.033698726 |\n",
      "| ent_coef_loss           | -1.838021   |\n",
      "| entropy                 | -5.2142296  |\n",
      "| episodes                | 550         |\n",
      "| fps                     | 133         |\n",
      "| mean 100 episode reward | 1.06e+03    |\n",
      "| n_updates               | 490961      |\n",
      "| policy_loss             | -101.653915 |\n",
      "| qf1_loss                | 0.64861965  |\n",
      "| qf2_loss                | 0.353535    |\n",
      "| time_elapsed            | 3673        |\n",
      "| total timesteps         | 491060      |\n",
      "| value_loss              | 0.8663571   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031007987 |\n",
      "| ent_coef_loss           | -2.1844032  |\n",
      "| entropy                 | -4.9376593  |\n",
      "| episodes                | 560         |\n",
      "| fps                     | 133         |\n",
      "| mean 100 episode reward | 1.1e+03     |\n",
      "| n_updates               | 500961      |\n",
      "| policy_loss             | -91.923676  |\n",
      "| qf1_loss                | 0.42342407  |\n",
      "| qf2_loss                | 0.54786795  |\n",
      "| time_elapsed            | 3764        |\n",
      "| total timesteps         | 501060      |\n",
      "| value_loss              | 0.67714363  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.032721777 |\n",
      "| ent_coef_loss           | 0.006909415 |\n",
      "| entropy                 | -5.3575993  |\n",
      "| episodes                | 570         |\n",
      "| fps                     | 132         |\n",
      "| mean 100 episode reward | 1.1e+03     |\n",
      "| n_updates               | 510961      |\n",
      "| policy_loss             | -96.1138    |\n",
      "| qf1_loss                | 0.42429692  |\n",
      "| qf2_loss                | 0.368464    |\n",
      "| time_elapsed            | 3861        |\n",
      "| total timesteps         | 511060      |\n",
      "| value_loss              | 0.13744467  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.034512077 |\n",
      "| ent_coef_loss           | -1.52788    |\n",
      "| entropy                 | -4.55285    |\n",
      "| episodes                | 580         |\n",
      "| fps                     | 131         |\n",
      "| mean 100 episode reward | 1.13e+03    |\n",
      "| n_updates               | 520961      |\n",
      "| policy_loss             | -100.42804  |\n",
      "| qf1_loss                | 0.8525845   |\n",
      "| qf2_loss                | 0.49151596  |\n",
      "| time_elapsed            | 3957        |\n",
      "| total timesteps         | 521060      |\n",
      "| value_loss              | 0.20601809  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.0349048   |\n",
      "| ent_coef_loss           | -0.67259526 |\n",
      "| entropy                 | -4.817876   |\n",
      "| episodes                | 590         |\n",
      "| fps                     | 131         |\n",
      "| mean 100 episode reward | 1.17e+03    |\n",
      "| n_updates               | 530114      |\n",
      "| policy_loss             | -100.24518  |\n",
      "| qf1_loss                | 0.84784895  |\n",
      "| qf2_loss                | 0.79949117  |\n",
      "| time_elapsed            | 4030        |\n",
      "| total timesteps         | 530213      |\n",
      "| value_loss              | 0.5559113   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029493438 |\n",
      "| ent_coef_loss           | -0.75124466 |\n",
      "| entropy                 | -5.7900324  |\n",
      "| episodes                | 600         |\n",
      "| fps                     | 130         |\n",
      "| mean 100 episode reward | 1.22e+03    |\n",
      "| n_updates               | 539604      |\n",
      "| policy_loss             | -103.54591  |\n",
      "| qf1_loss                | 17.025925   |\n",
      "| qf2_loss                | 33.6418     |\n",
      "| time_elapsed            | 4130        |\n",
      "| total timesteps         | 539703      |\n",
      "| value_loss              | 5.291253    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.032370318 |\n",
      "| ent_coef_loss           | 0.27333197  |\n",
      "| entropy                 | -5.755995   |\n",
      "| episodes                | 610         |\n",
      "| fps                     | 130         |\n",
      "| mean 100 episode reward | 1.28e+03    |\n",
      "| n_updates               | 548625      |\n",
      "| policy_loss             | -106.12341  |\n",
      "| qf1_loss                | 0.52532923  |\n",
      "| qf2_loss                | 0.7147467   |\n",
      "| time_elapsed            | 4212        |\n",
      "| total timesteps         | 548724      |\n",
      "| value_loss              | 1.228082    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030954855 |\n",
      "| ent_coef_loss           | -1.0336093  |\n",
      "| entropy                 | -5.051714   |\n",
      "| episodes                | 620         |\n",
      "| fps                     | 129         |\n",
      "| mean 100 episode reward | 1.34e+03    |\n",
      "| n_updates               | 558625      |\n",
      "| policy_loss             | -105.57176  |\n",
      "| qf1_loss                | 1.2403616   |\n",
      "| qf2_loss                | 1.2370871   |\n",
      "| time_elapsed            | 4303        |\n",
      "| total timesteps         | 558724      |\n",
      "| value_loss              | 0.7020006   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030513534 |\n",
      "| ent_coef_loss           | -2.2309914  |\n",
      "| entropy                 | -5.769412   |\n",
      "| episodes                | 630         |\n",
      "| fps                     | 129         |\n",
      "| mean 100 episode reward | 1.41e+03    |\n",
      "| n_updates               | 568625      |\n",
      "| policy_loss             | -113.048294 |\n",
      "| qf1_loss                | 0.6932341   |\n",
      "| qf2_loss                | 0.60651815  |\n",
      "| time_elapsed            | 4391        |\n",
      "| total timesteps         | 568724      |\n",
      "| value_loss              | 0.6987779   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.03524304  |\n",
      "| ent_coef_loss           | -0.15290293 |\n",
      "| entropy                 | -5.0417166  |\n",
      "| episodes                | 640         |\n",
      "| fps                     | 129         |\n",
      "| mean 100 episode reward | 1.44e+03    |\n",
      "| n_updates               | 578625      |\n",
      "| policy_loss             | -106.93576  |\n",
      "| qf1_loss                | 9.895241    |\n",
      "| qf2_loss                | 10.435096   |\n",
      "| time_elapsed            | 4473        |\n",
      "| total timesteps         | 578724      |\n",
      "| value_loss              | 0.7212794   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03389734 |\n",
      "| ent_coef_loss           | -1.4018633 |\n",
      "| entropy                 | -5.395296  |\n",
      "| episodes                | 650        |\n",
      "| fps                     | 129        |\n",
      "| mean 100 episode reward | 1.44e+03   |\n",
      "| n_updates               | 586080     |\n",
      "| policy_loss             | -116.94435 |\n",
      "| qf1_loss                | 0.6084765  |\n",
      "| qf2_loss                | 0.32800826 |\n",
      "| time_elapsed            | 4540       |\n",
      "| total timesteps         | 586179     |\n",
      "| value_loss              | 0.19187677 |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035090324 |\n",
      "| ent_coef_loss           | -1.6326672  |\n",
      "| entropy                 | -5.436388   |\n",
      "| episodes                | 660         |\n",
      "| fps                     | 128         |\n",
      "| mean 100 episode reward | 1.5e+03     |\n",
      "| n_updates               | 596080      |\n",
      "| policy_loss             | -121.9702   |\n",
      "| qf1_loss                | 1.3518648   |\n",
      "| qf2_loss                | 1.6441159   |\n",
      "| time_elapsed            | 4634        |\n",
      "| total timesteps         | 596179      |\n",
      "| value_loss              | 0.28034714  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.033166025 |\n",
      "| ent_coef_loss           | -0.26217973 |\n",
      "| entropy                 | -5.4699287  |\n",
      "| episodes                | 670         |\n",
      "| fps                     | 128         |\n",
      "| mean 100 episode reward | 1.52e+03    |\n",
      "| n_updates               | 605134      |\n",
      "| policy_loss             | -126.30826  |\n",
      "| qf1_loss                | 0.7568743   |\n",
      "| qf2_loss                | 0.8236425   |\n",
      "| time_elapsed            | 4706        |\n",
      "| total timesteps         | 605233      |\n",
      "| value_loss              | 0.52019763  |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03747006 |\n",
      "| ent_coef_loss           | 0.97840387 |\n",
      "| entropy                 | -5.463788  |\n",
      "| episodes                | 680        |\n",
      "| fps                     | 128        |\n",
      "| mean 100 episode reward | 1.53e+03   |\n",
      "| n_updates               | 613675     |\n",
      "| policy_loss             | -120.79387 |\n",
      "| qf1_loss                | 132.08914  |\n",
      "| qf2_loss                | 132.95241  |\n",
      "| time_elapsed            | 4770       |\n",
      "| total timesteps         | 613774     |\n",
      "| value_loss              | 0.2156167  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.037545204 |\n",
      "| ent_coef_loss           | -0.40229207 |\n",
      "| entropy                 | -4.783651   |\n",
      "| episodes                | 690         |\n",
      "| fps                     | 128         |\n",
      "| mean 100 episode reward | 1.51e+03    |\n",
      "| n_updates               | 621518      |\n",
      "| policy_loss             | -112.25789  |\n",
      "| qf1_loss                | 1.073349    |\n",
      "| qf2_loss                | 1.1445502   |\n",
      "| time_elapsed            | 4845        |\n",
      "| total timesteps         | 621617      |\n",
      "| value_loss              | 0.6940016   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036832247 |\n",
      "| ent_coef_loss           | -1.774014   |\n",
      "| entropy                 | -4.6784196  |\n",
      "| episodes                | 700         |\n",
      "| fps                     | 127         |\n",
      "| mean 100 episode reward | 1.53e+03    |\n",
      "| n_updates               | 631518      |\n",
      "| policy_loss             | -114.95128  |\n",
      "| qf1_loss                | 1.4792008   |\n",
      "| qf2_loss                | 1.2746446   |\n",
      "| time_elapsed            | 4935        |\n",
      "| total timesteps         | 631617      |\n",
      "| value_loss              | 0.5053557   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.03685882  |\n",
      "| ent_coef_loss           | -0.50481224 |\n",
      "| entropy                 | -4.6797476  |\n",
      "| episodes                | 710         |\n",
      "| fps                     | 127         |\n",
      "| mean 100 episode reward | 1.56e+03    |\n",
      "| n_updates               | 641518      |\n",
      "| policy_loss             | -108.01148  |\n",
      "| qf1_loss                | 1.202736    |\n",
      "| qf2_loss                | 1.0486119   |\n",
      "| time_elapsed            | 5012        |\n",
      "| total timesteps         | 641617      |\n",
      "| value_loss              | 0.45129874  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.03602349  |\n",
      "| ent_coef_loss           | -1.1132759  |\n",
      "| entropy                 | -5.17735    |\n",
      "| episodes                | 720         |\n",
      "| fps                     | 128         |\n",
      "| mean 100 episode reward | 1.57e+03    |\n",
      "| n_updates               | 650464      |\n",
      "| policy_loss             | -118.156364 |\n",
      "| qf1_loss                | 1.24522     |\n",
      "| qf2_loss                | 0.9634957   |\n",
      "| time_elapsed            | 5078        |\n",
      "| total timesteps         | 650563      |\n",
      "| value_loss              | 0.773769    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.037082564 |\n",
      "| ent_coef_loss           | 1.2951722   |\n",
      "| entropy                 | -4.9863195  |\n",
      "| episodes                | 730         |\n",
      "| fps                     | 127         |\n",
      "| mean 100 episode reward | 1.52e+03    |\n",
      "| n_updates               | 658119      |\n",
      "| policy_loss             | -122.27878  |\n",
      "| qf1_loss                | 1.523661    |\n",
      "| qf2_loss                | 1.7822345   |\n",
      "| time_elapsed            | 5155        |\n",
      "| total timesteps         | 658218      |\n",
      "| value_loss              | 0.44692913  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.038661424 |\n",
      "| ent_coef_loss           | 0.5653589   |\n",
      "| entropy                 | -4.4329395  |\n",
      "| episodes                | 740         |\n",
      "| fps                     | 127         |\n",
      "| mean 100 episode reward | 1.53e+03    |\n",
      "| n_updates               | 667137      |\n",
      "| policy_loss             | -125.82388  |\n",
      "| qf1_loss                | 0.3947323   |\n",
      "| qf2_loss                | 0.619712    |\n",
      "| time_elapsed            | 5227        |\n",
      "| total timesteps         | 667236      |\n",
      "| value_loss              | 0.6970163   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.03930996  |\n",
      "| ent_coef_loss           | -1.8727802  |\n",
      "| entropy                 | -4.8900757  |\n",
      "| episodes                | 750         |\n",
      "| fps                     | 128         |\n",
      "| mean 100 episode reward | 1.6e+03     |\n",
      "| n_updates               | 676977      |\n",
      "| policy_loss             | -120.224915 |\n",
      "| qf1_loss                | 0.795037    |\n",
      "| qf2_loss                | 0.8638341   |\n",
      "| time_elapsed            | 5289        |\n",
      "| total timesteps         | 677076      |\n",
      "| value_loss              | 0.3349424   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03873757 |\n",
      "| ent_coef_loss           | 1.1354856  |\n",
      "| entropy                 | -4.512223  |\n",
      "| episodes                | 760        |\n",
      "| fps                     | 127        |\n",
      "| mean 100 episode reward | 1.55e+03   |\n",
      "| n_updates               | 685216     |\n",
      "| policy_loss             | -117.15893 |\n",
      "| qf1_loss                | 1.6868196  |\n",
      "| qf2_loss                | 1.7855363  |\n",
      "| time_elapsed            | 5361       |\n",
      "| total timesteps         | 685315     |\n",
      "| value_loss              | 0.556041   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036389444 |\n",
      "| ent_coef_loss           | -1.14391    |\n",
      "| entropy                 | -4.63664    |\n",
      "| episodes                | 770         |\n",
      "| fps                     | 127         |\n",
      "| mean 100 episode reward | 1.57e+03    |\n",
      "| n_updates               | 694264      |\n",
      "| policy_loss             | -124.91086  |\n",
      "| qf1_loss                | 155.0722    |\n",
      "| qf2_loss                | 156.12657   |\n",
      "| time_elapsed            | 5436        |\n",
      "| total timesteps         | 694363      |\n",
      "| value_loss              | 0.71179134  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.033716198 |\n",
      "| ent_coef_loss           | -1.7438937  |\n",
      "| entropy                 | -4.9498725  |\n",
      "| episodes                | 780         |\n",
      "| fps                     | 127         |\n",
      "| mean 100 episode reward | 1.56e+03    |\n",
      "| n_updates               | 701714      |\n",
      "| policy_loss             | -123.30526  |\n",
      "| qf1_loss                | 2.0095396   |\n",
      "| qf2_loss                | 2.0840027   |\n",
      "| time_elapsed            | 5495        |\n",
      "| total timesteps         | 701813      |\n",
      "| value_loss              | 1.1322851   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036825027 |\n",
      "| ent_coef_loss           | 0.4767027   |\n",
      "| entropy                 | -4.941188   |\n",
      "| episodes                | 790         |\n",
      "| fps                     | 127         |\n",
      "| mean 100 episode reward | 1.6e+03     |\n",
      "| n_updates               | 711652      |\n",
      "| policy_loss             | -129.84647  |\n",
      "| qf1_loss                | 1.3400095   |\n",
      "| qf2_loss                | 1.4777832   |\n",
      "| time_elapsed            | 5590        |\n",
      "| total timesteps         | 711751      |\n",
      "| value_loss              | 0.7357738   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.0401467   |\n",
      "| ent_coef_loss           | -1.0722023  |\n",
      "| entropy                 | -3.878061   |\n",
      "| episodes                | 800         |\n",
      "| fps                     | 127         |\n",
      "| mean 100 episode reward | 1.62e+03    |\n",
      "| n_updates               | 721194      |\n",
      "| policy_loss             | -112.859665 |\n",
      "| qf1_loss                | 0.9611087   |\n",
      "| qf2_loss                | 1.1379764   |\n",
      "| time_elapsed            | 5673        |\n",
      "| total timesteps         | 721293      |\n",
      "| value_loss              | 0.43918133  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.040811718 |\n",
      "| ent_coef_loss           | 1.0147309   |\n",
      "| entropy                 | -4.3168917  |\n",
      "| episodes                | 810         |\n",
      "| fps                     | 126         |\n",
      "| mean 100 episode reward | 1.57e+03    |\n",
      "| n_updates               | 730289      |\n",
      "| policy_loss             | -139.3707   |\n",
      "| qf1_loss                | 0.85266936  |\n",
      "| qf2_loss                | 1.1074351   |\n",
      "| time_elapsed            | 5785        |\n",
      "| total timesteps         | 730388      |\n",
      "| value_loss              | 1.3993655   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.039931096 |\n",
      "| ent_coef_loss           | -0.4927573  |\n",
      "| entropy                 | -4.2295017  |\n",
      "| episodes                | 820         |\n",
      "| fps                     | 125         |\n",
      "| mean 100 episode reward | 1.54e+03    |\n",
      "| n_updates               | 737423      |\n",
      "| policy_loss             | -130.92148  |\n",
      "| qf1_loss                | 1.2954443   |\n",
      "| qf2_loss                | 2.2778463   |\n",
      "| time_elapsed            | 5854        |\n",
      "| total timesteps         | 737522      |\n",
      "| value_loss              | 1.3279985   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.038607325 |\n",
      "| ent_coef_loss           | -0.5578186  |\n",
      "| entropy                 | -4.870767   |\n",
      "| episodes                | 830         |\n",
      "| fps                     | 125         |\n",
      "| mean 100 episode reward | 1.58e+03    |\n",
      "| n_updates               | 745344      |\n",
      "| policy_loss             | -114.00864  |\n",
      "| qf1_loss                | 0.491672    |\n",
      "| qf2_loss                | 0.7424538   |\n",
      "| time_elapsed            | 5930        |\n",
      "| total timesteps         | 745443      |\n",
      "| value_loss              | 0.32226896  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.041307546 |\n",
      "| ent_coef_loss           | 0.3565752   |\n",
      "| entropy                 | -4.1001883  |\n",
      "| episodes                | 840         |\n",
      "| fps                     | 125         |\n",
      "| mean 100 episode reward | 1.61e+03    |\n",
      "| n_updates               | 754522      |\n",
      "| policy_loss             | -128.94815  |\n",
      "| qf1_loss                | 1.0225961   |\n",
      "| qf2_loss                | 1.177022    |\n",
      "| time_elapsed            | 6004        |\n",
      "| total timesteps         | 754621      |\n",
      "| value_loss              | 1.2117407   |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| current_lr              | 0.0003       |\n",
      "| ent_coef                | 0.03991067   |\n",
      "| ent_coef_loss           | -0.020990193 |\n",
      "| entropy                 | -4.225007    |\n",
      "| episodes                | 850          |\n",
      "| fps                     | 125          |\n",
      "| mean 100 episode reward | 1.59e+03     |\n",
      "| n_updates               | 762845       |\n",
      "| policy_loss             | -120.21779   |\n",
      "| qf1_loss                | 2.0230463    |\n",
      "| qf2_loss                | 2.6896882    |\n",
      "| time_elapsed            | 6062         |\n",
      "| total timesteps         | 762944       |\n",
      "| value_loss              | 1.0073545    |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.04049772 |\n",
      "| ent_coef_loss           | -1.7831597 |\n",
      "| entropy                 | -4.7586575 |\n",
      "| episodes                | 860        |\n",
      "| fps                     | 125        |\n",
      "| mean 100 episode reward | 1.61e+03   |\n",
      "| n_updates               | 770878     |\n",
      "| policy_loss             | -132.35297 |\n",
      "| qf1_loss                | 1.2737432  |\n",
      "| qf2_loss                | 1.2232871  |\n",
      "| time_elapsed            | 6121       |\n",
      "| total timesteps         | 770977     |\n",
      "| value_loss              | 1.1389195  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03544084 |\n",
      "| ent_coef_loss           | 0.5270404  |\n",
      "| entropy                 | -4.1773825 |\n",
      "| episodes                | 870        |\n",
      "| fps                     | 125        |\n",
      "| mean 100 episode reward | 1.61e+03   |\n",
      "| n_updates               | 780878     |\n",
      "| policy_loss             | -138.26001 |\n",
      "| qf1_loss                | 0.86492145 |\n",
      "| qf2_loss                | 0.72623074 |\n",
      "| time_elapsed            | 6202       |\n",
      "| total timesteps         | 780977     |\n",
      "| value_loss              | 0.55126154 |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.039594978 |\n",
      "| ent_coef_loss           | 1.8667771   |\n",
      "| entropy                 | -4.3277965  |\n",
      "| episodes                | 880         |\n",
      "| fps                     | 126         |\n",
      "| mean 100 episode reward | 1.65e+03    |\n",
      "| n_updates               | 789620      |\n",
      "| policy_loss             | -128.07187  |\n",
      "| qf1_loss                | 1.6996176   |\n",
      "| qf2_loss                | 1.3748398   |\n",
      "| time_elapsed            | 6258        |\n",
      "| total timesteps         | 789719      |\n",
      "| value_loss              | 1.0740111   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03544427 |\n",
      "| ent_coef_loss           | -1.0984042 |\n",
      "| entropy                 | -4.772976  |\n",
      "| episodes                | 890        |\n",
      "| fps                     | 125        |\n",
      "| mean 100 episode reward | 1.67e+03   |\n",
      "| n_updates               | 798283     |\n",
      "| policy_loss             | -125.45038 |\n",
      "| qf1_loss                | 7.5711884  |\n",
      "| qf2_loss                | 4.4160247  |\n",
      "| time_elapsed            | 6347       |\n",
      "| total timesteps         | 798382     |\n",
      "| value_loss              | 1.7558475  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.037047323 |\n",
      "| ent_coef_loss           | -4.4181     |\n",
      "| entropy                 | -4.505871   |\n",
      "| episodes                | 900         |\n",
      "| fps                     | 125         |\n",
      "| mean 100 episode reward | 1.66e+03    |\n",
      "| n_updates               | 807899      |\n",
      "| policy_loss             | -128.81573  |\n",
      "| qf1_loss                | 3.210185    |\n",
      "| qf2_loss                | 1.4116704   |\n",
      "| time_elapsed            | 6442        |\n",
      "| total timesteps         | 807998      |\n",
      "| value_loss              | 0.9366329   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03420758 |\n",
      "| ent_coef_loss           | -0.6163447 |\n",
      "| entropy                 | -4.7042747 |\n",
      "| episodes                | 910        |\n",
      "| fps                     | 125        |\n",
      "| mean 100 episode reward | 1.7e+03    |\n",
      "| n_updates               | 816469     |\n",
      "| policy_loss             | -129.43869 |\n",
      "| qf1_loss                | 1.600939   |\n",
      "| qf2_loss                | 1.8052125  |\n",
      "| time_elapsed            | 6513       |\n",
      "| total timesteps         | 816568     |\n",
      "| value_loss              | 0.4171707  |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.03480605  |\n",
      "| ent_coef_loss           | -0.48425782 |\n",
      "| entropy                 | -4.441493   |\n",
      "| episodes                | 920         |\n",
      "| fps                     | 125         |\n",
      "| mean 100 episode reward | 1.74e+03    |\n",
      "| n_updates               | 825932      |\n",
      "| policy_loss             | -134.17838  |\n",
      "| qf1_loss                | 0.5595369   |\n",
      "| qf2_loss                | 0.47700274  |\n",
      "| time_elapsed            | 6588        |\n",
      "| total timesteps         | 826031      |\n",
      "| value_loss              | 0.532079    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03776351 |\n",
      "| ent_coef_loss           | 0.30565977 |\n",
      "| entropy                 | -4.484875  |\n",
      "| episodes                | 930        |\n",
      "| fps                     | 125        |\n",
      "| mean 100 episode reward | 1.77e+03   |\n",
      "| n_updates               | 835233     |\n",
      "| policy_loss             | -132.23357 |\n",
      "| qf1_loss                | 0.6258188  |\n",
      "| qf2_loss                | 0.58635366 |\n",
      "| time_elapsed            | 6654       |\n",
      "| total timesteps         | 835332     |\n",
      "| value_loss              | 0.677081   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| current_lr              | 0.0003       |\n",
      "| ent_coef                | 0.036398917  |\n",
      "| ent_coef_loss           | -0.118299454 |\n",
      "| entropy                 | -4.42428     |\n",
      "| episodes                | 940          |\n",
      "| fps                     | 125          |\n",
      "| mean 100 episode reward | 1.78e+03     |\n",
      "| n_updates               | 844635       |\n",
      "| policy_loss             | -134.69144   |\n",
      "| qf1_loss                | 8.909119     |\n",
      "| qf2_loss                | 4.698968     |\n",
      "| time_elapsed            | 6715         |\n",
      "| total timesteps         | 844734       |\n",
      "| value_loss              | 0.79011106   |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035155572 |\n",
      "| ent_coef_loss           | -0.83238566 |\n",
      "| entropy                 | -4.634489   |\n",
      "| episodes                | 950         |\n",
      "| fps                     | 125         |\n",
      "| mean 100 episode reward | 1.81e+03    |\n",
      "| n_updates               | 854050      |\n",
      "| policy_loss             | -127.89436  |\n",
      "| qf1_loss                | 1.4557917   |\n",
      "| qf2_loss                | 1.2310011   |\n",
      "| time_elapsed            | 6801        |\n",
      "| total timesteps         | 854149      |\n",
      "| value_loss              | 0.82167935  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.038196813 |\n",
      "| ent_coef_loss           | -1.9542989  |\n",
      "| entropy                 | -4.615801   |\n",
      "| episodes                | 960         |\n",
      "| fps                     | 125         |\n",
      "| mean 100 episode reward | 1.84e+03    |\n",
      "| n_updates               | 863177      |\n",
      "| policy_loss             | -135.9694   |\n",
      "| qf1_loss                | 1.4517298   |\n",
      "| qf2_loss                | 0.89616215  |\n",
      "| time_elapsed            | 6869        |\n",
      "| total timesteps         | 863276      |\n",
      "| value_loss              | 1.9166117   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035314597 |\n",
      "| ent_coef_loss           | -1.2341437  |\n",
      "| entropy                 | -4.65802    |\n",
      "| episodes                | 970         |\n",
      "| fps                     | 125         |\n",
      "| mean 100 episode reward | 1.76e+03    |\n",
      "| n_updates               | 869989      |\n",
      "| policy_loss             | -134.20164  |\n",
      "| qf1_loss                | 1.1164515   |\n",
      "| qf2_loss                | 2.061629    |\n",
      "| time_elapsed            | 6930        |\n",
      "| total timesteps         | 870088      |\n",
      "| value_loss              | 0.679437    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03832728 |\n",
      "| ent_coef_loss           | -1.4489615 |\n",
      "| entropy                 | -4.4457173 |\n",
      "| episodes                | 980        |\n",
      "| fps                     | 125        |\n",
      "| mean 100 episode reward | 1.75e+03   |\n",
      "| n_updates               | 877613     |\n",
      "| policy_loss             | -125.84923 |\n",
      "| qf1_loss                | 4.595888   |\n",
      "| qf2_loss                | 2.3823624  |\n",
      "| time_elapsed            | 6982       |\n",
      "| total timesteps         | 877712     |\n",
      "| value_loss              | 3.28975    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.033780754 |\n",
      "| ent_coef_loss           | 2.6744614   |\n",
      "| entropy                 | -5.063113   |\n",
      "| episodes                | 990         |\n",
      "| fps                     | 125         |\n",
      "| mean 100 episode reward | 1.74e+03    |\n",
      "| n_updates               | 885575      |\n",
      "| policy_loss             | -134.48691  |\n",
      "| qf1_loss                | 0.7212996   |\n",
      "| qf2_loss                | 0.7019802   |\n",
      "| time_elapsed            | 7063        |\n",
      "| total timesteps         | 885674      |\n",
      "| value_loss              | 0.2800262   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036323905 |\n",
      "| ent_coef_loss           | -1.7414105  |\n",
      "| entropy                 | -4.0866094  |\n",
      "| episodes                | 1000        |\n",
      "| fps                     | 125         |\n",
      "| mean 100 episode reward | 1.75e+03    |\n",
      "| n_updates               | 895226      |\n",
      "| policy_loss             | -136.92511  |\n",
      "| qf1_loss                | 1.3566399   |\n",
      "| qf2_loss                | 1.4634352   |\n",
      "| time_elapsed            | 7154        |\n",
      "| total timesteps         | 895325      |\n",
      "| value_loss              | 0.3838169   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03401352 |\n",
      "| ent_coef_loss           | 0.2527359  |\n",
      "| entropy                 | -4.579308  |\n",
      "| episodes                | 1010       |\n",
      "| fps                     | 125        |\n",
      "| mean 100 episode reward | 1.78e+03   |\n",
      "| n_updates               | 904341     |\n",
      "| policy_loss             | -136.45221 |\n",
      "| qf1_loss                | 3.9297793  |\n",
      "| qf2_loss                | 3.6015995  |\n",
      "| time_elapsed            | 7222       |\n",
      "| total timesteps         | 904440     |\n",
      "| value_loss              | 0.38514835 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03534778 |\n",
      "| ent_coef_loss           | 1.5029998  |\n",
      "| entropy                 | -5.2153487 |\n",
      "| episodes                | 1020       |\n",
      "| fps                     | 125        |\n",
      "| mean 100 episode reward | 1.76e+03   |\n",
      "| n_updates               | 913151     |\n",
      "| policy_loss             | -144.41208 |\n",
      "| qf1_loss                | 3.607066   |\n",
      "| qf2_loss                | 4.28867    |\n",
      "| time_elapsed            | 7293       |\n",
      "| total timesteps         | 913250     |\n",
      "| value_loss              | 2.2235134  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.034360792 |\n",
      "| ent_coef_loss           | -0.24244213 |\n",
      "| entropy                 | -4.4275618  |\n",
      "| episodes                | 1030        |\n",
      "| fps                     | 125         |\n",
      "| mean 100 episode reward | 1.74e+03    |\n",
      "| n_updates               | 922575      |\n",
      "| policy_loss             | -131.55087  |\n",
      "| qf1_loss                | 4.575243    |\n",
      "| qf2_loss                | 3.2752228   |\n",
      "| time_elapsed            | 7379        |\n",
      "| total timesteps         | 922674      |\n",
      "| value_loss              | 1.6241341   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.038219713 |\n",
      "| ent_coef_loss           | 1.4447274   |\n",
      "| entropy                 | -4.505019   |\n",
      "| episodes                | 1040        |\n",
      "| fps                     | 125         |\n",
      "| mean 100 episode reward | 1.72e+03    |\n",
      "| n_updates               | 930364      |\n",
      "| policy_loss             | -141.5105   |\n",
      "| qf1_loss                | 1.9851835   |\n",
      "| qf2_loss                | 2.2753494   |\n",
      "| time_elapsed            | 7437        |\n",
      "| total timesteps         | 930463      |\n",
      "| value_loss              | 0.60163987  |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03493572 |\n",
      "| ent_coef_loss           | 0.19345796 |\n",
      "| entropy                 | -4.747601  |\n",
      "| episodes                | 1050       |\n",
      "| fps                     | 124        |\n",
      "| mean 100 episode reward | 1.65e+03   |\n",
      "| n_updates               | 937961     |\n",
      "| policy_loss             | -139.98012 |\n",
      "| qf1_loss                | 1.4954852  |\n",
      "| qf2_loss                | 1.4655492  |\n",
      "| time_elapsed            | 7508       |\n",
      "| total timesteps         | 938060     |\n",
      "| value_loss              | 0.7339027  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.0354641  |\n",
      "| ent_coef_loss           | 0.39582068 |\n",
      "| entropy                 | -4.705001  |\n",
      "| episodes                | 1060       |\n",
      "| fps                     | 124        |\n",
      "| mean 100 episode reward | 1.58e+03   |\n",
      "| n_updates               | 945156     |\n",
      "| policy_loss             | -146.84413 |\n",
      "| qf1_loss                | 1.4168628  |\n",
      "| qf2_loss                | 1.1755279  |\n",
      "| time_elapsed            | 7577       |\n",
      "| total timesteps         | 945255     |\n",
      "| value_loss              | 0.8859962  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035389002 |\n",
      "| ent_coef_loss           | 0.5041613   |\n",
      "| entropy                 | -4.498043   |\n",
      "| episodes                | 1070        |\n",
      "| fps                     | 124         |\n",
      "| mean 100 episode reward | 1.64e+03    |\n",
      "| n_updates               | 953397      |\n",
      "| policy_loss             | -143.54054  |\n",
      "| qf1_loss                | 8.647816    |\n",
      "| qf2_loss                | 8.475135    |\n",
      "| time_elapsed            | 7651        |\n",
      "| total timesteps         | 953496      |\n",
      "| value_loss              | 1.5699675   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.034575228 |\n",
      "| ent_coef_loss           | -1.7539848  |\n",
      "| entropy                 | -4.830515   |\n",
      "| episodes                | 1080        |\n",
      "| fps                     | 124         |\n",
      "| mean 100 episode reward | 1.68e+03    |\n",
      "| n_updates               | 962758      |\n",
      "| policy_loss             | -136.52802  |\n",
      "| qf1_loss                | 1.1527854   |\n",
      "| qf2_loss                | 1.3850362   |\n",
      "| time_elapsed            | 7747        |\n",
      "| total timesteps         | 962857      |\n",
      "| value_loss              | 0.83419085  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.034550175 |\n",
      "| ent_coef_loss           | 2.0535903   |\n",
      "| entropy                 | -4.2816744  |\n",
      "| episodes                | 1090        |\n",
      "| fps                     | 124         |\n",
      "| mean 100 episode reward | 1.65e+03    |\n",
      "| n_updates               | 972057      |\n",
      "| policy_loss             | -131.7443   |\n",
      "| qf1_loss                | 4.779027    |\n",
      "| qf2_loss                | 3.4156327   |\n",
      "| time_elapsed            | 7819        |\n",
      "| total timesteps         | 972156      |\n",
      "| value_loss              | 2.456999    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036171474 |\n",
      "| ent_coef_loss           | 1.4897577   |\n",
      "| entropy                 | -4.3079715  |\n",
      "| episodes                | 1100        |\n",
      "| fps                     | 124         |\n",
      "| mean 100 episode reward | 1.65e+03    |\n",
      "| n_updates               | 980667      |\n",
      "| policy_loss             | -136.64316  |\n",
      "| qf1_loss                | 1.0991457   |\n",
      "| qf2_loss                | 0.9953892   |\n",
      "| time_elapsed            | 7890        |\n",
      "| total timesteps         | 980766      |\n",
      "| value_loss              | 2.6994905   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.037967592 |\n",
      "| ent_coef_loss           | 2.4872034   |\n",
      "| entropy                 | -3.972549   |\n",
      "| episodes                | 1110        |\n",
      "| fps                     | 124         |\n",
      "| mean 100 episode reward | 1.61e+03    |\n",
      "| n_updates               | 987916      |\n",
      "| policy_loss             | -143.67851  |\n",
      "| qf1_loss                | 1.1488805   |\n",
      "| qf2_loss                | 0.784176    |\n",
      "| time_elapsed            | 7959        |\n",
      "| total timesteps         | 988015      |\n",
      "| value_loss              | 1.5043314   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03666638 |\n",
      "| ent_coef_loss           | -1.1092796 |\n",
      "| entropy                 | -4.398055  |\n",
      "| episodes                | 1120       |\n",
      "| fps                     | 124        |\n",
      "| mean 100 episode reward | 1.58e+03   |\n",
      "| n_updates               | 995519     |\n",
      "| policy_loss             | -137.00563 |\n",
      "| qf1_loss                | 2.158908   |\n",
      "| qf2_loss                | 2.028811   |\n",
      "| time_elapsed            | 8014       |\n",
      "| total timesteps         | 995618     |\n",
      "| value_loss              | 1.5966647  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.040737186 |\n",
      "| ent_coef_loss           | 1.0439942   |\n",
      "| entropy                 | -3.630324   |\n",
      "| episodes                | 1130        |\n",
      "| fps                     | 124         |\n",
      "| mean 100 episode reward | 1.63e+03    |\n",
      "| n_updates               | 1004429     |\n",
      "| policy_loss             | -146.52734  |\n",
      "| qf1_loss                | 1.6883981   |\n",
      "| qf2_loss                | 1.2387133   |\n",
      "| time_elapsed            | 8068        |\n",
      "| total timesteps         | 1004528     |\n",
      "| value_loss              | 0.5114354   |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| current_lr              | 0.0003        |\n",
      "| ent_coef                | 0.036816187   |\n",
      "| ent_coef_loss           | -0.0047427714 |\n",
      "| entropy                 | -4.3634725    |\n",
      "| episodes                | 1140          |\n",
      "| fps                     | 124           |\n",
      "| mean 100 episode reward | 1.62e+03      |\n",
      "| n_updates               | 1013445       |\n",
      "| policy_loss             | -159.17706    |\n",
      "| qf1_loss                | 1.1868999     |\n",
      "| qf2_loss                | 1.1660836     |\n",
      "| time_elapsed            | 8118          |\n",
      "| total timesteps         | 1013544       |\n",
      "| value_loss              | 0.7815795     |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.034754813 |\n",
      "| ent_coef_loss           | 1.7878923   |\n",
      "| entropy                 | -4.744462   |\n",
      "| episodes                | 1150        |\n",
      "| fps                     | 125         |\n",
      "| mean 100 episode reward | 1.64e+03    |\n",
      "| n_updates               | 1022284     |\n",
      "| policy_loss             | -156.70576  |\n",
      "| qf1_loss                | 0.86825687  |\n",
      "| qf2_loss                | 0.87518513  |\n",
      "| time_elapsed            | 8166        |\n",
      "| total timesteps         | 1022383     |\n",
      "| value_loss              | 0.74081504  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.037389442 |\n",
      "| ent_coef_loss           | -0.8038837  |\n",
      "| entropy                 | -4.5665283  |\n",
      "| episodes                | 1160        |\n",
      "| fps                     | 125         |\n",
      "| mean 100 episode reward | 1.73e+03    |\n",
      "| n_updates               | 1030432     |\n",
      "| policy_loss             | -159.18314  |\n",
      "| qf1_loss                | 5.1322417   |\n",
      "| qf2_loss                | 4.586484    |\n",
      "| time_elapsed            | 8211        |\n",
      "| total timesteps         | 1030531     |\n",
      "| value_loss              | 2.1446266   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.038712844 |\n",
      "| ent_coef_loss           | -0.68262625 |\n",
      "| entropy                 | -3.80366    |\n",
      "| episodes                | 1170        |\n",
      "| fps                     | 125         |\n",
      "| mean 100 episode reward | 1.76e+03    |\n",
      "| n_updates               | 1039460     |\n",
      "| policy_loss             | -145.9371   |\n",
      "| qf1_loss                | 1.6677611   |\n",
      "| qf2_loss                | 1.4882773   |\n",
      "| time_elapsed            | 8260        |\n",
      "| total timesteps         | 1039559     |\n",
      "| value_loss              | 0.3969648   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036984436 |\n",
      "| ent_coef_loss           | 1.3461609   |\n",
      "| entropy                 | -3.696677   |\n",
      "| episodes                | 1180        |\n",
      "| fps                     | 126         |\n",
      "| mean 100 episode reward | 1.73e+03    |\n",
      "| n_updates               | 1047524     |\n",
      "| policy_loss             | -144.02753  |\n",
      "| qf1_loss                | 3.5301883   |\n",
      "| qf2_loss                | 1.7264471   |\n",
      "| time_elapsed            | 8304        |\n",
      "| total timesteps         | 1047623     |\n",
      "| value_loss              | 1.208633    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03731516 |\n",
      "| ent_coef_loss           | 0.5657505  |\n",
      "| entropy                 | -4.072013  |\n",
      "| episodes                | 1190       |\n",
      "| fps                     | 126        |\n",
      "| mean 100 episode reward | 1.75e+03   |\n",
      "| n_updates               | 1056027    |\n",
      "| policy_loss             | -155.10555 |\n",
      "| qf1_loss                | 5.133918   |\n",
      "| qf2_loss                | 8.12259    |\n",
      "| time_elapsed            | 8351       |\n",
      "| total timesteps         | 1056126    |\n",
      "| value_loss              | 0.96385825 |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.037783276 |\n",
      "| ent_coef_loss           | -0.34730732 |\n",
      "| entropy                 | -4.172016   |\n",
      "| episodes                | 1200        |\n",
      "| fps                     | 126         |\n",
      "| mean 100 episode reward | 1.67e+03    |\n",
      "| n_updates               | 1062778     |\n",
      "| policy_loss             | -151.09254  |\n",
      "| qf1_loss                | 1.7587914   |\n",
      "| qf2_loss                | 1.5964366   |\n",
      "| time_elapsed            | 8388        |\n",
      "| total timesteps         | 1062877     |\n",
      "| value_loss              | 1.2779052   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.040286474 |\n",
      "| ent_coef_loss           | 2.3239515   |\n",
      "| entropy                 | -3.6576667  |\n",
      "| episodes                | 1210        |\n",
      "| fps                     | 126         |\n",
      "| mean 100 episode reward | 1.7e+03     |\n",
      "| n_updates               | 1070529     |\n",
      "| policy_loss             | -154.32767  |\n",
      "| qf1_loss                | 3.2094045   |\n",
      "| qf2_loss                | 3.2119637   |\n",
      "| time_elapsed            | 8430        |\n",
      "| total timesteps         | 1070628     |\n",
      "| value_loss              | 0.66013944  |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.04280698 |\n",
      "| ent_coef_loss           | -1.4803848 |\n",
      "| entropy                 | -3.5476704 |\n",
      "| episodes                | 1220       |\n",
      "| fps                     | 127        |\n",
      "| mean 100 episode reward | 1.68e+03   |\n",
      "| n_updates               | 1076159    |\n",
      "| policy_loss             | -134.39827 |\n",
      "| qf1_loss                | 4.36409    |\n",
      "| qf2_loss                | 3.9917169  |\n",
      "| time_elapsed            | 8461       |\n",
      "| total timesteps         | 1076258    |\n",
      "| value_loss              | 1.4046321  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03780047 |\n",
      "| ent_coef_loss           | -0.9898584 |\n",
      "| entropy                 | -4.149292  |\n",
      "| episodes                | 1230       |\n",
      "| fps                     | 127        |\n",
      "| mean 100 episode reward | 1.66e+03   |\n",
      "| n_updates               | 1084351    |\n",
      "| policy_loss             | -134.68121 |\n",
      "| qf1_loss                | 4.037202   |\n",
      "| qf2_loss                | 4.443158   |\n",
      "| time_elapsed            | 8506       |\n",
      "| total timesteps         | 1084450    |\n",
      "| value_loss              | 1.1610907  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03945188 |\n",
      "| ent_coef_loss           | 0.25664908 |\n",
      "| entropy                 | -3.894159  |\n",
      "| episodes                | 1240       |\n",
      "| fps                     | 127        |\n",
      "| mean 100 episode reward | 1.68e+03   |\n",
      "| n_updates               | 1093249    |\n",
      "| policy_loss             | -144.84943 |\n",
      "| qf1_loss                | 1.0084298  |\n",
      "| qf2_loss                | 1.1063567  |\n",
      "| time_elapsed            | 8555       |\n",
      "| total timesteps         | 1093348    |\n",
      "| value_loss              | 0.66063356 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03661063 |\n",
      "| ent_coef_loss           | 0.13363644 |\n",
      "| entropy                 | -4.079759  |\n",
      "| episodes                | 1250       |\n",
      "| fps                     | 128        |\n",
      "| mean 100 episode reward | 1.75e+03   |\n",
      "| n_updates               | 1102953    |\n",
      "| policy_loss             | -141.46933 |\n",
      "| qf1_loss                | 2.1413026  |\n",
      "| qf2_loss                | 1.9619613  |\n",
      "| time_elapsed            | 8608       |\n",
      "| total timesteps         | 1103052    |\n",
      "| value_loss              | 1.0975857  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03754464 |\n",
      "| ent_coef_loss           | -0.785375  |\n",
      "| entropy                 | -4.428732  |\n",
      "| episodes                | 1260       |\n",
      "| fps                     | 128        |\n",
      "| mean 100 episode reward | 1.78e+03   |\n",
      "| n_updates               | 1112490    |\n",
      "| policy_loss             | -147.0712  |\n",
      "| qf1_loss                | 6.9541783  |\n",
      "| qf2_loss                | 4.8444047  |\n",
      "| time_elapsed            | 8660       |\n",
      "| total timesteps         | 1112589    |\n",
      "| value_loss              | 3.620098   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036048904 |\n",
      "| ent_coef_loss           | -2.002067   |\n",
      "| entropy                 | -4.222671   |\n",
      "| episodes                | 1270        |\n",
      "| fps                     | 128         |\n",
      "| mean 100 episode reward | 1.76e+03    |\n",
      "| n_updates               | 1121261     |\n",
      "| policy_loss             | -142.318    |\n",
      "| qf1_loss                | 1.3087682   |\n",
      "| qf2_loss                | 1.3049881   |\n",
      "| time_elapsed            | 8708        |\n",
      "| total timesteps         | 1121360     |\n",
      "| value_loss              | 0.9257823   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035125177 |\n",
      "| ent_coef_loss           | -2.0741677  |\n",
      "| entropy                 | -4.415227   |\n",
      "| episodes                | 1280        |\n",
      "| fps                     | 129         |\n",
      "| mean 100 episode reward | 1.7e+03     |\n",
      "| n_updates               | 1130587     |\n",
      "| policy_loss             | -156.63745  |\n",
      "| qf1_loss                | 1.9522011   |\n",
      "| qf2_loss                | 2.9452062   |\n",
      "| time_elapsed            | 8759        |\n",
      "| total timesteps         | 1130686     |\n",
      "| value_loss              | 0.5865116   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03637474 |\n",
      "| ent_coef_loss           | 0.8521282  |\n",
      "| entropy                 | -4.424084  |\n",
      "| episodes                | 1290       |\n",
      "| fps                     | 129        |\n",
      "| mean 100 episode reward | 1.68e+03   |\n",
      "| n_updates               | 1139298    |\n",
      "| policy_loss             | -149.70291 |\n",
      "| qf1_loss                | 1.4025481  |\n",
      "| qf2_loss                | 1.5057032  |\n",
      "| time_elapsed            | 8807       |\n",
      "| total timesteps         | 1139397    |\n",
      "| value_loss              | 0.9949702  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.037192155 |\n",
      "| ent_coef_loss           | -0.1717053  |\n",
      "| entropy                 | -3.9312809  |\n",
      "| episodes                | 1300        |\n",
      "| fps                     | 129         |\n",
      "| mean 100 episode reward | 1.71e+03    |\n",
      "| n_updates               | 1146624     |\n",
      "| policy_loss             | -155.59021  |\n",
      "| qf1_loss                | 2.1600108   |\n",
      "| qf2_loss                | 2.5501344   |\n",
      "| time_elapsed            | 8847        |\n",
      "| total timesteps         | 1146723     |\n",
      "| value_loss              | 0.52279663  |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.0361613  |\n",
      "| ent_coef_loss           | 0.38197303 |\n",
      "| entropy                 | -4.510087  |\n",
      "| episodes                | 1310       |\n",
      "| fps                     | 129        |\n",
      "| mean 100 episode reward | 1.76e+03   |\n",
      "| n_updates               | 1156525    |\n",
      "| policy_loss             | -161.29555 |\n",
      "| qf1_loss                | 2.1564348  |\n",
      "| qf2_loss                | 2.2619123  |\n",
      "| time_elapsed            | 8901       |\n",
      "| total timesteps         | 1156624    |\n",
      "| value_loss              | 1.5803742  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.032990333 |\n",
      "| ent_coef_loss           | -0.2108621  |\n",
      "| entropy                 | -4.7577887  |\n",
      "| episodes                | 1320        |\n",
      "| fps                     | 130         |\n",
      "| mean 100 episode reward | 1.88e+03    |\n",
      "| n_updates               | 1166049     |\n",
      "| policy_loss             | -154.04608  |\n",
      "| qf1_loss                | 3.4034207   |\n",
      "| qf2_loss                | 2.4109635   |\n",
      "| time_elapsed            | 8954        |\n",
      "| total timesteps         | 1166148     |\n",
      "| value_loss              | 0.9086519   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.039119054 |\n",
      "| ent_coef_loss           | -0.2941056  |\n",
      "| entropy                 | -3.9750638  |\n",
      "| episodes                | 1330        |\n",
      "| fps                     | 130         |\n",
      "| mean 100 episode reward | 1.88e+03    |\n",
      "| n_updates               | 1174954     |\n",
      "| policy_loss             | -157.34647  |\n",
      "| qf1_loss                | 2.486035    |\n",
      "| qf2_loss                | 2.8079884   |\n",
      "| time_elapsed            | 9002        |\n",
      "| total timesteps         | 1175053     |\n",
      "| value_loss              | 2.667698    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.03484909  |\n",
      "| ent_coef_loss           | -0.94197005 |\n",
      "| entropy                 | -4.197966   |\n",
      "| episodes                | 1340        |\n",
      "| fps                     | 130         |\n",
      "| mean 100 episode reward | 1.87e+03    |\n",
      "| n_updates               | 1183089     |\n",
      "| policy_loss             | -162.68573  |\n",
      "| qf1_loss                | 5.100353    |\n",
      "| qf2_loss                | 4.595404    |\n",
      "| time_elapsed            | 9047        |\n",
      "| total timesteps         | 1183188     |\n",
      "| value_loss              | 2.0409837   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.033096846 |\n",
      "| ent_coef_loss           | -1.0246093  |\n",
      "| entropy                 | -4.8560724  |\n",
      "| episodes                | 1350        |\n",
      "| fps                     | 131         |\n",
      "| mean 100 episode reward | 1.78e+03    |\n",
      "| n_updates               | 1190569     |\n",
      "| policy_loss             | -149.49863  |\n",
      "| qf1_loss                | 1.5789458   |\n",
      "| qf2_loss                | 36.31129    |\n",
      "| time_elapsed            | 9088        |\n",
      "| total timesteps         | 1190668     |\n",
      "| value_loss              | 2.97813     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.034622774 |\n",
      "| ent_coef_loss           | 0.20847917  |\n",
      "| entropy                 | -4.8509293  |\n",
      "| episodes                | 1360        |\n",
      "| fps                     | 131         |\n",
      "| mean 100 episode reward | 1.66e+03    |\n",
      "| n_updates               | 1196634     |\n",
      "| policy_loss             | -165.10617  |\n",
      "| qf1_loss                | 1.4455888   |\n",
      "| qf2_loss                | 1.4087679   |\n",
      "| time_elapsed            | 9121        |\n",
      "| total timesteps         | 1196733     |\n",
      "| value_loss              | 1.0983021   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.034066085 |\n",
      "| ent_coef_loss           | 1.6253793   |\n",
      "| entropy                 | -4.5998836  |\n",
      "| episodes                | 1370        |\n",
      "| fps                     | 131         |\n",
      "| mean 100 episode reward | 1.68e+03    |\n",
      "| n_updates               | 1206290     |\n",
      "| policy_loss             | -157.3082   |\n",
      "| qf1_loss                | 19.794168   |\n",
      "| qf2_loss                | 18.855167   |\n",
      "| time_elapsed            | 9174        |\n",
      "| total timesteps         | 1206389     |\n",
      "| value_loss              | 2.5551753   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.032960724 |\n",
      "| ent_coef_loss           | -0.3286873  |\n",
      "| entropy                 | -5.035078   |\n",
      "| episodes                | 1380        |\n",
      "| fps                     | 131         |\n",
      "| mean 100 episode reward | 1.77e+03    |\n",
      "| n_updates               | 1215651     |\n",
      "| policy_loss             | -156.96323  |\n",
      "| qf1_loss                | 2.5630133   |\n",
      "| qf2_loss                | 3.088533    |\n",
      "| time_elapsed            | 9225        |\n",
      "| total timesteps         | 1215750     |\n",
      "| value_loss              | 0.8591928   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035918225 |\n",
      "| ent_coef_loss           | 0.96472156  |\n",
      "| entropy                 | -4.272978   |\n",
      "| episodes                | 1390        |\n",
      "| fps                     | 132         |\n",
      "| mean 100 episode reward | 1.79e+03    |\n",
      "| n_updates               | 1224170     |\n",
      "| policy_loss             | -156.48724  |\n",
      "| qf1_loss                | 3.6885805   |\n",
      "| qf2_loss                | 3.272163    |\n",
      "| time_elapsed            | 9272        |\n",
      "| total timesteps         | 1224269     |\n",
      "| value_loss              | 5.7717514   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.034277733 |\n",
      "| ent_coef_loss           | 1.8462319   |\n",
      "| entropy                 | -4.847026   |\n",
      "| episodes                | 1400        |\n",
      "| fps                     | 132         |\n",
      "| mean 100 episode reward | 1.85e+03    |\n",
      "| n_updates               | 1232357     |\n",
      "| policy_loss             | -151.36877  |\n",
      "| qf1_loss                | 239.86784   |\n",
      "| qf2_loss                | 245.78635   |\n",
      "| time_elapsed            | 9316        |\n",
      "| total timesteps         | 1232456     |\n",
      "| value_loss              | 2.8655367   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.034085397 |\n",
      "| ent_coef_loss           | 0.3630587   |\n",
      "| entropy                 | -4.5407324  |\n",
      "| episodes                | 1410        |\n",
      "| fps                     | 132         |\n",
      "| mean 100 episode reward | 1.78e+03    |\n",
      "| n_updates               | 1240903     |\n",
      "| policy_loss             | -148.09782  |\n",
      "| qf1_loss                | 2.3610747   |\n",
      "| qf2_loss                | 1.8316859   |\n",
      "| time_elapsed            | 9363        |\n",
      "| total timesteps         | 1241002     |\n",
      "| value_loss              | 1.0929027   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.034941696 |\n",
      "| ent_coef_loss           | 0.90269864  |\n",
      "| entropy                 | -4.43639    |\n",
      "| episodes                | 1420        |\n",
      "| fps                     | 132         |\n",
      "| mean 100 episode reward | 1.75e+03    |\n",
      "| n_updates               | 1248415     |\n",
      "| policy_loss             | -152.53021  |\n",
      "| qf1_loss                | 5.9028826   |\n",
      "| qf2_loss                | 4.963708    |\n",
      "| time_elapsed            | 9404        |\n",
      "| total timesteps         | 1248514     |\n",
      "| value_loss              | 2.9384174   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03446279 |\n",
      "| ent_coef_loss           | -1.3691097 |\n",
      "| entropy                 | -4.68117   |\n",
      "| episodes                | 1430       |\n",
      "| fps                     | 132        |\n",
      "| mean 100 episode reward | 1.73e+03   |\n",
      "| n_updates               | 1256825    |\n",
      "| policy_loss             | -152.40247 |\n",
      "| qf1_loss                | 3.1269054  |\n",
      "| qf2_loss                | 4.679322   |\n",
      "| time_elapsed            | 9450       |\n",
      "| total timesteps         | 1256924    |\n",
      "| value_loss              | 2.397358   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03381703 |\n",
      "| ent_coef_loss           | -4.1773806 |\n",
      "| entropy                 | -4.441163  |\n",
      "| episodes                | 1440       |\n",
      "| fps                     | 133        |\n",
      "| mean 100 episode reward | 1.77e+03   |\n",
      "| n_updates               | 1265244    |\n",
      "| policy_loss             | -141.10974 |\n",
      "| qf1_loss                | 3.4695354  |\n",
      "| qf2_loss                | 2.52735    |\n",
      "| time_elapsed            | 9497       |\n",
      "| total timesteps         | 1265343    |\n",
      "| value_loss              | 1.3774409  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03297505 |\n",
      "| ent_coef_loss           | 0.67922914 |\n",
      "| entropy                 | -4.82941   |\n",
      "| episodes                | 1450       |\n",
      "| fps                     | 133        |\n",
      "| mean 100 episode reward | 1.82e+03   |\n",
      "| n_updates               | 1273085    |\n",
      "| policy_loss             | -150.04953 |\n",
      "| qf1_loss                | 21.368643  |\n",
      "| qf2_loss                | 26.651413  |\n",
      "| time_elapsed            | 9539       |\n",
      "| total timesteps         | 1273184    |\n",
      "| value_loss              | 6.468564   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035973016 |\n",
      "| ent_coef_loss           | 0.92022485  |\n",
      "| entropy                 | -4.336335   |\n",
      "| episodes                | 1460        |\n",
      "| fps                     | 133         |\n",
      "| mean 100 episode reward | 1.95e+03    |\n",
      "| n_updates               | 1282447     |\n",
      "| policy_loss             | -147.60889  |\n",
      "| qf1_loss                | 3.0518022   |\n",
      "| qf2_loss                | 3.5422244   |\n",
      "| time_elapsed            | 9591        |\n",
      "| total timesteps         | 1282546     |\n",
      "| value_loss              | 2.8715844   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03550477 |\n",
      "| ent_coef_loss           | 0.35488904 |\n",
      "| entropy                 | -4.3815403 |\n",
      "| episodes                | 1470       |\n",
      "| fps                     | 133        |\n",
      "| mean 100 episode reward | 1.9e+03    |\n",
      "| n_updates               | 1288571    |\n",
      "| policy_loss             | -145.94458 |\n",
      "| qf1_loss                | 2.8973417  |\n",
      "| qf2_loss                | 2.0959785  |\n",
      "| time_elapsed            | 9625       |\n",
      "| total timesteps         | 1288670    |\n",
      "| value_loss              | 1.3272326  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.034678508 |\n",
      "| ent_coef_loss           | 0.513045    |\n",
      "| entropy                 | -4.578809   |\n",
      "| episodes                | 1480        |\n",
      "| fps                     | 134         |\n",
      "| mean 100 episode reward | 1.83e+03    |\n",
      "| n_updates               | 1297149     |\n",
      "| policy_loss             | -139.16194  |\n",
      "| qf1_loss                | 2.7374043   |\n",
      "| qf2_loss                | 2.660462    |\n",
      "| time_elapsed            | 9672        |\n",
      "| total timesteps         | 1297248     |\n",
      "| value_loss              | 1.0211644   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03519884 |\n",
      "| ent_coef_loss           | 1.2590225  |\n",
      "| entropy                 | -4.472699  |\n",
      "| episodes                | 1490       |\n",
      "| fps                     | 134        |\n",
      "| mean 100 episode reward | 1.84e+03   |\n",
      "| n_updates               | 1304259    |\n",
      "| policy_loss             | -148.06737 |\n",
      "| qf1_loss                | 17.932707  |\n",
      "| qf2_loss                | 14.616787  |\n",
      "| time_elapsed            | 9711       |\n",
      "| total timesteps         | 1304358    |\n",
      "| value_loss              | 4.631677   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.037441824 |\n",
      "| ent_coef_loss           | -3.0682094  |\n",
      "| entropy                 | -4.0824947  |\n",
      "| episodes                | 1500        |\n",
      "| fps                     | 134         |\n",
      "| mean 100 episode reward | 1.82e+03    |\n",
      "| n_updates               | 1312070     |\n",
      "| policy_loss             | -154.61859  |\n",
      "| qf1_loss                | 3.6960354   |\n",
      "| qf2_loss                | 3.0990539   |\n",
      "| time_elapsed            | 9754        |\n",
      "| total timesteps         | 1312169     |\n",
      "| value_loss              | 1.2527716   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.038726583 |\n",
      "| ent_coef_loss           | 0.19372237  |\n",
      "| entropy                 | -4.392946   |\n",
      "| episodes                | 1510        |\n",
      "| fps                     | 134         |\n",
      "| mean 100 episode reward | 1.81e+03    |\n",
      "| n_updates               | 1319948     |\n",
      "| policy_loss             | -160.25848  |\n",
      "| qf1_loss                | 3.6848938   |\n",
      "| qf2_loss                | 6.073351    |\n",
      "| time_elapsed            | 9797        |\n",
      "| total timesteps         | 1320047     |\n",
      "| value_loss              | 2.2879276   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.037914485 |\n",
      "| ent_coef_loss           | -0.5920564  |\n",
      "| entropy                 | -3.4968095  |\n",
      "| episodes                | 1520        |\n",
      "| fps                     | 134         |\n",
      "| mean 100 episode reward | 1.83e+03    |\n",
      "| n_updates               | 1329160     |\n",
      "| policy_loss             | -149.39503  |\n",
      "| qf1_loss                | 2.0486267   |\n",
      "| qf2_loss                | 1.8604106   |\n",
      "| time_elapsed            | 9848        |\n",
      "| total timesteps         | 1329259     |\n",
      "| value_loss              | 1.6751041   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.034283593 |\n",
      "| ent_coef_loss           | -0.08395535 |\n",
      "| entropy                 | -3.9967346  |\n",
      "| episodes                | 1530        |\n",
      "| fps                     | 135         |\n",
      "| mean 100 episode reward | 1.85e+03    |\n",
      "| n_updates               | 1336490     |\n",
      "| policy_loss             | -154.75494  |\n",
      "| qf1_loss                | 9.267354    |\n",
      "| qf2_loss                | 5.9671702   |\n",
      "| time_elapsed            | 9888        |\n",
      "| total timesteps         | 1336589     |\n",
      "| value_loss              | 3.4866111   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.034799196 |\n",
      "| ent_coef_loss           | 1.4516792   |\n",
      "| entropy                 | -4.467608   |\n",
      "| episodes                | 1540        |\n",
      "| fps                     | 135         |\n",
      "| mean 100 episode reward | 1.84e+03    |\n",
      "| n_updates               | 1344555     |\n",
      "| policy_loss             | -156.10703  |\n",
      "| qf1_loss                | 19.071005   |\n",
      "| qf2_loss                | 10.702595   |\n",
      "| time_elapsed            | 9931        |\n",
      "| total timesteps         | 1344654     |\n",
      "| value_loss              | 0.963961    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036096618 |\n",
      "| ent_coef_loss           | 1.5753373   |\n",
      "| entropy                 | -4.1441135  |\n",
      "| episodes                | 1550        |\n",
      "| fps                     | 135         |\n",
      "| mean 100 episode reward | 1.83e+03    |\n",
      "| n_updates               | 1352151     |\n",
      "| policy_loss             | -138.5148   |\n",
      "| qf1_loss                | 3.7594378   |\n",
      "| qf2_loss                | 5.2489195   |\n",
      "| time_elapsed            | 9973        |\n",
      "| total timesteps         | 1352250     |\n",
      "| value_loss              | 3.0797439   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.0341513  |\n",
      "| ent_coef_loss           | 1.2425222  |\n",
      "| entropy                 | -3.6325688 |\n",
      "| episodes                | 1560       |\n",
      "| fps                     | 135        |\n",
      "| mean 100 episode reward | 1.8e+03    |\n",
      "| n_updates               | 1359811    |\n",
      "| policy_loss             | -143.49638 |\n",
      "| qf1_loss                | 2.3013363  |\n",
      "| qf2_loss                | 4.35215    |\n",
      "| time_elapsed            | 10015      |\n",
      "| total timesteps         | 1359910    |\n",
      "| value_loss              | 9.290406   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.038318098 |\n",
      "| ent_coef_loss           | 0.02864024  |\n",
      "| entropy                 | -3.5783007  |\n",
      "| episodes                | 1570        |\n",
      "| fps                     | 136         |\n",
      "| mean 100 episode reward | 1.92e+03    |\n",
      "| n_updates               | 1369387     |\n",
      "| policy_loss             | -160.24373  |\n",
      "| qf1_loss                | 3.8769703   |\n",
      "| qf2_loss                | 4.133       |\n",
      "| time_elapsed            | 10067       |\n",
      "| total timesteps         | 1369486     |\n",
      "| value_loss              | 1.6601875   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.037088446 |\n",
      "| ent_coef_loss           | 1.4104354   |\n",
      "| entropy                 | -3.8939395  |\n",
      "| episodes                | 1580        |\n",
      "| fps                     | 136         |\n",
      "| mean 100 episode reward | 1.97e+03    |\n",
      "| n_updates               | 1378145     |\n",
      "| policy_loss             | -149.8628   |\n",
      "| qf1_loss                | 4.026384    |\n",
      "| qf2_loss                | 5.9016953   |\n",
      "| time_elapsed            | 10115       |\n",
      "| total timesteps         | 1378244     |\n",
      "| value_loss              | 3.384807    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.038083974 |\n",
      "| ent_coef_loss           | -0.28794557 |\n",
      "| entropy                 | -4.0535994  |\n",
      "| episodes                | 1590        |\n",
      "| fps                     | 136         |\n",
      "| mean 100 episode reward | 1.97e+03    |\n",
      "| n_updates               | 1386832     |\n",
      "| policy_loss             | -163.72313  |\n",
      "| qf1_loss                | 4.2036095   |\n",
      "| qf2_loss                | 2.156736    |\n",
      "| time_elapsed            | 10163       |\n",
      "| total timesteps         | 1386931     |\n",
      "| value_loss              | 1.5288782   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.033321857 |\n",
      "| ent_coef_loss           | -0.69366    |\n",
      "| entropy                 | -4.376612   |\n",
      "| episodes                | 1600        |\n",
      "| fps                     | 136         |\n",
      "| mean 100 episode reward | 2.02e+03    |\n",
      "| n_updates               | 1395453     |\n",
      "| policy_loss             | -153.11649  |\n",
      "| qf1_loss                | 4.449603    |\n",
      "| qf2_loss                | 3.2555218   |\n",
      "| time_elapsed            | 10210       |\n",
      "| total timesteps         | 1395552     |\n",
      "| value_loss              | 1.4560926   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.034005396 |\n",
      "| ent_coef_loss           | -1.3244567  |\n",
      "| entropy                 | -4.6422844  |\n",
      "| episodes                | 1610        |\n",
      "| fps                     | 136         |\n",
      "| mean 100 episode reward | 2.04e+03    |\n",
      "| n_updates               | 1402339     |\n",
      "| policy_loss             | -172.4444   |\n",
      "| qf1_loss                | 5.4169664   |\n",
      "| qf2_loss                | 3.0731342   |\n",
      "| time_elapsed            | 10248       |\n",
      "| total timesteps         | 1402438     |\n",
      "| value_loss              | 1.815722    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.033207715 |\n",
      "| ent_coef_loss           | 1.6311469   |\n",
      "| entropy                 | -4.9938984  |\n",
      "| episodes                | 1620        |\n",
      "| fps                     | 137         |\n",
      "| mean 100 episode reward | 1.99e+03    |\n",
      "| n_updates               | 1408916     |\n",
      "| policy_loss             | -161.6726   |\n",
      "| qf1_loss                | 5.2065005   |\n",
      "| qf2_loss                | 4.630887    |\n",
      "| time_elapsed            | 10283       |\n",
      "| total timesteps         | 1409015     |\n",
      "| value_loss              | 2.6895852   |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| current_lr              | 0.0003       |\n",
      "| ent_coef                | 0.034648888  |\n",
      "| ent_coef_loss           | -0.057686925 |\n",
      "| entropy                 | -4.7032423   |\n",
      "| episodes                | 1630         |\n",
      "| fps                     | 137          |\n",
      "| mean 100 episode reward | 2.01e+03     |\n",
      "| n_updates               | 1416498      |\n",
      "| policy_loss             | -157.18164   |\n",
      "| qf1_loss                | 4.852438     |\n",
      "| qf2_loss                | 4.041729     |\n",
      "| time_elapsed            | 10325        |\n",
      "| total timesteps         | 1416597      |\n",
      "| value_loss              | 3.2014074    |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.032523576 |\n",
      "| ent_coef_loss           | -0.5966483  |\n",
      "| entropy                 | -5.0660043  |\n",
      "| episodes                | 1640        |\n",
      "| fps                     | 137         |\n",
      "| mean 100 episode reward | 2.08e+03    |\n",
      "| n_updates               | 1426378     |\n",
      "| policy_loss             | -168.51605  |\n",
      "| qf1_loss                | 5.3364315   |\n",
      "| qf2_loss                | 8.068286    |\n",
      "| time_elapsed            | 10379       |\n",
      "| total timesteps         | 1426477     |\n",
      "| value_loss              | 1.61637     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.034850683 |\n",
      "| ent_coef_loss           | 2.0293112   |\n",
      "| entropy                 | -5.141433   |\n",
      "| episodes                | 1650        |\n",
      "| fps                     | 137         |\n",
      "| mean 100 episode reward | 2.13e+03    |\n",
      "| n_updates               | 1435287     |\n",
      "| policy_loss             | -155.28358  |\n",
      "| qf1_loss                | 17.918491   |\n",
      "| qf2_loss                | 22.656921   |\n",
      "| time_elapsed            | 10428       |\n",
      "| total timesteps         | 1435386     |\n",
      "| value_loss              | 2.0116372   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03327033 |\n",
      "| ent_coef_loss           | -2.325624  |\n",
      "| entropy                 | -4.529277  |\n",
      "| episodes                | 1660       |\n",
      "| fps                     | 137        |\n",
      "| mean 100 episode reward | 2.2e+03    |\n",
      "| n_updates               | 1445111    |\n",
      "| policy_loss             | -183.8239  |\n",
      "| qf1_loss                | 4.1024466  |\n",
      "| qf2_loss                | 5.0960364  |\n",
      "| time_elapsed            | 10481      |\n",
      "| total timesteps         | 1445210    |\n",
      "| value_loss              | 3.6892838  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.034805916 |\n",
      "| ent_coef_loss           | 0.93137693  |\n",
      "| entropy                 | -4.527109   |\n",
      "| episodes                | 1670        |\n",
      "| fps                     | 138         |\n",
      "| mean 100 episode reward | 2.15e+03    |\n",
      "| n_updates               | 1452746     |\n",
      "| policy_loss             | -165.69418  |\n",
      "| qf1_loss                | 32.7357     |\n",
      "| qf2_loss                | 30.12694    |\n",
      "| time_elapsed            | 10523       |\n",
      "| total timesteps         | 1452845     |\n",
      "| value_loss              | 1.8689224   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.033660375 |\n",
      "| ent_coef_loss           | 1.247498    |\n",
      "| entropy                 | -5.4563894  |\n",
      "| episodes                | 1680        |\n",
      "| fps                     | 138         |\n",
      "| mean 100 episode reward | 2.19e+03    |\n",
      "| n_updates               | 1461530     |\n",
      "| policy_loss             | -187.28644  |\n",
      "| qf1_loss                | 2.2659116   |\n",
      "| qf2_loss                | 2.2550516   |\n",
      "| time_elapsed            | 10571       |\n",
      "| total timesteps         | 1461629     |\n",
      "| value_loss              | 2.1738849   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03379959 |\n",
      "| ent_coef_loss           | -0.6314871 |\n",
      "| entropy                 | -4.883421  |\n",
      "| episodes                | 1690       |\n",
      "| fps                     | 138        |\n",
      "| mean 100 episode reward | 2.21e+03   |\n",
      "| n_updates               | 1468618    |\n",
      "| policy_loss             | -187.1125  |\n",
      "| qf1_loss                | 13.2901125 |\n",
      "| qf2_loss                | 16.943054  |\n",
      "| time_elapsed            | 10610      |\n",
      "| total timesteps         | 1468717    |\n",
      "| value_loss              | 10.536381  |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03594739 |\n",
      "| ent_coef_loss           | 1.286088   |\n",
      "| entropy                 | -4.8848996 |\n",
      "| episodes                | 1700       |\n",
      "| fps                     | 138        |\n",
      "| mean 100 episode reward | 2.19e+03   |\n",
      "| n_updates               | 1476085    |\n",
      "| policy_loss             | -188.90363 |\n",
      "| qf1_loss                | 3.3949757  |\n",
      "| qf2_loss                | 4.37254    |\n",
      "| time_elapsed            | 10651      |\n",
      "| total timesteps         | 1476184    |\n",
      "| value_loss              | 1.5677023  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035816565 |\n",
      "| ent_coef_loss           | 3.3793182   |\n",
      "| entropy                 | -4.6272426  |\n",
      "| episodes                | 1710        |\n",
      "| fps                     | 138         |\n",
      "| mean 100 episode reward | 2.21e+03    |\n",
      "| n_updates               | 1484637     |\n",
      "| policy_loss             | -176.80289  |\n",
      "| qf1_loss                | 6.4964943   |\n",
      "| qf2_loss                | 8.373882    |\n",
      "| time_elapsed            | 10698       |\n",
      "| total timesteps         | 1484736     |\n",
      "| value_loss              | 1.474248    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035662398 |\n",
      "| ent_coef_loss           | -1.4938037  |\n",
      "| entropy                 | -4.861227   |\n",
      "| episodes                | 1720        |\n",
      "| fps                     | 139         |\n",
      "| mean 100 episode reward | 2.34e+03    |\n",
      "| n_updates               | 1494637     |\n",
      "| policy_loss             | -193.10419  |\n",
      "| qf1_loss                | 312.42923   |\n",
      "| qf2_loss                | 312.62732   |\n",
      "| time_elapsed            | 10752       |\n",
      "| total timesteps         | 1494736     |\n",
      "| value_loss              | 1.815588    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03436947 |\n",
      "| ent_coef_loss           | 1.1189266  |\n",
      "| entropy                 | -5.012519  |\n",
      "| episodes                | 1730       |\n",
      "| fps                     | 139        |\n",
      "| mean 100 episode reward | 2.38e+03   |\n",
      "| n_updates               | 1503193    |\n",
      "| policy_loss             | -182.46353 |\n",
      "| qf1_loss                | 4.856541   |\n",
      "| qf2_loss                | 4.8730345  |\n",
      "| time_elapsed            | 10799      |\n",
      "| total timesteps         | 1503292    |\n",
      "| value_loss              | 1.7633203  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03427199 |\n",
      "| ent_coef_loss           | 0.60704046 |\n",
      "| entropy                 | -4.1795473 |\n",
      "| episodes                | 1740       |\n",
      "| fps                     | 139        |\n",
      "| mean 100 episode reward | 2.39e+03   |\n",
      "| n_updates               | 1512834    |\n",
      "| policy_loss             | -170.34871 |\n",
      "| qf1_loss                | 8.908588   |\n",
      "| qf2_loss                | 6.247774   |\n",
      "| time_elapsed            | 10851      |\n",
      "| total timesteps         | 1512933    |\n",
      "| value_loss              | 1.3747354  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.034799006 |\n",
      "| ent_coef_loss           | 0.64825875  |\n",
      "| entropy                 | -4.4086714  |\n",
      "| episodes                | 1750        |\n",
      "| fps                     | 139         |\n",
      "| mean 100 episode reward | 2.43e+03    |\n",
      "| n_updates               | 1522755     |\n",
      "| policy_loss             | -173.90775  |\n",
      "| qf1_loss                | 4.4516296   |\n",
      "| qf2_loss                | 3.6347878   |\n",
      "| time_elapsed            | 10906       |\n",
      "| total timesteps         | 1522854     |\n",
      "| value_loss              | 1.0669372   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036094528 |\n",
      "| ent_coef_loss           | -0.5516324  |\n",
      "| entropy                 | -4.625869   |\n",
      "| episodes                | 1760        |\n",
      "| fps                     | 139         |\n",
      "| mean 100 episode reward | 2.43e+03    |\n",
      "| n_updates               | 1532439     |\n",
      "| policy_loss             | -184.84174  |\n",
      "| qf1_loss                | 5.919684    |\n",
      "| qf2_loss                | 6.7004833   |\n",
      "| time_elapsed            | 10959       |\n",
      "| total timesteps         | 1532538     |\n",
      "| value_loss              | 1.8739097   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.038818013 |\n",
      "| ent_coef_loss           | 0.6159476   |\n",
      "| entropy                 | -4.715779   |\n",
      "| episodes                | 1770        |\n",
      "| fps                     | 140         |\n",
      "| mean 100 episode reward | 2.4e+03     |\n",
      "| n_updates               | 1540364     |\n",
      "| policy_loss             | -167.46906  |\n",
      "| qf1_loss                | 16.15464    |\n",
      "| qf2_loss                | 10.851827   |\n",
      "| time_elapsed            | 11002       |\n",
      "| total timesteps         | 1540463     |\n",
      "| value_loss              | 6.6930227   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03540188 |\n",
      "| ent_coef_loss           | -2.1648371 |\n",
      "| entropy                 | -4.900446  |\n",
      "| episodes                | 1780       |\n",
      "| fps                     | 140        |\n",
      "| mean 100 episode reward | 2.4e+03    |\n",
      "| n_updates               | 1549167    |\n",
      "| policy_loss             | -175.5979  |\n",
      "| qf1_loss                | 10.944836  |\n",
      "| qf2_loss                | 10.658851  |\n",
      "| time_elapsed            | 11050      |\n",
      "| total timesteps         | 1549266    |\n",
      "| value_loss              | 1.4608268  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.037206195 |\n",
      "| ent_coef_loss           | -0.554449   |\n",
      "| entropy                 | -4.7776937  |\n",
      "| episodes                | 1790        |\n",
      "| fps                     | 140         |\n",
      "| mean 100 episode reward | 2.45e+03    |\n",
      "| n_updates               | 1558048     |\n",
      "| policy_loss             | -166.59955  |\n",
      "| qf1_loss                | 6.001648    |\n",
      "| qf2_loss                | 3.5207658   |\n",
      "| time_elapsed            | 11099       |\n",
      "| total timesteps         | 1558147     |\n",
      "| value_loss              | 2.3676772   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.0378204  |\n",
      "| ent_coef_loss           | 0.46343577 |\n",
      "| entropy                 | -4.3424945 |\n",
      "| episodes                | 1800       |\n",
      "| fps                     | 140        |\n",
      "| mean 100 episode reward | 2.53e+03   |\n",
      "| n_updates               | 1568048    |\n",
      "| policy_loss             | -183.09283 |\n",
      "| qf1_loss                | 4.726629   |\n",
      "| qf2_loss                | 8.762122   |\n",
      "| time_elapsed            | 11153      |\n",
      "| total timesteps         | 1568147    |\n",
      "| value_loss              | 8.183672   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.037688505 |\n",
      "| ent_coef_loss           | -0.7551609  |\n",
      "| entropy                 | -4.9114723  |\n",
      "| episodes                | 1810        |\n",
      "| fps                     | 140         |\n",
      "| mean 100 episode reward | 2.63e+03    |\n",
      "| n_updates               | 1578048     |\n",
      "| policy_loss             | -189.84106  |\n",
      "| qf1_loss                | 63.164658   |\n",
      "| qf2_loss                | 55.833652   |\n",
      "| time_elapsed            | 11208       |\n",
      "| total timesteps         | 1578147     |\n",
      "| value_loss              | 7.4602537   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.037421074 |\n",
      "| ent_coef_loss           | -2.028324   |\n",
      "| entropy                 | -4.8012743  |\n",
      "| episodes                | 1820        |\n",
      "| fps                     | 140         |\n",
      "| mean 100 episode reward | 2.62e+03    |\n",
      "| n_updates               | 1587610     |\n",
      "| policy_loss             | -194.70306  |\n",
      "| qf1_loss                | 4.4601355   |\n",
      "| qf2_loss                | 5.3888254   |\n",
      "| time_elapsed            | 11267       |\n",
      "| total timesteps         | 1587709     |\n",
      "| value_loss              | 2.0311692   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.037883554 |\n",
      "| ent_coef_loss           | -1.4803176  |\n",
      "| entropy                 | -4.768909   |\n",
      "| episodes                | 1830        |\n",
      "| fps                     | 141         |\n",
      "| mean 100 episode reward | 2.6e+03     |\n",
      "| n_updates               | 1596097     |\n",
      "| policy_loss             | -191.05579  |\n",
      "| qf1_loss                | 296.89615   |\n",
      "| qf2_loss                | 302.48584   |\n",
      "| time_elapsed            | 11319       |\n",
      "| total timesteps         | 1596196     |\n",
      "| value_loss              | 3.4979033   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.038077645 |\n",
      "| ent_coef_loss           | 1.2714968   |\n",
      "| entropy                 | -3.7215211  |\n",
      "| episodes                | 1840        |\n",
      "| fps                     | 141         |\n",
      "| mean 100 episode reward | 2.59e+03    |\n",
      "| n_updates               | 1604950     |\n",
      "| policy_loss             | -168.46765  |\n",
      "| qf1_loss                | 10.864494   |\n",
      "| qf2_loss                | 7.622929    |\n",
      "| time_elapsed            | 11369       |\n",
      "| total timesteps         | 1605049     |\n",
      "| value_loss              | 2.8632545   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.040029753 |\n",
      "| ent_coef_loss           | 0.58388984  |\n",
      "| entropy                 | -3.9005227  |\n",
      "| episodes                | 1850        |\n",
      "| fps                     | 141         |\n",
      "| mean 100 episode reward | 2.57e+03    |\n",
      "| n_updates               | 1613659     |\n",
      "| policy_loss             | -173.71326  |\n",
      "| qf1_loss                | 4.099928    |\n",
      "| qf2_loss                | 3.2159028   |\n",
      "| time_elapsed            | 11419       |\n",
      "| total timesteps         | 1613758     |\n",
      "| value_loss              | 2.6980865   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.038608182 |\n",
      "| ent_coef_loss           | 2.1979623   |\n",
      "| entropy                 | -4.6295605  |\n",
      "| episodes                | 1860        |\n",
      "| fps                     | 141         |\n",
      "| mean 100 episode reward | 2.49e+03    |\n",
      "| n_updates               | 1621726     |\n",
      "| policy_loss             | -193.9708   |\n",
      "| qf1_loss                | 9.326443    |\n",
      "| qf2_loss                | 6.8698673   |\n",
      "| time_elapsed            | 11468       |\n",
      "| total timesteps         | 1621825     |\n",
      "| value_loss              | 2.0619597   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.03830753  |\n",
      "| ent_coef_loss           | -0.67649406 |\n",
      "| entropy                 | -3.6874473  |\n",
      "| episodes                | 1870        |\n",
      "| fps                     | 141         |\n",
      "| mean 100 episode reward | 2.57e+03    |\n",
      "| n_updates               | 1630842     |\n",
      "| policy_loss             | -191.50867  |\n",
      "| qf1_loss                | 2.9785428   |\n",
      "| qf2_loss                | 2.9946613   |\n",
      "| time_elapsed            | 11543       |\n",
      "| total timesteps         | 1630941     |\n",
      "| value_loss              | 1.045253    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036170345 |\n",
      "| ent_coef_loss           | 0.573431    |\n",
      "| entropy                 | -4.539178   |\n",
      "| episodes                | 1880        |\n",
      "| fps                     | 141         |\n",
      "| mean 100 episode reward | 2.56e+03    |\n",
      "| n_updates               | 1639870     |\n",
      "| policy_loss             | -177.89719  |\n",
      "| qf1_loss                | 12.217707   |\n",
      "| qf2_loss                | 9.64181     |\n",
      "| time_elapsed            | 11626       |\n",
      "| total timesteps         | 1639969     |\n",
      "| value_loss              | 1.6930857   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.037207898 |\n",
      "| ent_coef_loss           | 1.9397188   |\n",
      "| entropy                 | -5.1756773  |\n",
      "| episodes                | 1890        |\n",
      "| fps                     | 140         |\n",
      "| mean 100 episode reward | 2.58e+03    |\n",
      "| n_updates               | 1648735     |\n",
      "| policy_loss             | -201.675    |\n",
      "| qf1_loss                | 4.9898114   |\n",
      "| qf2_loss                | 7.458684    |\n",
      "| time_elapsed            | 11711       |\n",
      "| total timesteps         | 1648834     |\n",
      "| value_loss              | 1.4426197   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.039771948 |\n",
      "| ent_coef_loss           | -1.8555182  |\n",
      "| entropy                 | -5.0824738  |\n",
      "| episodes                | 1900        |\n",
      "| fps                     | 140         |\n",
      "| mean 100 episode reward | 2.51e+03    |\n",
      "| n_updates               | 1657397     |\n",
      "| policy_loss             | -201.81187  |\n",
      "| qf1_loss                | 3.297701    |\n",
      "| qf2_loss                | 4.0081286   |\n",
      "| time_elapsed            | 11796       |\n",
      "| total timesteps         | 1657496     |\n",
      "| value_loss              | 2.148147    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03795816 |\n",
      "| ent_coef_loss           | 0.08446169 |\n",
      "| entropy                 | -4.9229116 |\n",
      "| episodes                | 1910       |\n",
      "| fps                     | 140        |\n",
      "| mean 100 episode reward | 2.49e+03   |\n",
      "| n_updates               | 1666456    |\n",
      "| policy_loss             | -188.5946  |\n",
      "| qf1_loss                | 6.594634   |\n",
      "| qf2_loss                | 8.321391   |\n",
      "| time_elapsed            | 11888      |\n",
      "| total timesteps         | 1666555    |\n",
      "| value_loss              | 2.9410186  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03727902 |\n",
      "| ent_coef_loss           | 0.5058465  |\n",
      "| entropy                 | -3.7818093 |\n",
      "| episodes                | 1920       |\n",
      "| fps                     | 139        |\n",
      "| mean 100 episode reward | 2.4e+03    |\n",
      "| n_updates               | 1673021    |\n",
      "| policy_loss             | -181.06744 |\n",
      "| qf1_loss                | 6.6102514  |\n",
      "| qf2_loss                | 4.4193277  |\n",
      "| time_elapsed            | 11953      |\n",
      "| total timesteps         | 1673120    |\n",
      "| value_loss              | 1.4728489  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.039235167 |\n",
      "| ent_coef_loss           | -0.15646017 |\n",
      "| entropy                 | -4.269445   |\n",
      "| episodes                | 1930        |\n",
      "| fps                     | 139         |\n",
      "| mean 100 episode reward | 2.46e+03    |\n",
      "| n_updates               | 1682923     |\n",
      "| policy_loss             | -183.08179  |\n",
      "| qf1_loss                | 4.5138083   |\n",
      "| qf2_loss                | 4.089102    |\n",
      "| time_elapsed            | 12051       |\n",
      "| total timesteps         | 1683022     |\n",
      "| value_loss              | 2.687626    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.040717337 |\n",
      "| ent_coef_loss           | 0.51097715  |\n",
      "| entropy                 | -4.3303485  |\n",
      "| episodes                | 1940        |\n",
      "| fps                     | 139         |\n",
      "| mean 100 episode reward | 2.39e+03    |\n",
      "| n_updates               | 1690481     |\n",
      "| policy_loss             | -190.94855  |\n",
      "| qf1_loss                | 14.087303   |\n",
      "| qf2_loss                | 4.181756    |\n",
      "| time_elapsed            | 12126       |\n",
      "| total timesteps         | 1690580     |\n",
      "| value_loss              | 4.623949    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03939755 |\n",
      "| ent_coef_loss           | 0.7382158  |\n",
      "| entropy                 | -4.1288223 |\n",
      "| episodes                | 1950       |\n",
      "| fps                     | 139        |\n",
      "| mean 100 episode reward | 2.34e+03   |\n",
      "| n_updates               | 1698277    |\n",
      "| policy_loss             | -179.44989 |\n",
      "| qf1_loss                | 3.173049   |\n",
      "| qf2_loss                | 4.15137    |\n",
      "| time_elapsed            | 12204      |\n",
      "| total timesteps         | 1698376    |\n",
      "| value_loss              | 1.7686615  |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.040788196 |\n",
      "| ent_coef_loss           | -1.8244916  |\n",
      "| entropy                 | -4.340324   |\n",
      "| episodes                | 1960        |\n",
      "| fps                     | 138         |\n",
      "| mean 100 episode reward | 2.45e+03    |\n",
      "| n_updates               | 1707953     |\n",
      "| policy_loss             | -194.83432  |\n",
      "| qf1_loss                | 3.1342082   |\n",
      "| qf2_loss                | 2.7137866   |\n",
      "| time_elapsed            | 12303       |\n",
      "| total timesteps         | 1708052     |\n",
      "| value_loss              | 1.5772961   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.039644588 |\n",
      "| ent_coef_loss           | -2.350742   |\n",
      "| entropy                 | -4.5543594  |\n",
      "| episodes                | 1970        |\n",
      "| fps                     | 138         |\n",
      "| mean 100 episode reward | 2.4e+03     |\n",
      "| n_updates               | 1717172     |\n",
      "| policy_loss             | -188.76404  |\n",
      "| qf1_loss                | 4.2341843   |\n",
      "| qf2_loss                | 4.0165377   |\n",
      "| time_elapsed            | 12398       |\n",
      "| total timesteps         | 1717271     |\n",
      "| value_loss              | 1.5368066   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.042276196 |\n",
      "| ent_coef_loss           | 1.623567    |\n",
      "| entropy                 | -4.7145634  |\n",
      "| episodes                | 1980        |\n",
      "| fps                     | 138         |\n",
      "| mean 100 episode reward | 2.42e+03    |\n",
      "| n_updates               | 1725300     |\n",
      "| policy_loss             | -184.32129  |\n",
      "| qf1_loss                | 11.176193   |\n",
      "| qf2_loss                | 6.359413    |\n",
      "| time_elapsed            | 12482       |\n",
      "| total timesteps         | 1725399     |\n",
      "| value_loss              | 1.8518462   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.041116405 |\n",
      "| ent_coef_loss           | -1.1928372  |\n",
      "| entropy                 | -4.5297146  |\n",
      "| episodes                | 1990        |\n",
      "| fps                     | 137         |\n",
      "| mean 100 episode reward | 2.47e+03    |\n",
      "| n_updates               | 1735211     |\n",
      "| policy_loss             | -186.6092   |\n",
      "| qf1_loss                | 6.74802     |\n",
      "| qf2_loss                | 7.8555703   |\n",
      "| time_elapsed            | 12584       |\n",
      "| total timesteps         | 1735310     |\n",
      "| value_loss              | 2.1976647   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.0400355  |\n",
      "| ent_coef_loss           | 0.97759974 |\n",
      "| entropy                 | -4.078518  |\n",
      "| episodes                | 2000       |\n",
      "| fps                     | 137        |\n",
      "| mean 100 episode reward | 2.43e+03   |\n",
      "| n_updates               | 1742917    |\n",
      "| policy_loss             | -188.5516  |\n",
      "| qf1_loss                | 8.685833   |\n",
      "| qf2_loss                | 3.6097386  |\n",
      "| time_elapsed            | 12662      |\n",
      "| total timesteps         | 1743016    |\n",
      "| value_loss              | 1.9888425  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.042010937 |\n",
      "| ent_coef_loss           | -0.25573006 |\n",
      "| entropy                 | -3.7780712  |\n",
      "| episodes                | 2010        |\n",
      "| fps                     | 137         |\n",
      "| mean 100 episode reward | 2.42e+03    |\n",
      "| n_updates               | 1751622     |\n",
      "| policy_loss             | -193.78508  |\n",
      "| qf1_loss                | 8.376036    |\n",
      "| qf2_loss                | 8.46557     |\n",
      "| time_elapsed            | 12753       |\n",
      "| total timesteps         | 1751721     |\n",
      "| value_loss              | 2.6545837   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.04283761 |\n",
      "| ent_coef_loss           | 0.5783692  |\n",
      "| entropy                 | -3.7460194 |\n",
      "| episodes                | 2020       |\n",
      "| fps                     | 137        |\n",
      "| mean 100 episode reward | 2.5e+03    |\n",
      "| n_updates               | 1761115    |\n",
      "| policy_loss             | -187.15114 |\n",
      "| qf1_loss                | 7.27066    |\n",
      "| qf2_loss                | 9.693792   |\n",
      "| time_elapsed            | 12851      |\n",
      "| total timesteps         | 1761214    |\n",
      "| value_loss              | 3.7207232  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.044300005 |\n",
      "| ent_coef_loss           | -1.2403986  |\n",
      "| entropy                 | -4.202136   |\n",
      "| episodes                | 2030        |\n",
      "| fps                     | 136         |\n",
      "| mean 100 episode reward | 2.52e+03    |\n",
      "| n_updates               | 1770883     |\n",
      "| policy_loss             | -207.51588  |\n",
      "| qf1_loss                | 386.46967   |\n",
      "| qf2_loss                | 387.57666   |\n",
      "| time_elapsed            | 12952       |\n",
      "| total timesteps         | 1770982     |\n",
      "| value_loss              | 2.263998    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.04035691 |\n",
      "| ent_coef_loss           | -1.1398523 |\n",
      "| entropy                 | -3.6037064 |\n",
      "| episodes                | 2040       |\n",
      "| fps                     | 136        |\n",
      "| mean 100 episode reward | 2.62e+03   |\n",
      "| n_updates               | 1780182    |\n",
      "| policy_loss             | -192.155   |\n",
      "| qf1_loss                | 8.623099   |\n",
      "| qf2_loss                | 7.678873   |\n",
      "| time_elapsed            | 13049      |\n",
      "| total timesteps         | 1780281    |\n",
      "| value_loss              | 4.020562   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.042316675 |\n",
      "| ent_coef_loss           | -2.7856781  |\n",
      "| entropy                 | -3.9405437  |\n",
      "| episodes                | 2050        |\n",
      "| fps                     | 136         |\n",
      "| mean 100 episode reward | 2.69e+03    |\n",
      "| n_updates               | 1788779     |\n",
      "| policy_loss             | -193.46562  |\n",
      "| qf1_loss                | 7.5116367   |\n",
      "| qf2_loss                | 6.7229404   |\n",
      "| time_elapsed            | 13139       |\n",
      "| total timesteps         | 1788878     |\n",
      "| value_loss              | 1.3183178   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03775989 |\n",
      "| ent_coef_loss           | 0.7809055  |\n",
      "| entropy                 | -4.947636  |\n",
      "| episodes                | 2060       |\n",
      "| fps                     | 135        |\n",
      "| mean 100 episode reward | 2.64e+03   |\n",
      "| n_updates               | 1797516    |\n",
      "| policy_loss             | -211.62918 |\n",
      "| qf1_loss                | 3.5870109  |\n",
      "| qf2_loss                | 2.5697236  |\n",
      "| time_elapsed            | 13230      |\n",
      "| total timesteps         | 1797615    |\n",
      "| value_loss              | 0.83551294 |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.038334336 |\n",
      "| ent_coef_loss           | 3.2397773   |\n",
      "| entropy                 | -4.280307   |\n",
      "| episodes                | 2070        |\n",
      "| fps                     | 135         |\n",
      "| mean 100 episode reward | 2.73e+03    |\n",
      "| n_updates               | 1807357     |\n",
      "| policy_loss             | -199.80843  |\n",
      "| qf1_loss                | 16.458689   |\n",
      "| qf2_loss                | 7.9939327   |\n",
      "| time_elapsed            | 13333       |\n",
      "| total timesteps         | 1807456     |\n",
      "| value_loss              | 15.517306   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.037931092 |\n",
      "| ent_coef_loss           | 0.40423995  |\n",
      "| entropy                 | -4.2157145  |\n",
      "| episodes                | 2080        |\n",
      "| fps                     | 135         |\n",
      "| mean 100 episode reward | 2.79e+03    |\n",
      "| n_updates               | 1817337     |\n",
      "| policy_loss             | -212.25854  |\n",
      "| qf1_loss                | 2.092225    |\n",
      "| qf2_loss                | 2.4227939   |\n",
      "| time_elapsed            | 13428       |\n",
      "| total timesteps         | 1817436     |\n",
      "| value_loss              | 1.7438624   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| current_lr              | 0.0003       |\n",
      "| ent_coef                | 0.039121404  |\n",
      "| ent_coef_loss           | -0.079816215 |\n",
      "| entropy                 | -4.293209    |\n",
      "| episodes                | 2090         |\n",
      "| fps                     | 135          |\n",
      "| mean 100 episode reward | 2.6e+03      |\n",
      "| n_updates               | 1822990      |\n",
      "| policy_loss             | -208.18866   |\n",
      "| qf1_loss                | 5.1819897    |\n",
      "| qf2_loss                | 4.230557     |\n",
      "| time_elapsed            | 13480        |\n",
      "| total timesteps         | 1823089      |\n",
      "| value_loss              | 3.0064309    |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.041695554 |\n",
      "| ent_coef_loss           | -0.32056797 |\n",
      "| entropy                 | -4.0882154  |\n",
      "| episodes                | 2100        |\n",
      "| fps                     | 135         |\n",
      "| mean 100 episode reward | 2.68e+03    |\n",
      "| n_updates               | 1831240     |\n",
      "| policy_loss             | -196.20953  |\n",
      "| qf1_loss                | 15.325557   |\n",
      "| qf2_loss                | 6.9460754   |\n",
      "| time_elapsed            | 13557       |\n",
      "| total timesteps         | 1831339     |\n",
      "| value_loss              | 6.5769205   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.040496726 |\n",
      "| ent_coef_loss           | 2.4170582   |\n",
      "| entropy                 | -4.553322   |\n",
      "| episodes                | 2110        |\n",
      "| fps                     | 134         |\n",
      "| mean 100 episode reward | 2.73e+03    |\n",
      "| n_updates               | 1841003     |\n",
      "| policy_loss             | -212.22488  |\n",
      "| qf1_loss                | 6.223263    |\n",
      "| qf2_loss                | 6.860159    |\n",
      "| time_elapsed            | 13650       |\n",
      "| total timesteps         | 1841102     |\n",
      "| value_loss              | 2.4993649   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.04057112  |\n",
      "| ent_coef_loss           | -0.62769115 |\n",
      "| entropy                 | -4.0857162  |\n",
      "| episodes                | 2120        |\n",
      "| fps                     | 134         |\n",
      "| mean 100 episode reward | 2.67e+03    |\n",
      "| n_updates               | 1847764     |\n",
      "| policy_loss             | -194.07486  |\n",
      "| qf1_loss                | 33.178562   |\n",
      "| qf2_loss                | 49.327694   |\n",
      "| time_elapsed            | 13716       |\n",
      "| total timesteps         | 1847863     |\n",
      "| value_loss              | 3.9887283   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.04066492 |\n",
      "| ent_coef_loss           | 2.2850451  |\n",
      "| entropy                 | -4.169884  |\n",
      "| episodes                | 2130       |\n",
      "| fps                     | 134        |\n",
      "| mean 100 episode reward | 2.61e+03   |\n",
      "| n_updates               | 1855664    |\n",
      "| policy_loss             | -197.39189 |\n",
      "| qf1_loss                | 361.06592  |\n",
      "| qf2_loss                | 368.9788   |\n",
      "| time_elapsed            | 13795      |\n",
      "| total timesteps         | 1855763    |\n",
      "| value_loss              | 2.3356438  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.041721437 |\n",
      "| ent_coef_loss           | 1.2008884   |\n",
      "| entropy                 | -4.1548634  |\n",
      "| episodes                | 2140        |\n",
      "| fps                     | 134         |\n",
      "| mean 100 episode reward | 2.64e+03    |\n",
      "| n_updates               | 1865664     |\n",
      "| policy_loss             | -197.36786  |\n",
      "| qf1_loss                | 7.3728456   |\n",
      "| qf2_loss                | 7.5313497   |\n",
      "| time_elapsed            | 13895       |\n",
      "| total timesteps         | 1865763     |\n",
      "| value_loss              | 3.3626568   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03995762 |\n",
      "| ent_coef_loss           | -0.971305  |\n",
      "| entropy                 | -4.594363  |\n",
      "| episodes                | 2150       |\n",
      "| fps                     | 134        |\n",
      "| mean 100 episode reward | 2.62e+03   |\n",
      "| n_updates               | 1873335    |\n",
      "| policy_loss             | -202.38924 |\n",
      "| qf1_loss                | 4.1086783  |\n",
      "| qf2_loss                | 3.7700794  |\n",
      "| time_elapsed            | 13973      |\n",
      "| total timesteps         | 1873434    |\n",
      "| value_loss              | 2.3303733  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.041986123 |\n",
      "| ent_coef_loss           | -0.52585447 |\n",
      "| entropy                 | -4.2413454  |\n",
      "| episodes                | 2160        |\n",
      "| fps                     | 133         |\n",
      "| mean 100 episode reward | 2.69e+03    |\n",
      "| n_updates               | 1883335     |\n",
      "| policy_loss             | -203.90694  |\n",
      "| qf1_loss                | 10.31085    |\n",
      "| qf2_loss                | 11.847472   |\n",
      "| time_elapsed            | 14074       |\n",
      "| total timesteps         | 1883434     |\n",
      "| value_loss              | 6.00599     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.04012457  |\n",
      "| ent_coef_loss           | -0.23853824 |\n",
      "| entropy                 | -4.8505545  |\n",
      "| episodes                | 2170        |\n",
      "| fps                     | 133         |\n",
      "| mean 100 episode reward | 2.57e+03    |\n",
      "| n_updates               | 1890683     |\n",
      "| policy_loss             | -217.75694  |\n",
      "| qf1_loss                | 14.928639   |\n",
      "| qf2_loss                | 17.66385    |\n",
      "| time_elapsed            | 14150       |\n",
      "| total timesteps         | 1890782     |\n",
      "| value_loss              | 1.8744204   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.047417168 |\n",
      "| ent_coef_loss           | 0.18314236  |\n",
      "| entropy                 | -3.6355112  |\n",
      "| episodes                | 2180        |\n",
      "| fps                     | 133         |\n",
      "| mean 100 episode reward | 2.46e+03    |\n",
      "| n_updates               | 1898310     |\n",
      "| policy_loss             | -216.99872  |\n",
      "| qf1_loss                | 9.273663    |\n",
      "| qf2_loss                | 4.444246    |\n",
      "| time_elapsed            | 14228       |\n",
      "| total timesteps         | 1898409     |\n",
      "| value_loss              | 3.5802312   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.058702372 |\n",
      "| ent_coef_loss           | 0.49317777  |\n",
      "| entropy                 | -2.3176022  |\n",
      "| episodes                | 2190        |\n",
      "| fps                     | 133         |\n",
      "| mean 100 episode reward | 2.36e+03    |\n",
      "| n_updates               | 1900526     |\n",
      "| policy_loss             | -215.24713  |\n",
      "| qf1_loss                | 13.659917   |\n",
      "| qf2_loss                | 15.75325    |\n",
      "| time_elapsed            | 14252       |\n",
      "| total timesteps         | 1900625     |\n",
      "| value_loss              | 5.1877704   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.07712779 |\n",
      "| ent_coef_loss           | 5.530299   |\n",
      "| entropy                 | -0.6436416 |\n",
      "| episodes                | 2200       |\n",
      "| fps                     | 133        |\n",
      "| mean 100 episode reward | 2.08e+03   |\n",
      "| n_updates               | 1902090    |\n",
      "| policy_loss             | -218.89769 |\n",
      "| qf1_loss                | 23.644197  |\n",
      "| qf2_loss                | 31.322792  |\n",
      "| time_elapsed            | 14268      |\n",
      "| total timesteps         | 1902189    |\n",
      "| value_loss              | 15.226579  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.08778249 |\n",
      "| ent_coef_loss           | 1.4530501  |\n",
      "| entropy                 | -0.5806833 |\n",
      "| episodes                | 2210       |\n",
      "| fps                     | 133        |\n",
      "| mean 100 episode reward | 1.77e+03   |\n",
      "| n_updates               | 1902907    |\n",
      "| policy_loss             | -217.05063 |\n",
      "| qf1_loss                | 10.431163  |\n",
      "| qf2_loss                | 12.071766  |\n",
      "| time_elapsed            | 14276      |\n",
      "| total timesteps         | 1903006    |\n",
      "| value_loss              | 6.314872   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.13253796 |\n",
      "| ent_coef_loss           | 5.333423   |\n",
      "| entropy                 | 2.2343795  |\n",
      "| episodes                | 2220       |\n",
      "| fps                     | 133        |\n",
      "| mean 100 episode reward | 1.53e+03   |\n",
      "| n_updates               | 1904364    |\n",
      "| policy_loss             | -240.54945 |\n",
      "| qf1_loss                | 25.953682  |\n",
      "| qf2_loss                | 20.393234  |\n",
      "| time_elapsed            | 14291      |\n",
      "| total timesteps         | 1904463    |\n",
      "| value_loss              | 9.893545   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.21438022 |\n",
      "| ent_coef_loss           | 0.28704822 |\n",
      "| entropy                 | 2.5932846  |\n",
      "| episodes                | 2230       |\n",
      "| fps                     | 133        |\n",
      "| mean 100 episode reward | 1.13e+03   |\n",
      "| n_updates               | 1912829    |\n",
      "| policy_loss             | -581.69165 |\n",
      "| qf1_loss                | 54.17804   |\n",
      "| qf2_loss                | 58.189796  |\n",
      "| time_elapsed            | 14378      |\n",
      "| total timesteps         | 1912928    |\n",
      "| value_loss              | 40.70269   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.354968   |\n",
      "| ent_coef_loss           | 0.73582435 |\n",
      "| entropy                 | 5.0167637  |\n",
      "| episodes                | 2240       |\n",
      "| fps                     | 132        |\n",
      "| mean 100 episode reward | 662        |\n",
      "| n_updates               | 1922103    |\n",
      "| policy_loss             | -656.92505 |\n",
      "| qf1_loss                | 69.86023   |\n",
      "| qf2_loss                | 77.67724   |\n",
      "| time_elapsed            | 14475      |\n",
      "| total timesteps         | 1922202    |\n",
      "| value_loss              | 26.096138  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.38089764 |\n",
      "| ent_coef_loss           | 2.036446   |\n",
      "| entropy                 | 4.8279862  |\n",
      "| episodes                | 2250       |\n",
      "| fps                     | 132        |\n",
      "| mean 100 episode reward | 241        |\n",
      "| n_updates               | 1930321    |\n",
      "| policy_loss             | -862.9758  |\n",
      "| qf1_loss                | 54.74597   |\n",
      "| qf2_loss                | 46.930344  |\n",
      "| time_elapsed            | 14561      |\n",
      "| total timesteps         | 1930420    |\n",
      "| value_loss              | 44.78958   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.3059527  |\n",
      "| ent_coef_loss           | -1.3798603 |\n",
      "| entropy                 | 4.304333   |\n",
      "| episodes                | 2260       |\n",
      "| fps                     | 132        |\n",
      "| mean 100 episode reward | -194       |\n",
      "| n_updates               | 1936434    |\n",
      "| policy_loss             | -911.2544  |\n",
      "| qf1_loss                | 62.127464  |\n",
      "| qf2_loss                | 55.707687  |\n",
      "| time_elapsed            | 14624      |\n",
      "| total timesteps         | 1936533    |\n",
      "| value_loss              | 36.17888   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.15520601 |\n",
      "| ent_coef_loss           | 0.13719106 |\n",
      "| entropy                 | 1.6507361  |\n",
      "| episodes                | 2270       |\n",
      "| fps                     | 132        |\n",
      "| mean 100 episode reward | -522       |\n",
      "| n_updates               | 1943784    |\n",
      "| policy_loss             | -705.58154 |\n",
      "| qf1_loss                | 36.73347   |\n",
      "| qf2_loss                | 30.990059  |\n",
      "| time_elapsed            | 14700      |\n",
      "| total timesteps         | 1943883    |\n",
      "| value_loss              | 16.66269   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.22069667 |\n",
      "| ent_coef_loss           | -1.5430923 |\n",
      "| entropy                 | 4.323269   |\n",
      "| episodes                | 2280       |\n",
      "| fps                     | 132        |\n",
      "| mean 100 episode reward | -889       |\n",
      "| n_updates               | 1951920    |\n",
      "| policy_loss             | -593.45496 |\n",
      "| qf1_loss                | 8309.884   |\n",
      "| qf2_loss                | 8265.919   |\n",
      "| time_elapsed            | 14785      |\n",
      "| total timesteps         | 1952019    |\n",
      "| value_loss              | 21.039633  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.12352601 |\n",
      "| ent_coef_loss           | -0.8661537 |\n",
      "| entropy                 | 1.7225533  |\n",
      "| episodes                | 2290       |\n",
      "| fps                     | 131        |\n",
      "| mean 100 episode reward | -1.03e+03  |\n",
      "| n_updates               | 1959381    |\n",
      "| policy_loss             | -530.0908  |\n",
      "| qf1_loss                | 43.282413  |\n",
      "| qf2_loss                | 35.653038  |\n",
      "| time_elapsed            | 14862      |\n",
      "| total timesteps         | 1959480    |\n",
      "| value_loss              | 8.151173   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.15586875 |\n",
      "| ent_coef_loss           | -0.8494228 |\n",
      "| entropy                 | 3.1211557  |\n",
      "| episodes                | 2300       |\n",
      "| fps                     | 131        |\n",
      "| mean 100 episode reward | -1.12e+03  |\n",
      "| n_updates               | 1966445    |\n",
      "| policy_loss             | -471.74078 |\n",
      "| qf1_loss                | 1661.6886  |\n",
      "| qf2_loss                | 1641.3623  |\n",
      "| time_elapsed            | 14935      |\n",
      "| total timesteps         | 1966544    |\n",
      "| value_loss              | 8.159194   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.09976229 |\n",
      "| ent_coef_loss           | 1.3874555  |\n",
      "| entropy                 | 1.7907717  |\n",
      "| episodes                | 2310       |\n",
      "| fps                     | 131        |\n",
      "| mean 100 episode reward | -1.27e+03  |\n",
      "| n_updates               | 1975635    |\n",
      "| policy_loss             | -361.92505 |\n",
      "| qf1_loss                | 10.084573  |\n",
      "| qf2_loss                | 10.835675  |\n",
      "| time_elapsed            | 15023      |\n",
      "| total timesteps         | 1975734    |\n",
      "| value_loss              | 14.173843  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.074578755 |\n",
      "| ent_coef_loss           | -2.8100438  |\n",
      "| entropy                 | 0.6985896   |\n",
      "| episodes                | 2320        |\n",
      "| fps                     | 131         |\n",
      "| mean 100 episode reward | -1.31e+03   |\n",
      "| n_updates               | 1983745     |\n",
      "| policy_loss             | -309.93243  |\n",
      "| qf1_loss                | 20.948704   |\n",
      "| qf2_loss                | 21.621567   |\n",
      "| time_elapsed            | 15095       |\n",
      "| total timesteps         | 1983844     |\n",
      "| value_loss              | 9.887814    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.053590383 |\n",
      "| ent_coef_loss           | -0.89097446 |\n",
      "| entropy                 | -1.6769254  |\n",
      "| episodes                | 2330        |\n",
      "| fps                     | 131         |\n",
      "| mean 100 episode reward | -1.19e+03   |\n",
      "| n_updates               | 1992761     |\n",
      "| policy_loss             | -272.58295  |\n",
      "| qf1_loss                | 15.958097   |\n",
      "| qf2_loss                | 17.906986   |\n",
      "| time_elapsed            | 15178       |\n",
      "| total timesteps         | 1992860     |\n",
      "| value_loss              | 7.297641    |\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# TRAIN THE MODEL\n",
    "model.learn(total_timesteps=int(2e6), log_interval=10)\n",
    "model.save(\"ant_2M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading a model without an environment, this model cannot be trained until it has a valid environment.\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2cf4179650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2cf4179650>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2cf4179650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2cf4179650>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d7417b690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d7417b690>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d7417b690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d7417b690>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d2066b050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d2066b050>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d2066b050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d2066b050>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d2066b050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d2066b050>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d2066b050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d2066b050>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d2066b050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d2066b050>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d2066b050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d2066b050>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2cf418d3d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2cf418d3d0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2cf418d3d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2cf418d3d0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf4111f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf4111f10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf4111f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf4111f10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6c1af6d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6c1af6d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6c1af6d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6c1af6d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6c0a3750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6c0a3750>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6c0a3750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6c0a3750>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf419bb10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf419bb10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf419bb10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf419bb10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf40c1dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf40c1dd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf40c1dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf40c1dd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf419b7d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf419b7d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf419b7d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf419b7d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf419b7d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf419b7d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf419b7d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf419b7d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf418d990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf418d990>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf418d990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf418d990>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf4111f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf4111f10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf4111f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf4111f10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2cf448cf10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2cf448cf10>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2cf448cf10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2cf448cf10>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf4191690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf4191690>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf4191690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf4191690>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf411d390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf411d390>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf411d390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf411d390>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf448cf10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf448cf10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf448cf10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf448cf10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf419b7d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf419b7d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf419b7d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf419b7d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cec193b90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cec193b90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cec193b90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cec193b90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf40c1dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf40c1dd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf40c1dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf40c1dd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2cf4191ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2cf4191ad0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2cf4191ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2cf4191ad0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf418d990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf418d990>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf418d990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf418d990>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf418d990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf418d990>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf418d990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf418d990>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cec0f9050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cec0f9050>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cec0f9050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cec0f9050>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    }
   ],
   "source": [
    "# RUN THE SAVED MODEL\n",
    "env = gym.make('Ant-v2')\n",
    "model = SAC.load(\"ant_2M\")\n",
    "\n",
    "images = []\n",
    "obs = env.reset()\n",
    "for _ in range(350):\n",
    "    print('working')\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, dones, info = env.step(action)\n",
    "    images.append(env.render(mode='rgb_array'))\n",
    "env.close()\n",
    "    \n",
    "#imageio.mimsave('ant_sac.gif', [np.array(img) for i, img in enumerate(images) if i%2 == 0], fps=29)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800\"\n",
       "            src=\"http://localhost:6010\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f83d5655fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# DISPLAY THE RESULTS\n",
    "%tensorboard --logdir sac_ant_tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
