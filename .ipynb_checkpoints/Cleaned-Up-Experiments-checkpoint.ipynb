{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-Mocap Simulation Efforts\n",
    "\n",
    "This notebook contains the work we've made since pivoting at the start of Week 9 towards simulating realistic gaits with non-mocap RL techniques.\n",
    "\n",
    "To give some context, the focus of these efforts was to determine how visually realistic the learned gaits through non-mocap methods would appear to be for different models. We also experimented with achieving more and more optimal trained agents, which lead to us shifting training from PPO to SAC as discussed in the project report. Below you will find both the scripts we wrote to train our agents and data/graphs collected from training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# Gym provides all the training environments\n",
    "import gym\n",
    "\n",
    "# SAC used for all trained agents\n",
    "from stable_baselines.sac.policies import MlpPolicy\n",
    "from stable_baselines import SAC\n",
    "\n",
    "# Needed for the graphs displayed below\n",
    "%load_ext tensorboard\n",
    "\n",
    "# Needed for making GIFs of simulations\n",
    "import imageio\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task: Walk as far forward as possible without falling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fca8eb97a50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fca8eb97a50>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fca8eb97a50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fca8eb97a50>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fc9fa6840d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fc9fa6840d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fc9fa6840d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fc9fa6840d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fca7463eed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fca7463eed0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fca7463eed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fca7463eed0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fca742c7850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fca742c7850>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fca742c7850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fca742c7850>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fca742c7850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fca742c7850>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fca742c7850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fca742c7850>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fca74272390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fca74272390>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fca74272390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fca74272390>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fca8ea70490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fca8ea70490>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fca8ea70490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fca8ea70490>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fca740cb150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fca740cb150>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fca740cb150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fca740cb150>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fca58418e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fca58418e10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fca58418e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fca58418e10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fca4c61ad90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fca4c61ad90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fca4c61ad90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fca4c61ad90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fc9fa745d50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fc9fa745d50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fc9fa745d50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fc9fa745d50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fca4c61a510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fca4c61a510>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fca4c61a510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fca4c61a510>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fca8ea85fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fca8ea85fd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fca8ea85fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fca8ea85fd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcb297e5810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcb297e5810>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcb297e5810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcb297e5810>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcb297e5810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcb297e5810>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcb297e5810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fcb297e5810>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fca74272a10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fca74272a10>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fca74272a10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fca74272a10>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fca8ea85fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fca8ea85fd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fca8ea85fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fca8ea85fd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fca74272a10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fca74272a10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fca74272a10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fca74272a10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fca4c44a4d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fca4c44a4d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fca4c44a4d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fca4c44a4d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fca4c753090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fca4c753090>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fca4c753090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fca4c753090>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fca8ea89d10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fca8ea89d10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fca8ea89d10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fca8ea89d10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fca58418e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fca58418e10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fca58418e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fca58418e10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fca746b5550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fca746b5550>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fca746b5550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fca746b5550>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fca4c753d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fca4c753d90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fca4c753d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fca4c753d90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fca7463e7d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fca7463e7d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fca7463e7d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fca7463e7d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fca4c41e890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fca4c41e890>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fca4c41e890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fca4c41e890>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "Observation Space Dimensions: 376\n",
      "Action Space Dimensions: 17\n"
     ]
    }
   ],
   "source": [
    "# DEFINE THE ENVIRONMENT/MODEL WITH TUNED PARAMETERS\n",
    "env = gym.make('Humanoid-v2')\n",
    "policy_kwargs = dict(layers=[256, 256])\n",
    "model = SAC(MlpPolicy, env, verbose=1, tensorboard_log=\"./sac_humanoid_walk_tensorboard/\", \n",
    "            policy_kwargs=policy_kwargs, buffer_size=1000000)\n",
    "# PRINT THE STATE SPACE DIMENSIONS\n",
    "obs_dim = env.observation_space.shape[0]\n",
    "act_dim = env.action_space.shape[0]\n",
    "print('Observation Space Dimensions: %d' % obs_dim)\n",
    "print('Action Space Dimensions: %d' % act_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 1.0125033  |\n",
      "| ent_coef_loss           | 0.06119744 |\n",
      "| entropy                 | 20.704313  |\n",
      "| episodes                | 10         |\n",
      "| fps                     | 97         |\n",
      "| mean 100 episode reward | 98.4       |\n",
      "| n_updates               | 80         |\n",
      "| policy_loss             | 22.465284  |\n",
      "| qf1_loss                | 11.124978  |\n",
      "| qf2_loss                | 8.203977   |\n",
      "| time_elapsed            | 1          |\n",
      "| total timesteps         | 179        |\n",
      "| value_loss              | 174.56766  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.9544133  |\n",
      "| ent_coef_loss           | -1.1572626 |\n",
      "| entropy                 | 20.403168  |\n",
      "| episodes                | 20         |\n",
      "| fps                     | 94         |\n",
      "| mean 100 episode reward | 108        |\n",
      "| n_updates               | 316        |\n",
      "| policy_loss             | -2.3990934 |\n",
      "| qf1_loss                | 0.51813656 |\n",
      "| qf2_loss                | 0.5467812  |\n",
      "| time_elapsed            | 4          |\n",
      "| total timesteps         | 415        |\n",
      "| value_loss              | 10.668219  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.8891577   |\n",
      "| ent_coef_loss           | -3.0752764  |\n",
      "| entropy                 | 21.700241   |\n",
      "| episodes                | 30          |\n",
      "| fps                     | 88          |\n",
      "| mean 100 episode reward | 107         |\n",
      "| n_updates               | 525         |\n",
      "| policy_loss             | -14.2423315 |\n",
      "| qf1_loss                | 0.70251644  |\n",
      "| qf2_loss                | 0.6889137   |\n",
      "| time_elapsed            | 7           |\n",
      "| total timesteps         | 624         |\n",
      "| value_loss              | 5.3352      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.8115706  |\n",
      "| ent_coef_loss           | -5.916248  |\n",
      "| entropy                 | 23.042986  |\n",
      "| episodes                | 40         |\n",
      "| fps                     | 88         |\n",
      "| mean 100 episode reward | 113        |\n",
      "| n_updates               | 794        |\n",
      "| policy_loss             | -29.005184 |\n",
      "| qf1_loss                | 1.2019413  |\n",
      "| qf2_loss                | 1.1649554  |\n",
      "| time_elapsed            | 10         |\n",
      "| total timesteps         | 893        |\n",
      "| value_loss              | 2.4184105  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.7393683  |\n",
      "| ent_coef_loss           | -8.613232  |\n",
      "| entropy                 | 22.716064  |\n",
      "| episodes                | 50         |\n",
      "| fps                     | 87         |\n",
      "| mean 100 episode reward | 119        |\n",
      "| n_updates               | 1076       |\n",
      "| policy_loss             | -40.725273 |\n",
      "| qf1_loss                | 3.622107   |\n",
      "| qf2_loss                | 3.279561   |\n",
      "| time_elapsed            | 13         |\n",
      "| total timesteps         | 1175       |\n",
      "| value_loss              | 4.5796423  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.6888414  |\n",
      "| ent_coef_loss           | -10.592568 |\n",
      "| entropy                 | 22.489193  |\n",
      "| episodes                | 60         |\n",
      "| fps                     | 86         |\n",
      "| mean 100 episode reward | 118        |\n",
      "| n_updates               | 1297       |\n",
      "| policy_loss             | -50.334282 |\n",
      "| qf1_loss                | 2.6979723  |\n",
      "| qf2_loss                | 2.7989557  |\n",
      "| time_elapsed            | 16         |\n",
      "| total timesteps         | 1396       |\n",
      "| value_loss              | 5.4930654  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.62427056 |\n",
      "| ent_coef_loss           | -13.403842 |\n",
      "| entropy                 | 22.108063  |\n",
      "| episodes                | 70         |\n",
      "| fps                     | 86         |\n",
      "| mean 100 episode reward | 123        |\n",
      "| n_updates               | 1611       |\n",
      "| policy_loss             | -62.88182  |\n",
      "| qf1_loss                | 4.1122417  |\n",
      "| qf2_loss                | 3.619776   |\n",
      "| time_elapsed            | 19         |\n",
      "| total timesteps         | 1710       |\n",
      "| value_loss              | 10.349296  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.56952125 |\n",
      "| ent_coef_loss           | -15.776991 |\n",
      "| entropy                 | 21.762817  |\n",
      "| episodes                | 80         |\n",
      "| fps                     | 86         |\n",
      "| mean 100 episode reward | 127        |\n",
      "| n_updates               | 1910       |\n",
      "| policy_loss             | -71.248245 |\n",
      "| qf1_loss                | 6.4287796  |\n",
      "| qf2_loss                | 7.911027   |\n",
      "| time_elapsed            | 23         |\n",
      "| total timesteps         | 2009       |\n",
      "| value_loss              | 20.334583  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.4767425  |\n",
      "| ent_coef_loss           | -18.844227 |\n",
      "| entropy                 | 20.878826  |\n",
      "| episodes                | 90         |\n",
      "| fps                     | 87         |\n",
      "| mean 100 episode reward | 150        |\n",
      "| n_updates               | 2529       |\n",
      "| policy_loss             | -92.92145  |\n",
      "| qf1_loss                | 9.190144   |\n",
      "| qf2_loss                | 7.6697125  |\n",
      "| time_elapsed            | 30         |\n",
      "| total timesteps         | 2628       |\n",
      "| value_loss              | 20.027836  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.40211478  |\n",
      "| ent_coef_loss           | -22.043222  |\n",
      "| entropy                 | 20.203209   |\n",
      "| episodes                | 100         |\n",
      "| fps                     | 87          |\n",
      "| mean 100 episode reward | 166         |\n",
      "| n_updates               | 3134        |\n",
      "| policy_loss             | -112.467896 |\n",
      "| qf1_loss                | 11.829196   |\n",
      "| qf2_loss                | 11.159112   |\n",
      "| time_elapsed            | 36          |\n",
      "| total timesteps         | 3233        |\n",
      "| value_loss              | 17.997143   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.33293605 |\n",
      "| ent_coef_loss           | -24.982601 |\n",
      "| entropy                 | 20.049065  |\n",
      "| episodes                | 110        |\n",
      "| fps                     | 87         |\n",
      "| mean 100 episode reward | 189        |\n",
      "| n_updates               | 3817       |\n",
      "| policy_loss             | -131.8073  |\n",
      "| qf1_loss                | 17.377613  |\n",
      "| qf2_loss                | 12.465757  |\n",
      "| time_elapsed            | 44         |\n",
      "| total timesteps         | 3916       |\n",
      "| value_loss              | 15.478849  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.29728726 |\n",
      "| ent_coef_loss           | -25.666069 |\n",
      "| entropy                 | 19.63733   |\n",
      "| episodes                | 120        |\n",
      "| fps                     | 87         |\n",
      "| mean 100 episode reward | 198        |\n",
      "| n_updates               | 4237       |\n",
      "| policy_loss             | -140.4714  |\n",
      "| qf1_loss                | 14.375568  |\n",
      "| qf2_loss                | 17.754604  |\n",
      "| time_elapsed            | 49         |\n",
      "| total timesteps         | 4336       |\n",
      "| value_loss              | 19.468287  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.2523827  |\n",
      "| ent_coef_loss           | -27.12737  |\n",
      "| entropy                 | 19.214508  |\n",
      "| episodes                | 130        |\n",
      "| fps                     | 87         |\n",
      "| mean 100 episode reward | 218        |\n",
      "| n_updates               | 4846       |\n",
      "| policy_loss             | -137.58263 |\n",
      "| qf1_loss                | 25.793324  |\n",
      "| qf2_loss                | 24.253765  |\n",
      "| time_elapsed            | 56         |\n",
      "| total timesteps         | 4945       |\n",
      "| value_loss              | 19.377977  |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.21295615 |\n",
      "| ent_coef_loss           | -29.209871 |\n",
      "| entropy                 | 18.89505   |\n",
      "| episodes                | 140        |\n",
      "| fps                     | 87         |\n",
      "| mean 100 episode reward | 238        |\n",
      "| n_updates               | 5479       |\n",
      "| policy_loss             | -156.94156 |\n",
      "| qf1_loss                | 16.031916  |\n",
      "| qf2_loss                | 12.033306  |\n",
      "| time_elapsed            | 63         |\n",
      "| total timesteps         | 5578       |\n",
      "| value_loss              | 33.884926  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.18249518 |\n",
      "| ent_coef_loss           | -32.414444 |\n",
      "| entropy                 | 18.825909  |\n",
      "| episodes                | 150        |\n",
      "| fps                     | 87         |\n",
      "| mean 100 episode reward | 252        |\n",
      "| n_updates               | 6042       |\n",
      "| policy_loss             | -162.18289 |\n",
      "| qf1_loss                | 30.098217  |\n",
      "| qf2_loss                | 38.950745  |\n",
      "| time_elapsed            | 70         |\n",
      "| total timesteps         | 6141       |\n",
      "| value_loss              | 22.57944   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.15254408 |\n",
      "| ent_coef_loss           | -27.628506 |\n",
      "| entropy                 | 18.200464  |\n",
      "| episodes                | 160        |\n",
      "| fps                     | 87         |\n",
      "| mean 100 episode reward | 277        |\n",
      "| n_updates               | 6704       |\n",
      "| policy_loss             | -154.98166 |\n",
      "| qf1_loss                | 18.055695  |\n",
      "| qf2_loss                | 24.94688   |\n",
      "| time_elapsed            | 77         |\n",
      "| total timesteps         | 6803       |\n",
      "| value_loss              | 22.368639  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.13118824 |\n",
      "| ent_coef_loss           | -30.602484 |\n",
      "| entropy                 | 18.01033   |\n",
      "| episodes                | 170        |\n",
      "| fps                     | 86         |\n",
      "| mean 100 episode reward | 292        |\n",
      "| n_updates               | 7286       |\n",
      "| policy_loss             | -166.12207 |\n",
      "| qf1_loss                | 21.22596   |\n",
      "| qf2_loss                | 22.273788  |\n",
      "| time_elapsed            | 84         |\n",
      "| total timesteps         | 7385       |\n",
      "| value_loss              | 26.313612  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.11490361 |\n",
      "| ent_coef_loss           | -29.836452 |\n",
      "| entropy                 | 17.558891  |\n",
      "| episodes                | 180        |\n",
      "| fps                     | 86         |\n",
      "| mean 100 episode reward | 304        |\n",
      "| n_updates               | 7790       |\n",
      "| policy_loss             | -166.04343 |\n",
      "| qf1_loss                | 18.31955   |\n",
      "| qf2_loss                | 14.394957  |\n",
      "| time_elapsed            | 91         |\n",
      "| total timesteps         | 7889       |\n",
      "| value_loss              | 16.28587   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.09793598 |\n",
      "| ent_coef_loss           | -27.269707 |\n",
      "| entropy                 | 17.354301  |\n",
      "| episodes                | 190        |\n",
      "| fps                     | 86         |\n",
      "| mean 100 episode reward | 305        |\n",
      "| n_updates               | 8430       |\n",
      "| policy_loss             | -177.32858 |\n",
      "| qf1_loss                | 13.253316  |\n",
      "| qf2_loss                | 17.871521  |\n",
      "| time_elapsed            | 98         |\n",
      "| total timesteps         | 8529       |\n",
      "| value_loss              | 15.269998  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.08384285 |\n",
      "| ent_coef_loss           | -28.546589 |\n",
      "| entropy                 | 17.259373  |\n",
      "| episodes                | 200        |\n",
      "| fps                     | 84         |\n",
      "| mean 100 episode reward | 305        |\n",
      "| n_updates               | 9062       |\n",
      "| policy_loss             | -181.84647 |\n",
      "| qf1_loss                | 20.222431  |\n",
      "| qf2_loss                | 18.010527  |\n",
      "| time_elapsed            | 107        |\n",
      "| total timesteps         | 9161       |\n",
      "| value_loss              | 19.043793  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.070702486 |\n",
      "| ent_coef_loss           | -24.564644  |\n",
      "| entropy                 | 16.905891   |\n",
      "| episodes                | 210         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 306         |\n",
      "| n_updates               | 9764        |\n",
      "| policy_loss             | -173.4393   |\n",
      "| qf1_loss                | 25.69077    |\n",
      "| qf2_loss                | 24.23481    |\n",
      "| time_elapsed            | 116         |\n",
      "| total timesteps         | 9863        |\n",
      "| value_loss              | 30.879848   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.06042513 |\n",
      "| ent_coef_loss           | -17.903103 |\n",
      "| entropy                 | 16.065002  |\n",
      "| episodes                | 220        |\n",
      "| fps                     | 85         |\n",
      "| mean 100 episode reward | 319        |\n",
      "| n_updates               | 10492      |\n",
      "| policy_loss             | -173.39142 |\n",
      "| qf1_loss                | 27.072964  |\n",
      "| qf2_loss                | 29.223164  |\n",
      "| time_elapsed            | 124        |\n",
      "| total timesteps         | 10591      |\n",
      "| value_loss              | 15.484298  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.052604783 |\n",
      "| ent_coef_loss           | -15.768726  |\n",
      "| entropy                 | 16.442316   |\n",
      "| episodes                | 230         |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 324         |\n",
      "| n_updates               | 11188       |\n",
      "| policy_loss             | -193.73581  |\n",
      "| qf1_loss                | 15.858789   |\n",
      "| qf2_loss                | 20.433746   |\n",
      "| time_elapsed            | 132         |\n",
      "| total timesteps         | 11287       |\n",
      "| value_loss              | 30.895166   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.04740392 |\n",
      "| ent_coef_loss           | -8.710045  |\n",
      "| entropy                 | 15.350883  |\n",
      "| episodes                | 240        |\n",
      "| fps                     | 85         |\n",
      "| mean 100 episode reward | 325        |\n",
      "| n_updates               | 11828      |\n",
      "| policy_loss             | -160.25937 |\n",
      "| qf1_loss                | 26.523512  |\n",
      "| qf2_loss                | 22.681032  |\n",
      "| time_elapsed            | 140        |\n",
      "| total timesteps         | 11927      |\n",
      "| value_loss              | 48.61867   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.042913496 |\n",
      "| ent_coef_loss           | -8.88969    |\n",
      "| entropy                 | 15.228067   |\n",
      "| episodes                | 250         |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 329         |\n",
      "| n_updates               | 12495       |\n",
      "| policy_loss             | -177.51395  |\n",
      "| qf1_loss                | 25.267555   |\n",
      "| qf2_loss                | 23.372738   |\n",
      "| time_elapsed            | 148         |\n",
      "| total timesteps         | 12594       |\n",
      "| value_loss              | 17.455212   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03895132 |\n",
      "| ent_coef_loss           | -1.9013168 |\n",
      "| entropy                 | 15.29756   |\n",
      "| episodes                | 260        |\n",
      "| fps                     | 85         |\n",
      "| mean 100 episode reward | 331        |\n",
      "| n_updates               | 13200      |\n",
      "| policy_loss             | -174.34492 |\n",
      "| qf1_loss                | 20.992893  |\n",
      "| qf2_loss                | 21.55784   |\n",
      "| time_elapsed            | 156        |\n",
      "| total timesteps         | 13299      |\n",
      "| value_loss              | 21.641598  |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.034614637 |\n",
      "| ent_coef_loss           | -8.215527   |\n",
      "| entropy                 | 15.240572   |\n",
      "| episodes                | 270         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 335         |\n",
      "| n_updates               | 13886       |\n",
      "| policy_loss             | -173.10144  |\n",
      "| qf1_loss                | 37.088688   |\n",
      "| qf2_loss                | 41.026405   |\n",
      "| time_elapsed            | 164         |\n",
      "| total timesteps         | 13985       |\n",
      "| value_loss              | 50.987045   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.033174377 |\n",
      "| ent_coef_loss           | -4.037989   |\n",
      "| entropy                 | 15.20296    |\n",
      "| episodes                | 280         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 342         |\n",
      "| n_updates               | 14538       |\n",
      "| policy_loss             | -161.33522  |\n",
      "| qf1_loss                | 30.464998   |\n",
      "| qf2_loss                | 31.075954   |\n",
      "| time_elapsed            | 172         |\n",
      "| total timesteps         | 14637       |\n",
      "| value_loss              | 26.430822   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.033046357 |\n",
      "| ent_coef_loss           | 4.510425    |\n",
      "| entropy                 | 14.817541   |\n",
      "| episodes                | 290         |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 341         |\n",
      "| n_updates               | 15176       |\n",
      "| policy_loss             | -148.55542  |\n",
      "| qf1_loss                | 26.26422    |\n",
      "| qf2_loss                | 28.17683    |\n",
      "| time_elapsed            | 179         |\n",
      "| total timesteps         | 15275       |\n",
      "| value_loss              | 26.110825   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.032739382 |\n",
      "| ent_coef_loss           | 2.7368808   |\n",
      "| entropy                 | 14.672256   |\n",
      "| episodes                | 300         |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 340         |\n",
      "| n_updates               | 15734       |\n",
      "| policy_loss             | -165.23859  |\n",
      "| qf1_loss                | 21.91856    |\n",
      "| qf2_loss                | 23.270452   |\n",
      "| time_elapsed            | 186         |\n",
      "| total timesteps         | 15833       |\n",
      "| value_loss              | 18.093607   |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| current_lr              | 0.0003       |\n",
      "| ent_coef                | 0.03208289   |\n",
      "| ent_coef_loss           | -0.095465064 |\n",
      "| entropy                 | 14.8334055   |\n",
      "| episodes                | 310          |\n",
      "| fps                     | 84           |\n",
      "| mean 100 episode reward | 341          |\n",
      "| n_updates               | 16402        |\n",
      "| policy_loss             | -180.74248   |\n",
      "| qf1_loss                | 29.932617    |\n",
      "| qf2_loss                | 24.77969     |\n",
      "| time_elapsed            | 194          |\n",
      "| total timesteps         | 16501        |\n",
      "| value_loss              | 41.195457    |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030630251 |\n",
      "| ent_coef_loss           | 1.0768744   |\n",
      "| entropy                 | 14.952648   |\n",
      "| episodes                | 320         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 341         |\n",
      "| n_updates               | 17054       |\n",
      "| policy_loss             | -168.07895  |\n",
      "| qf1_loss                | 23.649698   |\n",
      "| qf2_loss                | 28.791582   |\n",
      "| time_elapsed            | 201         |\n",
      "| total timesteps         | 17153       |\n",
      "| value_loss              | 19.426285   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031135954 |\n",
      "| ent_coef_loss           | 6.947121    |\n",
      "| entropy                 | 14.584168   |\n",
      "| episodes                | 330         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 341         |\n",
      "| n_updates               | 17725       |\n",
      "| policy_loss             | -162.26657  |\n",
      "| qf1_loss                | 25.703625   |\n",
      "| qf2_loss                | 18.435188   |\n",
      "| time_elapsed            | 210         |\n",
      "| total timesteps         | 17824       |\n",
      "| value_loss              | 43.311386   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.032728408 |\n",
      "| ent_coef_loss           | 3.390902    |\n",
      "| entropy                 | 14.676775   |\n",
      "| episodes                | 340         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 346         |\n",
      "| n_updates               | 18478       |\n",
      "| policy_loss             | -157.97499  |\n",
      "| qf1_loss                | 13.732407   |\n",
      "| qf2_loss                | 12.021284   |\n",
      "| time_elapsed            | 218         |\n",
      "| total timesteps         | 18577       |\n",
      "| value_loss              | 15.629811   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.030682   |\n",
      "| ent_coef_loss           | -4.1557207 |\n",
      "| entropy                 | 14.7995205 |\n",
      "| episodes                | 350        |\n",
      "| fps                     | 84         |\n",
      "| mean 100 episode reward | 348        |\n",
      "| n_updates               | 19131      |\n",
      "| policy_loss             | -161.29086 |\n",
      "| qf1_loss                | 21.738556  |\n",
      "| qf2_loss                | 15.610068  |\n",
      "| time_elapsed            | 226        |\n",
      "| total timesteps         | 19230      |\n",
      "| value_loss              | 10.056982  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028289106 |\n",
      "| ent_coef_loss           | 2.2079372   |\n",
      "| entropy                 | 14.547414   |\n",
      "| episodes                | 360         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 341         |\n",
      "| n_updates               | 19727       |\n",
      "| policy_loss             | -151.51096  |\n",
      "| qf1_loss                | 25.241892   |\n",
      "| qf2_loss                | 34.342102   |\n",
      "| time_elapsed            | 233         |\n",
      "| total timesteps         | 19826       |\n",
      "| value_loss              | 16.510027   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.026911765 |\n",
      "| ent_coef_loss           | 6.4005184   |\n",
      "| entropy                 | 14.2589245  |\n",
      "| episodes                | 370         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 345         |\n",
      "| n_updates               | 20508       |\n",
      "| policy_loss             | -147.1713   |\n",
      "| qf1_loss                | 10.796417   |\n",
      "| qf2_loss                | 12.395942   |\n",
      "| time_elapsed            | 242         |\n",
      "| total timesteps         | 20607       |\n",
      "| value_loss              | 13.097912   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028452838 |\n",
      "| ent_coef_loss           | -6.3728113  |\n",
      "| entropy                 | 14.955286   |\n",
      "| episodes                | 380         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 344         |\n",
      "| n_updates               | 21141       |\n",
      "| policy_loss             | -151.08305  |\n",
      "| qf1_loss                | 17.232067   |\n",
      "| qf2_loss                | 13.577698   |\n",
      "| time_elapsed            | 250         |\n",
      "| total timesteps         | 21240       |\n",
      "| value_loss              | 13.358202   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.027033307 |\n",
      "| ent_coef_loss           | 2.5431812   |\n",
      "| entropy                 | 14.47817    |\n",
      "| episodes                | 390         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 343         |\n",
      "| n_updates               | 21750       |\n",
      "| policy_loss             | -141.7665   |\n",
      "| qf1_loss                | 16.410782   |\n",
      "| qf2_loss                | 12.473917   |\n",
      "| time_elapsed            | 258         |\n",
      "| total timesteps         | 21849       |\n",
      "| value_loss              | 17.088127   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.026362928 |\n",
      "| ent_coef_loss           | -9.37888    |\n",
      "| entropy                 | 14.606434   |\n",
      "| episodes                | 400         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 357         |\n",
      "| n_updates               | 22589       |\n",
      "| policy_loss             | -135.58908  |\n",
      "| qf1_loss                | 12.199048   |\n",
      "| qf2_loss                | 15.35365    |\n",
      "| time_elapsed            | 268         |\n",
      "| total timesteps         | 22688       |\n",
      "| value_loss              | 30.521551   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.026057212 |\n",
      "| ent_coef_loss           | -1.4226665  |\n",
      "| entropy                 | 14.728348   |\n",
      "| episodes                | 410         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 362         |\n",
      "| n_updates               | 23342       |\n",
      "| policy_loss             | -153.4196   |\n",
      "| qf1_loss                | 12.087395   |\n",
      "| qf2_loss                | 18.09408    |\n",
      "| time_elapsed            | 277         |\n",
      "| total timesteps         | 23441       |\n",
      "| value_loss              | 12.881041   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.025476098 |\n",
      "| ent_coef_loss           | -3.3333855  |\n",
      "| entropy                 | 14.255647   |\n",
      "| episodes                | 420         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 370         |\n",
      "| n_updates               | 24198       |\n",
      "| policy_loss             | -141.0019   |\n",
      "| qf1_loss                | 21.4388     |\n",
      "| qf2_loss                | 21.200886   |\n",
      "| time_elapsed            | 287         |\n",
      "| total timesteps         | 24297       |\n",
      "| value_loss              | 24.233612   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.025081282 |\n",
      "| ent_coef_loss           | -3.0086808  |\n",
      "| entropy                 | 14.46191    |\n",
      "| episodes                | 430         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 371         |\n",
      "| n_updates               | 24853       |\n",
      "| policy_loss             | -140.43692  |\n",
      "| qf1_loss                | 11.198189   |\n",
      "| qf2_loss                | 13.508974   |\n",
      "| time_elapsed            | 294         |\n",
      "| total timesteps         | 24952       |\n",
      "| value_loss              | 12.402882   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.024374893 |\n",
      "| ent_coef_loss           | -6.769656   |\n",
      "| entropy                 | 14.556588   |\n",
      "| episodes                | 440         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 372         |\n",
      "| n_updates               | 25604       |\n",
      "| policy_loss             | -140.41684  |\n",
      "| qf1_loss                | 23.783472   |\n",
      "| qf2_loss                | 16.667923   |\n",
      "| time_elapsed            | 303         |\n",
      "| total timesteps         | 25703       |\n",
      "| value_loss              | 23.284893   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.024839826 |\n",
      "| ent_coef_loss           | 3.8391738   |\n",
      "| entropy                 | 14.650056   |\n",
      "| episodes                | 450         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 379         |\n",
      "| n_updates               | 26403       |\n",
      "| policy_loss             | -134.3405   |\n",
      "| qf1_loss                | 22.014538   |\n",
      "| qf2_loss                | 16.878626   |\n",
      "| time_elapsed            | 313         |\n",
      "| total timesteps         | 26502       |\n",
      "| value_loss              | 22.393276   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.024432033 |\n",
      "| ent_coef_loss           | 1.7038181   |\n",
      "| entropy                 | 14.481007   |\n",
      "| episodes                | 460         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 389         |\n",
      "| n_updates               | 27185       |\n",
      "| policy_loss             | -158.15817  |\n",
      "| qf1_loss                | 15.582773   |\n",
      "| qf2_loss                | 11.567409   |\n",
      "| time_elapsed            | 322         |\n",
      "| total timesteps         | 27284       |\n",
      "| value_loss              | 15.232784   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.023771655 |\n",
      "| ent_coef_loss           | 2.91747     |\n",
      "| entropy                 | 14.334192   |\n",
      "| episodes                | 470         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 390         |\n",
      "| n_updates               | 27939       |\n",
      "| policy_loss             | -151.45811  |\n",
      "| qf1_loss                | 10.378284   |\n",
      "| qf2_loss                | 9.888224    |\n",
      "| time_elapsed            | 331         |\n",
      "| total timesteps         | 28038       |\n",
      "| value_loss              | 11.279968   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.023334123 |\n",
      "| ent_coef_loss           | 2.179316    |\n",
      "| entropy                 | 14.710414   |\n",
      "| episodes                | 480         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 394         |\n",
      "| n_updates               | 28641       |\n",
      "| policy_loss             | -137.30954  |\n",
      "| qf1_loss                | 13.260685   |\n",
      "| qf2_loss                | 14.4116955  |\n",
      "| time_elapsed            | 339         |\n",
      "| total timesteps         | 28740       |\n",
      "| value_loss              | 16.230568   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.023894476 |\n",
      "| ent_coef_loss           | -4.435982   |\n",
      "| entropy                 | 14.357632   |\n",
      "| episodes                | 490         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 395         |\n",
      "| n_updates               | 29286       |\n",
      "| policy_loss             | -146.38998  |\n",
      "| qf1_loss                | 11.066259   |\n",
      "| qf2_loss                | 11.56292    |\n",
      "| time_elapsed            | 347         |\n",
      "| total timesteps         | 29385       |\n",
      "| value_loss              | 11.300538   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.025803056 |\n",
      "| ent_coef_loss           | 4.7244945   |\n",
      "| entropy                 | 14.69162    |\n",
      "| episodes                | 500         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 384         |\n",
      "| n_updates               | 29888       |\n",
      "| policy_loss             | -143.97833  |\n",
      "| qf1_loss                | 9.59837     |\n",
      "| qf2_loss                | 7.6874447   |\n",
      "| time_elapsed            | 354         |\n",
      "| total timesteps         | 29987       |\n",
      "| value_loss              | 8.179801    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02484245 |\n",
      "| ent_coef_loss           | -1.20201   |\n",
      "| entropy                 | 14.643574  |\n",
      "| episodes                | 510        |\n",
      "| fps                     | 84         |\n",
      "| mean 100 episode reward | 375        |\n",
      "| n_updates               | 30478      |\n",
      "| policy_loss             | -142.85545 |\n",
      "| qf1_loss                | 7.3137197  |\n",
      "| qf2_loss                | 8.174442   |\n",
      "| time_elapsed            | 361        |\n",
      "| total timesteps         | 30577      |\n",
      "| value_loss              | 11.880911  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02360865 |\n",
      "| ent_coef_loss           | 2.156072   |\n",
      "| entropy                 | 14.48136   |\n",
      "| episodes                | 520        |\n",
      "| fps                     | 84         |\n",
      "| mean 100 episode reward | 365        |\n",
      "| n_updates               | 31089      |\n",
      "| policy_loss             | -132.22705 |\n",
      "| qf1_loss                | 10.271678  |\n",
      "| qf2_loss                | 10.556091  |\n",
      "| time_elapsed            | 368        |\n",
      "| total timesteps         | 31188      |\n",
      "| value_loss              | 11.804316  |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02345964 |\n",
      "| ent_coef_loss           | 8.760165   |\n",
      "| entropy                 | 14.863079  |\n",
      "| episodes                | 530        |\n",
      "| fps                     | 84         |\n",
      "| mean 100 episode reward | 367        |\n",
      "| n_updates               | 31817      |\n",
      "| policy_loss             | -160.20456 |\n",
      "| qf1_loss                | 10.708256  |\n",
      "| qf2_loss                | 12.858675  |\n",
      "| time_elapsed            | 377        |\n",
      "| total timesteps         | 31916      |\n",
      "| value_loss              | 9.410799   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.022857789 |\n",
      "| ent_coef_loss           | -0.46138573 |\n",
      "| entropy                 | 14.51716    |\n",
      "| episodes                | 540         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 365         |\n",
      "| n_updates               | 32546       |\n",
      "| policy_loss             | -140.9625   |\n",
      "| qf1_loss                | 17.35345    |\n",
      "| qf2_loss                | 16.978088   |\n",
      "| time_elapsed            | 385         |\n",
      "| total timesteps         | 32645       |\n",
      "| value_loss              | 23.724155   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.022296865 |\n",
      "| ent_coef_loss           | 3.4612005   |\n",
      "| entropy                 | 13.8328285  |\n",
      "| episodes                | 550         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 358         |\n",
      "| n_updates               | 33215       |\n",
      "| policy_loss             | -144.33084  |\n",
      "| qf1_loss                | 10.985901   |\n",
      "| qf2_loss                | 10.531967   |\n",
      "| time_elapsed            | 393         |\n",
      "| total timesteps         | 33314       |\n",
      "| value_loss              | 5.656151    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02353079 |\n",
      "| ent_coef_loss           | -3.2424304 |\n",
      "| entropy                 | 14.646822  |\n",
      "| episodes                | 560        |\n",
      "| fps                     | 84         |\n",
      "| mean 100 episode reward | 359        |\n",
      "| n_updates               | 34031      |\n",
      "| policy_loss             | -150.36542 |\n",
      "| qf1_loss                | 12.026604  |\n",
      "| qf2_loss                | 19.674736  |\n",
      "| time_elapsed            | 403        |\n",
      "| total timesteps         | 34130      |\n",
      "| value_loss              | 13.71878   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02338927 |\n",
      "| ent_coef_loss           | 7.486129   |\n",
      "| entropy                 | 14.844045  |\n",
      "| episodes                | 570        |\n",
      "| fps                     | 84         |\n",
      "| mean 100 episode reward | 360        |\n",
      "| n_updates               | 34819      |\n",
      "| policy_loss             | -145.51083 |\n",
      "| qf1_loss                | 8.494654   |\n",
      "| qf2_loss                | 11.125505  |\n",
      "| time_elapsed            | 412        |\n",
      "| total timesteps         | 34918      |\n",
      "| value_loss              | 12.154156  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.022511456 |\n",
      "| ent_coef_loss           | -6.5699987  |\n",
      "| entropy                 | 14.67705    |\n",
      "| episodes                | 580         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 368         |\n",
      "| n_updates               | 35666       |\n",
      "| policy_loss             | -132.69957  |\n",
      "| qf1_loss                | 7.843907    |\n",
      "| qf2_loss                | 9.17316     |\n",
      "| time_elapsed            | 422         |\n",
      "| total timesteps         | 35765       |\n",
      "| value_loss              | 7.6894207   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.022647573 |\n",
      "| ent_coef_loss           | 7.490626    |\n",
      "| entropy                 | 14.6204815  |\n",
      "| episodes                | 590         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 374         |\n",
      "| n_updates               | 36412       |\n",
      "| policy_loss             | -144.29868  |\n",
      "| qf1_loss                | 12.541809   |\n",
      "| qf2_loss                | 10.643619   |\n",
      "| time_elapsed            | 431         |\n",
      "| total timesteps         | 36511       |\n",
      "| value_loss              | 11.571001   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02282266 |\n",
      "| ent_coef_loss           | 10.702605  |\n",
      "| entropy                 | 14.731488  |\n",
      "| episodes                | 600        |\n",
      "| fps                     | 84         |\n",
      "| mean 100 episode reward | 379        |\n",
      "| n_updates               | 37112      |\n",
      "| policy_loss             | -159.10071 |\n",
      "| qf1_loss                | 10.443103  |\n",
      "| qf2_loss                | 14.121983  |\n",
      "| time_elapsed            | 439        |\n",
      "| total timesteps         | 37211      |\n",
      "| value_loss              | 12.441357  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02349482 |\n",
      "| ent_coef_loss           | -2.9316096 |\n",
      "| entropy                 | 14.803289  |\n",
      "| episodes                | 610        |\n",
      "| fps                     | 84         |\n",
      "| mean 100 episode reward | 382        |\n",
      "| n_updates               | 37764      |\n",
      "| policy_loss             | -145.04208 |\n",
      "| qf1_loss                | 8.61368    |\n",
      "| qf2_loss                | 7.6837797  |\n",
      "| time_elapsed            | 447        |\n",
      "| total timesteps         | 37863      |\n",
      "| value_loss              | 7.9445267  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.021718258 |\n",
      "| ent_coef_loss           | 10.10428    |\n",
      "| entropy                 | 14.138486   |\n",
      "| episodes                | 620         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 391         |\n",
      "| n_updates               | 38549       |\n",
      "| policy_loss             | -130.62341  |\n",
      "| qf1_loss                | 8.182379    |\n",
      "| qf2_loss                | 11.732786   |\n",
      "| time_elapsed            | 456         |\n",
      "| total timesteps         | 38648       |\n",
      "| value_loss              | 6.1676407   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.022029072 |\n",
      "| ent_coef_loss           | -3.0416088  |\n",
      "| entropy                 | 15.301498   |\n",
      "| episodes                | 630         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 398         |\n",
      "| n_updates               | 39387       |\n",
      "| policy_loss             | -142.19052  |\n",
      "| qf1_loss                | 8.336       |\n",
      "| qf2_loss                | 10.60507    |\n",
      "| time_elapsed            | 466         |\n",
      "| total timesteps         | 39486       |\n",
      "| value_loss              | 11.422369   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02108372 |\n",
      "| ent_coef_loss           | 2.343679   |\n",
      "| entropy                 | 14.73439   |\n",
      "| episodes                | 640        |\n",
      "| fps                     | 84         |\n",
      "| mean 100 episode reward | 406        |\n",
      "| n_updates               | 40244      |\n",
      "| policy_loss             | -151.48656 |\n",
      "| qf1_loss                | 7.950203   |\n",
      "| qf2_loss                | 6.763062   |\n",
      "| time_elapsed            | 476        |\n",
      "| total timesteps         | 40343      |\n",
      "| value_loss              | 8.29808    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.021089818 |\n",
      "| ent_coef_loss           | 6.626378    |\n",
      "| entropy                 | 13.822533   |\n",
      "| episodes                | 650         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 409         |\n",
      "| n_updates               | 40951       |\n",
      "| policy_loss             | -147.57472  |\n",
      "| qf1_loss                | 11.151835   |\n",
      "| qf2_loss                | 11.181138   |\n",
      "| time_elapsed            | 484         |\n",
      "| total timesteps         | 41050       |\n",
      "| value_loss              | 11.040905   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02111207 |\n",
      "| ent_coef_loss           | -3.9263606 |\n",
      "| entropy                 | 14.916639  |\n",
      "| episodes                | 660        |\n",
      "| fps                     | 84         |\n",
      "| mean 100 episode reward | 406        |\n",
      "| n_updates               | 41678      |\n",
      "| policy_loss             | -150.51184 |\n",
      "| qf1_loss                | 6.4043946  |\n",
      "| qf2_loss                | 8.534687   |\n",
      "| time_elapsed            | 493        |\n",
      "| total timesteps         | 41777      |\n",
      "| value_loss              | 5.54049    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.020920517 |\n",
      "| ent_coef_loss           | 6.5396233   |\n",
      "| entropy                 | 14.575903   |\n",
      "| episodes                | 670         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 402         |\n",
      "| n_updates               | 42379       |\n",
      "| policy_loss             | -139.5477   |\n",
      "| qf1_loss                | 9.526787    |\n",
      "| qf2_loss                | 9.901844    |\n",
      "| time_elapsed            | 501         |\n",
      "| total timesteps         | 42478       |\n",
      "| value_loss              | 6.900326    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.021471104 |\n",
      "| ent_coef_loss           | -5.0965166  |\n",
      "| entropy                 | 14.620501   |\n",
      "| episodes                | 680         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 398         |\n",
      "| n_updates               | 43156       |\n",
      "| policy_loss             | -128.18236  |\n",
      "| qf1_loss                | 12.367277   |\n",
      "| qf2_loss                | 12.123291   |\n",
      "| time_elapsed            | 510         |\n",
      "| total timesteps         | 43255       |\n",
      "| value_loss              | 16.25853    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.020990273 |\n",
      "| ent_coef_loss           | -7.5475397  |\n",
      "| entropy                 | 14.289497   |\n",
      "| episodes                | 690         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 396         |\n",
      "| n_updates               | 43881       |\n",
      "| policy_loss             | -148.11758  |\n",
      "| qf1_loss                | 10.557983   |\n",
      "| qf2_loss                | 8.748049    |\n",
      "| time_elapsed            | 519         |\n",
      "| total timesteps         | 43980       |\n",
      "| value_loss              | 8.38941     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.021351136 |\n",
      "| ent_coef_loss           | 3.0421622   |\n",
      "| entropy                 | 14.507201   |\n",
      "| episodes                | 700         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 404         |\n",
      "| n_updates               | 44719       |\n",
      "| policy_loss             | -145.95415  |\n",
      "| qf1_loss                | 6.7552137   |\n",
      "| qf2_loss                | 9.197535    |\n",
      "| time_elapsed            | 528         |\n",
      "| total timesteps         | 44818       |\n",
      "| value_loss              | 7.678665    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02042998 |\n",
      "| ent_coef_loss           | -3.766633  |\n",
      "| entropy                 | 14.946854  |\n",
      "| episodes                | 710        |\n",
      "| fps                     | 84         |\n",
      "| mean 100 episode reward | 408        |\n",
      "| n_updates               | 45443      |\n",
      "| policy_loss             | -133.09146 |\n",
      "| qf1_loss                | 7.8345213  |\n",
      "| qf2_loss                | 12.636549  |\n",
      "| time_elapsed            | 537        |\n",
      "| total timesteps         | 45542      |\n",
      "| value_loss              | 13.145618  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.020136172 |\n",
      "| ent_coef_loss           | -0.47509742 |\n",
      "| entropy                 | 14.486801   |\n",
      "| episodes                | 720         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 409         |\n",
      "| n_updates               | 46272       |\n",
      "| policy_loss             | -150.68243  |\n",
      "| qf1_loss                | 11.624931   |\n",
      "| qf2_loss                | 9.907316    |\n",
      "| time_elapsed            | 549         |\n",
      "| total timesteps         | 46371       |\n",
      "| value_loss              | 11.997977   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.019923778 |\n",
      "| ent_coef_loss           | -4.1080265  |\n",
      "| entropy                 | 15.171011   |\n",
      "| episodes                | 730         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 409         |\n",
      "| n_updates               | 47133       |\n",
      "| policy_loss             | -146.23218  |\n",
      "| qf1_loss                | 7.213092    |\n",
      "| qf2_loss                | 8.7460785   |\n",
      "| time_elapsed            | 559         |\n",
      "| total timesteps         | 47232       |\n",
      "| value_loss              | 7.111809    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.020990249 |\n",
      "| ent_coef_loss           | 5.5455523   |\n",
      "| entropy                 | 14.29958    |\n",
      "| episodes                | 740         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 412         |\n",
      "| n_updates               | 48069       |\n",
      "| policy_loss             | -134.2474   |\n",
      "| qf1_loss                | 8.928366    |\n",
      "| qf2_loss                | 7.5645275   |\n",
      "| time_elapsed            | 570         |\n",
      "| total timesteps         | 48168       |\n",
      "| value_loss              | 7.0399485   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.020371938 |\n",
      "| ent_coef_loss           | 2.5898635   |\n",
      "| entropy                 | 13.988668   |\n",
      "| episodes                | 750         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 416         |\n",
      "| n_updates               | 48872       |\n",
      "| policy_loss             | -153.96233  |\n",
      "| qf1_loss                | 11.34597    |\n",
      "| qf2_loss                | 11.370853   |\n",
      "| time_elapsed            | 580         |\n",
      "| total timesteps         | 48971       |\n",
      "| value_loss              | 13.663446   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02024594 |\n",
      "| ent_coef_loss           | -7.845292  |\n",
      "| entropy                 | 14.610966  |\n",
      "| episodes                | 760        |\n",
      "| fps                     | 84         |\n",
      "| mean 100 episode reward | 417        |\n",
      "| n_updates               | 49626      |\n",
      "| policy_loss             | -146.33258 |\n",
      "| qf1_loss                | 9.77622    |\n",
      "| qf2_loss                | 11.577167  |\n",
      "| time_elapsed            | 589        |\n",
      "| total timesteps         | 49725      |\n",
      "| value_loss              | 19.253288  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.021168187 |\n",
      "| ent_coef_loss           | -2.7607274  |\n",
      "| entropy                 | 14.221828   |\n",
      "| episodes                | 770         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 425         |\n",
      "| n_updates               | 50503       |\n",
      "| policy_loss             | -144.69568  |\n",
      "| qf1_loss                | 8.706518    |\n",
      "| qf2_loss                | 9.625148    |\n",
      "| time_elapsed            | 599         |\n",
      "| total timesteps         | 50602       |\n",
      "| value_loss              | 7.2458353   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02068694 |\n",
      "| ent_coef_loss           | 3.2789805  |\n",
      "| entropy                 | 14.33873   |\n",
      "| episodes                | 780        |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 422        |\n",
      "| n_updates               | 51250      |\n",
      "| policy_loss             | -147.58362 |\n",
      "| qf1_loss                | 10.634875  |\n",
      "| qf2_loss                | 9.856796   |\n",
      "| time_elapsed            | 613        |\n",
      "| total timesteps         | 51349      |\n",
      "| value_loss              | 8.175265   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.0195836  |\n",
      "| ent_coef_loss           | 5.817676   |\n",
      "| entropy                 | 14.099024  |\n",
      "| episodes                | 790        |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 428        |\n",
      "| n_updates               | 52117      |\n",
      "| policy_loss             | -156.18253 |\n",
      "| qf1_loss                | 9.894957   |\n",
      "| qf2_loss                | 11.857658  |\n",
      "| time_elapsed            | 624        |\n",
      "| total timesteps         | 52216      |\n",
      "| value_loss              | 6.3636813  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.01969059 |\n",
      "| ent_coef_loss           | -0.7623328 |\n",
      "| entropy                 | 14.413048  |\n",
      "| episodes                | 800        |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 418        |\n",
      "| n_updates               | 52814      |\n",
      "| policy_loss             | -128.5365  |\n",
      "| qf1_loss                | 5.6439743  |\n",
      "| qf2_loss                | 7.3846064  |\n",
      "| time_elapsed            | 632        |\n",
      "| total timesteps         | 52913      |\n",
      "| value_loss              | 5.9773965  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.01940481 |\n",
      "| ent_coef_loss           | -6.948046  |\n",
      "| entropy                 | 14.701941  |\n",
      "| episodes                | 810        |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 423        |\n",
      "| n_updates               | 53621      |\n",
      "| policy_loss             | -135.06918 |\n",
      "| qf1_loss                | 6.8755455  |\n",
      "| qf2_loss                | 9.041778   |\n",
      "| time_elapsed            | 641        |\n",
      "| total timesteps         | 53720      |\n",
      "| value_loss              | 6.38319    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.019667571 |\n",
      "| ent_coef_loss           | 1.2676356   |\n",
      "| entropy                 | 14.418239   |\n",
      "| episodes                | 820         |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 424         |\n",
      "| n_updates               | 54452       |\n",
      "| policy_loss             | -131.51016  |\n",
      "| qf1_loss                | 5.437169    |\n",
      "| qf2_loss                | 3.8791142   |\n",
      "| time_elapsed            | 651         |\n",
      "| total timesteps         | 54551       |\n",
      "| value_loss              | 7.4240627   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.019244567 |\n",
      "| ent_coef_loss           | 3.6681342   |\n",
      "| entropy                 | 14.634224   |\n",
      "| episodes                | 830         |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 428         |\n",
      "| n_updates               | 55383       |\n",
      "| policy_loss             | -150.36809  |\n",
      "| qf1_loss                | 9.589024    |\n",
      "| qf2_loss                | 6.4272738   |\n",
      "| time_elapsed            | 662         |\n",
      "| total timesteps         | 55482       |\n",
      "| value_loss              | 5.736169    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.019319737 |\n",
      "| ent_coef_loss           | -2.7570066  |\n",
      "| entropy                 | 13.8168125  |\n",
      "| episodes                | 840         |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 432         |\n",
      "| n_updates               | 56376       |\n",
      "| policy_loss             | -134.4628   |\n",
      "| qf1_loss                | 7.9675865   |\n",
      "| qf2_loss                | 8.315899    |\n",
      "| time_elapsed            | 675         |\n",
      "| total timesteps         | 56475       |\n",
      "| value_loss              | 7.7707148   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.01959799 |\n",
      "| ent_coef_loss           | -0.4833989 |\n",
      "| entropy                 | 14.275812  |\n",
      "| episodes                | 850        |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 431        |\n",
      "| n_updates               | 57216      |\n",
      "| policy_loss             | -147.86713 |\n",
      "| qf1_loss                | 10.926787  |\n",
      "| qf2_loss                | 7.646709   |\n",
      "| time_elapsed            | 685        |\n",
      "| total timesteps         | 57315      |\n",
      "| value_loss              | 7.7136984  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.01864925 |\n",
      "| ent_coef_loss           | -1.3180374 |\n",
      "| entropy                 | 13.702561  |\n",
      "| episodes                | 860        |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 431        |\n",
      "| n_updates               | 58020      |\n",
      "| policy_loss             | -149.28983 |\n",
      "| qf1_loss                | 6.313385   |\n",
      "| qf2_loss                | 10.708382  |\n",
      "| time_elapsed            | 695        |\n",
      "| total timesteps         | 58119      |\n",
      "| value_loss              | 8.079536   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.01936209 |\n",
      "| ent_coef_loss           | -1.9242351 |\n",
      "| entropy                 | 13.978514  |\n",
      "| episodes                | 870        |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 427        |\n",
      "| n_updates               | 58890      |\n",
      "| policy_loss             | -150.79245 |\n",
      "| qf1_loss                | 11.900009  |\n",
      "| qf2_loss                | 7.8115363  |\n",
      "| time_elapsed            | 707        |\n",
      "| total timesteps         | 58989      |\n",
      "| value_loss              | 5.8150787  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.020040609 |\n",
      "| ent_coef_loss           | -0.72536254 |\n",
      "| entropy                 | 14.881411   |\n",
      "| episodes                | 880         |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 438         |\n",
      "| n_updates               | 59853       |\n",
      "| policy_loss             | -127.50573  |\n",
      "| qf1_loss                | 5.578719    |\n",
      "| qf2_loss                | 6.1859097   |\n",
      "| time_elapsed            | 719         |\n",
      "| total timesteps         | 59952       |\n",
      "| value_loss              | 4.207038    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.019639658 |\n",
      "| ent_coef_loss           | -0.54431033 |\n",
      "| entropy                 | 14.224201   |\n",
      "| episodes                | 890         |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 435         |\n",
      "| n_updates               | 60636       |\n",
      "| policy_loss             | -144.66882  |\n",
      "| qf1_loss                | 13.039801   |\n",
      "| qf2_loss                | 8.913351    |\n",
      "| time_elapsed            | 730         |\n",
      "| total timesteps         | 60735       |\n",
      "| value_loss              | 6.100926    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.020635817 |\n",
      "| ent_coef_loss           | -5.002112   |\n",
      "| entropy                 | 14.36463    |\n",
      "| episodes                | 900         |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 447         |\n",
      "| n_updates               | 61570       |\n",
      "| policy_loss             | -162.51163  |\n",
      "| qf1_loss                | 6.796918    |\n",
      "| qf2_loss                | 7.3936095   |\n",
      "| time_elapsed            | 741         |\n",
      "| total timesteps         | 61669       |\n",
      "| value_loss              | 7.6544237   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.020377675 |\n",
      "| ent_coef_loss           | 3.161664    |\n",
      "| entropy                 | 14.710535   |\n",
      "| episodes                | 910         |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 454         |\n",
      "| n_updates               | 62564       |\n",
      "| policy_loss             | -151.06088  |\n",
      "| qf1_loss                | 6.883707    |\n",
      "| qf2_loss                | 8.568787    |\n",
      "| time_elapsed            | 753         |\n",
      "| total timesteps         | 62663       |\n",
      "| value_loss              | 9.175472    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.020037962 |\n",
      "| ent_coef_loss           | 6.1514173   |\n",
      "| entropy                 | 14.525033   |\n",
      "| episodes                | 920         |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 459         |\n",
      "| n_updates               | 63531       |\n",
      "| policy_loss             | -131.87897  |\n",
      "| qf1_loss                | 9.435118    |\n",
      "| qf2_loss                | 9.309918    |\n",
      "| time_elapsed            | 765         |\n",
      "| total timesteps         | 63630       |\n",
      "| value_loss              | 8.996816    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.019466816 |\n",
      "| ent_coef_loss           | 1.3782105   |\n",
      "| entropy                 | 14.206264   |\n",
      "| episodes                | 930         |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 456         |\n",
      "| n_updates               | 64450       |\n",
      "| policy_loss             | -139.76022  |\n",
      "| qf1_loss                | 9.988564    |\n",
      "| qf2_loss                | 8.125635    |\n",
      "| time_elapsed            | 777         |\n",
      "| total timesteps         | 64549       |\n",
      "| value_loss              | 7.5016785   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.019914428 |\n",
      "| ent_coef_loss           | 4.0951333   |\n",
      "| entropy                 | 13.956382   |\n",
      "| episodes                | 940         |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 456         |\n",
      "| n_updates               | 65516       |\n",
      "| policy_loss             | -168.15712  |\n",
      "| qf1_loss                | 12.784153   |\n",
      "| qf2_loss                | 13.348814   |\n",
      "| time_elapsed            | 791         |\n",
      "| total timesteps         | 65615       |\n",
      "| value_loss              | 8.36985     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.0202206  |\n",
      "| ent_coef_loss           | -4.384291  |\n",
      "| entropy                 | 14.392784  |\n",
      "| episodes                | 950        |\n",
      "| fps                     | 82         |\n",
      "| mean 100 episode reward | 452        |\n",
      "| n_updates               | 66331      |\n",
      "| policy_loss             | -141.09529 |\n",
      "| qf1_loss                | 9.096476   |\n",
      "| qf2_loss                | 9.376747   |\n",
      "| time_elapsed            | 802        |\n",
      "| total timesteps         | 66430      |\n",
      "| value_loss              | 5.338047   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.020388065 |\n",
      "| ent_coef_loss           | 12.876976   |\n",
      "| entropy                 | 14.192883   |\n",
      "| episodes                | 960         |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 459         |\n",
      "| n_updates               | 67297       |\n",
      "| policy_loss             | -143.29541  |\n",
      "| qf1_loss                | 9.485785    |\n",
      "| qf2_loss                | 7.6415634   |\n",
      "| time_elapsed            | 818         |\n",
      "| total timesteps         | 67396       |\n",
      "| value_loss              | 8.975731    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.020299915 |\n",
      "| ent_coef_loss           | 5.1260843   |\n",
      "| entropy                 | 14.311816   |\n",
      "| episodes                | 970         |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 460         |\n",
      "| n_updates               | 68146       |\n",
      "| policy_loss             | -161.39026  |\n",
      "| qf1_loss                | 9.248813    |\n",
      "| qf2_loss                | 10.127536   |\n",
      "| time_elapsed            | 828         |\n",
      "| total timesteps         | 68245       |\n",
      "| value_loss              | 6.772669    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.020285875 |\n",
      "| ent_coef_loss           | -2.2738657  |\n",
      "| entropy                 | 14.393362   |\n",
      "| episodes                | 980         |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 446         |\n",
      "| n_updates               | 68880       |\n",
      "| policy_loss             | -153.5069   |\n",
      "| qf1_loss                | 8.241764    |\n",
      "| qf2_loss                | 6.2833076   |\n",
      "| time_elapsed            | 837         |\n",
      "| total timesteps         | 68979       |\n",
      "| value_loss              | 6.5904493   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.019445283 |\n",
      "| ent_coef_loss           | -4.3819833  |\n",
      "| entropy                 | 14.282099   |\n",
      "| episodes                | 990         |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 445         |\n",
      "| n_updates               | 69723       |\n",
      "| policy_loss             | -165.75389  |\n",
      "| qf1_loss                | 10.440579   |\n",
      "| qf2_loss                | 8.6284685   |\n",
      "| time_elapsed            | 848         |\n",
      "| total timesteps         | 69822       |\n",
      "| value_loss              | 8.234003    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02016911 |\n",
      "| ent_coef_loss           | 1.444995   |\n",
      "| entropy                 | 14.641018  |\n",
      "| episodes                | 1000       |\n",
      "| fps                     | 82         |\n",
      "| mean 100 episode reward | 438        |\n",
      "| n_updates               | 70580      |\n",
      "| policy_loss             | -148.04758 |\n",
      "| qf1_loss                | 12.723666  |\n",
      "| qf2_loss                | 12.598084  |\n",
      "| time_elapsed            | 858        |\n",
      "| total timesteps         | 70679      |\n",
      "| value_loss              | 8.256583   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.019472698 |\n",
      "| ent_coef_loss           | -2.01864    |\n",
      "| entropy                 | 13.407592   |\n",
      "| episodes                | 1010        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 434         |\n",
      "| n_updates               | 71495       |\n",
      "| policy_loss             | -167.04565  |\n",
      "| qf1_loss                | 9.173526    |\n",
      "| qf2_loss                | 13.142884   |\n",
      "| time_elapsed            | 872         |\n",
      "| total timesteps         | 71594       |\n",
      "| value_loss              | 7.7036223   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.018894201 |\n",
      "| ent_coef_loss           | -6.400751   |\n",
      "| entropy                 | 13.799065   |\n",
      "| episodes                | 1020        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 427         |\n",
      "| n_updates               | 72349       |\n",
      "| policy_loss             | -179.30724  |\n",
      "| qf1_loss                | 11.114944   |\n",
      "| qf2_loss                | 10.904814   |\n",
      "| time_elapsed            | 886         |\n",
      "| total timesteps         | 72448       |\n",
      "| value_loss              | 9.4454975   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.019780466 |\n",
      "| ent_coef_loss           | -2.4265208  |\n",
      "| entropy                 | 13.929414   |\n",
      "| episodes                | 1030        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 425         |\n",
      "| n_updates               | 73233       |\n",
      "| policy_loss             | -157.38013  |\n",
      "| qf1_loss                | 14.341403   |\n",
      "| qf2_loss                | 11.321016   |\n",
      "| time_elapsed            | 899         |\n",
      "| total timesteps         | 73332       |\n",
      "| value_loss              | 6.7636046   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.019091163 |\n",
      "| ent_coef_loss           | 0.008064806 |\n",
      "| entropy                 | 14.268941   |\n",
      "| episodes                | 1040        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 417         |\n",
      "| n_updates               | 74093       |\n",
      "| policy_loss             | -166.13297  |\n",
      "| qf1_loss                | 7.3835287   |\n",
      "| qf2_loss                | 10.656995   |\n",
      "| time_elapsed            | 909         |\n",
      "| total timesteps         | 74192       |\n",
      "| value_loss              | 9.70038     |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.020101517 |\n",
      "| ent_coef_loss           | 3.1416376   |\n",
      "| entropy                 | 13.722512   |\n",
      "| episodes                | 1050        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 418         |\n",
      "| n_updates               | 74837       |\n",
      "| policy_loss             | -160.04816  |\n",
      "| qf1_loss                | 9.237646    |\n",
      "| qf2_loss                | 11.386145   |\n",
      "| time_elapsed            | 918         |\n",
      "| total timesteps         | 74936       |\n",
      "| value_loss              | 15.129594   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.020263908 |\n",
      "| ent_coef_loss           | 2.2702003   |\n",
      "| entropy                 | 13.851796   |\n",
      "| episodes                | 1060        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 419         |\n",
      "| n_updates               | 75808       |\n",
      "| policy_loss             | -153.09561  |\n",
      "| qf1_loss                | 9.10459     |\n",
      "| qf2_loss                | 9.326268    |\n",
      "| time_elapsed            | 930         |\n",
      "| total timesteps         | 75907       |\n",
      "| value_loss              | 8.952335    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.018977465 |\n",
      "| ent_coef_loss           | 4.540391    |\n",
      "| entropy                 | 13.738131   |\n",
      "| episodes                | 1070        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 422         |\n",
      "| n_updates               | 76702       |\n",
      "| policy_loss             | -160.51144  |\n",
      "| qf1_loss                | 6.2301426   |\n",
      "| qf2_loss                | 7.630122    |\n",
      "| time_elapsed            | 941         |\n",
      "| total timesteps         | 76801       |\n",
      "| value_loss              | 10.058994   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.018455049 |\n",
      "| ent_coef_loss           | 6.452741    |\n",
      "| entropy                 | 13.884153   |\n",
      "| episodes                | 1080        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 432         |\n",
      "| n_updates               | 77659       |\n",
      "| policy_loss             | -159.085    |\n",
      "| qf1_loss                | 9.090539    |\n",
      "| qf2_loss                | 11.675827   |\n",
      "| time_elapsed            | 953         |\n",
      "| total timesteps         | 77758       |\n",
      "| value_loss              | 12.978197   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.018242136 |\n",
      "| ent_coef_loss           | 4.324501    |\n",
      "| entropy                 | 13.685806   |\n",
      "| episodes                | 1090        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 442         |\n",
      "| n_updates               | 78660       |\n",
      "| policy_loss             | -145.54086  |\n",
      "| qf1_loss                | 11.954312   |\n",
      "| qf2_loss                | 9.516485    |\n",
      "| time_elapsed            | 965         |\n",
      "| total timesteps         | 78759       |\n",
      "| value_loss              | 10.9593525  |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.01865858 |\n",
      "| ent_coef_loss           | 8.101477   |\n",
      "| entropy                 | 13.803178  |\n",
      "| episodes                | 1100       |\n",
      "| fps                     | 81         |\n",
      "| mean 100 episode reward | 443        |\n",
      "| n_updates               | 79525      |\n",
      "| policy_loss             | -164.1921  |\n",
      "| qf1_loss                | 8.184504   |\n",
      "| qf2_loss                | 11.98036   |\n",
      "| time_elapsed            | 975        |\n",
      "| total timesteps         | 79624      |\n",
      "| value_loss              | 8.147497   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.018406838 |\n",
      "| ent_coef_loss           | -1.6056132  |\n",
      "| entropy                 | 14.273842   |\n",
      "| episodes                | 1110        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 443         |\n",
      "| n_updates               | 80428       |\n",
      "| policy_loss             | -162.25537  |\n",
      "| qf1_loss                | 7.3219795   |\n",
      "| qf2_loss                | 10.565304   |\n",
      "| time_elapsed            | 986         |\n",
      "| total timesteps         | 80527       |\n",
      "| value_loss              | 8.677317    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.018792924 |\n",
      "| ent_coef_loss           | -3.3364909  |\n",
      "| entropy                 | 13.586833   |\n",
      "| episodes                | 1120        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 454         |\n",
      "| n_updates               | 81541       |\n",
      "| policy_loss             | -154.0402   |\n",
      "| qf1_loss                | 12.788303   |\n",
      "| qf2_loss                | 7.0246325   |\n",
      "| time_elapsed            | 999         |\n",
      "| total timesteps         | 81640       |\n",
      "| value_loss              | 7.036372    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.019043848 |\n",
      "| ent_coef_loss           | 1.9503099   |\n",
      "| entropy                 | 14.307323   |\n",
      "| episodes                | 1130        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 455         |\n",
      "| n_updates               | 82478       |\n",
      "| policy_loss             | -154.3505   |\n",
      "| qf1_loss                | 9.928292    |\n",
      "| qf2_loss                | 14.025568   |\n",
      "| time_elapsed            | 1011        |\n",
      "| total timesteps         | 82577       |\n",
      "| value_loss              | 9.283243    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.019090977 |\n",
      "| ent_coef_loss           | -6.5883245  |\n",
      "| entropy                 | 14.030952   |\n",
      "| episodes                | 1140        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 449         |\n",
      "| n_updates               | 83245       |\n",
      "| policy_loss             | -156.98761  |\n",
      "| qf1_loss                | 6.3727865   |\n",
      "| qf2_loss                | 6.1309414   |\n",
      "| time_elapsed            | 1021        |\n",
      "| total timesteps         | 83344       |\n",
      "| value_loss              | 6.90069     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.018610328 |\n",
      "| ent_coef_loss           | -2.807592   |\n",
      "| entropy                 | 13.173039   |\n",
      "| episodes                | 1150        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 458         |\n",
      "| n_updates               | 84180       |\n",
      "| policy_loss             | -161.91728  |\n",
      "| qf1_loss                | 15.912395   |\n",
      "| qf2_loss                | 17.83324    |\n",
      "| time_elapsed            | 1033        |\n",
      "| total timesteps         | 84279       |\n",
      "| value_loss              | 11.182377   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.01980263 |\n",
      "| ent_coef_loss           | -4.456785  |\n",
      "| entropy                 | 14.431728  |\n",
      "| episodes                | 1160       |\n",
      "| fps                     | 81         |\n",
      "| mean 100 episode reward | 458        |\n",
      "| n_updates               | 85163      |\n",
      "| policy_loss             | -166.54892 |\n",
      "| qf1_loss                | 7.936171   |\n",
      "| qf2_loss                | 5.5473614  |\n",
      "| time_elapsed            | 1045       |\n",
      "| total timesteps         | 85262      |\n",
      "| value_loss              | 5.2485094  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.01890951 |\n",
      "| ent_coef_loss           | 1.2494016  |\n",
      "| entropy                 | 14.407334  |\n",
      "| episodes                | 1170       |\n",
      "| fps                     | 81         |\n",
      "| mean 100 episode reward | 461        |\n",
      "| n_updates               | 86097      |\n",
      "| policy_loss             | -159.3458  |\n",
      "| qf1_loss                | 9.695527   |\n",
      "| qf2_loss                | 8.851833   |\n",
      "| time_elapsed            | 1055       |\n",
      "| total timesteps         | 86196      |\n",
      "| value_loss              | 10.109938  |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.018651247 |\n",
      "| ent_coef_loss           | -4.556013   |\n",
      "| entropy                 | 14.131436   |\n",
      "| episodes                | 1180        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 475         |\n",
      "| n_updates               | 87279       |\n",
      "| policy_loss             | -157.82835  |\n",
      "| qf1_loss                | 12.037783   |\n",
      "| qf2_loss                | 9.379263    |\n",
      "| time_elapsed            | 1070        |\n",
      "| total timesteps         | 87378       |\n",
      "| value_loss              | 13.330234   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.01911511 |\n",
      "| ent_coef_loss           | -3.373487  |\n",
      "| entropy                 | 14.054893  |\n",
      "| episodes                | 1190       |\n",
      "| fps                     | 81         |\n",
      "| mean 100 episode reward | 469        |\n",
      "| n_updates               | 88131      |\n",
      "| policy_loss             | -144.96109 |\n",
      "| qf1_loss                | 8.279404   |\n",
      "| qf2_loss                | 9.92012    |\n",
      "| time_elapsed            | 1080       |\n",
      "| total timesteps         | 88230      |\n",
      "| value_loss              | 6.062558   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.019172447 |\n",
      "| ent_coef_loss           | 4.384152    |\n",
      "| entropy                 | 13.66209    |\n",
      "| episodes                | 1200        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 481         |\n",
      "| n_updates               | 89177       |\n",
      "| policy_loss             | -162.46893  |\n",
      "| qf1_loss                | 9.77994     |\n",
      "| qf2_loss                | 10.659842   |\n",
      "| time_elapsed            | 1092        |\n",
      "| total timesteps         | 89276       |\n",
      "| value_loss              | 6.946389    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.020010358 |\n",
      "| ent_coef_loss           | 1.6483922   |\n",
      "| entropy                 | 14.147065   |\n",
      "| episodes                | 1210        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 482         |\n",
      "| n_updates               | 90037       |\n",
      "| policy_loss             | -156.99489  |\n",
      "| qf1_loss                | 7.8851786   |\n",
      "| qf2_loss                | 7.605009    |\n",
      "| time_elapsed            | 1104        |\n",
      "| total timesteps         | 90136       |\n",
      "| value_loss              | 7.524032    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.019453032 |\n",
      "| ent_coef_loss           | 5.278385    |\n",
      "| entropy                 | 14.510665   |\n",
      "| episodes                | 1220        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 472         |\n",
      "| n_updates               | 90916       |\n",
      "| policy_loss             | -158.39407  |\n",
      "| qf1_loss                | 13.216995   |\n",
      "| qf2_loss                | 13.602888   |\n",
      "| time_elapsed            | 1116        |\n",
      "| total timesteps         | 91015       |\n",
      "| value_loss              | 6.732079    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.019953495 |\n",
      "| ent_coef_loss           | -1.8175408  |\n",
      "| entropy                 | 14.006584   |\n",
      "| episodes                | 1230        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 471         |\n",
      "| n_updates               | 91747       |\n",
      "| policy_loss             | -172.63396  |\n",
      "| qf1_loss                | 10.364583   |\n",
      "| qf2_loss                | 12.697238   |\n",
      "| time_elapsed            | 1126        |\n",
      "| total timesteps         | 91846       |\n",
      "| value_loss              | 7.7601004   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.019471463 |\n",
      "| ent_coef_loss           | 1.4123157   |\n",
      "| entropy                 | 13.718323   |\n",
      "| episodes                | 1240        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 480         |\n",
      "| n_updates               | 92623       |\n",
      "| policy_loss             | -170.48969  |\n",
      "| qf1_loss                | 9.74843     |\n",
      "| qf2_loss                | 7.178283    |\n",
      "| time_elapsed            | 1137        |\n",
      "| total timesteps         | 92722       |\n",
      "| value_loss              | 7.271837    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.019693965 |\n",
      "| ent_coef_loss           | -10.654989  |\n",
      "| entropy                 | 14.38703    |\n",
      "| episodes                | 1250        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 479         |\n",
      "| n_updates               | 93530       |\n",
      "| policy_loss             | -164.14626  |\n",
      "| qf1_loss                | 9.2001095   |\n",
      "| qf2_loss                | 6.8070436   |\n",
      "| time_elapsed            | 1148        |\n",
      "| total timesteps         | 93629       |\n",
      "| value_loss              | 6.5813837   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.019699328 |\n",
      "| ent_coef_loss           | -5.944031   |\n",
      "| entropy                 | 14.178559   |\n",
      "| episodes                | 1260        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 483         |\n",
      "| n_updates               | 94565       |\n",
      "| policy_loss             | -140.3081   |\n",
      "| qf1_loss                | 14.122512   |\n",
      "| qf2_loss                | 11.304325   |\n",
      "| time_elapsed            | 1161        |\n",
      "| total timesteps         | 94664       |\n",
      "| value_loss              | 6.122779    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.019902306 |\n",
      "| ent_coef_loss           | -0.704185   |\n",
      "| entropy                 | 14.375464   |\n",
      "| episodes                | 1270        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 483         |\n",
      "| n_updates               | 95481       |\n",
      "| policy_loss             | -144.07695  |\n",
      "| qf1_loss                | 8.776283    |\n",
      "| qf2_loss                | 8.511045    |\n",
      "| time_elapsed            | 1172        |\n",
      "| total timesteps         | 95580       |\n",
      "| value_loss              | 8.73132     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.019537207 |\n",
      "| ent_coef_loss           | -6.723821   |\n",
      "| entropy                 | 13.827469   |\n",
      "| episodes                | 1280        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 473         |\n",
      "| n_updates               | 96483       |\n",
      "| policy_loss             | -164.87112  |\n",
      "| qf1_loss                | 9.838817    |\n",
      "| qf2_loss                | 7.9658713   |\n",
      "| time_elapsed            | 1184        |\n",
      "| total timesteps         | 96582       |\n",
      "| value_loss              | 6.9604244   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02011356 |\n",
      "| ent_coef_loss           | 1.8521492  |\n",
      "| entropy                 | 14.5467205 |\n",
      "| episodes                | 1290       |\n",
      "| fps                     | 81         |\n",
      "| mean 100 episode reward | 470        |\n",
      "| n_updates               | 97279      |\n",
      "| policy_loss             | -162.0352  |\n",
      "| qf1_loss                | 8.517492   |\n",
      "| qf2_loss                | 7.8249917  |\n",
      "| time_elapsed            | 1193       |\n",
      "| total timesteps         | 97378      |\n",
      "| value_loss              | 7.3590755  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.019644829 |\n",
      "| ent_coef_loss           | 7.8747606   |\n",
      "| entropy                 | 14.077526   |\n",
      "| episodes                | 1300        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 462         |\n",
      "| n_updates               | 98140       |\n",
      "| policy_loss             | -144.51184  |\n",
      "| qf1_loss                | 8.866682    |\n",
      "| qf2_loss                | 10.491572   |\n",
      "| time_elapsed            | 1203        |\n",
      "| total timesteps         | 98239       |\n",
      "| value_loss              | 7.3805676   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.01961873 |\n",
      "| ent_coef_loss           | -1.9158077 |\n",
      "| entropy                 | 14.016521  |\n",
      "| episodes                | 1310       |\n",
      "| fps                     | 81         |\n",
      "| mean 100 episode reward | 469        |\n",
      "| n_updates               | 99210      |\n",
      "| policy_loss             | -165.45087 |\n",
      "| qf1_loss                | 8.1846285  |\n",
      "| qf2_loss                | 10.68044   |\n",
      "| time_elapsed            | 1216       |\n",
      "| total timesteps         | 99309      |\n",
      "| value_loss              | 6.167562   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.019552207 |\n",
      "| ent_coef_loss           | 7.219985    |\n",
      "| entropy                 | 14.475283   |\n",
      "| episodes                | 1320        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 480         |\n",
      "| n_updates               | 100298      |\n",
      "| policy_loss             | -162.76318  |\n",
      "| qf1_loss                | 11.94825    |\n",
      "| qf2_loss                | 11.7158985  |\n",
      "| time_elapsed            | 1229        |\n",
      "| total timesteps         | 100397      |\n",
      "| value_loss              | 11.764445   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.020506954 |\n",
      "| ent_coef_loss           | -9.659663   |\n",
      "| entropy                 | 14.105703   |\n",
      "| episodes                | 1330        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 499         |\n",
      "| n_updates               | 101572      |\n",
      "| policy_loss             | -160.88803  |\n",
      "| qf1_loss                | 11.687912   |\n",
      "| qf2_loss                | 7.802469    |\n",
      "| time_elapsed            | 1245        |\n",
      "| total timesteps         | 101671      |\n",
      "| value_loss              | 12.098127   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.01987485 |\n",
      "| ent_coef_loss           | 3.173627   |\n",
      "| entropy                 | 13.777264  |\n",
      "| episodes                | 1340       |\n",
      "| fps                     | 81         |\n",
      "| mean 100 episode reward | 502        |\n",
      "| n_updates               | 102580     |\n",
      "| policy_loss             | -165.7189  |\n",
      "| qf1_loss                | 11.963858  |\n",
      "| qf2_loss                | 7.3717537  |\n",
      "| time_elapsed            | 1259       |\n",
      "| total timesteps         | 102679     |\n",
      "| value_loss              | 9.684525   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.01969659 |\n",
      "| ent_coef_loss           | 0.5246248  |\n",
      "| entropy                 | 13.939337  |\n",
      "| episodes                | 1350       |\n",
      "| fps                     | 81         |\n",
      "| mean 100 episode reward | 507        |\n",
      "| n_updates               | 103618     |\n",
      "| policy_loss             | -155.5649  |\n",
      "| qf1_loss                | 9.57124    |\n",
      "| qf2_loss                | 12.114518  |\n",
      "| time_elapsed            | 1272       |\n",
      "| total timesteps         | 103717     |\n",
      "| value_loss              | 7.606074   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.01870827 |\n",
      "| ent_coef_loss           | 3.6053355  |\n",
      "| entropy                 | 13.982212  |\n",
      "| episodes                | 1360       |\n",
      "| fps                     | 81         |\n",
      "| mean 100 episode reward | 497        |\n",
      "| n_updates               | 104492     |\n",
      "| policy_loss             | -158.57    |\n",
      "| qf1_loss                | 10.718254  |\n",
      "| qf2_loss                | 10.809731  |\n",
      "| time_elapsed            | 1282       |\n",
      "| total timesteps         | 104591     |\n",
      "| value_loss              | 9.651854   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02076003 |\n",
      "| ent_coef_loss           | -4.501604  |\n",
      "| entropy                 | 14.171442  |\n",
      "| episodes                | 1370       |\n",
      "| fps                     | 81         |\n",
      "| mean 100 episode reward | 507        |\n",
      "| n_updates               | 105641     |\n",
      "| policy_loss             | -173.64966 |\n",
      "| qf1_loss                | 8.845429   |\n",
      "| qf2_loss                | 7.696664   |\n",
      "| time_elapsed            | 1295       |\n",
      "| total timesteps         | 105740     |\n",
      "| value_loss              | 6.283388   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02079948 |\n",
      "| ent_coef_loss           | -2.944419  |\n",
      "| entropy                 | 14.537357  |\n",
      "| episodes                | 1380       |\n",
      "| fps                     | 81         |\n",
      "| mean 100 episode reward | 508        |\n",
      "| n_updates               | 106701     |\n",
      "| policy_loss             | -154.24298 |\n",
      "| qf1_loss                | 12.86026   |\n",
      "| qf2_loss                | 12.183821  |\n",
      "| time_elapsed            | 1308       |\n",
      "| total timesteps         | 106800     |\n",
      "| value_loss              | 9.595011   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.020735068 |\n",
      "| ent_coef_loss           | 2.402624    |\n",
      "| entropy                 | 14.087012   |\n",
      "| episodes                | 1390        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 520         |\n",
      "| n_updates               | 107755      |\n",
      "| policy_loss             | -175.94824  |\n",
      "| qf1_loss                | 7.435195    |\n",
      "| qf2_loss                | 8.804233    |\n",
      "| time_elapsed            | 1320        |\n",
      "| total timesteps         | 107854      |\n",
      "| value_loss              | 4.893235    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02007394 |\n",
      "| ent_coef_loss           | -10.373407 |\n",
      "| entropy                 | 14.063377  |\n",
      "| episodes                | 1400       |\n",
      "| fps                     | 81         |\n",
      "| mean 100 episode reward | 533        |\n",
      "| n_updates               | 108875     |\n",
      "| policy_loss             | -161.54291 |\n",
      "| qf1_loss                | 9.472658   |\n",
      "| qf2_loss                | 10.721687  |\n",
      "| time_elapsed            | 1333       |\n",
      "| total timesteps         | 108974     |\n",
      "| value_loss              | 5.594591   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.02101689  |\n",
      "| ent_coef_loss           | 0.017517567 |\n",
      "| entropy                 | 14.585074   |\n",
      "| episodes                | 1410        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 533         |\n",
      "| n_updates               | 109906      |\n",
      "| policy_loss             | -156.76189  |\n",
      "| qf1_loss                | 15.009857   |\n",
      "| qf2_loss                | 15.162796   |\n",
      "| time_elapsed            | 1345        |\n",
      "| total timesteps         | 110005      |\n",
      "| value_loss              | 7.889426    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.0202999  |\n",
      "| ent_coef_loss           | -11.755862 |\n",
      "| entropy                 | 14.591982  |\n",
      "| episodes                | 1420       |\n",
      "| fps                     | 81         |\n",
      "| mean 100 episode reward | 527        |\n",
      "| n_updates               | 110874     |\n",
      "| policy_loss             | -160.04779 |\n",
      "| qf1_loss                | 9.515841   |\n",
      "| qf2_loss                | 11.012466  |\n",
      "| time_elapsed            | 1356       |\n",
      "| total timesteps         | 110973     |\n",
      "| value_loss              | 3.2405062  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02055168 |\n",
      "| ent_coef_loss           | -1.6632085 |\n",
      "| entropy                 | 13.859793  |\n",
      "| episodes                | 1430       |\n",
      "| fps                     | 81         |\n",
      "| mean 100 episode reward | 505        |\n",
      "| n_updates               | 111680     |\n",
      "| policy_loss             | -177.22444 |\n",
      "| qf1_loss                | 9.308351   |\n",
      "| qf2_loss                | 6.9932156  |\n",
      "| time_elapsed            | 1365       |\n",
      "| total timesteps         | 111779     |\n",
      "| value_loss              | 8.571508   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.020172188 |\n",
      "| ent_coef_loss           | -4.1439753  |\n",
      "| entropy                 | 14.109295   |\n",
      "| episodes                | 1440        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 511         |\n",
      "| n_updates               | 112782      |\n",
      "| policy_loss             | -167.24106  |\n",
      "| qf1_loss                | 9.847499    |\n",
      "| qf2_loss                | 8.819744    |\n",
      "| time_elapsed            | 1378        |\n",
      "| total timesteps         | 112881      |\n",
      "| value_loss              | 8.573309    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.020059645 |\n",
      "| ent_coef_loss           | 3.5800712   |\n",
      "| entropy                 | 14.011251   |\n",
      "| episodes                | 1450        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 515         |\n",
      "| n_updates               | 113908      |\n",
      "| policy_loss             | -155.04901  |\n",
      "| qf1_loss                | 11.946683   |\n",
      "| qf2_loss                | 13.213059   |\n",
      "| time_elapsed            | 1391        |\n",
      "| total timesteps         | 114007      |\n",
      "| value_loss              | 6.5918455   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.020872878 |\n",
      "| ent_coef_loss           | -2.6218219  |\n",
      "| entropy                 | 14.143831   |\n",
      "| episodes                | 1460        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 522         |\n",
      "| n_updates               | 114907      |\n",
      "| policy_loss             | -171.95856  |\n",
      "| qf1_loss                | 12.127285   |\n",
      "| qf2_loss                | 14.567734   |\n",
      "| time_elapsed            | 1402        |\n",
      "| total timesteps         | 115006      |\n",
      "| value_loss              | 11.234425   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.021203084 |\n",
      "| ent_coef_loss           | 4.3149724   |\n",
      "| entropy                 | 14.075466   |\n",
      "| episodes                | 1470        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 528         |\n",
      "| n_updates               | 116139      |\n",
      "| policy_loss             | -178.54718  |\n",
      "| qf1_loss                | 7.206277    |\n",
      "| qf2_loss                | 6.147005    |\n",
      "| time_elapsed            | 1416        |\n",
      "| total timesteps         | 116238      |\n",
      "| value_loss              | 6.6868916   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.021946501 |\n",
      "| ent_coef_loss           | 5.9899445   |\n",
      "| entropy                 | 13.949565   |\n",
      "| episodes                | 1480        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 523         |\n",
      "| n_updates               | 117014      |\n",
      "| policy_loss             | -181.16576  |\n",
      "| qf1_loss                | 10.657665   |\n",
      "| qf2_loss                | 5.7829847   |\n",
      "| time_elapsed            | 1426        |\n",
      "| total timesteps         | 117113      |\n",
      "| value_loss              | 8.2187195   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.021064099 |\n",
      "| ent_coef_loss           | 1.3776398   |\n",
      "| entropy                 | 14.148672   |\n",
      "| episodes                | 1490        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 524         |\n",
      "| n_updates               | 118074      |\n",
      "| policy_loss             | -156.37405  |\n",
      "| qf1_loss                | 7.7124386   |\n",
      "| qf2_loss                | 12.797891   |\n",
      "| time_elapsed            | 1438        |\n",
      "| total timesteps         | 118173      |\n",
      "| value_loss              | 10.711477   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.021042079 |\n",
      "| ent_coef_loss           | 1.463474    |\n",
      "| entropy                 | 14.152603   |\n",
      "| episodes                | 1500        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 526         |\n",
      "| n_updates               | 119232      |\n",
      "| policy_loss             | -169.2893   |\n",
      "| qf1_loss                | 10.142771   |\n",
      "| qf2_loss                | 11.451086   |\n",
      "| time_elapsed            | 1451        |\n",
      "| total timesteps         | 119331      |\n",
      "| value_loss              | 5.9522123   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.022807777 |\n",
      "| ent_coef_loss           | -6.65958    |\n",
      "| entropy                 | 14.895884   |\n",
      "| episodes                | 1510        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 528         |\n",
      "| n_updates               | 120314      |\n",
      "| policy_loss             | -154.7767   |\n",
      "| qf1_loss                | 9.818714    |\n",
      "| qf2_loss                | 10.230194   |\n",
      "| time_elapsed            | 1463        |\n",
      "| total timesteps         | 120413      |\n",
      "| value_loss              | 7.8683825   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.021609595 |\n",
      "| ent_coef_loss           | -1.0256782  |\n",
      "| entropy                 | 14.609728   |\n",
      "| episodes                | 1520        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 532         |\n",
      "| n_updates               | 121358      |\n",
      "| policy_loss             | -155.42122  |\n",
      "| qf1_loss                | 13.068403   |\n",
      "| qf2_loss                | 12.912933   |\n",
      "| time_elapsed            | 1475        |\n",
      "| total timesteps         | 121457      |\n",
      "| value_loss              | 13.66609    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02123921 |\n",
      "| ent_coef_loss           | 5.9780836  |\n",
      "| entropy                 | 14.775944  |\n",
      "| episodes                | 1530       |\n",
      "| fps                     | 82         |\n",
      "| mean 100 episode reward | 549        |\n",
      "| n_updates               | 122510     |\n",
      "| policy_loss             | -157.3099  |\n",
      "| qf1_loss                | 9.084165   |\n",
      "| qf2_loss                | 9.860333   |\n",
      "| time_elapsed            | 1487       |\n",
      "| total timesteps         | 122609     |\n",
      "| value_loss              | 7.94549    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.021899406 |\n",
      "| ent_coef_loss           | -4.4916735  |\n",
      "| entropy                 | 15.0327215  |\n",
      "| episodes                | 1540        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 569         |\n",
      "| n_updates               | 124050      |\n",
      "| policy_loss             | -163.76544  |\n",
      "| qf1_loss                | 13.833818   |\n",
      "| qf2_loss                | 13.718651   |\n",
      "| time_elapsed            | 1504        |\n",
      "| total timesteps         | 124149      |\n",
      "| value_loss              | 11.765288   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.021728875 |\n",
      "| ent_coef_loss           | 4.5610337   |\n",
      "| entropy                 | 14.066531   |\n",
      "| episodes                | 1550        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 572         |\n",
      "| n_updates               | 125269      |\n",
      "| policy_loss             | -171.3074   |\n",
      "| qf1_loss                | 10.666922   |\n",
      "| qf2_loss                | 9.287508    |\n",
      "| time_elapsed            | 1518        |\n",
      "| total timesteps         | 125368      |\n",
      "| value_loss              | 6.1683455   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.021745449 |\n",
      "| ent_coef_loss           | 1.8181372   |\n",
      "| entropy                 | 14.375391   |\n",
      "| episodes                | 1560        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 587         |\n",
      "| n_updates               | 126510      |\n",
      "| policy_loss             | -168.70786  |\n",
      "| qf1_loss                | 13.863511   |\n",
      "| qf2_loss                | 14.945701   |\n",
      "| time_elapsed            | 1532        |\n",
      "| total timesteps         | 126609      |\n",
      "| value_loss              | 7.958078    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.021854691 |\n",
      "| ent_coef_loss           | 10.252174   |\n",
      "| entropy                 | 14.087208   |\n",
      "| episodes                | 1570        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 584         |\n",
      "| n_updates               | 127696      |\n",
      "| policy_loss             | -174.08969  |\n",
      "| qf1_loss                | 11.697836   |\n",
      "| qf2_loss                | 11.466039   |\n",
      "| time_elapsed            | 1546        |\n",
      "| total timesteps         | 127795      |\n",
      "| value_loss              | 5.6389265   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.021884589 |\n",
      "| ent_coef_loss           | -4.7579403  |\n",
      "| entropy                 | 13.993997   |\n",
      "| episodes                | 1580        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 588         |\n",
      "| n_updates               | 128728      |\n",
      "| policy_loss             | -157.98367  |\n",
      "| qf1_loss                | 9.712808    |\n",
      "| qf2_loss                | 11.707916   |\n",
      "| time_elapsed            | 1559        |\n",
      "| total timesteps         | 128827      |\n",
      "| value_loss              | 13.161597   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.022240184 |\n",
      "| ent_coef_loss           | 5.8806376   |\n",
      "| entropy                 | 14.273108   |\n",
      "| episodes                | 1590        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 595         |\n",
      "| n_updates               | 129891      |\n",
      "| policy_loss             | -171.2031   |\n",
      "| qf1_loss                | 14.672164   |\n",
      "| qf2_loss                | 12.646503   |\n",
      "| time_elapsed            | 1574        |\n",
      "| total timesteps         | 129990      |\n",
      "| value_loss              | 11.513425   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.021577429 |\n",
      "| ent_coef_loss           | 3.2553544   |\n",
      "| entropy                 | 14.621109   |\n",
      "| episodes                | 1600        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 602         |\n",
      "| n_updates               | 131188      |\n",
      "| policy_loss             | -177.7374   |\n",
      "| qf1_loss                | 17.584394   |\n",
      "| qf2_loss                | 12.761179   |\n",
      "| time_elapsed            | 1588        |\n",
      "| total timesteps         | 131287      |\n",
      "| value_loss              | 10.828772   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.022635153 |\n",
      "| ent_coef_loss           | 9.692633    |\n",
      "| entropy                 | 14.568547   |\n",
      "| episodes                | 1610        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 595         |\n",
      "| n_updates               | 132129      |\n",
      "| policy_loss             | -168.3563   |\n",
      "| qf1_loss                | 21.695244   |\n",
      "| qf2_loss                | 14.938593   |\n",
      "| time_elapsed            | 1599        |\n",
      "| total timesteps         | 132228      |\n",
      "| value_loss              | 12.402203   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.021589387 |\n",
      "| ent_coef_loss           | -2.2470925  |\n",
      "| entropy                 | 14.238678   |\n",
      "| episodes                | 1620        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 602         |\n",
      "| n_updates               | 133359      |\n",
      "| policy_loss             | -162.7974   |\n",
      "| qf1_loss                | 9.830048    |\n",
      "| qf2_loss                | 16.237581   |\n",
      "| time_elapsed            | 1613        |\n",
      "| total timesteps         | 133458      |\n",
      "| value_loss              | 13.927931   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.021270279 |\n",
      "| ent_coef_loss           | -0.90941143 |\n",
      "| entropy                 | 14.386622   |\n",
      "| episodes                | 1630        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 600         |\n",
      "| n_updates               | 134483      |\n",
      "| policy_loss             | -194.61273  |\n",
      "| qf1_loss                | 18.946373   |\n",
      "| qf2_loss                | 15.20015    |\n",
      "| time_elapsed            | 1626        |\n",
      "| total timesteps         | 134582      |\n",
      "| value_loss              | 11.804801   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02182447 |\n",
      "| ent_coef_loss           | 0.82120514 |\n",
      "| entropy                 | 14.563338  |\n",
      "| episodes                | 1640       |\n",
      "| fps                     | 82         |\n",
      "| mean 100 episode reward | 604        |\n",
      "| n_updates               | 136030     |\n",
      "| policy_loss             | -166.21463 |\n",
      "| qf1_loss                | 9.059507   |\n",
      "| qf2_loss                | 11.588492  |\n",
      "| time_elapsed            | 1644       |\n",
      "| total timesteps         | 136129     |\n",
      "| value_loss              | 14.5263195 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.021357   |\n",
      "| ent_coef_loss           | -8.871094  |\n",
      "| entropy                 | 15.019145  |\n",
      "| episodes                | 1650       |\n",
      "| fps                     | 82         |\n",
      "| mean 100 episode reward | 599        |\n",
      "| n_updates               | 137112     |\n",
      "| policy_loss             | -152.64105 |\n",
      "| qf1_loss                | 8.054073   |\n",
      "| qf2_loss                | 12.275957  |\n",
      "| time_elapsed            | 1656       |\n",
      "| total timesteps         | 137211     |\n",
      "| value_loss              | 7.0633197  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.021794248 |\n",
      "| ent_coef_loss           | -5.617288   |\n",
      "| entropy                 | 14.064852   |\n",
      "| episodes                | 1660        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 598         |\n",
      "| n_updates               | 138391      |\n",
      "| policy_loss             | -189.6407   |\n",
      "| qf1_loss                | 10.484167   |\n",
      "| qf2_loss                | 11.303812   |\n",
      "| time_elapsed            | 1671        |\n",
      "| total timesteps         | 138490      |\n",
      "| value_loss              | 7.910592    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.022291964 |\n",
      "| ent_coef_loss           | 2.1733003   |\n",
      "| entropy                 | 13.848441   |\n",
      "| episodes                | 1670        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 617         |\n",
      "| n_updates               | 139941      |\n",
      "| policy_loss             | -173.31107  |\n",
      "| qf1_loss                | 15.579199   |\n",
      "| qf2_loss                | 17.763409   |\n",
      "| time_elapsed            | 1689        |\n",
      "| total timesteps         | 140040      |\n",
      "| value_loss              | 8.263042    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.022338465 |\n",
      "| ent_coef_loss           | -6.203889   |\n",
      "| entropy                 | 13.98444    |\n",
      "| episodes                | 1680        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 616         |\n",
      "| n_updates               | 140968      |\n",
      "| policy_loss             | -184.08441  |\n",
      "| qf1_loss                | 9.843754    |\n",
      "| qf2_loss                | 12.005376   |\n",
      "| time_elapsed            | 1701        |\n",
      "| total timesteps         | 141067      |\n",
      "| value_loss              | 8.859737    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.022625204 |\n",
      "| ent_coef_loss           | -1.0347106  |\n",
      "| entropy                 | 14.859694   |\n",
      "| episodes                | 1690        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 608         |\n",
      "| n_updates               | 142090      |\n",
      "| policy_loss             | -164.15967  |\n",
      "| qf1_loss                | 10.480379   |\n",
      "| qf2_loss                | 7.5341134   |\n",
      "| time_elapsed            | 1713        |\n",
      "| total timesteps         | 142189      |\n",
      "| value_loss              | 13.280217   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02267449 |\n",
      "| ent_coef_loss           | 2.6617682  |\n",
      "| entropy                 | 14.564955  |\n",
      "| episodes                | 1700       |\n",
      "| fps                     | 82         |\n",
      "| mean 100 episode reward | 603        |\n",
      "| n_updates               | 143355     |\n",
      "| policy_loss             | -172.85701 |\n",
      "| qf1_loss                | 12.463733  |\n",
      "| qf2_loss                | 20.294323  |\n",
      "| time_elapsed            | 1728       |\n",
      "| total timesteps         | 143454     |\n",
      "| value_loss              | 16.317646  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.023216456 |\n",
      "| ent_coef_loss           | -3.8325965  |\n",
      "| entropy                 | 14.862577   |\n",
      "| episodes                | 1710        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 628         |\n",
      "| n_updates               | 144780      |\n",
      "| policy_loss             | -163.7557   |\n",
      "| qf1_loss                | 8.5497875   |\n",
      "| qf2_loss                | 6.8346305   |\n",
      "| time_elapsed            | 1744        |\n",
      "| total timesteps         | 144879      |\n",
      "| value_loss              | 7.198472    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.023808347 |\n",
      "| ent_coef_loss           | -4.080044   |\n",
      "| entropy                 | 14.308163   |\n",
      "| episodes                | 1720        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 638         |\n",
      "| n_updates               | 146189      |\n",
      "| policy_loss             | -196.18576  |\n",
      "| qf1_loss                | 14.833855   |\n",
      "| qf2_loss                | 16.60403    |\n",
      "| time_elapsed            | 1761        |\n",
      "| total timesteps         | 146288      |\n",
      "| value_loss              | 12.076156   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02428391 |\n",
      "| ent_coef_loss           | -1.6918635 |\n",
      "| entropy                 | 14.286198  |\n",
      "| episodes                | 1730       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 646        |\n",
      "| n_updates               | 147424     |\n",
      "| policy_loss             | -171.10114 |\n",
      "| qf1_loss                | 7.4244633  |\n",
      "| qf2_loss                | 8.505354   |\n",
      "| time_elapsed            | 1775       |\n",
      "| total timesteps         | 147523     |\n",
      "| value_loss              | 5.346156   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.024304282 |\n",
      "| ent_coef_loss           | -3.4378052  |\n",
      "| entropy                 | 14.917103   |\n",
      "| episodes                | 1740        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 636         |\n",
      "| n_updates               | 148828      |\n",
      "| policy_loss             | -156.11064  |\n",
      "| qf1_loss                | 13.157606   |\n",
      "| qf2_loss                | 12.818549   |\n",
      "| time_elapsed            | 1792        |\n",
      "| total timesteps         | 148927      |\n",
      "| value_loss              | 8.430997    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.025140638 |\n",
      "| ent_coef_loss           | -2.3808205  |\n",
      "| entropy                 | 14.652432   |\n",
      "| episodes                | 1750        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 653         |\n",
      "| n_updates               | 150221      |\n",
      "| policy_loss             | -158.37564  |\n",
      "| qf1_loss                | 11.601957   |\n",
      "| qf2_loss                | 11.169577   |\n",
      "| time_elapsed            | 1810        |\n",
      "| total timesteps         | 150320      |\n",
      "| value_loss              | 10.587664   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.025730198 |\n",
      "| ent_coef_loss           | -4.635492   |\n",
      "| entropy                 | 14.306897   |\n",
      "| episodes                | 1760        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 652         |\n",
      "| n_updates               | 151463      |\n",
      "| policy_loss             | -169.49019  |\n",
      "| qf1_loss                | 15.09385    |\n",
      "| qf2_loss                | 10.629342   |\n",
      "| time_elapsed            | 1825        |\n",
      "| total timesteps         | 151562      |\n",
      "| value_loss              | 17.570911   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.024371916 |\n",
      "| ent_coef_loss           | -3.7028656  |\n",
      "| entropy                 | 14.349073   |\n",
      "| episodes                | 1770        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 628         |\n",
      "| n_updates               | 152568      |\n",
      "| policy_loss             | -175.13931  |\n",
      "| qf1_loss                | 9.980883    |\n",
      "| qf2_loss                | 15.489935   |\n",
      "| time_elapsed            | 1838        |\n",
      "| total timesteps         | 152667      |\n",
      "| value_loss              | 11.749472   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02423692 |\n",
      "| ent_coef_loss           | 1.0685169  |\n",
      "| entropy                 | 14.559077  |\n",
      "| episodes                | 1780       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 649        |\n",
      "| n_updates               | 154006     |\n",
      "| policy_loss             | -187.54701 |\n",
      "| qf1_loss                | 8.554914   |\n",
      "| qf2_loss                | 9.511713   |\n",
      "| time_elapsed            | 1855       |\n",
      "| total timesteps         | 154105     |\n",
      "| value_loss              | 12.582363  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.023833547 |\n",
      "| ent_coef_loss           | 1.3111792   |\n",
      "| entropy                 | 14.591619   |\n",
      "| episodes                | 1790        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 656         |\n",
      "| n_updates               | 155181      |\n",
      "| policy_loss             | -176.39186  |\n",
      "| qf1_loss                | 19.891645   |\n",
      "| qf2_loss                | 22.404968   |\n",
      "| time_elapsed            | 1869        |\n",
      "| total timesteps         | 155280      |\n",
      "| value_loss              | 11.556727   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.023821719 |\n",
      "| ent_coef_loss           | 0.944692    |\n",
      "| entropy                 | 13.998661   |\n",
      "| episodes                | 1800        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 652         |\n",
      "| n_updates               | 156333      |\n",
      "| policy_loss             | -186.3259   |\n",
      "| qf1_loss                | 9.8209505   |\n",
      "| qf2_loss                | 12.211185   |\n",
      "| time_elapsed            | 1883        |\n",
      "| total timesteps         | 156432      |\n",
      "| value_loss              | 8.321795    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.023871932 |\n",
      "| ent_coef_loss           | 2.2623959   |\n",
      "| entropy                 | 13.762995   |\n",
      "| episodes                | 1810        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 651         |\n",
      "| n_updates               | 157724      |\n",
      "| policy_loss             | -198.53708  |\n",
      "| qf1_loss                | 12.144512   |\n",
      "| qf2_loss                | 11.9616995  |\n",
      "| time_elapsed            | 1901        |\n",
      "| total timesteps         | 157823      |\n",
      "| value_loss              | 11.796014   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02481393 |\n",
      "| ent_coef_loss           | -1.5348933 |\n",
      "| entropy                 | 13.973993  |\n",
      "| episodes                | 1820       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 631        |\n",
      "| n_updates               | 158778     |\n",
      "| policy_loss             | -192.34988 |\n",
      "| qf1_loss                | 12.622112  |\n",
      "| qf2_loss                | 12.432493  |\n",
      "| time_elapsed            | 1913       |\n",
      "| total timesteps         | 158877     |\n",
      "| value_loss              | 13.617054  |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.025403362 |\n",
      "| ent_coef_loss           | 1.0383785   |\n",
      "| entropy                 | 14.67302    |\n",
      "| episodes                | 1830        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 635         |\n",
      "| n_updates               | 160096      |\n",
      "| policy_loss             | -188.39058  |\n",
      "| qf1_loss                | 10.775896   |\n",
      "| qf2_loss                | 10.491465   |\n",
      "| time_elapsed            | 1929        |\n",
      "| total timesteps         | 160195      |\n",
      "| value_loss              | 5.5978837   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.024729798 |\n",
      "| ent_coef_loss           | 7.954749    |\n",
      "| entropy                 | 14.163939   |\n",
      "| episodes                | 1840        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 635         |\n",
      "| n_updates               | 161503      |\n",
      "| policy_loss             | -166.97507  |\n",
      "| qf1_loss                | 14.64398    |\n",
      "| qf2_loss                | 12.842567   |\n",
      "| time_elapsed            | 1946        |\n",
      "| total timesteps         | 161602      |\n",
      "| value_loss              | 11.60369    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.025264785 |\n",
      "| ent_coef_loss           | -2.2920232  |\n",
      "| entropy                 | 14.336289   |\n",
      "| episodes                | 1850        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 633         |\n",
      "| n_updates               | 162940      |\n",
      "| policy_loss             | -178.58685  |\n",
      "| qf1_loss                | 13.826582   |\n",
      "| qf2_loss                | 10.61829    |\n",
      "| time_elapsed            | 1962        |\n",
      "| total timesteps         | 163039      |\n",
      "| value_loss              | 20.319279   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.024992991 |\n",
      "| ent_coef_loss           | -1.8404796  |\n",
      "| entropy                 | 14.453218   |\n",
      "| episodes                | 1860        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 639         |\n",
      "| n_updates               | 164311      |\n",
      "| policy_loss             | -171.207    |\n",
      "| qf1_loss                | 13.225038   |\n",
      "| qf2_loss                | 16.712923   |\n",
      "| time_elapsed            | 1978        |\n",
      "| total timesteps         | 164410      |\n",
      "| value_loss              | 22.500546   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02434814 |\n",
      "| ent_coef_loss           | 2.314576   |\n",
      "| entropy                 | 14.306799  |\n",
      "| episodes                | 1870       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 649        |\n",
      "| n_updates               | 165547     |\n",
      "| policy_loss             | -164.88684 |\n",
      "| qf1_loss                | 11.188612  |\n",
      "| qf2_loss                | 8.586008   |\n",
      "| time_elapsed            | 1993       |\n",
      "| total timesteps         | 165646     |\n",
      "| value_loss              | 11.230442  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.023572551 |\n",
      "| ent_coef_loss           | -0.17970908 |\n",
      "| entropy                 | 14.324713   |\n",
      "| episodes                | 1880        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 637         |\n",
      "| n_updates               | 166756      |\n",
      "| policy_loss             | -174.57736  |\n",
      "| qf1_loss                | 11.856771   |\n",
      "| qf2_loss                | 16.329735   |\n",
      "| time_elapsed            | 2007        |\n",
      "| total timesteps         | 166855      |\n",
      "| value_loss              | 11.181612   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.024529897 |\n",
      "| ent_coef_loss           | -3.6827514  |\n",
      "| entropy                 | 14.932859   |\n",
      "| episodes                | 1890        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 645         |\n",
      "| n_updates               | 168111      |\n",
      "| policy_loss             | -174.124    |\n",
      "| qf1_loss                | 11.218939   |\n",
      "| qf2_loss                | 10.310883   |\n",
      "| time_elapsed            | 2023        |\n",
      "| total timesteps         | 168210      |\n",
      "| value_loss              | 10.16668    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.025152065 |\n",
      "| ent_coef_loss           | -7.4432592  |\n",
      "| entropy                 | 15.198528   |\n",
      "| episodes                | 1900        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 648         |\n",
      "| n_updates               | 169287      |\n",
      "| policy_loss             | -168.68567  |\n",
      "| qf1_loss                | 10.542976   |\n",
      "| qf2_loss                | 11.355822   |\n",
      "| time_elapsed            | 2037        |\n",
      "| total timesteps         | 169386      |\n",
      "| value_loss              | 10.485597   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02501233 |\n",
      "| ent_coef_loss           | 6.641528   |\n",
      "| entropy                 | 14.282267  |\n",
      "| episodes                | 1910       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 648        |\n",
      "| n_updates               | 170689     |\n",
      "| policy_loss             | -182.4336  |\n",
      "| qf1_loss                | 14.736694  |\n",
      "| qf2_loss                | 13.272818  |\n",
      "| time_elapsed            | 2054       |\n",
      "| total timesteps         | 170788     |\n",
      "| value_loss              | 10.695801  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.025844492 |\n",
      "| ent_coef_loss           | -1.027495   |\n",
      "| entropy                 | 14.189255   |\n",
      "| episodes                | 1920        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 672         |\n",
      "| n_updates               | 172197      |\n",
      "| policy_loss             | -186.79543  |\n",
      "| qf1_loss                | 12.471725   |\n",
      "| qf2_loss                | 13.749929   |\n",
      "| time_elapsed            | 2071        |\n",
      "| total timesteps         | 172296      |\n",
      "| value_loss              | 14.284832   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.026717251 |\n",
      "| ent_coef_loss           | 7.3872232   |\n",
      "| entropy                 | 14.56212    |\n",
      "| episodes                | 1930        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 678         |\n",
      "| n_updates               | 173661      |\n",
      "| policy_loss             | -174.9939   |\n",
      "| qf1_loss                | 16.81496    |\n",
      "| qf2_loss                | 13.745334   |\n",
      "| time_elapsed            | 2089        |\n",
      "| total timesteps         | 173760      |\n",
      "| value_loss              | 11.70886    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02622491 |\n",
      "| ent_coef_loss           | 2.3274326  |\n",
      "| entropy                 | 14.339713  |\n",
      "| episodes                | 1940       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 675        |\n",
      "| n_updates               | 174973     |\n",
      "| policy_loss             | -177.04938 |\n",
      "| qf1_loss                | 26.542921  |\n",
      "| qf2_loss                | 17.266037  |\n",
      "| time_elapsed            | 2104       |\n",
      "| total timesteps         | 175072     |\n",
      "| value_loss              | 13.268026  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.026258895 |\n",
      "| ent_coef_loss           | -4.1575027  |\n",
      "| entropy                 | 14.548979   |\n",
      "| episodes                | 1950        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 681         |\n",
      "| n_updates               | 176443      |\n",
      "| policy_loss             | -176.3745   |\n",
      "| qf1_loss                | 13.157121   |\n",
      "| qf2_loss                | 15.952522   |\n",
      "| time_elapsed            | 2120        |\n",
      "| total timesteps         | 176542      |\n",
      "| value_loss              | 13.175455   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.024816705 |\n",
      "| ent_coef_loss           | 2.7036355   |\n",
      "| entropy                 | 14.360016   |\n",
      "| episodes                | 1960        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 688         |\n",
      "| n_updates               | 177917      |\n",
      "| policy_loss             | -198.94154  |\n",
      "| qf1_loss                | 10.875999   |\n",
      "| qf2_loss                | 10.9692955  |\n",
      "| time_elapsed            | 2136        |\n",
      "| total timesteps         | 178016      |\n",
      "| value_loss              | 8.991541    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02555347 |\n",
      "| ent_coef_loss           | -5.0055532 |\n",
      "| entropy                 | 14.194661  |\n",
      "| episodes                | 1970       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 687        |\n",
      "| n_updates               | 179123     |\n",
      "| policy_loss             | -192.05356 |\n",
      "| qf1_loss                | 16.922796  |\n",
      "| qf2_loss                | 16.911625  |\n",
      "| time_elapsed            | 2149       |\n",
      "| total timesteps         | 179222     |\n",
      "| value_loss              | 8.612157   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.025547463 |\n",
      "| ent_coef_loss           | 5.7502685   |\n",
      "| entropy                 | 13.937789   |\n",
      "| episodes                | 1980        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 695         |\n",
      "| n_updates               | 180430      |\n",
      "| policy_loss             | -171.60832  |\n",
      "| qf1_loss                | 15.652312   |\n",
      "| qf2_loss                | 11.493585   |\n",
      "| time_elapsed            | 2164        |\n",
      "| total timesteps         | 180529      |\n",
      "| value_loss              | 9.207185    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.025385974 |\n",
      "| ent_coef_loss           | 4.63295     |\n",
      "| entropy                 | 13.594534   |\n",
      "| episodes                | 1990        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 711         |\n",
      "| n_updates               | 182040      |\n",
      "| policy_loss             | -191.39334  |\n",
      "| qf1_loss                | 17.84109    |\n",
      "| qf2_loss                | 15.771383   |\n",
      "| time_elapsed            | 2184        |\n",
      "| total timesteps         | 182139      |\n",
      "| value_loss              | 14.927735   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.026399653 |\n",
      "| ent_coef_loss           | 3.0559974   |\n",
      "| entropy                 | 13.684661   |\n",
      "| episodes                | 2000        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 701         |\n",
      "| n_updates               | 183031      |\n",
      "| policy_loss             | -212.47702  |\n",
      "| qf1_loss                | 21.356895   |\n",
      "| qf2_loss                | 15.822674   |\n",
      "| time_elapsed            | 2196        |\n",
      "| total timesteps         | 183130      |\n",
      "| value_loss              | 11.880592   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.027161263 |\n",
      "| ent_coef_loss           | 0.26861334  |\n",
      "| entropy                 | 14.682964   |\n",
      "| episodes                | 2010        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 709         |\n",
      "| n_updates               | 184545      |\n",
      "| policy_loss             | -174.242    |\n",
      "| qf1_loss                | 18.304186   |\n",
      "| qf2_loss                | 16.666992   |\n",
      "| time_elapsed            | 2213        |\n",
      "| total timesteps         | 184644      |\n",
      "| value_loss              | 11.116484   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.027088076 |\n",
      "| ent_coef_loss           | 3.0961218   |\n",
      "| entropy                 | 14.1838     |\n",
      "| episodes                | 2020        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 701         |\n",
      "| n_updates               | 185848      |\n",
      "| policy_loss             | -191.34607  |\n",
      "| qf1_loss                | 13.660524   |\n",
      "| qf2_loss                | 22.304775   |\n",
      "| time_elapsed            | 2227        |\n",
      "| total timesteps         | 185947      |\n",
      "| value_loss              | 22.920544   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02781806 |\n",
      "| ent_coef_loss           | 10.943294  |\n",
      "| entropy                 | 13.718428  |\n",
      "| episodes                | 2030       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 682        |\n",
      "| n_updates               | 186901     |\n",
      "| policy_loss             | -199.95496 |\n",
      "| qf1_loss                | 21.530323  |\n",
      "| qf2_loss                | 20.733177  |\n",
      "| time_elapsed            | 2239       |\n",
      "| total timesteps         | 187000     |\n",
      "| value_loss              | 14.146317  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02667568 |\n",
      "| ent_coef_loss           | -1.3993138 |\n",
      "| entropy                 | 14.818403  |\n",
      "| episodes                | 2040       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 667        |\n",
      "| n_updates               | 187947     |\n",
      "| policy_loss             | -168.89767 |\n",
      "| qf1_loss                | 10.723822  |\n",
      "| qf2_loss                | 11.629926  |\n",
      "| time_elapsed            | 2251       |\n",
      "| total timesteps         | 188046     |\n",
      "| value_loss              | 11.51826   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.027575806 |\n",
      "| ent_coef_loss           | -6.060593   |\n",
      "| entropy                 | 14.926925   |\n",
      "| episodes                | 2050        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 672         |\n",
      "| n_updates               | 189529      |\n",
      "| policy_loss             | -191.0657   |\n",
      "| qf1_loss                | 15.686653   |\n",
      "| qf2_loss                | 14.625753   |\n",
      "| time_elapsed            | 2269        |\n",
      "| total timesteps         | 189628      |\n",
      "| value_loss              | 10.582542   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028243493 |\n",
      "| ent_coef_loss           | -2.7502122  |\n",
      "| entropy                 | 14.5097275  |\n",
      "| episodes                | 2060        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 677         |\n",
      "| n_updates               | 191129      |\n",
      "| policy_loss             | -170.4784   |\n",
      "| qf1_loss                | 16.76844    |\n",
      "| qf2_loss                | 14.905441   |\n",
      "| time_elapsed            | 2288        |\n",
      "| total timesteps         | 191228      |\n",
      "| value_loss              | 8.789458    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02747767 |\n",
      "| ent_coef_loss           | -19.500374 |\n",
      "| entropy                 | 14.683467  |\n",
      "| episodes                | 2070       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 692        |\n",
      "| n_updates               | 192749     |\n",
      "| policy_loss             | -191.64554 |\n",
      "| qf1_loss                | 12.119638  |\n",
      "| qf2_loss                | 12.337578  |\n",
      "| time_elapsed            | 2306       |\n",
      "| total timesteps         | 192848     |\n",
      "| value_loss              | 12.605509  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.027830478 |\n",
      "| ent_coef_loss           | -1.9017576  |\n",
      "| entropy                 | 14.043648   |\n",
      "| episodes                | 2080        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 698         |\n",
      "| n_updates               | 194194      |\n",
      "| policy_loss             | -193.29565  |\n",
      "| qf1_loss                | 10.393009   |\n",
      "| qf2_loss                | 12.986513   |\n",
      "| time_elapsed            | 2322        |\n",
      "| total timesteps         | 194293      |\n",
      "| value_loss              | 5.922474    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.027005613 |\n",
      "| ent_coef_loss           | 1.356554    |\n",
      "| entropy                 | 14.211111   |\n",
      "| episodes                | 2090        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 676         |\n",
      "| n_updates               | 195395      |\n",
      "| policy_loss             | -196.23822  |\n",
      "| qf1_loss                | 13.026674   |\n",
      "| qf2_loss                | 16.747437   |\n",
      "| time_elapsed            | 2336        |\n",
      "| total timesteps         | 195494      |\n",
      "| value_loss              | 8.841707    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.027444653 |\n",
      "| ent_coef_loss           | 1.7154655   |\n",
      "| entropy                 | 14.744289   |\n",
      "| episodes                | 2100        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 702         |\n",
      "| n_updates               | 196923      |\n",
      "| policy_loss             | -180.41713  |\n",
      "| qf1_loss                | 17.311127   |\n",
      "| qf2_loss                | 19.20626    |\n",
      "| time_elapsed            | 2354        |\n",
      "| total timesteps         | 197022      |\n",
      "| value_loss              | 22.800217   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028255805 |\n",
      "| ent_coef_loss           | 1.869623    |\n",
      "| entropy                 | 14.42283    |\n",
      "| episodes                | 2110        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 688         |\n",
      "| n_updates               | 198142      |\n",
      "| policy_loss             | -170.45383  |\n",
      "| qf1_loss                | 13.544975   |\n",
      "| qf2_loss                | 12.091161   |\n",
      "| time_elapsed            | 2367        |\n",
      "| total timesteps         | 198241      |\n",
      "| value_loss              | 8.757269    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028472062 |\n",
      "| ent_coef_loss           | 4.4339657   |\n",
      "| entropy                 | 14.0739565  |\n",
      "| episodes                | 2120        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 692         |\n",
      "| n_updates               | 199525      |\n",
      "| policy_loss             | -204.93597  |\n",
      "| qf1_loss                | 14.034366   |\n",
      "| qf2_loss                | 10.927919   |\n",
      "| time_elapsed            | 2384        |\n",
      "| total timesteps         | 199624      |\n",
      "| value_loss              | 9.207018    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02802882 |\n",
      "| ent_coef_loss           | 1.2319654  |\n",
      "| entropy                 | 14.243269  |\n",
      "| episodes                | 2130       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 714        |\n",
      "| n_updates               | 201030     |\n",
      "| policy_loss             | -193.89139 |\n",
      "| qf1_loss                | 18.914354  |\n",
      "| qf2_loss                | 10.415092  |\n",
      "| time_elapsed            | 2402       |\n",
      "| total timesteps         | 201129     |\n",
      "| value_loss              | 11.37945   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028506275 |\n",
      "| ent_coef_loss           | 5.672721    |\n",
      "| entropy                 | 14.217222   |\n",
      "| episodes                | 2140        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 750         |\n",
      "| n_updates               | 202806      |\n",
      "| policy_loss             | -199.30063  |\n",
      "| qf1_loss                | 30.105215   |\n",
      "| qf2_loss                | 26.846176   |\n",
      "| time_elapsed            | 2422        |\n",
      "| total timesteps         | 202905      |\n",
      "| value_loss              | 18.307844   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029172884 |\n",
      "| ent_coef_loss           | 4.811089    |\n",
      "| entropy                 | 14.595144   |\n",
      "| episodes                | 2150        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 754         |\n",
      "| n_updates               | 204441      |\n",
      "| policy_loss             | -206.39044  |\n",
      "| qf1_loss                | 11.450836   |\n",
      "| qf2_loss                | 12.268326   |\n",
      "| time_elapsed            | 2440        |\n",
      "| total timesteps         | 204540      |\n",
      "| value_loss              | 16.898537   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028470026 |\n",
      "| ent_coef_loss           | -8.729003   |\n",
      "| entropy                 | 14.788562   |\n",
      "| episodes                | 2160        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 749         |\n",
      "| n_updates               | 205927      |\n",
      "| policy_loss             | -202.04166  |\n",
      "| qf1_loss                | 18.546547   |\n",
      "| qf2_loss                | 20.01476    |\n",
      "| time_elapsed            | 2459        |\n",
      "| total timesteps         | 206026      |\n",
      "| value_loss              | 9.30625     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02847025 |\n",
      "| ent_coef_loss           | -4.462369  |\n",
      "| entropy                 | 14.683218  |\n",
      "| episodes                | 2170       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 735        |\n",
      "| n_updates               | 207231     |\n",
      "| policy_loss             | -196.43669 |\n",
      "| qf1_loss                | 14.5858555 |\n",
      "| qf2_loss                | 11.252096  |\n",
      "| time_elapsed            | 2475       |\n",
      "| total timesteps         | 207330     |\n",
      "| value_loss              | 14.946774  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028811708 |\n",
      "| ent_coef_loss           | -4.9174414  |\n",
      "| entropy                 | 14.550729   |\n",
      "| episodes                | 2180        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 727         |\n",
      "| n_updates               | 208586      |\n",
      "| policy_loss             | -198.08655  |\n",
      "| qf1_loss                | 11.707621   |\n",
      "| qf2_loss                | 13.665365   |\n",
      "| time_elapsed            | 2490        |\n",
      "| total timesteps         | 208685      |\n",
      "| value_loss              | 10.528481   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028363476 |\n",
      "| ent_coef_loss           | 2.7484283   |\n",
      "| entropy                 | 14.00968    |\n",
      "| episodes                | 2190        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 742         |\n",
      "| n_updates               | 210135      |\n",
      "| policy_loss             | -204.35968  |\n",
      "| qf1_loss                | 13.92291    |\n",
      "| qf2_loss                | 16.450375   |\n",
      "| time_elapsed            | 2507        |\n",
      "| total timesteps         | 210234      |\n",
      "| value_loss              | 6.0489473   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029345104 |\n",
      "| ent_coef_loss           | -7.9840713  |\n",
      "| entropy                 | 14.778465   |\n",
      "| episodes                | 2200        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 715         |\n",
      "| n_updates               | 211138      |\n",
      "| policy_loss             | -189.92307  |\n",
      "| qf1_loss                | 13.736845   |\n",
      "| qf2_loss                | 13.312      |\n",
      "| time_elapsed            | 2519        |\n",
      "| total timesteps         | 211237      |\n",
      "| value_loss              | 16.069508   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029400723 |\n",
      "| ent_coef_loss           | 6.5816574   |\n",
      "| entropy                 | 13.682611   |\n",
      "| episodes                | 2210        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 717         |\n",
      "| n_updates               | 212461      |\n",
      "| policy_loss             | -225.29996  |\n",
      "| qf1_loss                | 19.29541    |\n",
      "| qf2_loss                | 18.075382   |\n",
      "| time_elapsed            | 2534        |\n",
      "| total timesteps         | 212560      |\n",
      "| value_loss              | 23.380182   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028630137 |\n",
      "| ent_coef_loss           | 1.367549    |\n",
      "| entropy                 | 14.484201   |\n",
      "| episodes                | 2220        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 706         |\n",
      "| n_updates               | 213626      |\n",
      "| policy_loss             | -193.60297  |\n",
      "| qf1_loss                | 22.198212   |\n",
      "| qf2_loss                | 20.824247   |\n",
      "| time_elapsed            | 2547        |\n",
      "| total timesteps         | 213725      |\n",
      "| value_loss              | 8.71564     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029931005 |\n",
      "| ent_coef_loss           | -2.2275922  |\n",
      "| entropy                 | 14.862116   |\n",
      "| episodes                | 2230        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 728         |\n",
      "| n_updates               | 215495      |\n",
      "| policy_loss             | -190.44359  |\n",
      "| qf1_loss                | 18.796747   |\n",
      "| qf2_loss                | 16.176804   |\n",
      "| time_elapsed            | 2568        |\n",
      "| total timesteps         | 215594      |\n",
      "| value_loss              | 11.2231865  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029978378 |\n",
      "| ent_coef_loss           | -3.1240277  |\n",
      "| entropy                 | 14.222283   |\n",
      "| episodes                | 2240        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 712         |\n",
      "| n_updates               | 216934      |\n",
      "| policy_loss             | -202.60272  |\n",
      "| qf1_loss                | 30.26477    |\n",
      "| qf2_loss                | 23.617937   |\n",
      "| time_elapsed            | 2585        |\n",
      "| total timesteps         | 217033      |\n",
      "| value_loss              | 14.539797   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029891783 |\n",
      "| ent_coef_loss           | -1.6986125  |\n",
      "| entropy                 | 14.895342   |\n",
      "| episodes                | 2250        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 703         |\n",
      "| n_updates               | 218408      |\n",
      "| policy_loss             | -203.58427  |\n",
      "| qf1_loss                | 19.315155   |\n",
      "| qf2_loss                | 20.773777   |\n",
      "| time_elapsed            | 2604        |\n",
      "| total timesteps         | 218507      |\n",
      "| value_loss              | 14.031309   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030624768 |\n",
      "| ent_coef_loss           | -9.930386   |\n",
      "| entropy                 | 14.898289   |\n",
      "| episodes                | 2260        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 710         |\n",
      "| n_updates               | 220003      |\n",
      "| policy_loss             | -202.17464  |\n",
      "| qf1_loss                | 17.249542   |\n",
      "| qf2_loss                | 10.341377   |\n",
      "| time_elapsed            | 2621        |\n",
      "| total timesteps         | 220102      |\n",
      "| value_loss              | 9.886293    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030627973 |\n",
      "| ent_coef_loss           | 2.1574445   |\n",
      "| entropy                 | 13.746074   |\n",
      "| episodes                | 2270        |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 725         |\n",
      "| n_updates               | 221550      |\n",
      "| policy_loss             | -207.20677  |\n",
      "| qf1_loss                | 18.473686   |\n",
      "| qf2_loss                | 19.556282   |\n",
      "| time_elapsed            | 2638        |\n",
      "| total timesteps         | 221649      |\n",
      "| value_loss              | 21.330942   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030244274 |\n",
      "| ent_coef_loss           | -1.0537395  |\n",
      "| entropy                 | 14.82908    |\n",
      "| episodes                | 2280        |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 728         |\n",
      "| n_updates               | 222884      |\n",
      "| policy_loss             | -204.7322   |\n",
      "| qf1_loss                | 15.726856   |\n",
      "| qf2_loss                | 18.409979   |\n",
      "| time_elapsed            | 2653        |\n",
      "| total timesteps         | 222983      |\n",
      "| value_loss              | 12.535695   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031017147 |\n",
      "| ent_coef_loss           | 1.6126572   |\n",
      "| entropy                 | 14.289879   |\n",
      "| episodes                | 2290        |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 730         |\n",
      "| n_updates               | 224425      |\n",
      "| policy_loss             | -191.27449  |\n",
      "| qf1_loss                | 13.776123   |\n",
      "| qf2_loss                | 11.410454   |\n",
      "| time_elapsed            | 2670        |\n",
      "| total timesteps         | 224524      |\n",
      "| value_loss              | 19.463537   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03154635 |\n",
      "| ent_coef_loss           | 10.361381  |\n",
      "| entropy                 | 14.272766  |\n",
      "| episodes                | 2300       |\n",
      "| fps                     | 84         |\n",
      "| mean 100 episode reward | 754        |\n",
      "| n_updates               | 225901     |\n",
      "| policy_loss             | -203.60127 |\n",
      "| qf1_loss                | 27.293266  |\n",
      "| qf2_loss                | 21.999287  |\n",
      "| time_elapsed            | 2685       |\n",
      "| total timesteps         | 226000     |\n",
      "| value_loss              | 9.676245   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.0310821  |\n",
      "| ent_coef_loss           | 1.768805   |\n",
      "| entropy                 | 14.539597  |\n",
      "| episodes                | 2310       |\n",
      "| fps                     | 84         |\n",
      "| mean 100 episode reward | 752        |\n",
      "| n_updates               | 227154     |\n",
      "| policy_loss             | -209.98457 |\n",
      "| qf1_loss                | 32.07435   |\n",
      "| qf2_loss                | 24.969383  |\n",
      "| time_elapsed            | 2698       |\n",
      "| total timesteps         | 227253     |\n",
      "| value_loss              | 13.245318  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030725878 |\n",
      "| ent_coef_loss           | -3.8751616  |\n",
      "| entropy                 | 15.19584    |\n",
      "| episodes                | 2320        |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 790         |\n",
      "| n_updates               | 229159      |\n",
      "| policy_loss             | -194.73636  |\n",
      "| qf1_loss                | 17.170021   |\n",
      "| qf2_loss                | 14.754725   |\n",
      "| time_elapsed            | 2719        |\n",
      "| total timesteps         | 229258      |\n",
      "| value_loss              | 5.9511986   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031184362 |\n",
      "| ent_coef_loss           | -2.227676   |\n",
      "| entropy                 | 14.653955   |\n",
      "| episodes                | 2330        |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 793         |\n",
      "| n_updates               | 231108      |\n",
      "| policy_loss             | -196.355    |\n",
      "| qf1_loss                | 10.599629   |\n",
      "| qf2_loss                | 9.957336    |\n",
      "| time_elapsed            | 2740        |\n",
      "| total timesteps         | 231207      |\n",
      "| value_loss              | 10.163292   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030060828 |\n",
      "| ent_coef_loss           | -1.2433388  |\n",
      "| entropy                 | 13.883796   |\n",
      "| episodes                | 2340        |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 799         |\n",
      "| n_updates               | 232735      |\n",
      "| policy_loss             | -219.7012   |\n",
      "| qf1_loss                | 23.122093   |\n",
      "| qf2_loss                | 29.898134   |\n",
      "| time_elapsed            | 2758        |\n",
      "| total timesteps         | 232834      |\n",
      "| value_loss              | 18.17745    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.032047678 |\n",
      "| ent_coef_loss           | -0.2857238  |\n",
      "| entropy                 | 14.773907   |\n",
      "| episodes                | 2350        |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 787         |\n",
      "| n_updates               | 233971      |\n",
      "| policy_loss             | -202.5552   |\n",
      "| qf1_loss                | 21.652813   |\n",
      "| qf2_loss                | 23.207275   |\n",
      "| time_elapsed            | 2771        |\n",
      "| total timesteps         | 234070      |\n",
      "| value_loss              | 19.748571   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031414926 |\n",
      "| ent_coef_loss           | 6.5624857   |\n",
      "| entropy                 | 13.967148   |\n",
      "| episodes                | 2360        |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 827         |\n",
      "| n_updates               | 236389      |\n",
      "| policy_loss             | -190.88489  |\n",
      "| qf1_loss                | 13.033174   |\n",
      "| qf2_loss                | 10.513069   |\n",
      "| time_elapsed            | 2797        |\n",
      "| total timesteps         | 236488      |\n",
      "| value_loss              | 16.958267   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031403366 |\n",
      "| ent_coef_loss           | -4.341761   |\n",
      "| entropy                 | 14.384861   |\n",
      "| episodes                | 2370        |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 842         |\n",
      "| n_updates               | 238292      |\n",
      "| policy_loss             | -192.4173   |\n",
      "| qf1_loss                | 13.127241   |\n",
      "| qf2_loss                | 16.467644   |\n",
      "| time_elapsed            | 2820        |\n",
      "| total timesteps         | 238391      |\n",
      "| value_loss              | 8.567742    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031915095 |\n",
      "| ent_coef_loss           | -4.9190674  |\n",
      "| entropy                 | 14.789514   |\n",
      "| episodes                | 2380        |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 852         |\n",
      "| n_updates               | 239874      |\n",
      "| policy_loss             | -197.3899   |\n",
      "| qf1_loss                | 15.338716   |\n",
      "| qf2_loss                | 19.163437   |\n",
      "| time_elapsed            | 2837        |\n",
      "| total timesteps         | 239973      |\n",
      "| value_loss              | 7.282838    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031346947 |\n",
      "| ent_coef_loss           | -8.642336   |\n",
      "| entropy                 | 14.901524   |\n",
      "| episodes                | 2390        |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 860         |\n",
      "| n_updates               | 241555      |\n",
      "| policy_loss             | -171.83282  |\n",
      "| qf1_loss                | 12.755266   |\n",
      "| qf2_loss                | 21.044754   |\n",
      "| time_elapsed            | 2854        |\n",
      "| total timesteps         | 241654      |\n",
      "| value_loss              | 14.78702    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031372234 |\n",
      "| ent_coef_loss           | -5.607807   |\n",
      "| entropy                 | 14.747271   |\n",
      "| episodes                | 2400        |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 859         |\n",
      "| n_updates               | 242995      |\n",
      "| policy_loss             | -200.78441  |\n",
      "| qf1_loss                | 20.239109   |\n",
      "| qf2_loss                | 25.179226   |\n",
      "| time_elapsed            | 2869        |\n",
      "| total timesteps         | 243094      |\n",
      "| value_loss              | 18.584345   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03192368 |\n",
      "| ent_coef_loss           | 4.000783   |\n",
      "| entropy                 | 14.7119255 |\n",
      "| episodes                | 2410       |\n",
      "| fps                     | 84         |\n",
      "| mean 100 episode reward | 858        |\n",
      "| n_updates               | 244198     |\n",
      "| policy_loss             | -187.74475 |\n",
      "| qf1_loss                | 14.708235  |\n",
      "| qf2_loss                | 22.002277  |\n",
      "| time_elapsed            | 2881       |\n",
      "| total timesteps         | 244297     |\n",
      "| value_loss              | 16.05232   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.032517   |\n",
      "| ent_coef_loss           | 4.272448   |\n",
      "| entropy                 | 14.20905   |\n",
      "| episodes                | 2420       |\n",
      "| fps                     | 84         |\n",
      "| mean 100 episode reward | 828        |\n",
      "| n_updates               | 245524     |\n",
      "| policy_loss             | -230.96089 |\n",
      "| qf1_loss                | 22.683088  |\n",
      "| qf2_loss                | 18.599293  |\n",
      "| time_elapsed            | 2895       |\n",
      "| total timesteps         | 245623     |\n",
      "| value_loss              | 11.0971985 |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.032218896 |\n",
      "| ent_coef_loss           | -0.6245457  |\n",
      "| entropy                 | 14.801079   |\n",
      "| episodes                | 2430        |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 845         |\n",
      "| n_updates               | 247793      |\n",
      "| policy_loss             | -190.83281  |\n",
      "| qf1_loss                | 17.567049   |\n",
      "| qf2_loss                | 15.043467   |\n",
      "| time_elapsed            | 2918        |\n",
      "| total timesteps         | 247892      |\n",
      "| value_loss              | 17.750378   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03298024 |\n",
      "| ent_coef_loss           | -7.8043084 |\n",
      "| entropy                 | 14.733273  |\n",
      "| episodes                | 2440       |\n",
      "| fps                     | 84         |\n",
      "| mean 100 episode reward | 850        |\n",
      "| n_updates               | 249462     |\n",
      "| policy_loss             | -212.86653 |\n",
      "| qf1_loss                | 20.049725  |\n",
      "| qf2_loss                | 25.134403  |\n",
      "| time_elapsed            | 2936       |\n",
      "| total timesteps         | 249561     |\n",
      "| value_loss              | 13.59548   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.032664005 |\n",
      "| ent_coef_loss           | -6.3482857  |\n",
      "| entropy                 | 14.556084   |\n",
      "| episodes                | 2450        |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 865         |\n",
      "| n_updates               | 250971      |\n",
      "| policy_loss             | -214.38638  |\n",
      "| qf1_loss                | 23.664124   |\n",
      "| qf2_loss                | 21.019106   |\n",
      "| time_elapsed            | 2951        |\n",
      "| total timesteps         | 251070      |\n",
      "| value_loss              | 10.009308   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03279208 |\n",
      "| ent_coef_loss           | -6.8391733 |\n",
      "| entropy                 | 14.50598   |\n",
      "| episodes                | 2460       |\n",
      "| fps                     | 85         |\n",
      "| mean 100 episode reward | 840        |\n",
      "| n_updates               | 252896     |\n",
      "| policy_loss             | -207.15073 |\n",
      "| qf1_loss                | 17.124123  |\n",
      "| qf2_loss                | 16.355843  |\n",
      "| time_elapsed            | 2972       |\n",
      "| total timesteps         | 252995     |\n",
      "| value_loss              | 12.478087  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.032974925 |\n",
      "| ent_coef_loss           | -9.028177   |\n",
      "| entropy                 | 14.859552   |\n",
      "| episodes                | 2470        |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 828         |\n",
      "| n_updates               | 254522      |\n",
      "| policy_loss             | -214.19159  |\n",
      "| qf1_loss                | 24.757595   |\n",
      "| qf2_loss                | 23.523624   |\n",
      "| time_elapsed            | 2991        |\n",
      "| total timesteps         | 254621      |\n",
      "| value_loss              | 13.049879   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03169588 |\n",
      "| ent_coef_loss           | 8.472141   |\n",
      "| entropy                 | 14.012999  |\n",
      "| episodes                | 2480       |\n",
      "| fps                     | 85         |\n",
      "| mean 100 episode reward | 845        |\n",
      "| n_updates               | 256431     |\n",
      "| policy_loss             | -206.37323 |\n",
      "| qf1_loss                | 14.906103  |\n",
      "| qf2_loss                | 16.658484  |\n",
      "| time_elapsed            | 3011       |\n",
      "| total timesteps         | 256530     |\n",
      "| value_loss              | 25.834759  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.034261048 |\n",
      "| ent_coef_loss           | 1.6934528   |\n",
      "| entropy                 | 14.779165   |\n",
      "| episodes                | 2490        |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 829         |\n",
      "| n_updates               | 257789      |\n",
      "| policy_loss             | -235.39273  |\n",
      "| qf1_loss                | 14.634723   |\n",
      "| qf2_loss                | 22.302074   |\n",
      "| time_elapsed            | 3027        |\n",
      "| total timesteps         | 257888      |\n",
      "| value_loss              | 18.339443   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.032511357 |\n",
      "| ent_coef_loss           | 0.22655153  |\n",
      "| entropy                 | 13.628399   |\n",
      "| episodes                | 2500        |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 838         |\n",
      "| n_updates               | 259483      |\n",
      "| policy_loss             | -209.65994  |\n",
      "| qf1_loss                | 20.560204   |\n",
      "| qf2_loss                | 22.072634   |\n",
      "| time_elapsed            | 3045        |\n",
      "| total timesteps         | 259582      |\n",
      "| value_loss              | 12.510516   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031121481 |\n",
      "| ent_coef_loss           | -3.620656   |\n",
      "| entropy                 | 14.6409855  |\n",
      "| episodes                | 2510        |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 903         |\n",
      "| n_updates               | 262010      |\n",
      "| policy_loss             | -204.04498  |\n",
      "| qf1_loss                | 17.549488   |\n",
      "| qf2_loss                | 23.06605    |\n",
      "| time_elapsed            | 3075        |\n",
      "| total timesteps         | 262109      |\n",
      "| value_loss              | 14.653355   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.032740194 |\n",
      "| ent_coef_loss           | -3.071032   |\n",
      "| entropy                 | 14.036766   |\n",
      "| episodes                | 2520        |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 936         |\n",
      "| n_updates               | 264049      |\n",
      "| policy_loss             | -203.24353  |\n",
      "| qf1_loss                | 22.914272   |\n",
      "| qf2_loss                | 18.540913   |\n",
      "| time_elapsed            | 3096        |\n",
      "| total timesteps         | 264148      |\n",
      "| value_loss              | 17.4897     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.032189965 |\n",
      "| ent_coef_loss           | 0.44049275  |\n",
      "| entropy                 | 13.859234   |\n",
      "| episodes                | 2530        |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 936         |\n",
      "| n_updates               | 266337      |\n",
      "| policy_loss             | -218.85466  |\n",
      "| qf1_loss                | 24.875494   |\n",
      "| qf2_loss                | 19.659363   |\n",
      "| time_elapsed            | 3120        |\n",
      "| total timesteps         | 266436      |\n",
      "| value_loss              | 15.573429   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03316908 |\n",
      "| ent_coef_loss           | 1.6169822  |\n",
      "| entropy                 | 14.271088  |\n",
      "| episodes                | 2540       |\n",
      "| fps                     | 85         |\n",
      "| mean 100 episode reward | 957        |\n",
      "| n_updates               | 268445     |\n",
      "| policy_loss             | -220.30917 |\n",
      "| qf1_loss                | 24.990728  |\n",
      "| qf2_loss                | 18.818764  |\n",
      "| time_elapsed            | 3142       |\n",
      "| total timesteps         | 268544     |\n",
      "| value_loss              | 11.520169  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.032159988 |\n",
      "| ent_coef_loss           | -1.7820938  |\n",
      "| entropy                 | 14.3030815  |\n",
      "| episodes                | 2550        |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 974         |\n",
      "| n_updates               | 270309      |\n",
      "| policy_loss             | -214.52289  |\n",
      "| qf1_loss                | 25.074203   |\n",
      "| qf2_loss                | 19.662752   |\n",
      "| time_elapsed            | 3161        |\n",
      "| total timesteps         | 270408      |\n",
      "| value_loss              | 9.517488    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03247468 |\n",
      "| ent_coef_loss           | 1.150799   |\n",
      "| entropy                 | 13.779242  |\n",
      "| episodes                | 2560       |\n",
      "| fps                     | 85         |\n",
      "| mean 100 episode reward | 1.03e+03   |\n",
      "| n_updates               | 273324     |\n",
      "| policy_loss             | -214.77759 |\n",
      "| qf1_loss                | 17.806011  |\n",
      "| qf2_loss                | 20.82716   |\n",
      "| time_elapsed            | 3192       |\n",
      "| total timesteps         | 273423     |\n",
      "| value_loss              | 9.587427   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03396496 |\n",
      "| ent_coef_loss           | -6.0377045 |\n",
      "| entropy                 | 15.28479   |\n",
      "| episodes                | 2570       |\n",
      "| fps                     | 85         |\n",
      "| mean 100 episode reward | 1.06e+03   |\n",
      "| n_updates               | 275561     |\n",
      "| policy_loss             | -230.72662 |\n",
      "| qf1_loss                | 16.250908  |\n",
      "| qf2_loss                | 18.265858  |\n",
      "| time_elapsed            | 3215       |\n",
      "| total timesteps         | 275660     |\n",
      "| value_loss              | 10.537747  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.033368852 |\n",
      "| ent_coef_loss           | -5.9048686  |\n",
      "| entropy                 | 13.954583   |\n",
      "| episodes                | 2580        |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 1.08e+03    |\n",
      "| n_updates               | 277807      |\n",
      "| policy_loss             | -219.43326  |\n",
      "| qf1_loss                | 17.276121   |\n",
      "| qf2_loss                | 16.295212   |\n",
      "| time_elapsed            | 3239        |\n",
      "| total timesteps         | 277906      |\n",
      "| value_loss              | 12.421591   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03416965 |\n",
      "| ent_coef_loss           | 3.6600697  |\n",
      "| entropy                 | 14.111429  |\n",
      "| episodes                | 2590       |\n",
      "| fps                     | 85         |\n",
      "| mean 100 episode reward | 1.12e+03   |\n",
      "| n_updates               | 279953     |\n",
      "| policy_loss             | -204.82489 |\n",
      "| qf1_loss                | 20.388615  |\n",
      "| qf2_loss                | 15.817951  |\n",
      "| time_elapsed            | 3263       |\n",
      "| total timesteps         | 280052     |\n",
      "| value_loss              | 21.417343  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.033244934 |\n",
      "| ent_coef_loss           | -5.771246   |\n",
      "| entropy                 | 14.617327   |\n",
      "| episodes                | 2600        |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 1.15e+03    |\n",
      "| n_updates               | 282121      |\n",
      "| policy_loss             | -204.91953  |\n",
      "| qf1_loss                | 22.628052   |\n",
      "| qf2_loss                | 20.136738   |\n",
      "| time_elapsed            | 3288        |\n",
      "| total timesteps         | 282220      |\n",
      "| value_loss              | 11.199917   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.033204462 |\n",
      "| ent_coef_loss           | -4.409906   |\n",
      "| entropy                 | 14.352977   |\n",
      "| episodes                | 2610        |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 1.14e+03    |\n",
      "| n_updates               | 284285      |\n",
      "| policy_loss             | -228.30515  |\n",
      "| qf1_loss                | 15.729067   |\n",
      "| qf2_loss                | 14.471083   |\n",
      "| time_elapsed            | 3310        |\n",
      "| total timesteps         | 284384      |\n",
      "| value_loss              | 15.70075    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03464734 |\n",
      "| ent_coef_loss           | 2.9685683  |\n",
      "| entropy                 | 13.7981    |\n",
      "| episodes                | 2620       |\n",
      "| fps                     | 85         |\n",
      "| mean 100 episode reward | 1.14e+03   |\n",
      "| n_updates               | 286279     |\n",
      "| policy_loss             | -230.94188 |\n",
      "| qf1_loss                | 45.080097  |\n",
      "| qf2_loss                | 25.467758  |\n",
      "| time_elapsed            | 3330       |\n",
      "| total timesteps         | 286378     |\n",
      "| value_loss              | 58.886726  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035411496 |\n",
      "| ent_coef_loss           | 3.7423148   |\n",
      "| entropy                 | 13.94529    |\n",
      "| episodes                | 2630        |\n",
      "| fps                     | 86          |\n",
      "| mean 100 episode reward | 1.12e+03    |\n",
      "| n_updates               | 288247      |\n",
      "| policy_loss             | -204.18893  |\n",
      "| qf1_loss                | 15.365349   |\n",
      "| qf2_loss                | 13.346051   |\n",
      "| time_elapsed            | 3351        |\n",
      "| total timesteps         | 288346      |\n",
      "| value_loss              | 14.806957   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.034905307 |\n",
      "| ent_coef_loss           | -2.560594   |\n",
      "| entropy                 | 14.517075   |\n",
      "| episodes                | 2640        |\n",
      "| fps                     | 86          |\n",
      "| mean 100 episode reward | 1.15e+03    |\n",
      "| n_updates               | 291079      |\n",
      "| policy_loss             | -229.22443  |\n",
      "| qf1_loss                | 24.806969   |\n",
      "| qf2_loss                | 26.414059   |\n",
      "| time_elapsed            | 3380        |\n",
      "| total timesteps         | 291178      |\n",
      "| value_loss              | 16.897404   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.03426623  |\n",
      "| ent_coef_loss           | -0.13562179 |\n",
      "| entropy                 | 14.237202   |\n",
      "| episodes                | 2650        |\n",
      "| fps                     | 86          |\n",
      "| mean 100 episode reward | 1.21e+03    |\n",
      "| n_updates               | 294137      |\n",
      "| policy_loss             | -247.68839  |\n",
      "| qf1_loss                | 18.853203   |\n",
      "| qf2_loss                | 13.486107   |\n",
      "| time_elapsed            | 3415        |\n",
      "| total timesteps         | 294236      |\n",
      "| value_loss              | 16.205482   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.034599066 |\n",
      "| ent_coef_loss           | 16.332607   |\n",
      "| entropy                 | 13.601641   |\n",
      "| episodes                | 2660        |\n",
      "| fps                     | 86          |\n",
      "| mean 100 episode reward | 1.2e+03     |\n",
      "| n_updates               | 296913      |\n",
      "| policy_loss             | -255.04776  |\n",
      "| qf1_loss                | 29.187513   |\n",
      "| qf2_loss                | 29.622807   |\n",
      "| time_elapsed            | 3445        |\n",
      "| total timesteps         | 297012      |\n",
      "| value_loss              | 11.357231   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.032544184 |\n",
      "| ent_coef_loss           | -10.303692  |\n",
      "| entropy                 | 14.269972   |\n",
      "| episodes                | 2670        |\n",
      "| fps                     | 86          |\n",
      "| mean 100 episode reward | 1.17e+03    |\n",
      "| n_updates               | 298703      |\n",
      "| policy_loss             | -220.15546  |\n",
      "| qf1_loss                | 28.391464   |\n",
      "| qf2_loss                | 35.22182    |\n",
      "| time_elapsed            | 3464        |\n",
      "| total timesteps         | 298802      |\n",
      "| value_loss              | 12.403453   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.033783626 |\n",
      "| ent_coef_loss           | -12.221984  |\n",
      "| entropy                 | 14.347954   |\n",
      "| episodes                | 2680        |\n",
      "| fps                     | 86          |\n",
      "| mean 100 episode reward | 1.18e+03    |\n",
      "| n_updates               | 301189      |\n",
      "| policy_loss             | -223.29439  |\n",
      "| qf1_loss                | 17.710976   |\n",
      "| qf2_loss                | 23.054068   |\n",
      "| time_elapsed            | 3489        |\n",
      "| total timesteps         | 301288      |\n",
      "| value_loss              | 13.968718   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.033843245 |\n",
      "| ent_coef_loss           | 4.2181816   |\n",
      "| entropy                 | 13.635207   |\n",
      "| episodes                | 2690        |\n",
      "| fps                     | 86          |\n",
      "| mean 100 episode reward | 1.19e+03    |\n",
      "| n_updates               | 303552      |\n",
      "| policy_loss             | -220.97488  |\n",
      "| qf1_loss                | 18.861025   |\n",
      "| qf2_loss                | 21.315392   |\n",
      "| time_elapsed            | 3519        |\n",
      "| total timesteps         | 303651      |\n",
      "| value_loss              | 10.559311   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035186935 |\n",
      "| ent_coef_loss           | 5.887736    |\n",
      "| entropy                 | 14.3312435  |\n",
      "| episodes                | 2700        |\n",
      "| fps                     | 86          |\n",
      "| mean 100 episode reward | 1.2e+03     |\n",
      "| n_updates               | 305842      |\n",
      "| policy_loss             | -211.78476  |\n",
      "| qf1_loss                | 26.968607   |\n",
      "| qf2_loss                | 31.854652   |\n",
      "| time_elapsed            | 3549        |\n",
      "| total timesteps         | 305941      |\n",
      "| value_loss              | 45.0279     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.034045786 |\n",
      "| ent_coef_loss           | -11.472035  |\n",
      "| entropy                 | 14.692821   |\n",
      "| episodes                | 2710        |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 1.25e+03    |\n",
      "| n_updates               | 309027      |\n",
      "| policy_loss             | -209.50546  |\n",
      "| qf1_loss                | 16.537405   |\n",
      "| qf2_loss                | 14.720251   |\n",
      "| time_elapsed            | 3595        |\n",
      "| total timesteps         | 309126      |\n",
      "| value_loss              | 11.277486   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.034528576 |\n",
      "| ent_coef_loss           | -4.2728157  |\n",
      "| entropy                 | 14.306927   |\n",
      "| episodes                | 2720        |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 1.28e+03    |\n",
      "| n_updates               | 311481      |\n",
      "| policy_loss             | -251.03366  |\n",
      "| qf1_loss                | 27.327152   |\n",
      "| qf2_loss                | 26.424257   |\n",
      "| time_elapsed            | 3626        |\n",
      "| total timesteps         | 311580      |\n",
      "| value_loss              | 14.7596855  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.034049124 |\n",
      "| ent_coef_loss           | 2.4542994   |\n",
      "| entropy                 | 14.638479   |\n",
      "| episodes                | 2730        |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 1.3e+03     |\n",
      "| n_updates               | 314026      |\n",
      "| policy_loss             | -242.56622  |\n",
      "| qf1_loss                | 21.266342   |\n",
      "| qf2_loss                | 29.374266   |\n",
      "| time_elapsed            | 3660        |\n",
      "| total timesteps         | 314125      |\n",
      "| value_loss              | 12.878658   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035443347 |\n",
      "| ent_coef_loss           | 1.296416    |\n",
      "| entropy                 | 14.118126   |\n",
      "| episodes                | 2740        |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 1.31e+03    |\n",
      "| n_updates               | 316832      |\n",
      "| policy_loss             | -250.76245  |\n",
      "| qf1_loss                | 23.818066   |\n",
      "| qf2_loss                | 21.024256   |\n",
      "| time_elapsed            | 3695        |\n",
      "| total timesteps         | 316931      |\n",
      "| value_loss              | 10.731155   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03451925 |\n",
      "| ent_coef_loss           | -6.885414  |\n",
      "| entropy                 | 14.260357  |\n",
      "| episodes                | 2750       |\n",
      "| fps                     | 85         |\n",
      "| mean 100 episode reward | 1.3e+03    |\n",
      "| n_updates               | 319721     |\n",
      "| policy_loss             | -228.64653 |\n",
      "| qf1_loss                | 20.393555  |\n",
      "| qf2_loss                | 22.954681  |\n",
      "| time_elapsed            | 3733       |\n",
      "| total timesteps         | 319820     |\n",
      "| value_loss              | 16.171204  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.0349224  |\n",
      "| ent_coef_loss           | -5.019112  |\n",
      "| entropy                 | 14.572037  |\n",
      "| episodes                | 2760       |\n",
      "| fps                     | 85         |\n",
      "| mean 100 episode reward | 1.29e+03   |\n",
      "| n_updates               | 322215     |\n",
      "| policy_loss             | -265.51788 |\n",
      "| qf1_loss                | 16.92776   |\n",
      "| qf2_loss                | 15.26357   |\n",
      "| time_elapsed            | 3766       |\n",
      "| total timesteps         | 322314     |\n",
      "| value_loss              | 14.633429  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03574328 |\n",
      "| ent_coef_loss           | 5.0928965  |\n",
      "| entropy                 | 14.372396  |\n",
      "| episodes                | 2770       |\n",
      "| fps                     | 85         |\n",
      "| mean 100 episode reward | 1.36e+03   |\n",
      "| n_updates               | 325454     |\n",
      "| policy_loss             | -231.88821 |\n",
      "| qf1_loss                | 19.032368  |\n",
      "| qf2_loss                | 18.973923  |\n",
      "| time_elapsed            | 3806       |\n",
      "| total timesteps         | 325553     |\n",
      "| value_loss              | 13.3431    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036019597 |\n",
      "| ent_coef_loss           | 2.086008    |\n",
      "| entropy                 | 14.448618   |\n",
      "| episodes                | 2780        |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 1.36e+03    |\n",
      "| n_updates               | 328004      |\n",
      "| policy_loss             | -227.6584   |\n",
      "| qf1_loss                | 29.545311   |\n",
      "| qf2_loss                | 36.73671    |\n",
      "| time_elapsed            | 3839        |\n",
      "| total timesteps         | 328103      |\n",
      "| value_loss              | 24.547993   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03334298 |\n",
      "| ent_coef_loss           | 5.9019065  |\n",
      "| entropy                 | 13.919022  |\n",
      "| episodes                | 2790       |\n",
      "| fps                     | 85         |\n",
      "| mean 100 episode reward | 1.37e+03   |\n",
      "| n_updates               | 330449     |\n",
      "| policy_loss             | -218.93591 |\n",
      "| qf1_loss                | 30.127491  |\n",
      "| qf2_loss                | 26.280111  |\n",
      "| time_elapsed            | 3873       |\n",
      "| total timesteps         | 330548     |\n",
      "| value_loss              | 22.197521  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.034523785 |\n",
      "| ent_coef_loss           | -4.0536857  |\n",
      "| entropy                 | 14.376237   |\n",
      "| episodes                | 2800        |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 1.34e+03    |\n",
      "| n_updates               | 332192      |\n",
      "| policy_loss             | -245.40897  |\n",
      "| qf1_loss                | 17.970995   |\n",
      "| qf2_loss                | 11.861379   |\n",
      "| time_elapsed            | 3895        |\n",
      "| total timesteps         | 332291      |\n",
      "| value_loss              | 36.458885   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03479983 |\n",
      "| ent_coef_loss           | -4.7279224 |\n",
      "| entropy                 | 14.335835  |\n",
      "| episodes                | 2810       |\n",
      "| fps                     | 85         |\n",
      "| mean 100 episode reward | 1.31e+03   |\n",
      "| n_updates               | 334870     |\n",
      "| policy_loss             | -213.58499 |\n",
      "| qf1_loss                | 34.661484  |\n",
      "| qf2_loss                | 20.744183  |\n",
      "| time_elapsed            | 3924       |\n",
      "| total timesteps         | 334969     |\n",
      "| value_loss              | 18.474987  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035209145 |\n",
      "| ent_coef_loss           | 4.1890206   |\n",
      "| entropy                 | 13.614674   |\n",
      "| episodes                | 2820        |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 1.32e+03    |\n",
      "| n_updates               | 337548      |\n",
      "| policy_loss             | -247.50044  |\n",
      "| qf1_loss                | 28.508299   |\n",
      "| qf2_loss                | 36.21926    |\n",
      "| time_elapsed            | 3952        |\n",
      "| total timesteps         | 337647      |\n",
      "| value_loss              | 24.89613    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.033804946 |\n",
      "| ent_coef_loss           | -4.6758747  |\n",
      "| entropy                 | 14.346809   |\n",
      "| episodes                | 2830        |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 1.34e+03    |\n",
      "| n_updates               | 340408      |\n",
      "| policy_loss             | -234.64548  |\n",
      "| qf1_loss                | 14.559048   |\n",
      "| qf2_loss                | 18.83892    |\n",
      "| time_elapsed            | 3982        |\n",
      "| total timesteps         | 340507      |\n",
      "| value_loss              | 15.494921   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.0359645  |\n",
      "| ent_coef_loss           | 4.170557   |\n",
      "| entropy                 | 14.245802  |\n",
      "| episodes                | 2840       |\n",
      "| fps                     | 85         |\n",
      "| mean 100 episode reward | 1.33e+03   |\n",
      "| n_updates               | 343035     |\n",
      "| policy_loss             | -271.62372 |\n",
      "| qf1_loss                | 22.113914  |\n",
      "| qf2_loss                | 33.202614  |\n",
      "| time_elapsed            | 4009       |\n",
      "| total timesteps         | 343134     |\n",
      "| value_loss              | 23.136925  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.034556594 |\n",
      "| ent_coef_loss           | -0.6875967  |\n",
      "| entropy                 | 14.108434   |\n",
      "| episodes                | 2850        |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 1.36e+03    |\n",
      "| n_updates               | 346486      |\n",
      "| policy_loss             | -225.6761   |\n",
      "| qf1_loss                | 19.449348   |\n",
      "| qf2_loss                | 18.701273   |\n",
      "| time_elapsed            | 4044        |\n",
      "| total timesteps         | 346585      |\n",
      "| value_loss              | 15.877823   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035687864 |\n",
      "| ent_coef_loss           | 8.318498    |\n",
      "| entropy                 | 13.253987   |\n",
      "| episodes                | 2860        |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 1.36e+03    |\n",
      "| n_updates               | 349085      |\n",
      "| policy_loss             | -272.80133  |\n",
      "| qf1_loss                | 27.232635   |\n",
      "| qf2_loss                | 23.936611   |\n",
      "| time_elapsed            | 4071        |\n",
      "| total timesteps         | 349184      |\n",
      "| value_loss              | 16.201168   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03544226 |\n",
      "| ent_coef_loss           | 2.3151364  |\n",
      "| entropy                 | 14.032547  |\n",
      "| episodes                | 2870       |\n",
      "| fps                     | 85         |\n",
      "| mean 100 episode reward | 1.32e+03   |\n",
      "| n_updates               | 351556     |\n",
      "| policy_loss             | -261.39484 |\n",
      "| qf1_loss                | 19.124615  |\n",
      "| qf2_loss                | 27.353382  |\n",
      "| time_elapsed            | 4097       |\n",
      "| total timesteps         | 351655     |\n",
      "| value_loss              | 11.358231  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.0356659  |\n",
      "| ent_coef_loss           | -1.3157396 |\n",
      "| entropy                 | 14.046041  |\n",
      "| episodes                | 2880       |\n",
      "| fps                     | 85         |\n",
      "| mean 100 episode reward | 1.34e+03   |\n",
      "| n_updates               | 354391     |\n",
      "| policy_loss             | -235.36436 |\n",
      "| qf1_loss                | 16.477362  |\n",
      "| qf2_loss                | 16.734568  |\n",
      "| time_elapsed            | 4126       |\n",
      "| total timesteps         | 354490     |\n",
      "| value_loss              | 12.674389  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.037399463 |\n",
      "| ent_coef_loss           | -15.9124    |\n",
      "| entropy                 | 15.190786   |\n",
      "| episodes                | 2890        |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 1.38e+03    |\n",
      "| n_updates               | 357462      |\n",
      "| policy_loss             | -240.8618   |\n",
      "| qf1_loss                | 21.4222     |\n",
      "| qf2_loss                | 22.727066   |\n",
      "| time_elapsed            | 4158        |\n",
      "| total timesteps         | 357561      |\n",
      "| value_loss              | 22.084003   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03527788 |\n",
      "| ent_coef_loss           | 4.313955   |\n",
      "| entropy                 | 14.219479  |\n",
      "| episodes                | 2900       |\n",
      "| fps                     | 86         |\n",
      "| mean 100 episode reward | 1.46e+03   |\n",
      "| n_updates               | 360880     |\n",
      "| policy_loss             | -244.93013 |\n",
      "| qf1_loss                | 26.793758  |\n",
      "| qf2_loss                | 22.710684  |\n",
      "| time_elapsed            | 4193       |\n",
      "| total timesteps         | 360979     |\n",
      "| value_loss              | 16.059952  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.034787558 |\n",
      "| ent_coef_loss           | -0.5971302  |\n",
      "| entropy                 | 13.902368   |\n",
      "| episodes                | 2910        |\n",
      "| fps                     | 86          |\n",
      "| mean 100 episode reward | 1.45e+03    |\n",
      "| n_updates               | 363330      |\n",
      "| policy_loss             | -278.96753  |\n",
      "| qf1_loss                | 18.385681   |\n",
      "| qf2_loss                | 19.23883    |\n",
      "| time_elapsed            | 4218        |\n",
      "| total timesteps         | 363429      |\n",
      "| value_loss              | 25.891155   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036203906 |\n",
      "| ent_coef_loss           | 2.1790977   |\n",
      "| entropy                 | 14.20002    |\n",
      "| episodes                | 2920        |\n",
      "| fps                     | 86          |\n",
      "| mean 100 episode reward | 1.47e+03    |\n",
      "| n_updates               | 366308      |\n",
      "| policy_loss             | -266.22943  |\n",
      "| qf1_loss                | 10.512178   |\n",
      "| qf2_loss                | 13.432165   |\n",
      "| time_elapsed            | 4249        |\n",
      "| total timesteps         | 366407      |\n",
      "| value_loss              | 19.23719    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036188725 |\n",
      "| ent_coef_loss           | -7.871543   |\n",
      "| entropy                 | 14.456811   |\n",
      "| episodes                | 2930        |\n",
      "| fps                     | 86          |\n",
      "| mean 100 episode reward | 1.45e+03    |\n",
      "| n_updates               | 368890      |\n",
      "| policy_loss             | -234.40787  |\n",
      "| qf1_loss                | 27.195326   |\n",
      "| qf2_loss                | 23.068588   |\n",
      "| time_elapsed            | 4276        |\n",
      "| total timesteps         | 368989      |\n",
      "| value_loss              | 11.444147   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035535645 |\n",
      "| ent_coef_loss           | 1.1345552   |\n",
      "| entropy                 | 14.014536   |\n",
      "| episodes                | 2940        |\n",
      "| fps                     | 86          |\n",
      "| mean 100 episode reward | 1.5e+03     |\n",
      "| n_updates               | 372489      |\n",
      "| policy_loss             | -262.8407   |\n",
      "| qf1_loss                | 24.209064   |\n",
      "| qf2_loss                | 21.318583   |\n",
      "| time_elapsed            | 4313        |\n",
      "| total timesteps         | 372588      |\n",
      "| value_loss              | 26.630486   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03546743 |\n",
      "| ent_coef_loss           | 2.1900826  |\n",
      "| entropy                 | 13.8145485 |\n",
      "| episodes                | 2950       |\n",
      "| fps                     | 86         |\n",
      "| mean 100 episode reward | 1.47e+03   |\n",
      "| n_updates               | 375130     |\n",
      "| policy_loss             | -266.07532 |\n",
      "| qf1_loss                | 38.165344  |\n",
      "| qf2_loss                | 31.82483   |\n",
      "| time_elapsed            | 4340       |\n",
      "| total timesteps         | 375229     |\n",
      "| value_loss              | 21.679955  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036591947 |\n",
      "| ent_coef_loss           | 4.2992673   |\n",
      "| entropy                 | 14.38721    |\n",
      "| episodes                | 2960        |\n",
      "| fps                     | 86          |\n",
      "| mean 100 episode reward | 1.45e+03    |\n",
      "| n_updates               | 377421      |\n",
      "| policy_loss             | -266.05396  |\n",
      "| qf1_loss                | 24.646019   |\n",
      "| qf2_loss                | 29.14925    |\n",
      "| time_elapsed            | 4364        |\n",
      "| total timesteps         | 377520      |\n",
      "| value_loss              | 15.000055   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035621412 |\n",
      "| ent_coef_loss           | 2.4118662   |\n",
      "| entropy                 | 13.872871   |\n",
      "| episodes                | 2970        |\n",
      "| fps                     | 86          |\n",
      "| mean 100 episode reward | 1.45e+03    |\n",
      "| n_updates               | 379890      |\n",
      "| policy_loss             | -249.63753  |\n",
      "| qf1_loss                | 46.289955   |\n",
      "| qf2_loss                | 38.49798    |\n",
      "| time_elapsed            | 4389        |\n",
      "| total timesteps         | 379989      |\n",
      "| value_loss              | 20.736452   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035701744 |\n",
      "| ent_coef_loss           | -11.830394  |\n",
      "| entropy                 | 14.526136   |\n",
      "| episodes                | 2980        |\n",
      "| fps                     | 86          |\n",
      "| mean 100 episode reward | 1.41e+03    |\n",
      "| n_updates               | 382057      |\n",
      "| policy_loss             | -266.3987   |\n",
      "| qf1_loss                | 21.178589   |\n",
      "| qf2_loss                | 28.248735   |\n",
      "| time_elapsed            | 4412        |\n",
      "| total timesteps         | 382156      |\n",
      "| value_loss              | 21.21868    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036817398 |\n",
      "| ent_coef_loss           | -2.8988767  |\n",
      "| entropy                 | 14.650793   |\n",
      "| episodes                | 2990        |\n",
      "| fps                     | 86          |\n",
      "| mean 100 episode reward | 1.45e+03    |\n",
      "| n_updates               | 385908      |\n",
      "| policy_loss             | -245.66144  |\n",
      "| qf1_loss                | 24.356163   |\n",
      "| qf2_loss                | 27.382185   |\n",
      "| time_elapsed            | 4451        |\n",
      "| total timesteps         | 386007      |\n",
      "| value_loss              | 21.146118   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03557991 |\n",
      "| ent_coef_loss           | 11.05124   |\n",
      "| entropy                 | 13.709602  |\n",
      "| episodes                | 3000       |\n",
      "| fps                     | 86         |\n",
      "| mean 100 episode reward | 1.42e+03   |\n",
      "| n_updates               | 388695     |\n",
      "| policy_loss             | -252.17758 |\n",
      "| qf1_loss                | 43.397682  |\n",
      "| qf2_loss                | 41.258636  |\n",
      "| time_elapsed            | 4480       |\n",
      "| total timesteps         | 388794     |\n",
      "| value_loss              | 39.501205  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035019908 |\n",
      "| ent_coef_loss           | -5.1553345  |\n",
      "| entropy                 | 13.97574    |\n",
      "| episodes                | 3010        |\n",
      "| fps                     | 86          |\n",
      "| mean 100 episode reward | 1.46e+03    |\n",
      "| n_updates               | 391903      |\n",
      "| policy_loss             | -279.3997   |\n",
      "| qf1_loss                | 16.622803   |\n",
      "| qf2_loss                | 18.859867   |\n",
      "| time_elapsed            | 4513        |\n",
      "| total timesteps         | 392002      |\n",
      "| value_loss              | 17.143492   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03516091 |\n",
      "| ent_coef_loss           | 4.1011167  |\n",
      "| entropy                 | 13.999865  |\n",
      "| episodes                | 3020       |\n",
      "| fps                     | 86         |\n",
      "| mean 100 episode reward | 1.45e+03   |\n",
      "| n_updates               | 394674     |\n",
      "| policy_loss             | -260.36853 |\n",
      "| qf1_loss                | 20.399239  |\n",
      "| qf2_loss                | 32.104214  |\n",
      "| time_elapsed            | 4541       |\n",
      "| total timesteps         | 394773     |\n",
      "| value_loss              | 31.492273  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036757685 |\n",
      "| ent_coef_loss           | -6.416581   |\n",
      "| entropy                 | 13.866131   |\n",
      "| episodes                | 3030        |\n",
      "| fps                     | 86          |\n",
      "| mean 100 episode reward | 1.47e+03    |\n",
      "| n_updates               | 397532      |\n",
      "| policy_loss             | -271.06213  |\n",
      "| qf1_loss                | 17.335743   |\n",
      "| qf2_loss                | 14.610231   |\n",
      "| time_elapsed            | 4571        |\n",
      "| total timesteps         | 397631      |\n",
      "| value_loss              | 13.245155   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.033969246 |\n",
      "| ent_coef_loss           | -2.0195885  |\n",
      "| entropy                 | 14.448246   |\n",
      "| episodes                | 3040        |\n",
      "| fps                     | 87          |\n",
      "| mean 100 episode reward | 1.44e+03    |\n",
      "| n_updates               | 400463      |\n",
      "| policy_loss             | -264.184    |\n",
      "| qf1_loss                | 14.678702   |\n",
      "| qf2_loss                | 17.2432     |\n",
      "| time_elapsed            | 4601        |\n",
      "| total timesteps         | 400562      |\n",
      "| value_loss              | 10.395016   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036458455 |\n",
      "| ent_coef_loss           | -0.7441914  |\n",
      "| entropy                 | 14.778381   |\n",
      "| episodes                | 3050        |\n",
      "| fps                     | 87          |\n",
      "| mean 100 episode reward | 1.51e+03    |\n",
      "| n_updates               | 404610      |\n",
      "| policy_loss             | -262.45834  |\n",
      "| qf1_loss                | 37.26213    |\n",
      "| qf2_loss                | 24.588411   |\n",
      "| time_elapsed            | 4643        |\n",
      "| total timesteps         | 404709      |\n",
      "| value_loss              | 22.679287   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03450198 |\n",
      "| ent_coef_loss           | 1.6437392  |\n",
      "| entropy                 | 13.888292  |\n",
      "| episodes                | 3060       |\n",
      "| fps                     | 87         |\n",
      "| mean 100 episode reward | 1.56e+03   |\n",
      "| n_updates               | 407864     |\n",
      "| policy_loss             | -240.77902 |\n",
      "| qf1_loss                | 25.487152  |\n",
      "| qf2_loss                | 28.80857   |\n",
      "| time_elapsed            | 4677       |\n",
      "| total timesteps         | 407963     |\n",
      "| value_loss              | 16.102144  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035842653 |\n",
      "| ent_coef_loss           | -13.896336  |\n",
      "| entropy                 | 14.401157   |\n",
      "| episodes                | 3070        |\n",
      "| fps                     | 87          |\n",
      "| mean 100 episode reward | 1.63e+03    |\n",
      "| n_updates               | 411640      |\n",
      "| policy_loss             | -267.6037   |\n",
      "| qf1_loss                | 30.665298   |\n",
      "| qf2_loss                | 22.124767   |\n",
      "| time_elapsed            | 4716        |\n",
      "| total timesteps         | 411739      |\n",
      "| value_loss              | 12.613925   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03697285 |\n",
      "| ent_coef_loss           | -4.5052214 |\n",
      "| entropy                 | 14.644793  |\n",
      "| episodes                | 3080       |\n",
      "| fps                     | 87         |\n",
      "| mean 100 episode reward | 1.69e+03   |\n",
      "| n_updates               | 414877     |\n",
      "| policy_loss             | -239.93    |\n",
      "| qf1_loss                | 24.728043  |\n",
      "| qf2_loss                | 23.252262  |\n",
      "| time_elapsed            | 4749       |\n",
      "| total timesteps         | 414976     |\n",
      "| value_loss              | 17.835152  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.037059188 |\n",
      "| ent_coef_loss           | 0.16613173  |\n",
      "| entropy                 | 14.280196   |\n",
      "| episodes                | 3090        |\n",
      "| fps                     | 87          |\n",
      "| mean 100 episode reward | 1.62e+03    |\n",
      "| n_updates               | 417362      |\n",
      "| policy_loss             | -274.7544   |\n",
      "| qf1_loss                | 24.873142   |\n",
      "| qf2_loss                | 28.246769   |\n",
      "| time_elapsed            | 4774        |\n",
      "| total timesteps         | 417461      |\n",
      "| value_loss              | 25.844715   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03626231 |\n",
      "| ent_coef_loss           | -2.0843368 |\n",
      "| entropy                 | 14.33119   |\n",
      "| episodes                | 3100       |\n",
      "| fps                     | 87         |\n",
      "| mean 100 episode reward | 1.64e+03   |\n",
      "| n_updates               | 420583     |\n",
      "| policy_loss             | -283.34845 |\n",
      "| qf1_loss                | 15.902502  |\n",
      "| qf2_loss                | 15.937313  |\n",
      "| time_elapsed            | 4808       |\n",
      "| total timesteps         | 420682     |\n",
      "| value_loss              | 12.873383  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.0364978  |\n",
      "| ent_coef_loss           | 0.7202244  |\n",
      "| entropy                 | 14.3160095 |\n",
      "| episodes                | 3110       |\n",
      "| fps                     | 87         |\n",
      "| mean 100 episode reward | 1.66e+03   |\n",
      "| n_updates               | 424255     |\n",
      "| policy_loss             | -282.98306 |\n",
      "| qf1_loss                | 27.047672  |\n",
      "| qf2_loss                | 20.782307  |\n",
      "| time_elapsed            | 4846       |\n",
      "| total timesteps         | 424354     |\n",
      "| value_loss              | 14.751756  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036959346 |\n",
      "| ent_coef_loss           | 2.1685243   |\n",
      "| entropy                 | 13.675584   |\n",
      "| episodes                | 3120        |\n",
      "| fps                     | 87          |\n",
      "| mean 100 episode reward | 1.64e+03    |\n",
      "| n_updates               | 426412      |\n",
      "| policy_loss             | -286.30136  |\n",
      "| qf1_loss                | 37.256756   |\n",
      "| qf2_loss                | 24.24198    |\n",
      "| time_elapsed            | 4867        |\n",
      "| total timesteps         | 426511      |\n",
      "| value_loss              | 17.485464   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035768785 |\n",
      "| ent_coef_loss           | 4.143008    |\n",
      "| entropy                 | 13.937021   |\n",
      "| episodes                | 3130        |\n",
      "| fps                     | 87          |\n",
      "| mean 100 episode reward | 1.69e+03    |\n",
      "| n_updates               | 430240      |\n",
      "| policy_loss             | -262.41327  |\n",
      "| qf1_loss                | 63.21901    |\n",
      "| qf2_loss                | 50.19799    |\n",
      "| time_elapsed            | 4907        |\n",
      "| total timesteps         | 430339      |\n",
      "| value_loss              | 43.217396   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03629561 |\n",
      "| ent_coef_loss           | 4.1929073  |\n",
      "| entropy                 | 14.20621   |\n",
      "| episodes                | 3140       |\n",
      "| fps                     | 87         |\n",
      "| mean 100 episode reward | 1.7e+03    |\n",
      "| n_updates               | 433405     |\n",
      "| policy_loss             | -269.48666 |\n",
      "| qf1_loss                | 32.38251   |\n",
      "| qf2_loss                | 35.36547   |\n",
      "| time_elapsed            | 4939       |\n",
      "| total timesteps         | 433504     |\n",
      "| value_loss              | 28.442936  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03659891 |\n",
      "| ent_coef_loss           | 3.5303354  |\n",
      "| entropy                 | 14.396297  |\n",
      "| episodes                | 3150       |\n",
      "| fps                     | 87         |\n",
      "| mean 100 episode reward | 1.65e+03   |\n",
      "| n_updates               | 436683     |\n",
      "| policy_loss             | -258.9734  |\n",
      "| qf1_loss                | 29.320137  |\n",
      "| qf2_loss                | 18.061218  |\n",
      "| time_elapsed            | 4973       |\n",
      "| total timesteps         | 436782     |\n",
      "| value_loss              | 15.152737  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036502752 |\n",
      "| ent_coef_loss           | 6.269856    |\n",
      "| entropy                 | 13.985421   |\n",
      "| episodes                | 3160        |\n",
      "| fps                     | 87          |\n",
      "| mean 100 episode reward | 1.67e+03    |\n",
      "| n_updates               | 440202      |\n",
      "| policy_loss             | -291.08835  |\n",
      "| qf1_loss                | 40.217354   |\n",
      "| qf2_loss                | 36.686966   |\n",
      "| time_elapsed            | 5009        |\n",
      "| total timesteps         | 440301      |\n",
      "| value_loss              | 19.504547   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036634047 |\n",
      "| ent_coef_loss           | -4.010417   |\n",
      "| entropy                 | 14.348999   |\n",
      "| episodes                | 3170        |\n",
      "| fps                     | 87          |\n",
      "| mean 100 episode reward | 1.61e+03    |\n",
      "| n_updates               | 442840      |\n",
      "| policy_loss             | -249.76491  |\n",
      "| qf1_loss                | 19.24148    |\n",
      "| qf2_loss                | 23.750559   |\n",
      "| time_elapsed            | 5036        |\n",
      "| total timesteps         | 442939      |\n",
      "| value_loss              | 17.29977    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035618287 |\n",
      "| ent_coef_loss           | 2.7916236   |\n",
      "| entropy                 | 14.32233    |\n",
      "| episodes                | 3180        |\n",
      "| fps                     | 88          |\n",
      "| mean 100 episode reward | 1.61e+03    |\n",
      "| n_updates               | 445966      |\n",
      "| policy_loss             | -266.41797  |\n",
      "| qf1_loss                | 29.68191    |\n",
      "| qf2_loss                | 29.956682   |\n",
      "| time_elapsed            | 5068        |\n",
      "| total timesteps         | 446065      |\n",
      "| value_loss              | 13.582044   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036730476 |\n",
      "| ent_coef_loss           | -0.59070086 |\n",
      "| entropy                 | 14.093685   |\n",
      "| episodes                | 3190        |\n",
      "| fps                     | 88          |\n",
      "| mean 100 episode reward | 1.61e+03    |\n",
      "| n_updates               | 448420      |\n",
      "| policy_loss             | -277.10123  |\n",
      "| qf1_loss                | 36.75096    |\n",
      "| qf2_loss                | 27.859465   |\n",
      "| time_elapsed            | 5093        |\n",
      "| total timesteps         | 448519      |\n",
      "| value_loss              | 31.603672   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035752844 |\n",
      "| ent_coef_loss           | 4.6272593   |\n",
      "| entropy                 | 14.015474   |\n",
      "| episodes                | 3200        |\n",
      "| fps                     | 88          |\n",
      "| mean 100 episode reward | 1.57e+03    |\n",
      "| n_updates               | 451013      |\n",
      "| policy_loss             | -257.2032   |\n",
      "| qf1_loss                | 28.820957   |\n",
      "| qf2_loss                | 30.104565   |\n",
      "| time_elapsed            | 5120        |\n",
      "| total timesteps         | 451112      |\n",
      "| value_loss              | 23.502928   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.03612297  |\n",
      "| ent_coef_loss           | -0.70642114 |\n",
      "| entropy                 | 13.933323   |\n",
      "| episodes                | 3210        |\n",
      "| fps                     | 88          |\n",
      "| mean 100 episode reward | 1.54e+03    |\n",
      "| n_updates               | 454000      |\n",
      "| policy_loss             | -288.7337   |\n",
      "| qf1_loss                | 31.402746   |\n",
      "| qf2_loss                | 39.623657   |\n",
      "| time_elapsed            | 5150        |\n",
      "| total timesteps         | 454099      |\n",
      "| value_loss              | 28.064095   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036087763 |\n",
      "| ent_coef_loss           | -2.4387102  |\n",
      "| entropy                 | 14.466444   |\n",
      "| episodes                | 3220        |\n",
      "| fps                     | 88          |\n",
      "| mean 100 episode reward | 1.61e+03    |\n",
      "| n_updates               | 457535      |\n",
      "| policy_loss             | -256.7561   |\n",
      "| qf1_loss                | 26.772812   |\n",
      "| qf2_loss                | 33.998222   |\n",
      "| time_elapsed            | 5187        |\n",
      "| total timesteps         | 457634      |\n",
      "| value_loss              | 21.037548   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035631962 |\n",
      "| ent_coef_loss           | -8.265778   |\n",
      "| entropy                 | 14.723995   |\n",
      "| episodes                | 3230        |\n",
      "| fps                     | 88          |\n",
      "| mean 100 episode reward | 1.59e+03    |\n",
      "| n_updates               | 461098      |\n",
      "| policy_loss             | -278.87183  |\n",
      "| qf1_loss                | 18.364628   |\n",
      "| qf2_loss                | 22.248426   |\n",
      "| time_elapsed            | 5224        |\n",
      "| total timesteps         | 461197      |\n",
      "| value_loss              | 9.309727    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03640184 |\n",
      "| ent_coef_loss           | 16.310787  |\n",
      "| entropy                 | 13.531922  |\n",
      "| episodes                | 3240       |\n",
      "| fps                     | 88         |\n",
      "| mean 100 episode reward | 1.58e+03   |\n",
      "| n_updates               | 463977     |\n",
      "| policy_loss             | -268.68542 |\n",
      "| qf1_loss                | 50.751724  |\n",
      "| qf2_loss                | 55.144867  |\n",
      "| time_elapsed            | 5254       |\n",
      "| total timesteps         | 464076     |\n",
      "| value_loss              | 26.344763  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03615773 |\n",
      "| ent_coef_loss           | -7.049009  |\n",
      "| entropy                 | 14.104278  |\n",
      "| episodes                | 3250       |\n",
      "| fps                     | 88         |\n",
      "| mean 100 episode reward | 1.58e+03   |\n",
      "| n_updates               | 467457     |\n",
      "| policy_loss             | -237.9208  |\n",
      "| qf1_loss                | 27.162855  |\n",
      "| qf2_loss                | 27.54255   |\n",
      "| time_elapsed            | 5290       |\n",
      "| total timesteps         | 467556     |\n",
      "| value_loss              | 22.72063   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.037483383 |\n",
      "| ent_coef_loss           | 1.0392596   |\n",
      "| entropy                 | 14.298502   |\n",
      "| episodes                | 3260        |\n",
      "| fps                     | 88          |\n",
      "| mean 100 episode reward | 1.62e+03    |\n",
      "| n_updates               | 471535      |\n",
      "| policy_loss             | -251.45934  |\n",
      "| qf1_loss                | 18.404839   |\n",
      "| qf2_loss                | 20.09607    |\n",
      "| time_elapsed            | 5332        |\n",
      "| total timesteps         | 471634      |\n",
      "| value_loss              | 21.696196   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035678267 |\n",
      "| ent_coef_loss           | 9.805456    |\n",
      "| entropy                 | 13.497698   |\n",
      "| episodes                | 3270        |\n",
      "| fps                     | 88          |\n",
      "| mean 100 episode reward | 1.62e+03    |\n",
      "| n_updates               | 474142      |\n",
      "| policy_loss             | -285.75345  |\n",
      "| qf1_loss                | 32.95546    |\n",
      "| qf2_loss                | 29.180332   |\n",
      "| time_elapsed            | 5359        |\n",
      "| total timesteps         | 474241      |\n",
      "| value_loss              | 29.411774   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03634601 |\n",
      "| ent_coef_loss           | -0.8967749 |\n",
      "| entropy                 | 14.137215  |\n",
      "| episodes                | 3280       |\n",
      "| fps                     | 88         |\n",
      "| mean 100 episode reward | 1.63e+03   |\n",
      "| n_updates               | 477553     |\n",
      "| policy_loss             | -286.98502 |\n",
      "| qf1_loss                | 23.982683  |\n",
      "| qf2_loss                | 17.069557  |\n",
      "| time_elapsed            | 5394       |\n",
      "| total timesteps         | 477652     |\n",
      "| value_loss              | 12.43185   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03569535 |\n",
      "| ent_coef_loss           | 0.18812072 |\n",
      "| entropy                 | 14.621686  |\n",
      "| episodes                | 3290       |\n",
      "| fps                     | 88         |\n",
      "| mean 100 episode reward | 1.65e+03   |\n",
      "| n_updates               | 480389     |\n",
      "| policy_loss             | -254.39264 |\n",
      "| qf1_loss                | 14.875053  |\n",
      "| qf2_loss                | 21.969162  |\n",
      "| time_elapsed            | 5423       |\n",
      "| total timesteps         | 480488     |\n",
      "| value_loss              | 21.524382  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036334947 |\n",
      "| ent_coef_loss           | -1.2164667  |\n",
      "| entropy                 | 14.690214   |\n",
      "| episodes                | 3300        |\n",
      "| fps                     | 88          |\n",
      "| mean 100 episode reward | 1.76e+03    |\n",
      "| n_updates               | 485029      |\n",
      "| policy_loss             | -273.37946  |\n",
      "| qf1_loss                | 14.060209   |\n",
      "| qf2_loss                | 16.444393   |\n",
      "| time_elapsed            | 5470        |\n",
      "| total timesteps         | 485128      |\n",
      "| value_loss              | 18.155079   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035903525 |\n",
      "| ent_coef_loss           | -2.1011937  |\n",
      "| entropy                 | 14.2814045  |\n",
      "| episodes                | 3310        |\n",
      "| fps                     | 88          |\n",
      "| mean 100 episode reward | 1.75e+03    |\n",
      "| n_updates               | 487735      |\n",
      "| policy_loss             | -303.90204  |\n",
      "| qf1_loss                | 26.616707   |\n",
      "| qf2_loss                | 19.623093   |\n",
      "| time_elapsed            | 5498        |\n",
      "| total timesteps         | 487834      |\n",
      "| value_loss              | 11.837278   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03693293 |\n",
      "| ent_coef_loss           | 0.24420476 |\n",
      "| entropy                 | 14.389158  |\n",
      "| episodes                | 3320       |\n",
      "| fps                     | 88         |\n",
      "| mean 100 episode reward | 1.76e+03   |\n",
      "| n_updates               | 491589     |\n",
      "| policy_loss             | -280.9631  |\n",
      "| qf1_loss                | 19.14418   |\n",
      "| qf2_loss                | 25.78307   |\n",
      "| time_elapsed            | 5538       |\n",
      "| total timesteps         | 491688     |\n",
      "| value_loss              | 18.504017  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036014576 |\n",
      "| ent_coef_loss           | 11.452261   |\n",
      "| entropy                 | 13.701049   |\n",
      "| episodes                | 3330        |\n",
      "| fps                     | 88          |\n",
      "| mean 100 episode reward | 1.71e+03    |\n",
      "| n_updates               | 494154      |\n",
      "| policy_loss             | -288.84607  |\n",
      "| qf1_loss                | 17.870056   |\n",
      "| qf2_loss                | 16.353445   |\n",
      "| time_elapsed            | 5565        |\n",
      "| total timesteps         | 494253      |\n",
      "| value_loss              | 22.60719    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03520015 |\n",
      "| ent_coef_loss           | -3.8023877 |\n",
      "| entropy                 | 14.444155  |\n",
      "| episodes                | 3340       |\n",
      "| fps                     | 88         |\n",
      "| mean 100 episode reward | 1.7e+03    |\n",
      "| n_updates               | 496964     |\n",
      "| policy_loss             | -277.25958 |\n",
      "| qf1_loss                | 22.517666  |\n",
      "| qf2_loss                | 27.904491  |\n",
      "| time_elapsed            | 5594       |\n",
      "| total timesteps         | 497063     |\n",
      "| value_loss              | 15.630865  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03712339 |\n",
      "| ent_coef_loss           | 8.669659   |\n",
      "| entropy                 | 14.063671  |\n",
      "| episodes                | 3350       |\n",
      "| fps                     | 88         |\n",
      "| mean 100 episode reward | 1.66e+03   |\n",
      "| n_updates               | 499506     |\n",
      "| policy_loss             | -288.43054 |\n",
      "| qf1_loss                | 26.99427   |\n",
      "| qf2_loss                | 30.992546  |\n",
      "| time_elapsed            | 5619       |\n",
      "| total timesteps         | 499605     |\n",
      "| value_loss              | 20.339994  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036286052 |\n",
      "| ent_coef_loss           | 2.5525692   |\n",
      "| entropy                 | 14.09613    |\n",
      "| episodes                | 3360        |\n",
      "| fps                     | 88          |\n",
      "| mean 100 episode reward | 1.72e+03    |\n",
      "| n_updates               | 504929      |\n",
      "| policy_loss             | -277.43646  |\n",
      "| qf1_loss                | 14.953323   |\n",
      "| qf2_loss                | 23.900517   |\n",
      "| time_elapsed            | 5675        |\n",
      "| total timesteps         | 505028      |\n",
      "| value_loss              | 13.822123   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.037801675 |\n",
      "| ent_coef_loss           | 17.157598   |\n",
      "| entropy                 | 13.440931   |\n",
      "| episodes                | 3370        |\n",
      "| fps                     | 89          |\n",
      "| mean 100 episode reward | 1.75e+03    |\n",
      "| n_updates               | 508012      |\n",
      "| policy_loss             | -257.8103   |\n",
      "| qf1_loss                | 32.635765   |\n",
      "| qf2_loss                | 36.326973   |\n",
      "| time_elapsed            | 5707        |\n",
      "| total timesteps         | 508111      |\n",
      "| value_loss              | 35.25757    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.037358325 |\n",
      "| ent_coef_loss           | 4.706766    |\n",
      "| entropy                 | 14.049862   |\n",
      "| episodes                | 3380        |\n",
      "| fps                     | 89          |\n",
      "| mean 100 episode reward | 1.72e+03    |\n",
      "| n_updates               | 510857      |\n",
      "| policy_loss             | -260.57605  |\n",
      "| qf1_loss                | 14.948355   |\n",
      "| qf2_loss                | 19.086346   |\n",
      "| time_elapsed            | 5736        |\n",
      "| total timesteps         | 510956      |\n",
      "| value_loss              | 17.57586    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036740165 |\n",
      "| ent_coef_loss           | 10.811926   |\n",
      "| entropy                 | 13.900652   |\n",
      "| episodes                | 3390        |\n",
      "| fps                     | 89          |\n",
      "| mean 100 episode reward | 1.72e+03    |\n",
      "| n_updates               | 513698      |\n",
      "| policy_loss             | -272.53268  |\n",
      "| qf1_loss                | 46.048904   |\n",
      "| qf2_loss                | 25.930641   |\n",
      "| time_elapsed            | 5767        |\n",
      "| total timesteps         | 513797      |\n",
      "| value_loss              | 20.413235   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03798117 |\n",
      "| ent_coef_loss           | -1.7176542 |\n",
      "| entropy                 | 14.184507  |\n",
      "| episodes                | 3400       |\n",
      "| fps                     | 89         |\n",
      "| mean 100 episode reward | 1.64e+03   |\n",
      "| n_updates               | 516691     |\n",
      "| policy_loss             | -266.2097  |\n",
      "| qf1_loss                | 22.163353  |\n",
      "| qf2_loss                | 35.998802  |\n",
      "| time_elapsed            | 5800       |\n",
      "| total timesteps         | 516790     |\n",
      "| value_loss              | 17.977825  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.038064975 |\n",
      "| ent_coef_loss           | 4.672869    |\n",
      "| entropy                 | 13.758293   |\n",
      "| episodes                | 3410        |\n",
      "| fps                     | 89          |\n",
      "| mean 100 episode reward | 1.65e+03    |\n",
      "| n_updates               | 519632      |\n",
      "| policy_loss             | -280.14648  |\n",
      "| qf1_loss                | 31.821291   |\n",
      "| qf2_loss                | 34.824135   |\n",
      "| time_elapsed            | 5832        |\n",
      "| total timesteps         | 519731      |\n",
      "| value_loss              | 20.629917   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03782354 |\n",
      "| ent_coef_loss           | 4.406988   |\n",
      "| entropy                 | 14.118959  |\n",
      "| episodes                | 3420       |\n",
      "| fps                     | 89         |\n",
      "| mean 100 episode reward | 1.64e+03   |\n",
      "| n_updates               | 523164     |\n",
      "| policy_loss             | -253.78455 |\n",
      "| qf1_loss                | 51.065258  |\n",
      "| qf2_loss                | 45.176662  |\n",
      "| time_elapsed            | 5870       |\n",
      "| total timesteps         | 523263     |\n",
      "| value_loss              | 18.28723   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03616186 |\n",
      "| ent_coef_loss           | 3.287141   |\n",
      "| entropy                 | 13.662535  |\n",
      "| episodes                | 3430       |\n",
      "| fps                     | 89         |\n",
      "| mean 100 episode reward | 1.68e+03   |\n",
      "| n_updates               | 526549     |\n",
      "| policy_loss             | -299.02612 |\n",
      "| qf1_loss                | 28.449562  |\n",
      "| qf2_loss                | 24.228495  |\n",
      "| time_elapsed            | 5908       |\n",
      "| total timesteps         | 526648     |\n",
      "| value_loss              | 14.478835  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035840612 |\n",
      "| ent_coef_loss           | 2.049385    |\n",
      "| entropy                 | 14.226403   |\n",
      "| episodes                | 3440        |\n",
      "| fps                     | 89          |\n",
      "| mean 100 episode reward | 1.66e+03    |\n",
      "| n_updates               | 528948      |\n",
      "| policy_loss             | -291.4486   |\n",
      "| qf1_loss                | 33.57301    |\n",
      "| qf2_loss                | 32.78794    |\n",
      "| time_elapsed            | 5936        |\n",
      "| total timesteps         | 529047      |\n",
      "| value_loss              | 19.197077   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03668676 |\n",
      "| ent_coef_loss           | 2.448213   |\n",
      "| entropy                 | 14.3508    |\n",
      "| episodes                | 3450       |\n",
      "| fps                     | 89         |\n",
      "| mean 100 episode reward | 1.71e+03   |\n",
      "| n_updates               | 532347     |\n",
      "| policy_loss             | -256.9474  |\n",
      "| qf1_loss                | 60.68061   |\n",
      "| qf2_loss                | 67.770584  |\n",
      "| time_elapsed            | 5974       |\n",
      "| total timesteps         | 532446     |\n",
      "| value_loss              | 14.698427  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.038639456 |\n",
      "| ent_coef_loss           | -4.7123957  |\n",
      "| entropy                 | 14.267347   |\n",
      "| episodes                | 3460        |\n",
      "| fps                     | 89          |\n",
      "| mean 100 episode reward | 1.61e+03    |\n",
      "| n_updates               | 535718      |\n",
      "| policy_loss             | -275.9572   |\n",
      "| qf1_loss                | 44.647354   |\n",
      "| qf2_loss                | 45.411728   |\n",
      "| time_elapsed            | 6009        |\n",
      "| total timesteps         | 535817      |\n",
      "| value_loss              | 22.821516   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.039359167 |\n",
      "| ent_coef_loss           | -18.72236   |\n",
      "| entropy                 | 14.998098   |\n",
      "| episodes                | 3470        |\n",
      "| fps                     | 89          |\n",
      "| mean 100 episode reward | 1.63e+03    |\n",
      "| n_updates               | 539295      |\n",
      "| policy_loss             | -269.7289   |\n",
      "| qf1_loss                | 25.49629    |\n",
      "| qf2_loss                | 24.445744   |\n",
      "| time_elapsed            | 6046        |\n",
      "| total timesteps         | 539394      |\n",
      "| value_loss              | 17.722755   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.037487894 |\n",
      "| ent_coef_loss           | -8.854601   |\n",
      "| entropy                 | 13.86476    |\n",
      "| episodes                | 3480        |\n",
      "| fps                     | 89          |\n",
      "| mean 100 episode reward | 1.64e+03    |\n",
      "| n_updates               | 542435      |\n",
      "| policy_loss             | -302.36456  |\n",
      "| qf1_loss                | 26.560936   |\n",
      "| qf2_loss                | 28.441517   |\n",
      "| time_elapsed            | 6078        |\n",
      "| total timesteps         | 542534      |\n",
      "| value_loss              | 24.290195   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.038279984 |\n",
      "| ent_coef_loss           | -8.162748   |\n",
      "| entropy                 | 14.329224   |\n",
      "| episodes                | 3490        |\n",
      "| fps                     | 89          |\n",
      "| mean 100 episode reward | 1.67e+03    |\n",
      "| n_updates               | 545744      |\n",
      "| policy_loss             | -281.8244   |\n",
      "| qf1_loss                | 18.83617    |\n",
      "| qf2_loss                | 17.360226   |\n",
      "| time_elapsed            | 6115        |\n",
      "| total timesteps         | 545843      |\n",
      "| value_loss              | 13.279575   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03797595 |\n",
      "| ent_coef_loss           | 1.5742347  |\n",
      "| entropy                 | 13.9104595 |\n",
      "| episodes                | 3500       |\n",
      "| fps                     | 89         |\n",
      "| mean 100 episode reward | 1.77e+03   |\n",
      "| n_updates               | 550800     |\n",
      "| policy_loss             | -299.26215 |\n",
      "| qf1_loss                | 50.424065  |\n",
      "| qf2_loss                | 36.567963  |\n",
      "| time_elapsed            | 6168       |\n",
      "| total timesteps         | 550899     |\n",
      "| value_loss              | 25.662146  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03733462 |\n",
      "| ent_coef_loss           | 8.043416   |\n",
      "| entropy                 | 14.246227  |\n",
      "| episodes                | 3510       |\n",
      "| fps                     | 89         |\n",
      "| mean 100 episode reward | 1.8e+03    |\n",
      "| n_updates               | 554114     |\n",
      "| policy_loss             | -266.0774  |\n",
      "| qf1_loss                | 24.444016  |\n",
      "| qf2_loss                | 29.060532  |\n",
      "| time_elapsed            | 6204       |\n",
      "| total timesteps         | 554213     |\n",
      "| value_loss              | 29.461397  |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036207758 |\n",
      "| ent_coef_loss           | -4.8840065  |\n",
      "| entropy                 | 14.272851   |\n",
      "| episodes                | 3520        |\n",
      "| fps                     | 89          |\n",
      "| mean 100 episode reward | 1.76e+03    |\n",
      "| n_updates               | 556902      |\n",
      "| policy_loss             | -278.7376   |\n",
      "| qf1_loss                | 23.210829   |\n",
      "| qf2_loss                | 24.893444   |\n",
      "| time_elapsed            | 6234        |\n",
      "| total timesteps         | 557001      |\n",
      "| value_loss              | 20.583055   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03762919 |\n",
      "| ent_coef_loss           | 9.801144   |\n",
      "| entropy                 | 13.823221  |\n",
      "| episodes                | 3530       |\n",
      "| fps                     | 89         |\n",
      "| mean 100 episode reward | 1.81e+03   |\n",
      "| n_updates               | 561210     |\n",
      "| policy_loss             | -261.12762 |\n",
      "| qf1_loss                | 25.795776  |\n",
      "| qf2_loss                | 21.745174  |\n",
      "| time_elapsed            | 6290       |\n",
      "| total timesteps         | 561309     |\n",
      "| value_loss              | 26.582214  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035433836 |\n",
      "| ent_coef_loss           | 6.1709166   |\n",
      "| entropy                 | 13.672492   |\n",
      "| episodes                | 3540        |\n",
      "| fps                     | 89          |\n",
      "| mean 100 episode reward | 1.82e+03    |\n",
      "| n_updates               | 563811      |\n",
      "| policy_loss             | -286.35568  |\n",
      "| qf1_loss                | 24.448502   |\n",
      "| qf2_loss                | 11.6170635  |\n",
      "| time_elapsed            | 6322        |\n",
      "| total timesteps         | 563910      |\n",
      "| value_loss              | 10.743255   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.037859302 |\n",
      "| ent_coef_loss           | 0.060370445 |\n",
      "| entropy                 | 14.119455   |\n",
      "| episodes                | 3550        |\n",
      "| fps                     | 89          |\n",
      "| mean 100 episode reward | 1.82e+03    |\n",
      "| n_updates               | 567120      |\n",
      "| policy_loss             | -293.65747  |\n",
      "| qf1_loss                | 18.40963    |\n",
      "| qf2_loss                | 34.150837   |\n",
      "| time_elapsed            | 6363        |\n",
      "| total timesteps         | 567219      |\n",
      "| value_loss              | 12.7762985  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036291882 |\n",
      "| ent_coef_loss           | -3.3447018  |\n",
      "| entropy                 | 14.489204   |\n",
      "| episodes                | 3560        |\n",
      "| fps                     | 89          |\n",
      "| mean 100 episode reward | 1.89e+03    |\n",
      "| n_updates               | 571855      |\n",
      "| policy_loss             | -263.62784  |\n",
      "| qf1_loss                | 20.565323   |\n",
      "| qf2_loss                | 12.911829   |\n",
      "| time_elapsed            | 6421        |\n",
      "| total timesteps         | 571954      |\n",
      "| value_loss              | 18.350136   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03732009 |\n",
      "| ent_coef_loss           | 6.599284   |\n",
      "| entropy                 | 13.549844  |\n",
      "| episodes                | 3570       |\n",
      "| fps                     | 88         |\n",
      "| mean 100 episode reward | 1.99e+03   |\n",
      "| n_updates               | 577244     |\n",
      "| policy_loss             | -295.6412  |\n",
      "| qf1_loss                | 38.867172  |\n",
      "| qf2_loss                | 34.96514   |\n",
      "| time_elapsed            | 6487       |\n",
      "| total timesteps         | 577343     |\n",
      "| value_loss              | 12.665121  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.039269052 |\n",
      "| ent_coef_loss           | -10.454092  |\n",
      "| entropy                 | 14.1930065  |\n",
      "| episodes                | 3580        |\n",
      "| fps                     | 88          |\n",
      "| mean 100 episode reward | 2.03e+03    |\n",
      "| n_updates               | 581188      |\n",
      "| policy_loss             | -322.7318   |\n",
      "| qf1_loss                | 19.668808   |\n",
      "| qf2_loss                | 18.263197   |\n",
      "| time_elapsed            | 6535        |\n",
      "| total timesteps         | 581287      |\n",
      "| value_loss              | 9.421879    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03712047 |\n",
      "| ent_coef_loss           | -2.084992  |\n",
      "| entropy                 | 14.147861  |\n",
      "| episodes                | 3590       |\n",
      "| fps                     | 88         |\n",
      "| mean 100 episode reward | 2.06e+03   |\n",
      "| n_updates               | 585145     |\n",
      "| policy_loss             | -297.63208 |\n",
      "| qf1_loss                | 30.605272  |\n",
      "| qf2_loss                | 24.286903  |\n",
      "| time_elapsed            | 6584       |\n",
      "| total timesteps         | 585244     |\n",
      "| value_loss              | 26.949387  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03743742 |\n",
      "| ent_coef_loss           | 11.597352  |\n",
      "| entropy                 | 13.995575  |\n",
      "| episodes                | 3600       |\n",
      "| fps                     | 88         |\n",
      "| mean 100 episode reward | 1.97e+03   |\n",
      "| n_updates               | 588253     |\n",
      "| policy_loss             | -273.4671  |\n",
      "| qf1_loss                | 33.287163  |\n",
      "| qf2_loss                | 34.52317   |\n",
      "| time_elapsed            | 6623       |\n",
      "| total timesteps         | 588352     |\n",
      "| value_loss              | 39.97649   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03672674 |\n",
      "| ent_coef_loss           | 2.9514475  |\n",
      "| entropy                 | 14.433139  |\n",
      "| episodes                | 3610       |\n",
      "| fps                     | 88         |\n",
      "| mean 100 episode reward | 1.98e+03   |\n",
      "| n_updates               | 591899     |\n",
      "| policy_loss             | -275.8884  |\n",
      "| qf1_loss                | 26.823431  |\n",
      "| qf2_loss                | 33.209835  |\n",
      "| time_elapsed            | 6667       |\n",
      "| total timesteps         | 591998     |\n",
      "| value_loss              | 14.449371  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.0373461  |\n",
      "| ent_coef_loss           | -7.277728  |\n",
      "| entropy                 | 14.854822  |\n",
      "| episodes                | 3620       |\n",
      "| fps                     | 88         |\n",
      "| mean 100 episode reward | 2.07e+03   |\n",
      "| n_updates               | 596404     |\n",
      "| policy_loss             | -314.13635 |\n",
      "| qf1_loss                | 18.160215  |\n",
      "| qf2_loss                | 18.042831  |\n",
      "| time_elapsed            | 6742       |\n",
      "| total timesteps         | 596503     |\n",
      "| value_loss              | 5.614299   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03760295 |\n",
      "| ent_coef_loss           | -1.802835  |\n",
      "| entropy                 | 14.295328  |\n",
      "| episodes                | 3630       |\n",
      "| fps                     | 88         |\n",
      "| mean 100 episode reward | 2.1e+03    |\n",
      "| n_updates               | 601177     |\n",
      "| policy_loss             | -296.2132  |\n",
      "| qf1_loss                | 23.848312  |\n",
      "| qf2_loss                | 34.023544  |\n",
      "| time_elapsed            | 6820       |\n",
      "| total timesteps         | 601276     |\n",
      "| value_loss              | 10.564877  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.038609866 |\n",
      "| ent_coef_loss           | -8.241882   |\n",
      "| entropy                 | 15.1482525  |\n",
      "| episodes                | 3640        |\n",
      "| fps                     | 88          |\n",
      "| mean 100 episode reward | 2.18e+03    |\n",
      "| n_updates               | 605406      |\n",
      "| policy_loss             | -257.07916  |\n",
      "| qf1_loss                | 22.820803   |\n",
      "| qf2_loss                | 26.434948   |\n",
      "| time_elapsed            | 6878        |\n",
      "| total timesteps         | 605505      |\n",
      "| value_loss              | 14.2429085  |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.037362065 |\n",
      "| ent_coef_loss           | 8.284481    |\n",
      "| entropy                 | 14.298344   |\n",
      "| episodes                | 3650        |\n",
      "| fps                     | 87          |\n",
      "| mean 100 episode reward | 2.31e+03    |\n",
      "| n_updates               | 611025      |\n",
      "| policy_loss             | -271.28485  |\n",
      "| qf1_loss                | 48.680904   |\n",
      "| qf2_loss                | 33.29479    |\n",
      "| time_elapsed            | 6952        |\n",
      "| total timesteps         | 611124      |\n",
      "| value_loss              | 25.339237   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036210943 |\n",
      "| ent_coef_loss           | 1.5827245   |\n",
      "| entropy                 | 13.685816   |\n",
      "| episodes                | 3660        |\n",
      "| fps                     | 87          |\n",
      "| mean 100 episode reward | 2.28e+03    |\n",
      "| n_updates               | 615216      |\n",
      "| policy_loss             | -285.7924   |\n",
      "| qf1_loss                | 29.174202   |\n",
      "| qf2_loss                | 24.658691   |\n",
      "| time_elapsed            | 7004        |\n",
      "| total timesteps         | 615315      |\n",
      "| value_loss              | 20.04131    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03644973 |\n",
      "| ent_coef_loss           | -1.2811264 |\n",
      "| entropy                 | 14.200801  |\n",
      "| episodes                | 3670       |\n",
      "| fps                     | 87         |\n",
      "| mean 100 episode reward | 2.24e+03   |\n",
      "| n_updates               | 619816     |\n",
      "| policy_loss             | -278.35535 |\n",
      "| qf1_loss                | 31.631298  |\n",
      "| qf2_loss                | 33.971455  |\n",
      "| time_elapsed            | 7060       |\n",
      "| total timesteps         | 619915     |\n",
      "| value_loss              | 34.88241   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03770013 |\n",
      "| ent_coef_loss           | 2.231055   |\n",
      "| entropy                 | 13.280018  |\n",
      "| episodes                | 3680       |\n",
      "| fps                     | 87         |\n",
      "| mean 100 episode reward | 2.29e+03   |\n",
      "| n_updates               | 624702     |\n",
      "| policy_loss             | -319.51773 |\n",
      "| qf1_loss                | 32.525345  |\n",
      "| qf2_loss                | 15.423413  |\n",
      "| time_elapsed            | 7117       |\n",
      "| total timesteps         | 624801     |\n",
      "| value_loss              | 22.348639  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.037336126 |\n",
      "| ent_coef_loss           | -8.843679   |\n",
      "| entropy                 | 14.899838   |\n",
      "| episodes                | 3690        |\n",
      "| fps                     | 87          |\n",
      "| mean 100 episode reward | 2.31e+03    |\n",
      "| n_updates               | 629052      |\n",
      "| policy_loss             | -316.7096   |\n",
      "| qf1_loss                | 19.671555   |\n",
      "| qf2_loss                | 18.145908   |\n",
      "| time_elapsed            | 7173        |\n",
      "| total timesteps         | 629151      |\n",
      "| value_loss              | 18.00035    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03784167 |\n",
      "| ent_coef_loss           | 1.2253237  |\n",
      "| entropy                 | 14.223976  |\n",
      "| episodes                | 3700       |\n",
      "| fps                     | 87         |\n",
      "| mean 100 episode reward | 2.37e+03   |\n",
      "| n_updates               | 633412     |\n",
      "| policy_loss             | -276.03284 |\n",
      "| qf1_loss                | 29.551838  |\n",
      "| qf2_loss                | 31.866371  |\n",
      "| time_elapsed            | 7234       |\n",
      "| total timesteps         | 633511     |\n",
      "| value_loss              | 11.862334  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.038100492 |\n",
      "| ent_coef_loss           | 2.048367    |\n",
      "| entropy                 | 15.032872   |\n",
      "| episodes                | 3710        |\n",
      "| fps                     | 87          |\n",
      "| mean 100 episode reward | 2.35e+03    |\n",
      "| n_updates               | 636524      |\n",
      "| policy_loss             | -280.8386   |\n",
      "| qf1_loss                | 28.185879   |\n",
      "| qf2_loss                | 34.37014    |\n",
      "| time_elapsed            | 7272        |\n",
      "| total timesteps         | 636623      |\n",
      "| value_loss              | 17.072426   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03706957 |\n",
      "| ent_coef_loss           | -10.749901 |\n",
      "| entropy                 | 14.394156  |\n",
      "| episodes                | 3720       |\n",
      "| fps                     | 87         |\n",
      "| mean 100 episode reward | 2.41e+03   |\n",
      "| n_updates               | 642213     |\n",
      "| policy_loss             | -296.5526  |\n",
      "| qf1_loss                | 21.19337   |\n",
      "| qf2_loss                | 22.358788  |\n",
      "| time_elapsed            | 7343       |\n",
      "| total timesteps         | 642312     |\n",
      "| value_loss              | 31.517042  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03749737 |\n",
      "| ent_coef_loss           | -8.343317  |\n",
      "| entropy                 | 14.793886  |\n",
      "| episodes                | 3730       |\n",
      "| fps                     | 87         |\n",
      "| mean 100 episode reward | 2.47e+03   |\n",
      "| n_updates               | 648173     |\n",
      "| policy_loss             | -310.8169  |\n",
      "| qf1_loss                | 16.837372  |\n",
      "| qf2_loss                | 20.79445   |\n",
      "| time_elapsed            | 7413       |\n",
      "| total timesteps         | 648272     |\n",
      "| value_loss              | 19.609964  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03661575 |\n",
      "| ent_coef_loss           | -3.0472689 |\n",
      "| entropy                 | 14.709182  |\n",
      "| episodes                | 3740       |\n",
      "| fps                     | 87         |\n",
      "| mean 100 episode reward | 2.47e+03   |\n",
      "| n_updates               | 652299     |\n",
      "| policy_loss             | -314.27734 |\n",
      "| qf1_loss                | 25.504204  |\n",
      "| qf2_loss                | 28.222939  |\n",
      "| time_elapsed            | 7466       |\n",
      "| total timesteps         | 652398     |\n",
      "| value_loss              | 36.589516  |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| current_lr              | 0.0003       |\n",
      "| ent_coef                | 0.03743046   |\n",
      "| ent_coef_loss           | -0.045946836 |\n",
      "| entropy                 | 14.09864     |\n",
      "| episodes                | 3750         |\n",
      "| fps                     | 87           |\n",
      "| mean 100 episode reward | 2.43e+03     |\n",
      "| n_updates               | 657239       |\n",
      "| policy_loss             | -298.74896   |\n",
      "| qf1_loss                | 15.740737    |\n",
      "| qf2_loss                | 20.654057    |\n",
      "| time_elapsed            | 7534         |\n",
      "| total timesteps         | 657338       |\n",
      "| value_loss              | 10.604107    |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.03946195  |\n",
      "| ent_coef_loss           | -0.20291066 |\n",
      "| entropy                 | 14.051177   |\n",
      "| episodes                | 3760        |\n",
      "| fps                     | 87          |\n",
      "| mean 100 episode reward | 2.45e+03    |\n",
      "| n_updates               | 661728      |\n",
      "| policy_loss             | -308.8475   |\n",
      "| qf1_loss                | 19.870317   |\n",
      "| qf2_loss                | 24.120811   |\n",
      "| time_elapsed            | 7593        |\n",
      "| total timesteps         | 661827      |\n",
      "| value_loss              | 17.994432   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.038462255 |\n",
      "| ent_coef_loss           | 0.13686919  |\n",
      "| entropy                 | 14.375844   |\n",
      "| episodes                | 3770        |\n",
      "| fps                     | 87          |\n",
      "| mean 100 episode reward | 2.5e+03     |\n",
      "| n_updates               | 667117      |\n",
      "| policy_loss             | -314.39624  |\n",
      "| qf1_loss                | 30.681213   |\n",
      "| qf2_loss                | 37.876614   |\n",
      "| time_elapsed            | 7664        |\n",
      "| total timesteps         | 667216      |\n",
      "| value_loss              | 23.392288   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.038632784 |\n",
      "| ent_coef_loss           | -1.827709   |\n",
      "| entropy                 | 14.673859   |\n",
      "| episodes                | 3780        |\n",
      "| fps                     | 86          |\n",
      "| mean 100 episode reward | 2.59e+03    |\n",
      "| n_updates               | 673564      |\n",
      "| policy_loss             | -286.11237  |\n",
      "| qf1_loss                | 29.005793   |\n",
      "| qf2_loss                | 16.245358   |\n",
      "| time_elapsed            | 7745        |\n",
      "| total timesteps         | 673663      |\n",
      "| value_loss              | 17.398264   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.0383379  |\n",
      "| ent_coef_loss           | -3.291133  |\n",
      "| entropy                 | 14.480913  |\n",
      "| episodes                | 3790       |\n",
      "| fps                     | 86         |\n",
      "| mean 100 episode reward | 2.67e+03   |\n",
      "| n_updates               | 679436     |\n",
      "| policy_loss             | -318.66202 |\n",
      "| qf1_loss                | 29.22526   |\n",
      "| qf2_loss                | 28.242807  |\n",
      "| time_elapsed            | 7820       |\n",
      "| total timesteps         | 679535     |\n",
      "| value_loss              | 20.069729  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03824025 |\n",
      "| ent_coef_loss           | 5.41446    |\n",
      "| entropy                 | 14.118678  |\n",
      "| episodes                | 3800       |\n",
      "| fps                     | 86         |\n",
      "| mean 100 episode reward | 2.77e+03   |\n",
      "| n_updates               | 685619     |\n",
      "| policy_loss             | -325.44647 |\n",
      "| qf1_loss                | 43.60328   |\n",
      "| qf2_loss                | 42.534805  |\n",
      "| time_elapsed            | 7899       |\n",
      "| total timesteps         | 685718     |\n",
      "| value_loss              | 26.27659   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036564738 |\n",
      "| ent_coef_loss           | -2.574391   |\n",
      "| entropy                 | 13.7508545  |\n",
      "| episodes                | 3810        |\n",
      "| fps                     | 86          |\n",
      "| mean 100 episode reward | 2.75e+03    |\n",
      "| n_updates               | 688261      |\n",
      "| policy_loss             | -300.9122   |\n",
      "| qf1_loss                | 30.539274   |\n",
      "| qf2_loss                | 22.240059   |\n",
      "| time_elapsed            | 7934        |\n",
      "| total timesteps         | 688360      |\n",
      "| value_loss              | 11.758034   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03719203 |\n",
      "| ent_coef_loss           | 4.8738346  |\n",
      "| entropy                 | 14.293314  |\n",
      "| episodes                | 3820       |\n",
      "| fps                     | 86         |\n",
      "| mean 100 episode reward | 2.72e+03   |\n",
      "| n_updates               | 693551     |\n",
      "| policy_loss             | -313.56815 |\n",
      "| qf1_loss                | 21.854458  |\n",
      "| qf2_loss                | 23.04597   |\n",
      "| time_elapsed            | 7995       |\n",
      "| total timesteps         | 693650     |\n",
      "| value_loss              | 13.809688  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03741283 |\n",
      "| ent_coef_loss           | 8.103493   |\n",
      "| entropy                 | 14.2149725 |\n",
      "| episodes                | 3830       |\n",
      "| fps                     | 86         |\n",
      "| mean 100 episode reward | 2.62e+03   |\n",
      "| n_updates               | 697673     |\n",
      "| policy_loss             | -348.15997 |\n",
      "| qf1_loss                | 30.508488  |\n",
      "| qf2_loss                | 27.922812  |\n",
      "| time_elapsed            | 8057       |\n",
      "| total timesteps         | 697772     |\n",
      "| value_loss              | 31.348644  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03679997 |\n",
      "| ent_coef_loss           | 1.8479757  |\n",
      "| entropy                 | 14.013671  |\n",
      "| episodes                | 3840       |\n",
      "| fps                     | 86         |\n",
      "| mean 100 episode reward | 2.69e+03   |\n",
      "| n_updates               | 703083     |\n",
      "| policy_loss             | -259.72705 |\n",
      "| qf1_loss                | 30.603804  |\n",
      "| qf2_loss                | 22.126795  |\n",
      "| time_elapsed            | 8132       |\n",
      "| total timesteps         | 703182     |\n",
      "| value_loss              | 35.63307   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.037142865 |\n",
      "| ent_coef_loss           | -3.1250398  |\n",
      "| entropy                 | 14.339994   |\n",
      "| episodes                | 3850        |\n",
      "| fps                     | 86          |\n",
      "| mean 100 episode reward | 2.73e+03    |\n",
      "| n_updates               | 709029      |\n",
      "| policy_loss             | -309.14502  |\n",
      "| qf1_loss                | 14.906836   |\n",
      "| qf2_loss                | 17.382893   |\n",
      "| time_elapsed            | 8227        |\n",
      "| total timesteps         | 709128      |\n",
      "| value_loss              | 16.169237   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035066452 |\n",
      "| ent_coef_loss           | -4.6883664  |\n",
      "| entropy                 | 14.4656515  |\n",
      "| episodes                | 3860        |\n",
      "| fps                     | 86          |\n",
      "| mean 100 episode reward | 2.82e+03    |\n",
      "| n_updates               | 715154      |\n",
      "| policy_loss             | -336.2807   |\n",
      "| qf1_loss                | 43.621143   |\n",
      "| qf2_loss                | 37.120968   |\n",
      "| time_elapsed            | 8316        |\n",
      "| total timesteps         | 715253      |\n",
      "| value_loss              | 26.73154    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.037350263 |\n",
      "| ent_coef_loss           | 3.5041776   |\n",
      "| entropy                 | 14.0865345  |\n",
      "| episodes                | 3870        |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 2.92e+03    |\n",
      "| n_updates               | 722445      |\n",
      "| policy_loss             | -294.5336   |\n",
      "| qf1_loss                | 30.8553     |\n",
      "| qf2_loss                | 24.772621   |\n",
      "| time_elapsed            | 8426        |\n",
      "| total timesteps         | 722544      |\n",
      "| value_loss              | 19.146692   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036554355 |\n",
      "| ent_coef_loss           | -3.4964576  |\n",
      "| entropy                 | 13.830366   |\n",
      "| episodes                | 3880        |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 2.76e+03    |\n",
      "| n_updates               | 725895      |\n",
      "| policy_loss             | -329.8266   |\n",
      "| qf1_loss                | 32.584084   |\n",
      "| qf2_loss                | 31.309864   |\n",
      "| time_elapsed            | 8480        |\n",
      "| total timesteps         | 725994      |\n",
      "| value_loss              | 16.576263   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035896335 |\n",
      "| ent_coef_loss           | -5.967346   |\n",
      "| entropy                 | 14.656326   |\n",
      "| episodes                | 3890        |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 2.68e+03    |\n",
      "| n_updates               | 730319      |\n",
      "| policy_loss             | -299.2425   |\n",
      "| qf1_loss                | 16.16975    |\n",
      "| qf2_loss                | 18.789106   |\n",
      "| time_elapsed            | 8550        |\n",
      "| total timesteps         | 730418      |\n",
      "| value_loss              | 15.22377    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036587443 |\n",
      "| ent_coef_loss           | 5.382058    |\n",
      "| entropy                 | 14.559313   |\n",
      "| episodes                | 3900        |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 2.71e+03    |\n",
      "| n_updates               | 737081      |\n",
      "| policy_loss             | -308.17456  |\n",
      "| qf1_loss                | 18.891628   |\n",
      "| qf2_loss                | 23.594255   |\n",
      "| time_elapsed            | 8655        |\n",
      "| total timesteps         | 737180      |\n",
      "| value_loss              | 17.822973   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03791237 |\n",
      "| ent_coef_loss           | -2.402586  |\n",
      "| entropy                 | 13.7119465 |\n",
      "| episodes                | 3910       |\n",
      "| fps                     | 85         |\n",
      "| mean 100 episode reward | 2.89e+03   |\n",
      "| n_updates               | 743331     |\n",
      "| policy_loss             | -331.50604 |\n",
      "| qf1_loss                | 39.811462  |\n",
      "| qf2_loss                | 53.046463  |\n",
      "| time_elapsed            | 8741       |\n",
      "| total timesteps         | 743430     |\n",
      "| value_loss              | 14.136328  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035781983 |\n",
      "| ent_coef_loss           | -0.16826773 |\n",
      "| entropy                 | 14.148108   |\n",
      "| episodes                | 3920        |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 2.84e+03    |\n",
      "| n_updates               | 747725      |\n",
      "| policy_loss             | -333.49866  |\n",
      "| qf1_loss                | 22.917295   |\n",
      "| qf2_loss                | 15.686949   |\n",
      "| time_elapsed            | 8805        |\n",
      "| total timesteps         | 747824      |\n",
      "| value_loss              | 11.087343   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.038435966 |\n",
      "| ent_coef_loss           | -11.208544  |\n",
      "| entropy                 | 14.649311   |\n",
      "| episodes                | 3930        |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 2.97e+03    |\n",
      "| n_updates               | 754084      |\n",
      "| policy_loss             | -341.40576  |\n",
      "| qf1_loss                | 20.36129    |\n",
      "| qf2_loss                | 12.288735   |\n",
      "| time_elapsed            | 8889        |\n",
      "| total timesteps         | 754183      |\n",
      "| value_loss              | 14.1324625  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.037238907 |\n",
      "| ent_coef_loss           | 16.529865   |\n",
      "| entropy                 | 14.61601    |\n",
      "| episodes                | 3940        |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 3e+03       |\n",
      "| n_updates               | 760000      |\n",
      "| policy_loss             | -330.21005  |\n",
      "| qf1_loss                | 29.940948   |\n",
      "| qf2_loss                | 29.994495   |\n",
      "| time_elapsed            | 8969        |\n",
      "| total timesteps         | 760099      |\n",
      "| value_loss              | 22.361202   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036125038 |\n",
      "| ent_coef_loss           | -2.1431563  |\n",
      "| entropy                 | 14.197622   |\n",
      "| episodes                | 3950        |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 2.99e+03    |\n",
      "| n_updates               | 765607      |\n",
      "| policy_loss             | -348.8032   |\n",
      "| qf1_loss                | 32.9769     |\n",
      "| qf2_loss                | 35.68528    |\n",
      "| time_elapsed            | 9040        |\n",
      "| total timesteps         | 765706      |\n",
      "| value_loss              | 17.894407   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03729103 |\n",
      "| ent_coef_loss           | 1.9851875  |\n",
      "| entropy                 | 13.785604  |\n",
      "| episodes                | 3960       |\n",
      "| fps                     | 84         |\n",
      "| mean 100 episode reward | 3.06e+03   |\n",
      "| n_updates               | 772997     |\n",
      "| policy_loss             | -320.4574  |\n",
      "| qf1_loss                | 21.313034  |\n",
      "| qf2_loss                | 27.72958   |\n",
      "| time_elapsed            | 9131       |\n",
      "| total timesteps         | 773096     |\n",
      "| value_loss              | 15.419067  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.038512286 |\n",
      "| ent_coef_loss           | 3.3452258   |\n",
      "| entropy                 | 14.349675   |\n",
      "| episodes                | 3970        |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 2.99e+03    |\n",
      "| n_updates               | 779039      |\n",
      "| policy_loss             | -302.4318   |\n",
      "| qf1_loss                | 34.637016   |\n",
      "| qf2_loss                | 38.66788    |\n",
      "| time_elapsed            | 9209        |\n",
      "| total timesteps         | 779138      |\n",
      "| value_loss              | 13.782836   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035339274 |\n",
      "| ent_coef_loss           | -10.275114  |\n",
      "| entropy                 | 14.767581   |\n",
      "| episodes                | 3980        |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 3.14e+03    |\n",
      "| n_updates               | 785293      |\n",
      "| policy_loss             | -320.99152  |\n",
      "| qf1_loss                | 31.377752   |\n",
      "| qf2_loss                | 19.90651    |\n",
      "| time_elapsed            | 9286        |\n",
      "| total timesteps         | 785392      |\n",
      "| value_loss              | 25.26191    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03677351 |\n",
      "| ent_coef_loss           | 4.0440483  |\n",
      "| entropy                 | 14.045564  |\n",
      "| episodes                | 3990       |\n",
      "| fps                     | 84         |\n",
      "| mean 100 episode reward | 3.22e+03   |\n",
      "| n_updates               | 791257     |\n",
      "| policy_loss             | -330.97516 |\n",
      "| qf1_loss                | 21.85663   |\n",
      "| qf2_loss                | 20.510578  |\n",
      "| time_elapsed            | 9361       |\n",
      "| total timesteps         | 791356     |\n",
      "| value_loss              | 17.309158  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035472862 |\n",
      "| ent_coef_loss           | -0.6049646  |\n",
      "| entropy                 | 13.980989   |\n",
      "| episodes                | 4000        |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 3.22e+03    |\n",
      "| n_updates               | 797908      |\n",
      "| policy_loss             | -328.6369   |\n",
      "| qf1_loss                | 28.952312   |\n",
      "| qf2_loss                | 32.969868   |\n",
      "| time_elapsed            | 9440        |\n",
      "| total timesteps         | 798007      |\n",
      "| value_loss              | 29.235407   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03740072 |\n",
      "| ent_coef_loss           | 0.6501343  |\n",
      "| entropy                 | 14.122322  |\n",
      "| episodes                | 4010       |\n",
      "| fps                     | 84         |\n",
      "| mean 100 episode reward | 3.22e+03   |\n",
      "| n_updates               | 804102     |\n",
      "| policy_loss             | -320.80255 |\n",
      "| qf1_loss                | 29.962032  |\n",
      "| qf2_loss                | 23.283682  |\n",
      "| time_elapsed            | 9527       |\n",
      "| total timesteps         | 804201     |\n",
      "| value_loss              | 18.053358  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03657279 |\n",
      "| ent_coef_loss           | 4.885437   |\n",
      "| entropy                 | 13.626011  |\n",
      "| episodes                | 4020       |\n",
      "| fps                     | 84         |\n",
      "| mean 100 episode reward | 3.38e+03   |\n",
      "| n_updates               | 811257     |\n",
      "| policy_loss             | -345.17422 |\n",
      "| qf1_loss                | 23.023365  |\n",
      "| qf2_loss                | 38.92733   |\n",
      "| time_elapsed            | 9625       |\n",
      "| total timesteps         | 811356     |\n",
      "| value_loss              | 19.116482  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036644407 |\n",
      "| ent_coef_loss           | 0.5565664   |\n",
      "| entropy                 | 14.524886   |\n",
      "| episodes                | 4030        |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 3.39e+03    |\n",
      "| n_updates               | 817905      |\n",
      "| policy_loss             | -306.34424  |\n",
      "| qf1_loss                | 35.556324   |\n",
      "| qf2_loss                | 37.74778    |\n",
      "| time_elapsed            | 9708        |\n",
      "| total timesteps         | 818004      |\n",
      "| value_loss              | 10.324268   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036069762 |\n",
      "| ent_coef_loss           | 1.3314829   |\n",
      "| entropy                 | 14.136479   |\n",
      "| episodes                | 4040        |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 3.38e+03    |\n",
      "| n_updates               | 823614      |\n",
      "| policy_loss             | -353.62585  |\n",
      "| qf1_loss                | 23.589272   |\n",
      "| qf2_loss                | 15.734314   |\n",
      "| time_elapsed            | 9790        |\n",
      "| total timesteps         | 823713      |\n",
      "| value_loss              | 10.930536   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036388386 |\n",
      "| ent_coef_loss           | 7.2973404   |\n",
      "| entropy                 | 14.12973    |\n",
      "| episodes                | 4050        |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 3.45e+03    |\n",
      "| n_updates               | 830432      |\n",
      "| policy_loss             | -317.44128  |\n",
      "| qf1_loss                | 33.673313   |\n",
      "| qf2_loss                | 33.144554   |\n",
      "| time_elapsed            | 9881        |\n",
      "| total timesteps         | 830531      |\n",
      "| value_loss              | 10.655596   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036290612 |\n",
      "| ent_coef_loss           | 1.7869183   |\n",
      "| entropy                 | 14.994562   |\n",
      "| episodes                | 4060        |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 3.43e+03    |\n",
      "| n_updates               | 837386      |\n",
      "| policy_loss             | -356.86035  |\n",
      "| qf1_loss                | 32.27346    |\n",
      "| qf2_loss                | 21.49914    |\n",
      "| time_elapsed            | 9955        |\n",
      "| total timesteps         | 837485      |\n",
      "| value_loss              | 18.363018   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03553115 |\n",
      "| ent_coef_loss           | -5.6320386 |\n",
      "| entropy                 | 14.659012  |\n",
      "| episodes                | 4070       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 3.5e+03    |\n",
      "| n_updates               | 844918     |\n",
      "| policy_loss             | -342.30188 |\n",
      "| qf1_loss                | 30.174273  |\n",
      "| qf2_loss                | 19.663193  |\n",
      "| time_elapsed            | 10063      |\n",
      "| total timesteps         | 845017     |\n",
      "| value_loss              | 14.232666  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035446238 |\n",
      "| ent_coef_loss           | 5.231277    |\n",
      "| entropy                 | 13.602005   |\n",
      "| episodes                | 4080        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.5e+03     |\n",
      "| n_updates               | 851151      |\n",
      "| policy_loss             | -312.4442   |\n",
      "| qf1_loss                | 45.39889    |\n",
      "| qf2_loss                | 44.759804   |\n",
      "| time_elapsed            | 10144       |\n",
      "| total timesteps         | 851250      |\n",
      "| value_loss              | 25.348228   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03575397 |\n",
      "| ent_coef_loss           | -4.8540773 |\n",
      "| entropy                 | 14.674082  |\n",
      "| episodes                | 4090       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 3.48e+03   |\n",
      "| n_updates               | 856707     |\n",
      "| policy_loss             | -339.4572  |\n",
      "| qf1_loss                | 20.46154   |\n",
      "| qf2_loss                | 21.031006  |\n",
      "| time_elapsed            | 10216      |\n",
      "| total timesteps         | 856806     |\n",
      "| value_loss              | 11.453663  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03531011 |\n",
      "| ent_coef_loss           | 5.5337133  |\n",
      "| entropy                 | 14.367708  |\n",
      "| episodes                | 4100       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 3.44e+03   |\n",
      "| n_updates               | 862590     |\n",
      "| policy_loss             | -324.66125 |\n",
      "| qf1_loss                | 22.342691  |\n",
      "| qf2_loss                | 23.2188    |\n",
      "| time_elapsed            | 10291      |\n",
      "| total timesteps         | 862689     |\n",
      "| value_loss              | 15.190661  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036289167 |\n",
      "| ent_coef_loss           | 3.3378546   |\n",
      "| entropy                 | 14.442972   |\n",
      "| episodes                | 4110        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.51e+03    |\n",
      "| n_updates               | 870090      |\n",
      "| policy_loss             | -338.50323  |\n",
      "| qf1_loss                | 31.647198   |\n",
      "| qf2_loss                | 23.334446   |\n",
      "| time_elapsed            | 10373       |\n",
      "| total timesteps         | 870189      |\n",
      "| value_loss              | 11.013388   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.034447633 |\n",
      "| ent_coef_loss           | -5.68703    |\n",
      "| entropy                 | 14.542567   |\n",
      "| episodes                | 4120        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.52e+03    |\n",
      "| n_updates               | 877360      |\n",
      "| policy_loss             | -349.18002  |\n",
      "| qf1_loss                | 11.854071   |\n",
      "| qf2_loss                | 13.814597   |\n",
      "| time_elapsed            | 10478       |\n",
      "| total timesteps         | 877459      |\n",
      "| value_loss              | 9.516912    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| current_lr              | 0.0003       |\n",
      "| ent_coef                | 0.03529303   |\n",
      "| ent_coef_loss           | -0.096857786 |\n",
      "| entropy                 | 14.244188    |\n",
      "| episodes                | 4130         |\n",
      "| fps                     | 83           |\n",
      "| mean 100 episode reward | 3.47e+03     |\n",
      "| n_updates               | 882997       |\n",
      "| policy_loss             | -345.01422   |\n",
      "| qf1_loss                | 20.014301    |\n",
      "| qf2_loss                | 25.085781    |\n",
      "| time_elapsed            | 10556        |\n",
      "| total timesteps         | 883096       |\n",
      "| value_loss              | 14.436989    |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03486921 |\n",
      "| ent_coef_loss           | -4.133052  |\n",
      "| entropy                 | 13.378304  |\n",
      "| episodes                | 4140       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 3.59e+03   |\n",
      "| n_updates               | 890836     |\n",
      "| policy_loss             | -357.1911  |\n",
      "| qf1_loss                | 29.096075  |\n",
      "| qf2_loss                | 32.280296  |\n",
      "| time_elapsed            | 10650      |\n",
      "| total timesteps         | 890935     |\n",
      "| value_loss              | 27.292053  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03784119 |\n",
      "| ent_coef_loss           | -2.1857116 |\n",
      "| entropy                 | 14.187202  |\n",
      "| episodes                | 4150       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 3.57e+03   |\n",
      "| n_updates               | 897418     |\n",
      "| policy_loss             | -357.3107  |\n",
      "| qf1_loss                | 41.86605   |\n",
      "| qf2_loss                | 33.918365  |\n",
      "| time_elapsed            | 10733      |\n",
      "| total timesteps         | 897517     |\n",
      "| value_loss              | 22.140594  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03478582 |\n",
      "| ent_coef_loss           | 2.096517   |\n",
      "| entropy                 | 14.430133  |\n",
      "| episodes                | 4160       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 3.57e+03   |\n",
      "| n_updates               | 904221     |\n",
      "| policy_loss             | -336.59534 |\n",
      "| qf1_loss                | 11.007869  |\n",
      "| qf2_loss                | 21.714344  |\n",
      "| time_elapsed            | 10816      |\n",
      "| total timesteps         | 904320     |\n",
      "| value_loss              | 17.018929  |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.0377008  |\n",
      "| ent_coef_loss           | 6.1839786  |\n",
      "| entropy                 | 14.493202  |\n",
      "| episodes                | 4170       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 3.59e+03   |\n",
      "| n_updates               | 912010     |\n",
      "| policy_loss             | -366.35202 |\n",
      "| qf1_loss                | 44.418144  |\n",
      "| qf2_loss                | 43.077236  |\n",
      "| time_elapsed            | 10905      |\n",
      "| total timesteps         | 912109     |\n",
      "| value_loss              | 10.091852  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035857476 |\n",
      "| ent_coef_loss           | -11.331043  |\n",
      "| entropy                 | 14.412275   |\n",
      "| episodes                | 4180        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.66e+03    |\n",
      "| n_updates               | 919442      |\n",
      "| policy_loss             | -363.95248  |\n",
      "| qf1_loss                | 25.15254    |\n",
      "| qf2_loss                | 18.99337    |\n",
      "| time_elapsed            | 11000       |\n",
      "| total timesteps         | 919541      |\n",
      "| value_loss              | 14.697247   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.033897024 |\n",
      "| ent_coef_loss           | 5.393432    |\n",
      "| entropy                 | 13.907408   |\n",
      "| episodes                | 4190        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.73e+03    |\n",
      "| n_updates               | 926303      |\n",
      "| policy_loss             | -284.23138  |\n",
      "| qf1_loss                | 49.421684   |\n",
      "| qf2_loss                | 34.560097   |\n",
      "| time_elapsed            | 11091       |\n",
      "| total timesteps         | 926402      |\n",
      "| value_loss              | 14.320995   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.033541955 |\n",
      "| ent_coef_loss           | -2.5277624  |\n",
      "| entropy                 | 13.925432   |\n",
      "| episodes                | 4200        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.76e+03    |\n",
      "| n_updates               | 932792      |\n",
      "| policy_loss             | -372.85065  |\n",
      "| qf1_loss                | 50.800056   |\n",
      "| qf2_loss                | 41.959686   |\n",
      "| time_elapsed            | 11160       |\n",
      "| total timesteps         | 932891      |\n",
      "| value_loss              | 12.66709    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.033238146 |\n",
      "| ent_coef_loss           | 6.785434    |\n",
      "| entropy                 | 14.159573   |\n",
      "| episodes                | 4210        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.81e+03    |\n",
      "| n_updates               | 941172      |\n",
      "| policy_loss             | -340.8406   |\n",
      "| qf1_loss                | 38.817      |\n",
      "| qf2_loss                | 27.241385   |\n",
      "| time_elapsed            | 11247       |\n",
      "| total timesteps         | 941271      |\n",
      "| value_loss              | 11.520916   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.033378106 |\n",
      "| ent_coef_loss           | -3.119216   |\n",
      "| entropy                 | 14.57606    |\n",
      "| episodes                | 4220        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.85e+03    |\n",
      "| n_updates               | 949128      |\n",
      "| policy_loss             | -369.44293  |\n",
      "| qf1_loss                | 41.41352    |\n",
      "| qf2_loss                | 35.932198   |\n",
      "| time_elapsed            | 11329       |\n",
      "| total timesteps         | 949227      |\n",
      "| value_loss              | 7.2777934   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03480182 |\n",
      "| ent_coef_loss           | 6.34517    |\n",
      "| entropy                 | 13.6602745 |\n",
      "| episodes                | 4230       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 3.91e+03   |\n",
      "| n_updates               | 956065     |\n",
      "| policy_loss             | -380.04926 |\n",
      "| qf1_loss                | 68.915184  |\n",
      "| qf2_loss                | 64.44243   |\n",
      "| time_elapsed            | 11401      |\n",
      "| total timesteps         | 956164     |\n",
      "| value_loss              | 27.911587  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035357606 |\n",
      "| ent_coef_loss           | -0.9245243  |\n",
      "| entropy                 | 14.751389   |\n",
      "| episodes                | 4240        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.82e+03    |\n",
      "| n_updates               | 962141      |\n",
      "| policy_loss             | -352.39148  |\n",
      "| qf1_loss                | 14.846949   |\n",
      "| qf2_loss                | 20.809095   |\n",
      "| time_elapsed            | 11463       |\n",
      "| total timesteps         | 962240      |\n",
      "| value_loss              | 7.5499043   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03552514 |\n",
      "| ent_coef_loss           | 1.6764315  |\n",
      "| entropy                 | 14.5095005 |\n",
      "| episodes                | 4250       |\n",
      "| fps                     | 84         |\n",
      "| mean 100 episode reward | 3.9e+03    |\n",
      "| n_updates               | 970103     |\n",
      "| policy_loss             | -372.7925  |\n",
      "| qf1_loss                | 21.069159  |\n",
      "| qf2_loss                | 17.211815  |\n",
      "| time_elapsed            | 11544      |\n",
      "| total timesteps         | 970202     |\n",
      "| value_loss              | 8.645994   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.034067426 |\n",
      "| ent_coef_loss           | -0.09060168 |\n",
      "| entropy                 | 14.253069   |\n",
      "| episodes                | 4260        |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 3.9e+03     |\n",
      "| n_updates               | 977021      |\n",
      "| policy_loss             | -378.60757  |\n",
      "| qf1_loss                | 11.436849   |\n",
      "| qf2_loss                | 12.113352   |\n",
      "| time_elapsed            | 11619       |\n",
      "| total timesteps         | 977120      |\n",
      "| value_loss              | 18.566349   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035565402 |\n",
      "| ent_coef_loss           | -1.4173925  |\n",
      "| entropy                 | 14.302273   |\n",
      "| episodes                | 4270        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.98e+03    |\n",
      "| n_updates               | 986242      |\n",
      "| policy_loss             | -361.52515  |\n",
      "| qf1_loss                | 46.4116     |\n",
      "| qf2_loss                | 34.49969    |\n",
      "| time_elapsed            | 11750       |\n",
      "| total timesteps         | 986341      |\n",
      "| value_loss              | 28.616951   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.03547112  |\n",
      "| ent_coef_loss           | 0.030967236 |\n",
      "| entropy                 | 13.7783375  |\n",
      "| episodes                | 4280        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 4.02e+03    |\n",
      "| n_updates               | 994609      |\n",
      "| policy_loss             | -337.5243   |\n",
      "| qf1_loss                | 54.106476   |\n",
      "| qf2_loss                | 47.91198    |\n",
      "| time_elapsed            | 11867       |\n",
      "| total timesteps         | 994708      |\n",
      "| value_loss              | 26.798306   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.032903314 |\n",
      "| ent_coef_loss           | -0.11307335 |\n",
      "| entropy                 | 13.7442875  |\n",
      "| episodes                | 4290        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.97e+03    |\n",
      "| n_updates               | 1000377     |\n",
      "| policy_loss             | -350.17722  |\n",
      "| qf1_loss                | 27.976124   |\n",
      "| qf2_loss                | 29.559675   |\n",
      "| time_elapsed            | 11942       |\n",
      "| total timesteps         | 1000476     |\n",
      "| value_loss              | 11.4160185  |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.032931622 |\n",
      "| ent_coef_loss           | 1.09899     |\n",
      "| entropy                 | 14.206955   |\n",
      "| episodes                | 4300        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.95e+03    |\n",
      "| n_updates               | 1006556     |\n",
      "| policy_loss             | -382.5041   |\n",
      "| qf1_loss                | 7.176057    |\n",
      "| qf2_loss                | 16.449078   |\n",
      "| time_elapsed            | 12024       |\n",
      "| total timesteps         | 1006655     |\n",
      "| value_loss              | 21.143557   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.034302782 |\n",
      "| ent_coef_loss           | -3.8168266  |\n",
      "| entropy                 | 15.025036   |\n",
      "| episodes                | 4310        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.83e+03    |\n",
      "| n_updates               | 1012898     |\n",
      "| policy_loss             | -356.48306  |\n",
      "| qf1_loss                | 14.166665   |\n",
      "| qf2_loss                | 16.072998   |\n",
      "| time_elapsed            | 12107       |\n",
      "| total timesteps         | 1012997     |\n",
      "| value_loss              | 24.009848   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.033293236 |\n",
      "| ent_coef_loss           | -8.272352   |\n",
      "| entropy                 | 14.706566   |\n",
      "| episodes                | 4320        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.83e+03    |\n",
      "| n_updates               | 1020711     |\n",
      "| policy_loss             | -360.49463  |\n",
      "| qf1_loss                | 17.52545    |\n",
      "| qf2_loss                | 16.122028   |\n",
      "| time_elapsed            | 12204       |\n",
      "| total timesteps         | 1020810     |\n",
      "| value_loss              | 10.417657   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.034554947 |\n",
      "| ent_coef_loss           | -12.647502  |\n",
      "| entropy                 | 14.909933   |\n",
      "| episodes                | 4330        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.91e+03    |\n",
      "| n_updates               | 1029171     |\n",
      "| policy_loss             | -355.53003  |\n",
      "| qf1_loss                | 20.959803   |\n",
      "| qf2_loss                | 16.790932   |\n",
      "| time_elapsed            | 12311       |\n",
      "| total timesteps         | 1029270     |\n",
      "| value_loss              | 6.65357     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03460372 |\n",
      "| ent_coef_loss           | -9.605457  |\n",
      "| entropy                 | 14.451521  |\n",
      "| episodes                | 4340       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 4e+03      |\n",
      "| n_updates               | 1037021    |\n",
      "| policy_loss             | -389.57248 |\n",
      "| qf1_loss                | 28.636484  |\n",
      "| qf2_loss                | 18.489033  |\n",
      "| time_elapsed            | 12414      |\n",
      "| total timesteps         | 1037120    |\n",
      "| value_loss              | 19.988565  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03150185 |\n",
      "| ent_coef_loss           | 2.9018626  |\n",
      "| entropy                 | 14.632143  |\n",
      "| episodes                | 4350       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 3.92e+03   |\n",
      "| n_updates               | 1043553    |\n",
      "| policy_loss             | -371.9613  |\n",
      "| qf1_loss                | 17.530245  |\n",
      "| qf2_loss                | 23.836336  |\n",
      "| time_elapsed            | 12496      |\n",
      "| total timesteps         | 1043652    |\n",
      "| value_loss              | 17.888193  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03441447 |\n",
      "| ent_coef_loss           | -3.1768863 |\n",
      "| entropy                 | 14.442696  |\n",
      "| episodes                | 4360       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 3.91e+03   |\n",
      "| n_updates               | 1050206    |\n",
      "| policy_loss             | -351.81738 |\n",
      "| qf1_loss                | 13.528103  |\n",
      "| qf2_loss                | 14.2046995 |\n",
      "| time_elapsed            | 12576      |\n",
      "| total timesteps         | 1050305    |\n",
      "| value_loss              | 19.654463  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.033006836 |\n",
      "| ent_coef_loss           | 2.7545643   |\n",
      "| entropy                 | 14.106201   |\n",
      "| episodes                | 4370        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.71e+03    |\n",
      "| n_updates               | 1055666     |\n",
      "| policy_loss             | -349.28433  |\n",
      "| qf1_loss                | 27.398228   |\n",
      "| qf2_loss                | 29.744295   |\n",
      "| time_elapsed            | 12648       |\n",
      "| total timesteps         | 1055765     |\n",
      "| value_loss              | 18.922153   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.032181595 |\n",
      "| ent_coef_loss           | 5.518394    |\n",
      "| entropy                 | 14.996433   |\n",
      "| episodes                | 4380        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.45e+03    |\n",
      "| n_updates               | 1059137     |\n",
      "| policy_loss             | -355.74164  |\n",
      "| qf1_loss                | 28.44062    |\n",
      "| qf2_loss                | 17.843678   |\n",
      "| time_elapsed            | 12692       |\n",
      "| total timesteps         | 1059236     |\n",
      "| value_loss              | 24.978493   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.032510668 |\n",
      "| ent_coef_loss           | 3.5990639   |\n",
      "| entropy                 | 14.599123   |\n",
      "| episodes                | 4390        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.41e+03    |\n",
      "| n_updates               | 1064094     |\n",
      "| policy_loss             | -389.8944   |\n",
      "| qf1_loss                | 25.919144   |\n",
      "| qf2_loss                | 22.97268    |\n",
      "| time_elapsed            | 12751       |\n",
      "| total timesteps         | 1064193     |\n",
      "| value_loss              | 13.895401   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.032058973 |\n",
      "| ent_coef_loss           | 0.80148196  |\n",
      "| entropy                 | 14.554829   |\n",
      "| episodes                | 4400        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.54e+03    |\n",
      "| n_updates               | 1072660     |\n",
      "| policy_loss             | -366.35413  |\n",
      "| qf1_loss                | 41.756977   |\n",
      "| qf2_loss                | 28.482029   |\n",
      "| time_elapsed            | 12851       |\n",
      "| total timesteps         | 1072759     |\n",
      "| value_loss              | 18.161125   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03290889 |\n",
      "| ent_coef_loss           | 1.5958023  |\n",
      "| entropy                 | 14.697247  |\n",
      "| episodes                | 4410       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 3.51e+03   |\n",
      "| n_updates               | 1078367    |\n",
      "| policy_loss             | -361.59894 |\n",
      "| qf1_loss                | 33.296005  |\n",
      "| qf2_loss                | 21.683685  |\n",
      "| time_elapsed            | 12921      |\n",
      "| total timesteps         | 1078466    |\n",
      "| value_loss              | 12.643597  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.032324363 |\n",
      "| ent_coef_loss           | 7.553064    |\n",
      "| entropy                 | 14.628891   |\n",
      "| episodes                | 4420        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.37e+03    |\n",
      "| n_updates               | 1083593     |\n",
      "| policy_loss             | -345.43225  |\n",
      "| qf1_loss                | 29.38131    |\n",
      "| qf2_loss                | 27.767475   |\n",
      "| time_elapsed            | 12986       |\n",
      "| total timesteps         | 1083692     |\n",
      "| value_loss              | 21.806248   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.0333493  |\n",
      "| ent_coef_loss           | 4.334362   |\n",
      "| entropy                 | 13.478243  |\n",
      "| episodes                | 4430       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 3.01e+03   |\n",
      "| n_updates               | 1085252    |\n",
      "| policy_loss             | -361.03802 |\n",
      "| qf1_loss                | 23.185667  |\n",
      "| qf2_loss                | 18.590303  |\n",
      "| time_elapsed            | 13005      |\n",
      "| total timesteps         | 1085351    |\n",
      "| value_loss              | 28.853842  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031090148 |\n",
      "| ent_coef_loss           | 1.4938004   |\n",
      "| entropy                 | 15.161728   |\n",
      "| episodes                | 4440        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 2.92e+03    |\n",
      "| n_updates               | 1091420     |\n",
      "| policy_loss             | -363.69705  |\n",
      "| qf1_loss                | 12.455484   |\n",
      "| qf2_loss                | 14.341899   |\n",
      "| time_elapsed            | 13084       |\n",
      "| total timesteps         | 1091519     |\n",
      "| value_loss              | 13.978033   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031995084 |\n",
      "| ent_coef_loss           | -12.700774  |\n",
      "| entropy                 | 15.202607   |\n",
      "| episodes                | 4450        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 2.98e+03    |\n",
      "| n_updates               | 1099075     |\n",
      "| policy_loss             | -381.50757  |\n",
      "| qf1_loss                | 10.045204   |\n",
      "| qf2_loss                | 18.41537    |\n",
      "| time_elapsed            | 13180       |\n",
      "| total timesteps         | 1099174     |\n",
      "| value_loss              | 13.985168   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031058224 |\n",
      "| ent_coef_loss           | -1.565969   |\n",
      "| entropy                 | 13.838335   |\n",
      "| episodes                | 4460        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 2.88e+03    |\n",
      "| n_updates               | 1104040     |\n",
      "| policy_loss             | -372.86377  |\n",
      "| qf1_loss                | 28.658297   |\n",
      "| qf2_loss                | 18.978382   |\n",
      "| time_elapsed            | 13239       |\n",
      "| total timesteps         | 1104139     |\n",
      "| value_loss              | 9.855945    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031131389 |\n",
      "| ent_coef_loss           | 0.7691045   |\n",
      "| entropy                 | 14.697379   |\n",
      "| episodes                | 4470        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 2.85e+03    |\n",
      "| n_updates               | 1108859     |\n",
      "| policy_loss             | -380.51733  |\n",
      "| qf1_loss                | 28.854286   |\n",
      "| qf2_loss                | 28.80836    |\n",
      "| time_elapsed            | 13306       |\n",
      "| total timesteps         | 1108958     |\n",
      "| value_loss              | 12.095278   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.033172794 |\n",
      "| ent_coef_loss           | -6.4446387  |\n",
      "| entropy                 | 14.691728   |\n",
      "| episodes                | 4480        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.09e+03    |\n",
      "| n_updates               | 1116927     |\n",
      "| policy_loss             | -361.24597  |\n",
      "| qf1_loss                | 14.524552   |\n",
      "| qf2_loss                | 20.069393   |\n",
      "| time_elapsed            | 13405       |\n",
      "| total timesteps         | 1117026     |\n",
      "| value_loss              | 12.331305   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02951711 |\n",
      "| ent_coef_loss           | 6.1249995  |\n",
      "| entropy                 | 14.76473   |\n",
      "| episodes                | 4490       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 3.21e+03   |\n",
      "| n_updates               | 1124135    |\n",
      "| policy_loss             | -379.51645 |\n",
      "| qf1_loss                | 19.543655  |\n",
      "| qf2_loss                | 22.282175  |\n",
      "| time_elapsed            | 13496      |\n",
      "| total timesteps         | 1124234    |\n",
      "| value_loss              | 15.378317  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029540913 |\n",
      "| ent_coef_loss           | -2.5711737  |\n",
      "| entropy                 | 14.698154   |\n",
      "| episodes                | 4500        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 2.96e+03    |\n",
      "| n_updates               | 1128105     |\n",
      "| policy_loss             | -392.9614   |\n",
      "| qf1_loss                | 18.98739    |\n",
      "| qf2_loss                | 28.508116   |\n",
      "| time_elapsed            | 13547       |\n",
      "| total timesteps         | 1128204     |\n",
      "| value_loss              | 8.356819    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030738635 |\n",
      "| ent_coef_loss           | -4.784898   |\n",
      "| entropy                 | 13.918833   |\n",
      "| episodes                | 4510        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.04e+03    |\n",
      "| n_updates               | 1135112     |\n",
      "| policy_loss             | -387.70862  |\n",
      "| qf1_loss                | 1344.8329   |\n",
      "| qf2_loss                | 1333.7152   |\n",
      "| time_elapsed            | 13634       |\n",
      "| total timesteps         | 1135211     |\n",
      "| value_loss              | 14.353847   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031426974 |\n",
      "| ent_coef_loss           | -11.122457  |\n",
      "| entropy                 | 14.803665   |\n",
      "| episodes                | 4520        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 2.93e+03    |\n",
      "| n_updates               | 1138104     |\n",
      "| policy_loss             | -386.53253  |\n",
      "| qf1_loss                | 23.097174   |\n",
      "| qf2_loss                | 26.831964   |\n",
      "| time_elapsed            | 13670       |\n",
      "| total timesteps         | 1138203     |\n",
      "| value_loss              | 7.7493997   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031910304 |\n",
      "| ent_coef_loss           | 0.59146285  |\n",
      "| entropy                 | 15.2082205  |\n",
      "| episodes                | 4530        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.25e+03    |\n",
      "| n_updates               | 1145729     |\n",
      "| policy_loss             | -380.32263  |\n",
      "| qf1_loss                | 18.968063   |\n",
      "| qf2_loss                | 23.850714   |\n",
      "| time_elapsed            | 13763       |\n",
      "| total timesteps         | 1145828     |\n",
      "| value_loss              | 17.122528   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030199766 |\n",
      "| ent_coef_loss           | 1.8795156   |\n",
      "| entropy                 | 14.18993    |\n",
      "| episodes                | 4540        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.3e+03     |\n",
      "| n_updates               | 1152902     |\n",
      "| policy_loss             | -402.8955   |\n",
      "| qf1_loss                | 10.030003   |\n",
      "| qf2_loss                | 8.887243    |\n",
      "| time_elapsed            | 13850       |\n",
      "| total timesteps         | 1153001     |\n",
      "| value_loss              | 12.448381   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029747069 |\n",
      "| ent_coef_loss           | 1.6373885   |\n",
      "| entropy                 | 14.494099   |\n",
      "| episodes                | 4550        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.24e+03    |\n",
      "| n_updates               | 1159499     |\n",
      "| policy_loss             | -408.25073  |\n",
      "| qf1_loss                | 13.062692   |\n",
      "| qf2_loss                | 11.91711    |\n",
      "| time_elapsed            | 13925       |\n",
      "| total timesteps         | 1159598     |\n",
      "| value_loss              | 7.4555006   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031548403 |\n",
      "| ent_coef_loss           | -8.923805   |\n",
      "| entropy                 | 15.036744   |\n",
      "| episodes                | 4560        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.22e+03    |\n",
      "| n_updates               | 1164006     |\n",
      "| policy_loss             | -389.75464  |\n",
      "| qf1_loss                | 13.231338   |\n",
      "| qf2_loss                | 9.818841    |\n",
      "| time_elapsed            | 13976       |\n",
      "| total timesteps         | 1164105     |\n",
      "| value_loss              | 8.287279    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030821295 |\n",
      "| ent_coef_loss           | -10.210688  |\n",
      "| entropy                 | 14.983618   |\n",
      "| episodes                | 4570        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.31e+03    |\n",
      "| n_updates               | 1170428     |\n",
      "| policy_loss             | -411.2095   |\n",
      "| qf1_loss                | 11.973644   |\n",
      "| qf2_loss                | 13.002394   |\n",
      "| time_elapsed            | 14049       |\n",
      "| total timesteps         | 1170527     |\n",
      "| value_loss              | 9.688807    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02959302 |\n",
      "| ent_coef_loss           | -9.292609  |\n",
      "| entropy                 | 14.048855  |\n",
      "| episodes                | 4580       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 3.2e+03    |\n",
      "| n_updates               | 1176462    |\n",
      "| policy_loss             | -415.39545 |\n",
      "| qf1_loss                | 8.5829525  |\n",
      "| qf2_loss                | 6.5559025  |\n",
      "| time_elapsed            | 14128      |\n",
      "| total timesteps         | 1176561    |\n",
      "| value_loss              | 5.378621   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03225463 |\n",
      "| ent_coef_loss           | -6.7015734 |\n",
      "| entropy                 | 15.152246  |\n",
      "| episodes                | 4590       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 3.11e+03   |\n",
      "| n_updates               | 1182181    |\n",
      "| policy_loss             | -396.4178  |\n",
      "| qf1_loss                | 17.321466  |\n",
      "| qf2_loss                | 20.005253  |\n",
      "| time_elapsed            | 14202      |\n",
      "| total timesteps         | 1182280    |\n",
      "| value_loss              | 9.0949335  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031463027 |\n",
      "| ent_coef_loss           | 0.6830143   |\n",
      "| entropy                 | 14.170125   |\n",
      "| episodes                | 4600        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.13e+03    |\n",
      "| n_updates               | 1186447     |\n",
      "| policy_loss             | -373.41452  |\n",
      "| qf1_loss                | 28.851109   |\n",
      "| qf2_loss                | 39.68699    |\n",
      "| time_elapsed            | 14255       |\n",
      "| total timesteps         | 1186546     |\n",
      "| value_loss              | 17.404713   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029453875 |\n",
      "| ent_coef_loss           | 0.5215547   |\n",
      "| entropy                 | 13.961468   |\n",
      "| episodes                | 4610        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.07e+03    |\n",
      "| n_updates               | 1192571     |\n",
      "| policy_loss             | -385.91235  |\n",
      "| qf1_loss                | 21.159086   |\n",
      "| qf2_loss                | 17.74789    |\n",
      "| time_elapsed            | 14329       |\n",
      "| total timesteps         | 1192670     |\n",
      "| value_loss              | 17.43459    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030518468 |\n",
      "| ent_coef_loss           | 7.055725    |\n",
      "| entropy                 | 14.072962   |\n",
      "| episodes                | 4620        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.22e+03    |\n",
      "| n_updates               | 1198409     |\n",
      "| policy_loss             | -381.02246  |\n",
      "| qf1_loss                | 32.763607   |\n",
      "| qf2_loss                | 24.018454   |\n",
      "| time_elapsed            | 14401       |\n",
      "| total timesteps         | 1198508     |\n",
      "| value_loss              | 21.37151    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029942326 |\n",
      "| ent_coef_loss           | -0.71948385 |\n",
      "| entropy                 | 14.645064   |\n",
      "| episodes                | 4630        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.17e+03    |\n",
      "| n_updates               | 1205258     |\n",
      "| policy_loss             | -416.12628  |\n",
      "| qf1_loss                | 22.227861   |\n",
      "| qf2_loss                | 20.928577   |\n",
      "| time_elapsed            | 14486       |\n",
      "| total timesteps         | 1205357     |\n",
      "| value_loss              | 7.4274874   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.033069003 |\n",
      "| ent_coef_loss           | 0.73905694  |\n",
      "| entropy                 | 14.635466   |\n",
      "| episodes                | 4640        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.17e+03    |\n",
      "| n_updates               | 1212470     |\n",
      "| policy_loss             | -375.70654  |\n",
      "| qf1_loss                | 23.235065   |\n",
      "| qf2_loss                | 17.564278   |\n",
      "| time_elapsed            | 14569       |\n",
      "| total timesteps         | 1212569     |\n",
      "| value_loss              | 24.109272   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03364777 |\n",
      "| ent_coef_loss           | 5.562018   |\n",
      "| entropy                 | 14.57645   |\n",
      "| episodes                | 4650       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 3.07e+03   |\n",
      "| n_updates               | 1217451    |\n",
      "| policy_loss             | -400.4463  |\n",
      "| qf1_loss                | 20.254246  |\n",
      "| qf2_loss                | 25.185192  |\n",
      "| time_elapsed            | 14632      |\n",
      "| total timesteps         | 1217550    |\n",
      "| value_loss              | 17.079546  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.032874055 |\n",
      "| ent_coef_loss           | -8.154174   |\n",
      "| entropy                 | 14.742957   |\n",
      "| episodes                | 4660        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.05e+03    |\n",
      "| n_updates               | 1221647     |\n",
      "| policy_loss             | -413.0006   |\n",
      "| qf1_loss                | 22.61298    |\n",
      "| qf2_loss                | 24.061157   |\n",
      "| time_elapsed            | 14682       |\n",
      "| total timesteps         | 1221746     |\n",
      "| value_loss              | 10.548319   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.032159083 |\n",
      "| ent_coef_loss           | -0.13305998 |\n",
      "| entropy                 | 15.000093   |\n",
      "| episodes                | 4670        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.16e+03    |\n",
      "| n_updates               | 1230173     |\n",
      "| policy_loss             | -382.76218  |\n",
      "| qf1_loss                | 42.8753     |\n",
      "| qf2_loss                | 36.09678    |\n",
      "| time_elapsed            | 14785       |\n",
      "| total timesteps         | 1230272     |\n",
      "| value_loss              | 19.875841   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030964842 |\n",
      "| ent_coef_loss           | -3.004755   |\n",
      "| entropy                 | 14.844395   |\n",
      "| episodes                | 4680        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.33e+03    |\n",
      "| n_updates               | 1239164     |\n",
      "| policy_loss             | -412.63144  |\n",
      "| qf1_loss                | 29.28577    |\n",
      "| qf2_loss                | 18.992268   |\n",
      "| time_elapsed            | 14890       |\n",
      "| total timesteps         | 1239263     |\n",
      "| value_loss              | 11.946696   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.027718937 |\n",
      "| ent_coef_loss           | -6.5352225  |\n",
      "| entropy                 | 13.675625   |\n",
      "| episodes                | 4690        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.5e+03     |\n",
      "| n_updates               | 1247948     |\n",
      "| policy_loss             | -413.52417  |\n",
      "| qf1_loss                | 18.187092   |\n",
      "| qf2_loss                | 26.71135    |\n",
      "| time_elapsed            | 14991       |\n",
      "| total timesteps         | 1248047     |\n",
      "| value_loss              | 17.072006   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028489698 |\n",
      "| ent_coef_loss           | -0.1266368  |\n",
      "| entropy                 | 13.98067    |\n",
      "| episodes                | 4700        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.56e+03    |\n",
      "| n_updates               | 1253213     |\n",
      "| policy_loss             | -409.32883  |\n",
      "| qf1_loss                | 34.713398   |\n",
      "| qf2_loss                | 32.901463   |\n",
      "| time_elapsed            | 15051       |\n",
      "| total timesteps         | 1253312     |\n",
      "| value_loss              | 23.807777   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029441807 |\n",
      "| ent_coef_loss           | 1.7717334   |\n",
      "| entropy                 | 13.64837    |\n",
      "| episodes                | 4710        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.72e+03    |\n",
      "| n_updates               | 1262075     |\n",
      "| policy_loss             | -398.41608  |\n",
      "| qf1_loss                | 11.597394   |\n",
      "| qf2_loss                | 19.534313   |\n",
      "| time_elapsed            | 15154       |\n",
      "| total timesteps         | 1262174     |\n",
      "| value_loss              | 22.947973   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.026796514 |\n",
      "| ent_coef_loss           | 2.550488    |\n",
      "| entropy                 | 13.381535   |\n",
      "| episodes                | 4720        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.88e+03    |\n",
      "| n_updates               | 1270872     |\n",
      "| policy_loss             | -392.32333  |\n",
      "| qf1_loss                | 26.702322   |\n",
      "| qf2_loss                | 11.449345   |\n",
      "| time_elapsed            | 15259       |\n",
      "| total timesteps         | 1270971     |\n",
      "| value_loss              | 14.80231    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030933443 |\n",
      "| ent_coef_loss           | 6.661243    |\n",
      "| entropy                 | 14.372118   |\n",
      "| episodes                | 4730        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.98e+03    |\n",
      "| n_updates               | 1279422     |\n",
      "| policy_loss             | -411.237    |\n",
      "| qf1_loss                | 16.606804   |\n",
      "| qf2_loss                | 22.055641   |\n",
      "| time_elapsed            | 15364       |\n",
      "| total timesteps         | 1279521     |\n",
      "| value_loss              | 9.861782    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031907335 |\n",
      "| ent_coef_loss           | -11.359731  |\n",
      "| entropy                 | 14.316734   |\n",
      "| episodes                | 4740        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.98e+03    |\n",
      "| n_updates               | 1286531     |\n",
      "| policy_loss             | -416.3676   |\n",
      "| qf1_loss                | 19.008774   |\n",
      "| qf2_loss                | 12.709184   |\n",
      "| time_elapsed            | 15447       |\n",
      "| total timesteps         | 1286630     |\n",
      "| value_loss              | 8.140703    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029769951 |\n",
      "| ent_coef_loss           | 3.136643    |\n",
      "| entropy                 | 13.930703   |\n",
      "| episodes                | 4750        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 4.07e+03    |\n",
      "| n_updates               | 1292916     |\n",
      "| policy_loss             | -404.84576  |\n",
      "| qf1_loss                | 22.470522   |\n",
      "| qf2_loss                | 14.496952   |\n",
      "| time_elapsed            | 15527       |\n",
      "| total timesteps         | 1293015     |\n",
      "| value_loss              | 19.842743   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.027657155 |\n",
      "| ent_coef_loss           | -0.01214695 |\n",
      "| entropy                 | 14.339914   |\n",
      "| episodes                | 4760        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 4.23e+03    |\n",
      "| n_updates               | 1299861     |\n",
      "| policy_loss             | -423.03564  |\n",
      "| qf1_loss                | 8.367517    |\n",
      "| qf2_loss                | 12.607267   |\n",
      "| time_elapsed            | 15615       |\n",
      "| total timesteps         | 1299960     |\n",
      "| value_loss              | 13.585474   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028665552 |\n",
      "| ent_coef_loss           | -16.622063  |\n",
      "| entropy                 | 15.076967   |\n",
      "| episodes                | 4770        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 4.25e+03    |\n",
      "| n_updates               | 1308522     |\n",
      "| policy_loss             | -430.65967  |\n",
      "| qf1_loss                | 12.273869   |\n",
      "| qf2_loss                | 17.513058   |\n",
      "| time_elapsed            | 15745       |\n",
      "| total timesteps         | 1308621     |\n",
      "| value_loss              | 9.429866    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.027520694 |\n",
      "| ent_coef_loss           | 5.310293    |\n",
      "| entropy                 | 13.978738   |\n",
      "| episodes                | 4780        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 4.17e+03    |\n",
      "| n_updates               | 1316176     |\n",
      "| policy_loss             | -407.5349   |\n",
      "| qf1_loss                | 46.211594   |\n",
      "| qf2_loss                | 25.86856    |\n",
      "| time_elapsed            | 15860       |\n",
      "| total timesteps         | 1316275     |\n",
      "| value_loss              | 11.591336   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029565172 |\n",
      "| ent_coef_loss           | 11.197067   |\n",
      "| entropy                 | 14.570263   |\n",
      "| episodes                | 4790        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 4.12e+03    |\n",
      "| n_updates               | 1324154     |\n",
      "| policy_loss             | -405.64154  |\n",
      "| qf1_loss                | 38.416294   |\n",
      "| qf2_loss                | 44.326347   |\n",
      "| time_elapsed            | 15980       |\n",
      "| total timesteps         | 1324253     |\n",
      "| value_loss              | 9.931402    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028929535 |\n",
      "| ent_coef_loss           | -1.3951993  |\n",
      "| entropy                 | 14.732822   |\n",
      "| episodes                | 4800        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 4.26e+03    |\n",
      "| n_updates               | 1332000     |\n",
      "| policy_loss             | -419.2256   |\n",
      "| qf1_loss                | 24.50227    |\n",
      "| qf2_loss                | 21.618652   |\n",
      "| time_elapsed            | 16096       |\n",
      "| total timesteps         | 1332099     |\n",
      "| value_loss              | 10.828849   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028687019 |\n",
      "| ent_coef_loss           | -20.90469   |\n",
      "| entropy                 | 15.090248   |\n",
      "| episodes                | 4810        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 4.23e+03    |\n",
      "| n_updates               | 1340467     |\n",
      "| policy_loss             | -411.88998  |\n",
      "| qf1_loss                | 16.849611   |\n",
      "| qf2_loss                | 27.782314   |\n",
      "| time_elapsed            | 16218       |\n",
      "| total timesteps         | 1340566     |\n",
      "| value_loss              | 9.6488085   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030893821 |\n",
      "| ent_coef_loss           | 2.0187287   |\n",
      "| entropy                 | 14.762737   |\n",
      "| episodes                | 4820        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 4.2e+03     |\n",
      "| n_updates               | 1348624     |\n",
      "| policy_loss             | -423.39713  |\n",
      "| qf1_loss                | 26.353664   |\n",
      "| qf2_loss                | 23.610834   |\n",
      "| time_elapsed            | 16347       |\n",
      "| total timesteps         | 1348723     |\n",
      "| value_loss              | 16.155067   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03088525 |\n",
      "| ent_coef_loss           | -12.652441 |\n",
      "| entropy                 | 15.114635  |\n",
      "| episodes                | 4830       |\n",
      "| fps                     | 82         |\n",
      "| mean 100 episode reward | 4.09e+03   |\n",
      "| n_updates               | 1355107    |\n",
      "| policy_loss             | -437.64008 |\n",
      "| qf1_loss                | 9.0941     |\n",
      "| qf2_loss                | 6.1550093  |\n",
      "| time_elapsed            | 16438      |\n",
      "| total timesteps         | 1355206    |\n",
      "| value_loss              | 5.134454   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028774878 |\n",
      "| ent_coef_loss           | 4.676939    |\n",
      "| entropy                 | 14.067465   |\n",
      "| episodes                | 4840        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 3.94e+03    |\n",
      "| n_updates               | 1359486     |\n",
      "| policy_loss             | -424.0244   |\n",
      "| qf1_loss                | 25.958145   |\n",
      "| qf2_loss                | 18.685772   |\n",
      "| time_elapsed            | 16503       |\n",
      "| total timesteps         | 1359585     |\n",
      "| value_loss              | 18.698809   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029911466 |\n",
      "| ent_coef_loss           | -3.8033762  |\n",
      "| entropy                 | 14.883317   |\n",
      "| episodes                | 4850        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 3.93e+03    |\n",
      "| n_updates               | 1365878     |\n",
      "| policy_loss             | -430.06647  |\n",
      "| qf1_loss                | 21.402185   |\n",
      "| qf2_loss                | 20.463718   |\n",
      "| time_elapsed            | 16594       |\n",
      "| total timesteps         | 1365977     |\n",
      "| value_loss              | 9.409874    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028558193 |\n",
      "| ent_coef_loss           | -9.994448   |\n",
      "| entropy                 | 14.88106    |\n",
      "| episodes                | 4860        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 4e+03       |\n",
      "| n_updates               | 1374183     |\n",
      "| policy_loss             | -428.07928  |\n",
      "| qf1_loss                | 34.5451     |\n",
      "| qf2_loss                | 22.205969   |\n",
      "| time_elapsed            | 16700       |\n",
      "| total timesteps         | 1374282     |\n",
      "| value_loss              | 7.284384    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029112602 |\n",
      "| ent_coef_loss           | -6.5640965  |\n",
      "| entropy                 | 15.105557   |\n",
      "| episodes                | 4870        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 3.91e+03    |\n",
      "| n_updates               | 1381444     |\n",
      "| policy_loss             | -425.3202   |\n",
      "| qf1_loss                | 26.853909   |\n",
      "| qf2_loss                | 22.113792   |\n",
      "| time_elapsed            | 16789       |\n",
      "| total timesteps         | 1381543     |\n",
      "| value_loss              | 14.009164   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02692172 |\n",
      "| ent_coef_loss           | -7.3967843 |\n",
      "| entropy                 | 14.212481  |\n",
      "| episodes                | 4880       |\n",
      "| fps                     | 82         |\n",
      "| mean 100 episode reward | 3.74e+03   |\n",
      "| n_updates               | 1385839    |\n",
      "| policy_loss             | -431.55548 |\n",
      "| qf1_loss                | 5.5338163  |\n",
      "| qf2_loss                | 8.810286   |\n",
      "| time_elapsed            | 16836      |\n",
      "| total timesteps         | 1385938    |\n",
      "| value_loss              | 5.3006477  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02931157 |\n",
      "| ent_coef_loss           | -1.9252799 |\n",
      "| entropy                 | 14.5298    |\n",
      "| episodes                | 4890       |\n",
      "| fps                     | 82         |\n",
      "| mean 100 episode reward | 3.64e+03   |\n",
      "| n_updates               | 1391861    |\n",
      "| policy_loss             | -419.99942 |\n",
      "| qf1_loss                | 22.158312  |\n",
      "| qf2_loss                | 11.051484  |\n",
      "| time_elapsed            | 16900      |\n",
      "| total timesteps         | 1391960    |\n",
      "| value_loss              | 13.393807  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030838408 |\n",
      "| ent_coef_loss           | -3.907464   |\n",
      "| entropy                 | 14.418226   |\n",
      "| episodes                | 4900        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 3.66e+03    |\n",
      "| n_updates               | 1400097     |\n",
      "| policy_loss             | -431.39227  |\n",
      "| qf1_loss                | 13.4305315  |\n",
      "| qf2_loss                | 10.371884   |\n",
      "| time_elapsed            | 16989       |\n",
      "| total timesteps         | 1400196     |\n",
      "| value_loss              | 16.101444   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031158194 |\n",
      "| ent_coef_loss           | 1.2638628   |\n",
      "| entropy                 | 14.5897045  |\n",
      "| episodes                | 4910        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 3.67e+03    |\n",
      "| n_updates               | 1408784     |\n",
      "| policy_loss             | -423.9497   |\n",
      "| qf1_loss                | 23.648445   |\n",
      "| qf2_loss                | 8.721216    |\n",
      "| time_elapsed            | 17101       |\n",
      "| total timesteps         | 1408883     |\n",
      "| value_loss              | 15.425955   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.027770698 |\n",
      "| ent_coef_loss           | 15.756151   |\n",
      "| entropy                 | 14.048111   |\n",
      "| episodes                | 4920        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 3.44e+03    |\n",
      "| n_updates               | 1412674     |\n",
      "| policy_loss             | -394.95367  |\n",
      "| qf1_loss                | 21.43163    |\n",
      "| qf2_loss                | 25.225151   |\n",
      "| time_elapsed            | 17164       |\n",
      "| total timesteps         | 1412773     |\n",
      "| value_loss              | 15.375331   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028234681 |\n",
      "| ent_coef_loss           | -2.0055163  |\n",
      "| entropy                 | 14.255329   |\n",
      "| episodes                | 4930        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 3.51e+03    |\n",
      "| n_updates               | 1420473     |\n",
      "| policy_loss             | -424.27484  |\n",
      "| qf1_loss                | 30.558456   |\n",
      "| qf2_loss                | 27.52766    |\n",
      "| time_elapsed            | 17275       |\n",
      "| total timesteps         | 1420572     |\n",
      "| value_loss              | 20.259993   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029355194 |\n",
      "| ent_coef_loss           | 7.2815824   |\n",
      "| entropy                 | 14.181046   |\n",
      "| episodes                | 4940        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 3.78e+03    |\n",
      "| n_updates               | 1429836     |\n",
      "| policy_loss             | -392.38025  |\n",
      "| qf1_loss                | 20.920248   |\n",
      "| qf2_loss                | 19.255953   |\n",
      "| time_elapsed            | 17413       |\n",
      "| total timesteps         | 1429935     |\n",
      "| value_loss              | 23.018696   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.027849646 |\n",
      "| ent_coef_loss           | 16.995588   |\n",
      "| entropy                 | 13.534981   |\n",
      "| episodes                | 4950        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 3.84e+03    |\n",
      "| n_updates               | 1437063     |\n",
      "| policy_loss             | -400.14398  |\n",
      "| qf1_loss                | 25.95176    |\n",
      "| qf2_loss                | 22.867792   |\n",
      "| time_elapsed            | 17536       |\n",
      "| total timesteps         | 1437162     |\n",
      "| value_loss              | 12.761326   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.027199231 |\n",
      "| ent_coef_loss           | 14.929903   |\n",
      "| entropy                 | 14.32896    |\n",
      "| episodes                | 4960        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 3.83e+03    |\n",
      "| n_updates               | 1444980     |\n",
      "| policy_loss             | -419.27258  |\n",
      "| qf1_loss                | 32.744484   |\n",
      "| qf2_loss                | 19.555525   |\n",
      "| time_elapsed            | 17642       |\n",
      "| total timesteps         | 1445079     |\n",
      "| value_loss              | 18.097229   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.027234135 |\n",
      "| ent_coef_loss           | -3.9067469  |\n",
      "| entropy                 | 14.973588   |\n",
      "| episodes                | 4970        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 3.92e+03    |\n",
      "| n_updates               | 1453741     |\n",
      "| policy_loss             | -440.89343  |\n",
      "| qf1_loss                | 22.24014    |\n",
      "| qf2_loss                | 9.356161    |\n",
      "| time_elapsed            | 17772       |\n",
      "| total timesteps         | 1453840     |\n",
      "| value_loss              | 20.158588   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.026237981 |\n",
      "| ent_coef_loss           | -3.8440397  |\n",
      "| entropy                 | 13.617139   |\n",
      "| episodes                | 4980        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 3.98e+03    |\n",
      "| n_updates               | 1459381     |\n",
      "| policy_loss             | -432.10052  |\n",
      "| qf1_loss                | 44.174377   |\n",
      "| qf2_loss                | 36.564972   |\n",
      "| time_elapsed            | 17861       |\n",
      "| total timesteps         | 1459480     |\n",
      "| value_loss              | 18.31028    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.027638612 |\n",
      "| ent_coef_loss           | 2.84926     |\n",
      "| entropy                 | 14.459934   |\n",
      "| episodes                | 4990        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 4.02e+03    |\n",
      "| n_updates               | 1466356     |\n",
      "| policy_loss             | -418.74445  |\n",
      "| qf1_loss                | 23.572346   |\n",
      "| qf2_loss                | 25.96753    |\n",
      "| time_elapsed            | 17972       |\n",
      "| total timesteps         | 1466455     |\n",
      "| value_loss              | 12.668266   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.027442526 |\n",
      "| ent_coef_loss           | -0.5155716  |\n",
      "| entropy                 | 14.503395   |\n",
      "| episodes                | 5000        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 3.92e+03    |\n",
      "| n_updates               | 1472489     |\n",
      "| policy_loss             | -411.71277  |\n",
      "| qf1_loss                | 26.638527   |\n",
      "| qf2_loss                | 23.403843   |\n",
      "| time_elapsed            | 18071       |\n",
      "| total timesteps         | 1472588     |\n",
      "| value_loss              | 15.264112   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.026165871 |\n",
      "| ent_coef_loss           | -5.325344   |\n",
      "| entropy                 | 14.978943   |\n",
      "| episodes                | 5010        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 3.77e+03    |\n",
      "| n_updates               | 1478462     |\n",
      "| policy_loss             | -415.24664  |\n",
      "| qf1_loss                | 12.881838   |\n",
      "| qf2_loss                | 4.7037215   |\n",
      "| time_elapsed            | 18168       |\n",
      "| total timesteps         | 1478561     |\n",
      "| value_loss              | 8.373249    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.027464284 |\n",
      "| ent_coef_loss           | -7.2669535  |\n",
      "| entropy                 | 15.035132   |\n",
      "| episodes                | 5020        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 4.05e+03    |\n",
      "| n_updates               | 1487358     |\n",
      "| policy_loss             | -443.85168  |\n",
      "| qf1_loss                | 24.539875   |\n",
      "| qf2_loss                | 21.570902   |\n",
      "| time_elapsed            | 18310       |\n",
      "| total timesteps         | 1487457     |\n",
      "| value_loss              | 7.863242    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.027783923 |\n",
      "| ent_coef_loss           | -3.3183503  |\n",
      "| entropy                 | 14.84368    |\n",
      "| episodes                | 5030        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 4.01e+03    |\n",
      "| n_updates               | 1494289     |\n",
      "| policy_loss             | -426.43997  |\n",
      "| qf1_loss                | 20.904154   |\n",
      "| qf2_loss                | 31.372118   |\n",
      "| time_elapsed            | 18391       |\n",
      "| total timesteps         | 1494388     |\n",
      "| value_loss              | 26.665436   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029119253 |\n",
      "| ent_coef_loss           | -7.978      |\n",
      "| entropy                 | 15.151413   |\n",
      "| episodes                | 5040        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 3.79e+03    |\n",
      "| n_updates               | 1499554     |\n",
      "| policy_loss             | -430.7598   |\n",
      "| qf1_loss                | 8.593088    |\n",
      "| qf2_loss                | 7.9533772   |\n",
      "| time_elapsed            | 18446       |\n",
      "| total timesteps         | 1499653     |\n",
      "| value_loss              | 12.704058   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028081415 |\n",
      "| ent_coef_loss           | -15.316221  |\n",
      "| entropy                 | 14.456032   |\n",
      "| episodes                | 5050        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 3.9e+03     |\n",
      "| n_updates               | 1508718     |\n",
      "| policy_loss             | -446.16928  |\n",
      "| qf1_loss                | 38.730827   |\n",
      "| qf2_loss                | 26.78573    |\n",
      "| time_elapsed            | 18544       |\n",
      "| total timesteps         | 1508817     |\n",
      "| value_loss              | 14.101718   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029235898 |\n",
      "| ent_coef_loss           | -15.363142  |\n",
      "| entropy                 | 15.053864   |\n",
      "| episodes                | 5060        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 3.93e+03    |\n",
      "| n_updates               | 1517052     |\n",
      "| policy_loss             | -438.28143  |\n",
      "| qf1_loss                | 14.718515   |\n",
      "| qf2_loss                | 18.477757   |\n",
      "| time_elapsed            | 18632       |\n",
      "| total timesteps         | 1517151     |\n",
      "| value_loss              | 11.116659   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.027795438 |\n",
      "| ent_coef_loss           | -1.6932344  |\n",
      "| entropy                 | 14.18121    |\n",
      "| episodes                | 5070        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 3.79e+03    |\n",
      "| n_updates               | 1523216     |\n",
      "| policy_loss             | -432.23566  |\n",
      "| qf1_loss                | 19.22658    |\n",
      "| qf2_loss                | 10.887161   |\n",
      "| time_elapsed            | 18698       |\n",
      "| total timesteps         | 1523315     |\n",
      "| value_loss              | 11.653297   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.027761528 |\n",
      "| ent_coef_loss           | -11.949507  |\n",
      "| entropy                 | 15.105493   |\n",
      "| episodes                | 5080        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 3.84e+03    |\n",
      "| n_updates               | 1529659     |\n",
      "| policy_loss             | -444.05518  |\n",
      "| qf1_loss                | 7.627598    |\n",
      "| qf2_loss                | 6.6715155   |\n",
      "| time_elapsed            | 18767       |\n",
      "| total timesteps         | 1529758     |\n",
      "| value_loss              | 5.973584    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.026431212 |\n",
      "| ent_coef_loss           | -10.720377  |\n",
      "| entropy                 | 14.92044    |\n",
      "| episodes                | 5090        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 3.99e+03    |\n",
      "| n_updates               | 1539058     |\n",
      "| policy_loss             | -435.13574  |\n",
      "| qf1_loss                | 13.92595    |\n",
      "| qf2_loss                | 10.586875   |\n",
      "| time_elapsed            | 18866       |\n",
      "| total timesteps         | 1539157     |\n",
      "| value_loss              | 17.578753   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031511717 |\n",
      "| ent_coef_loss           | 1.1926198   |\n",
      "| entropy                 | 14.710289   |\n",
      "| episodes                | 5100        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 4.02e+03    |\n",
      "| n_updates               | 1545821     |\n",
      "| policy_loss             | -433.6376   |\n",
      "| qf1_loss                | 16.388191   |\n",
      "| qf2_loss                | 12.994824   |\n",
      "| time_elapsed            | 18938       |\n",
      "| total timesteps         | 1545920     |\n",
      "| value_loss              | 13.033691   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.0276202  |\n",
      "| ent_coef_loss           | 0.82931113 |\n",
      "| entropy                 | 14.159228  |\n",
      "| episodes                | 5110       |\n",
      "| fps                     | 81         |\n",
      "| mean 100 episode reward | 4.09e+03   |\n",
      "| n_updates               | 1552852    |\n",
      "| policy_loss             | -436.51703 |\n",
      "| qf1_loss                | 11.983243  |\n",
      "| qf2_loss                | 17.111895  |\n",
      "| time_elapsed            | 19012      |\n",
      "| total timesteps         | 1552951    |\n",
      "| value_loss              | 5.8416967  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028448496 |\n",
      "| ent_coef_loss           | 13.600281   |\n",
      "| entropy                 | 14.679515   |\n",
      "| episodes                | 5120        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 4.1e+03     |\n",
      "| n_updates               | 1561936     |\n",
      "| policy_loss             | -413.52957  |\n",
      "| qf1_loss                | 19.35       |\n",
      "| qf2_loss                | 13.077816   |\n",
      "| time_elapsed            | 19109       |\n",
      "| total timesteps         | 1562035     |\n",
      "| value_loss              | 19.32266    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.0301353  |\n",
      "| ent_coef_loss           | -2.9950337 |\n",
      "| entropy                 | 14.352768  |\n",
      "| episodes                | 5130       |\n",
      "| fps                     | 81         |\n",
      "| mean 100 episode reward | 4.06e+03   |\n",
      "| n_updates               | 1568395    |\n",
      "| policy_loss             | -454.2911  |\n",
      "| qf1_loss                | 30.45112   |\n",
      "| qf2_loss                | 31.994534  |\n",
      "| time_elapsed            | 19177      |\n",
      "| total timesteps         | 1568494    |\n",
      "| value_loss              | 28.456514  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02739143 |\n",
      "| ent_coef_loss           | -3.9665508 |\n",
      "| entropy                 | 13.674968  |\n",
      "| episodes                | 5140       |\n",
      "| fps                     | 81         |\n",
      "| mean 100 episode reward | 4.19e+03   |\n",
      "| n_updates               | 1575735    |\n",
      "| policy_loss             | -413.25836 |\n",
      "| qf1_loss                | 19.962688  |\n",
      "| qf2_loss                | 23.36056   |\n",
      "| time_elapsed            | 19255      |\n",
      "| total timesteps         | 1575834    |\n",
      "| value_loss              | 23.764755  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030355772 |\n",
      "| ent_coef_loss           | -1.3496177  |\n",
      "| entropy                 | 14.580101   |\n",
      "| episodes                | 5150        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 4.07e+03    |\n",
      "| n_updates               | 1582716     |\n",
      "| policy_loss             | -435.61145  |\n",
      "| qf1_loss                | 27.70811    |\n",
      "| qf2_loss                | 24.352325   |\n",
      "| time_elapsed            | 19328       |\n",
      "| total timesteps         | 1582815     |\n",
      "| value_loss              | 9.4441805   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029162627 |\n",
      "| ent_coef_loss           | 2.6322558   |\n",
      "| entropy                 | 14.549913   |\n",
      "| episodes                | 5160        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 4.11e+03    |\n",
      "| n_updates               | 1591827     |\n",
      "| policy_loss             | -425.85724  |\n",
      "| qf1_loss                | 18.028362   |\n",
      "| qf2_loss                | 14.734481   |\n",
      "| time_elapsed            | 19425       |\n",
      "| total timesteps         | 1591926     |\n",
      "| value_loss              | 28.816761   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028674206 |\n",
      "| ent_coef_loss           | 5.8897862   |\n",
      "| entropy                 | 14.818251   |\n",
      "| episodes                | 5170        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 4.27e+03    |\n",
      "| n_updates               | 1600997     |\n",
      "| policy_loss             | -412.55637  |\n",
      "| qf1_loss                | 30.265223   |\n",
      "| qf2_loss                | 19.681135   |\n",
      "| time_elapsed            | 19522       |\n",
      "| total timesteps         | 1601096     |\n",
      "| value_loss              | 7.9886346   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031598084 |\n",
      "| ent_coef_loss           | 3.5222216   |\n",
      "| entropy                 | 14.168704   |\n",
      "| episodes                | 5180        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 4.42e+03    |\n",
      "| n_updates               | 1609954     |\n",
      "| policy_loss             | -431.9673   |\n",
      "| qf1_loss                | 40.96723    |\n",
      "| qf2_loss                | 21.241243   |\n",
      "| time_elapsed            | 19621       |\n",
      "| total timesteps         | 1610053     |\n",
      "| value_loss              | 20.294216   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028485378 |\n",
      "| ent_coef_loss           | -1.4538074  |\n",
      "| entropy                 | 14.535371   |\n",
      "| episodes                | 5190        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 4.35e+03    |\n",
      "| n_updates               | 1617990     |\n",
      "| policy_loss             | -424.69214  |\n",
      "| qf1_loss                | 13.636562   |\n",
      "| qf2_loss                | 14.962355   |\n",
      "| time_elapsed            | 19708       |\n",
      "| total timesteps         | 1618089     |\n",
      "| value_loss              | 20.31694    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028536223 |\n",
      "| ent_coef_loss           | 2.1669118   |\n",
      "| entropy                 | 14.326082   |\n",
      "| episodes                | 5200        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 4.36e+03    |\n",
      "| n_updates               | 1624792     |\n",
      "| policy_loss             | -429.1457   |\n",
      "| qf1_loss                | 15.3621855  |\n",
      "| qf2_loss                | 12.922678   |\n",
      "| time_elapsed            | 19780       |\n",
      "| total timesteps         | 1624891     |\n",
      "| value_loss              | 21.13757    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03022234 |\n",
      "| ent_coef_loss           | 7.232462   |\n",
      "| entropy                 | 13.993225  |\n",
      "| episodes                | 5210       |\n",
      "| fps                     | 82         |\n",
      "| mean 100 episode reward | 4.43e+03   |\n",
      "| n_updates               | 1633095    |\n",
      "| policy_loss             | -440.28934 |\n",
      "| qf1_loss                | 15.385001  |\n",
      "| qf2_loss                | 16.51794   |\n",
      "| time_elapsed            | 19869      |\n",
      "| total timesteps         | 1633194    |\n",
      "| value_loss              | 6.684456   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02793943 |\n",
      "| ent_coef_loss           | -3.0425763 |\n",
      "| entropy                 | 14.281975  |\n",
      "| episodes                | 5220       |\n",
      "| fps                     | 82         |\n",
      "| mean 100 episode reward | 4.25e+03   |\n",
      "| n_updates               | 1638874    |\n",
      "| policy_loss             | -431.43124 |\n",
      "| qf1_loss                | 6.030054   |\n",
      "| qf2_loss                | 15.032359  |\n",
      "| time_elapsed            | 19931      |\n",
      "| total timesteps         | 1638973    |\n",
      "| value_loss              | 11.195568  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028437505 |\n",
      "| ent_coef_loss           | 4.41158     |\n",
      "| entropy                 | 14.543958   |\n",
      "| episodes                | 5230        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 4.26e+03    |\n",
      "| n_updates               | 1645511     |\n",
      "| policy_loss             | -442.544    |\n",
      "| qf1_loss                | 19.019035   |\n",
      "| qf2_loss                | 54.390434   |\n",
      "| time_elapsed            | 20002       |\n",
      "| total timesteps         | 1645610     |\n",
      "| value_loss              | 23.705194   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028470298 |\n",
      "| ent_coef_loss           | 0.38507462  |\n",
      "| entropy                 | 14.941883   |\n",
      "| episodes                | 5240        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 4.18e+03    |\n",
      "| n_updates               | 1651271     |\n",
      "| policy_loss             | -437.38     |\n",
      "| qf1_loss                | 12.62315    |\n",
      "| qf2_loss                | 9.701993    |\n",
      "| time_elapsed            | 20063       |\n",
      "| total timesteps         | 1651370     |\n",
      "| value_loss              | 4.76409     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029036185 |\n",
      "| ent_coef_loss           | 3.8506784   |\n",
      "| entropy                 | 14.717987   |\n",
      "| episodes                | 5250        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 4.11e+03    |\n",
      "| n_updates               | 1656937     |\n",
      "| policy_loss             | -431.8553   |\n",
      "| qf1_loss                | 9.394657    |\n",
      "| qf2_loss                | 20.95409    |\n",
      "| time_elapsed            | 20123       |\n",
      "| total timesteps         | 1657036     |\n",
      "| value_loss              | 5.0079355   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.027322585 |\n",
      "| ent_coef_loss           | 9.422425    |\n",
      "| entropy                 | 13.355223   |\n",
      "| episodes                | 5260        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 4.07e+03    |\n",
      "| n_updates               | 1665283     |\n",
      "| policy_loss             | -421.4519   |\n",
      "| qf1_loss                | 8.137091    |\n",
      "| qf2_loss                | 15.678598   |\n",
      "| time_elapsed            | 20211       |\n",
      "| total timesteps         | 1665382     |\n",
      "| value_loss              | 9.288737    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028152412 |\n",
      "| ent_coef_loss           | -6.794527   |\n",
      "| entropy                 | 14.279665   |\n",
      "| episodes                | 5270        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 4e+03       |\n",
      "| n_updates               | 1673430     |\n",
      "| policy_loss             | -432.35165  |\n",
      "| qf1_loss                | 11.946665   |\n",
      "| qf2_loss                | 7.9017906   |\n",
      "| time_elapsed            | 20298       |\n",
      "| total timesteps         | 1673529     |\n",
      "| value_loss              | 8.249122    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.027855908 |\n",
      "| ent_coef_loss           | 9.666199    |\n",
      "| entropy                 | 13.751051   |\n",
      "| episodes                | 5280        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 3.86e+03    |\n",
      "| n_updates               | 1680050     |\n",
      "| policy_loss             | -417.6551   |\n",
      "| qf1_loss                | 11.557052   |\n",
      "| qf2_loss                | 23.009552   |\n",
      "| time_elapsed            | 20368       |\n",
      "| total timesteps         | 1680149     |\n",
      "| value_loss              | 21.974735   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.027753342 |\n",
      "| ent_coef_loss           | -3.477269   |\n",
      "| entropy                 | 14.266816   |\n",
      "| episodes                | 5290        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 3.86e+03    |\n",
      "| n_updates               | 1687935     |\n",
      "| policy_loss             | -432.45187  |\n",
      "| qf1_loss                | 11.663385   |\n",
      "| qf2_loss                | 25.817421   |\n",
      "| time_elapsed            | 20452       |\n",
      "| total timesteps         | 1688034     |\n",
      "| value_loss              | 8.901488    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.027218284 |\n",
      "| ent_coef_loss           | -12.695534  |\n",
      "| entropy                 | 14.531222   |\n",
      "| episodes                | 5300        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 3.95e+03    |\n",
      "| n_updates               | 1696388     |\n",
      "| policy_loss             | -442.1854   |\n",
      "| qf1_loss                | 39.010773   |\n",
      "| qf2_loss                | 37.700348   |\n",
      "| time_elapsed            | 20541       |\n",
      "| total timesteps         | 1696487     |\n",
      "| value_loss              | 10.010439   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.027425397 |\n",
      "| ent_coef_loss           | -3.522092   |\n",
      "| entropy                 | 14.715565   |\n",
      "| episodes                | 5310        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 3.89e+03    |\n",
      "| n_updates               | 1703649     |\n",
      "| policy_loss             | -419.81427  |\n",
      "| qf1_loss                | 18.584003   |\n",
      "| qf2_loss                | 15.464287   |\n",
      "| time_elapsed            | 20618       |\n",
      "| total timesteps         | 1703748     |\n",
      "| value_loss              | 7.7219276   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028719485 |\n",
      "| ent_coef_loss           | 4.491871    |\n",
      "| entropy                 | 14.895055   |\n",
      "| episodes                | 5320        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 3.84e+03    |\n",
      "| n_updates               | 1708712     |\n",
      "| policy_loss             | -429.49194  |\n",
      "| qf1_loss                | 40.51549    |\n",
      "| qf2_loss                | 16.647335   |\n",
      "| time_elapsed            | 20671       |\n",
      "| total timesteps         | 1708811     |\n",
      "| value_loss              | 9.501934    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029987907 |\n",
      "| ent_coef_loss           | -0.94289666 |\n",
      "| entropy                 | 14.423759   |\n",
      "| episodes                | 5330        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 3.84e+03    |\n",
      "| n_updates               | 1715251     |\n",
      "| policy_loss             | -439.30676  |\n",
      "| qf1_loss                | 11.228678   |\n",
      "| qf2_loss                | 12.767899   |\n",
      "| time_elapsed            | 20740       |\n",
      "| total timesteps         | 1715350     |\n",
      "| value_loss              | 3.6708817   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031042188 |\n",
      "| ent_coef_loss           | -1.7417643  |\n",
      "| entropy                 | 13.8299885  |\n",
      "| episodes                | 5340        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 3.76e+03    |\n",
      "| n_updates               | 1719784     |\n",
      "| policy_loss             | -420.516    |\n",
      "| qf1_loss                | 41.28412    |\n",
      "| qf2_loss                | 12.842125   |\n",
      "| time_elapsed            | 20789       |\n",
      "| total timesteps         | 1719883     |\n",
      "| value_loss              | 7.440008    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030456392 |\n",
      "| ent_coef_loss           | 7.4296513   |\n",
      "| entropy                 | 13.376277   |\n",
      "| episodes                | 5350        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 3.84e+03    |\n",
      "| n_updates               | 1727047     |\n",
      "| policy_loss             | -441.41824  |\n",
      "| qf1_loss                | 32.669914   |\n",
      "| qf2_loss                | 30.691265   |\n",
      "| time_elapsed            | 20866       |\n",
      "| total timesteps         | 1727146     |\n",
      "| value_loss              | 11.324757   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031069644 |\n",
      "| ent_coef_loss           | -7.999904   |\n",
      "| entropy                 | 14.075526   |\n",
      "| episodes                | 5360        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 3.62e+03    |\n",
      "| n_updates               | 1731351     |\n",
      "| policy_loss             | -437.6958   |\n",
      "| qf1_loss                | 692.12286   |\n",
      "| qf2_loss                | 585.5472    |\n",
      "| time_elapsed            | 20912       |\n",
      "| total timesteps         | 1731450     |\n",
      "| value_loss              | 19.124771   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03058573 |\n",
      "| ent_coef_loss           | 5.983846   |\n",
      "| entropy                 | 14.605041  |\n",
      "| episodes                | 5370       |\n",
      "| fps                     | 82         |\n",
      "| mean 100 episode reward | 3.65e+03   |\n",
      "| n_updates               | 1740049    |\n",
      "| policy_loss             | -429.3124  |\n",
      "| qf1_loss                | 15.6787815 |\n",
      "| qf2_loss                | 23.822819  |\n",
      "| time_elapsed            | 21008      |\n",
      "| total timesteps         | 1740148    |\n",
      "| value_loss              | 15.562279  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028879931 |\n",
      "| ent_coef_loss           | -2.9706044  |\n",
      "| entropy                 | 14.068977   |\n",
      "| episodes                | 5380        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 3.64e+03    |\n",
      "| n_updates               | 1746874     |\n",
      "| policy_loss             | -434.90973  |\n",
      "| qf1_loss                | 10.814505   |\n",
      "| qf2_loss                | 11.352846   |\n",
      "| time_elapsed            | 21089       |\n",
      "| total timesteps         | 1746973     |\n",
      "| value_loss              | 6.673716    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031185113 |\n",
      "| ent_coef_loss           | 4.209318    |\n",
      "| entropy                 | 14.542936   |\n",
      "| episodes                | 5390        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 3.61e+03    |\n",
      "| n_updates               | 1754325     |\n",
      "| policy_loss             | -413.54474  |\n",
      "| qf1_loss                | 18.529375   |\n",
      "| qf2_loss                | 21.071365   |\n",
      "| time_elapsed            | 21170       |\n",
      "| total timesteps         | 1754424     |\n",
      "| value_loss              | 19.512653   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03154698 |\n",
      "| ent_coef_loss           | 1.3215375  |\n",
      "| entropy                 | 14.085138  |\n",
      "| episodes                | 5400       |\n",
      "| fps                     | 82         |\n",
      "| mean 100 episode reward | 3.58e+03   |\n",
      "| n_updates               | 1762314    |\n",
      "| policy_loss             | -433.77612 |\n",
      "| qf1_loss                | 23.917633  |\n",
      "| qf2_loss                | 8.712568   |\n",
      "| time_elapsed            | 21254      |\n",
      "| total timesteps         | 1762413    |\n",
      "| value_loss              | 14.228395  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03164945 |\n",
      "| ent_coef_loss           | 7.3349843  |\n",
      "| entropy                 | 13.28759   |\n",
      "| episodes                | 5410       |\n",
      "| fps                     | 82         |\n",
      "| mean 100 episode reward | 3.66e+03   |\n",
      "| n_updates               | 1771157    |\n",
      "| policy_loss             | -429.00803 |\n",
      "| qf1_loss                | 13.114708  |\n",
      "| qf2_loss                | 16.532442  |\n",
      "| time_elapsed            | 21348      |\n",
      "| total timesteps         | 1771256    |\n",
      "| value_loss              | 15.664197  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028652295 |\n",
      "| ent_coef_loss           | -8.18576    |\n",
      "| entropy                 | 14.181464   |\n",
      "| episodes                | 5420        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.89e+03    |\n",
      "| n_updates               | 1780325     |\n",
      "| policy_loss             | -434.42188  |\n",
      "| qf1_loss                | 9.782009    |\n",
      "| qf2_loss                | 8.85445     |\n",
      "| time_elapsed            | 21445       |\n",
      "| total timesteps         | 1780424     |\n",
      "| value_loss              | 7.4326897   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028613793 |\n",
      "| ent_coef_loss           | -10.090923  |\n",
      "| entropy                 | 15.066849   |\n",
      "| episodes                | 5430        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.91e+03    |\n",
      "| n_updates               | 1787156     |\n",
      "| policy_loss             | -429.58423  |\n",
      "| qf1_loss                | 18.861523   |\n",
      "| qf2_loss                | 25.470991   |\n",
      "| time_elapsed            | 21517       |\n",
      "| total timesteps         | 1787255     |\n",
      "| value_loss              | 15.906436   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028113268 |\n",
      "| ent_coef_loss           | -11.499125  |\n",
      "| entropy                 | 15.18391    |\n",
      "| episodes                | 5440        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.97e+03    |\n",
      "| n_updates               | 1792879     |\n",
      "| policy_loss             | -442.67853  |\n",
      "| qf1_loss                | 6.723777    |\n",
      "| qf2_loss                | 5.531251    |\n",
      "| time_elapsed            | 21577       |\n",
      "| total timesteps         | 1792978     |\n",
      "| value_loss              | 3.072418    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030488817 |\n",
      "| ent_coef_loss           | -7.155197   |\n",
      "| entropy                 | 14.536329   |\n",
      "| episodes                | 5450        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.96e+03    |\n",
      "| n_updates               | 1800019     |\n",
      "| policy_loss             | -442.13687  |\n",
      "| qf1_loss                | 6.7421293   |\n",
      "| qf2_loss                | 15.982632   |\n",
      "| time_elapsed            | 21652       |\n",
      "| total timesteps         | 1800118     |\n",
      "| value_loss              | 12.982727   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029562375 |\n",
      "| ent_coef_loss           | -8.325622   |\n",
      "| entropy                 | 14.843882   |\n",
      "| episodes                | 5460        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 4.13e+03    |\n",
      "| n_updates               | 1807358     |\n",
      "| policy_loss             | -426.10474  |\n",
      "| qf1_loss                | 20.069084   |\n",
      "| qf2_loss                | 41.152805   |\n",
      "| time_elapsed            | 21729       |\n",
      "| total timesteps         | 1807457     |\n",
      "| value_loss              | 20.710087   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029370407 |\n",
      "| ent_coef_loss           | -0.60967827 |\n",
      "| entropy                 | 14.126799   |\n",
      "| episodes                | 5470        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.94e+03    |\n",
      "| n_updates               | 1812632     |\n",
      "| policy_loss             | -425.5194   |\n",
      "| qf1_loss                | 16.695164   |\n",
      "| qf2_loss                | 14.571318   |\n",
      "| time_elapsed            | 21784       |\n",
      "| total timesteps         | 1812731     |\n",
      "| value_loss              | 23.012783   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030695682 |\n",
      "| ent_coef_loss           | -0.45108318 |\n",
      "| entropy                 | 14.259212   |\n",
      "| episodes                | 5480        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.99e+03    |\n",
      "| n_updates               | 1820254     |\n",
      "| policy_loss             | -420.1197   |\n",
      "| qf1_loss                | 19.196781   |\n",
      "| qf2_loss                | 21.874556   |\n",
      "| time_elapsed            | 21864       |\n",
      "| total timesteps         | 1820353     |\n",
      "| value_loss              | 13.518612   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029180147 |\n",
      "| ent_coef_loss           | 2.1445749   |\n",
      "| entropy                 | 14.110508   |\n",
      "| episodes                | 5490        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 4.05e+03    |\n",
      "| n_updates               | 1828597     |\n",
      "| policy_loss             | -428.44223  |\n",
      "| qf1_loss                | 21.325165   |\n",
      "| qf2_loss                | 39.37571    |\n",
      "| time_elapsed            | 21952       |\n",
      "| total timesteps         | 1828696     |\n",
      "| value_loss              | 9.680168    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.027629368 |\n",
      "| ent_coef_loss           | -7.2829843  |\n",
      "| entropy                 | 13.940953   |\n",
      "| episodes                | 5500        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 4.09e+03    |\n",
      "| n_updates               | 1837269     |\n",
      "| policy_loss             | -428.14545  |\n",
      "| qf1_loss                | 33.593903   |\n",
      "| qf2_loss                | 21.794367   |\n",
      "| time_elapsed            | 22043       |\n",
      "| total timesteps         | 1837368     |\n",
      "| value_loss              | 9.649459    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030496495 |\n",
      "| ent_coef_loss           | 4.18402     |\n",
      "| entropy                 | 13.55598    |\n",
      "| episodes                | 5510        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 4.01e+03    |\n",
      "| n_updates               | 1844450     |\n",
      "| policy_loss             | -423.1313   |\n",
      "| qf1_loss                | 25.34929    |\n",
      "| qf2_loss                | 10.255416   |\n",
      "| time_elapsed            | 22119       |\n",
      "| total timesteps         | 1844549     |\n",
      "| value_loss              | 14.875849   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028803514 |\n",
      "| ent_coef_loss           | -7.855604   |\n",
      "| entropy                 | 14.273399   |\n",
      "| episodes                | 5520        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.95e+03    |\n",
      "| n_updates               | 1852347     |\n",
      "| policy_loss             | -429.52475  |\n",
      "| qf1_loss                | 19.6839     |\n",
      "| qf2_loss                | 10.089951   |\n",
      "| time_elapsed            | 22201       |\n",
      "| total timesteps         | 1852446     |\n",
      "| value_loss              | 12.083624   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029815149 |\n",
      "| ent_coef_loss           | -1.9189128  |\n",
      "| entropy                 | 14.302855   |\n",
      "| episodes                | 5530        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 4.04e+03    |\n",
      "| n_updates               | 1860823     |\n",
      "| policy_loss             | -424.88702  |\n",
      "| qf1_loss                | 40.043716   |\n",
      "| qf2_loss                | 35.19978    |\n",
      "| time_elapsed            | 22291       |\n",
      "| total timesteps         | 1860922     |\n",
      "| value_loss              | 22.743408   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.027763858 |\n",
      "| ent_coef_loss           | -3.9171305  |\n",
      "| entropy                 | 14.449324   |\n",
      "| episodes                | 5540        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 4.15e+03    |\n",
      "| n_updates               | 1868405     |\n",
      "| policy_loss             | -440.7514   |\n",
      "| qf1_loss                | 24.07923    |\n",
      "| qf2_loss                | 18.129671   |\n",
      "| time_elapsed            | 22370       |\n",
      "| total timesteps         | 1868504     |\n",
      "| value_loss              | 7.2116885   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029528625 |\n",
      "| ent_coef_loss           | -4.419806   |\n",
      "| entropy                 | 15.225439   |\n",
      "| episodes                | 5550        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 4.18e+03    |\n",
      "| n_updates               | 1875897     |\n",
      "| policy_loss             | -442.1637   |\n",
      "| qf1_loss                | 28.60773    |\n",
      "| qf2_loss                | 19.513805   |\n",
      "| time_elapsed            | 22449       |\n",
      "| total timesteps         | 1875996     |\n",
      "| value_loss              | 10.548169   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028221503 |\n",
      "| ent_coef_loss           | -10.916938  |\n",
      "| entropy                 | 14.177142   |\n",
      "| episodes                | 5560        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 4.14e+03    |\n",
      "| n_updates               | 1882467     |\n",
      "| policy_loss             | -442.74176  |\n",
      "| qf1_loss                | 13.910986   |\n",
      "| qf2_loss                | 17.798193   |\n",
      "| time_elapsed            | 22517       |\n",
      "| total timesteps         | 1882566     |\n",
      "| value_loss              | 17.756752   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02603171 |\n",
      "| ent_coef_loss           | -9.503414  |\n",
      "| entropy                 | 14.080562  |\n",
      "| episodes                | 5570       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 4.26e+03   |\n",
      "| n_updates               | 1889819    |\n",
      "| policy_loss             | -428.90692 |\n",
      "| qf1_loss                | 7.6489177  |\n",
      "| qf2_loss                | 7.8969893  |\n",
      "| time_elapsed            | 22594      |\n",
      "| total timesteps         | 1889918    |\n",
      "| value_loss              | 6.668939   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028879944 |\n",
      "| ent_coef_loss           | -0.22504735 |\n",
      "| entropy                 | 14.221369   |\n",
      "| episodes                | 5580        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 4.3e+03     |\n",
      "| n_updates               | 1898027     |\n",
      "| policy_loss             | -410.7528   |\n",
      "| qf1_loss                | 19.73468    |\n",
      "| qf2_loss                | 27.026783   |\n",
      "| time_elapsed            | 22680       |\n",
      "| total timesteps         | 1898126     |\n",
      "| value_loss              | 20.465288   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.033500884 |\n",
      "| ent_coef_loss           | -0.89444923 |\n",
      "| entropy                 | 14.575241   |\n",
      "| episodes                | 5590        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 4.37e+03    |\n",
      "| n_updates               | 1907462     |\n",
      "| policy_loss             | -420.22186  |\n",
      "| qf1_loss                | 13.195826   |\n",
      "| qf2_loss                | 13.10508    |\n",
      "| time_elapsed            | 22779       |\n",
      "| total timesteps         | 1907561     |\n",
      "| value_loss              | 9.700703    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02894218 |\n",
      "| ent_coef_loss           | -2.8412938 |\n",
      "| entropy                 | 15.157005  |\n",
      "| episodes                | 5600       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 4.37e+03   |\n",
      "| n_updates               | 1916039    |\n",
      "| policy_loss             | -436.90063 |\n",
      "| qf1_loss                | 15.057048  |\n",
      "| qf2_loss                | 10.85241   |\n",
      "| time_elapsed            | 22869      |\n",
      "| total timesteps         | 1916138    |\n",
      "| value_loss              | 7.080185   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031102566 |\n",
      "| ent_coef_loss           | 0.67548156  |\n",
      "| entropy                 | 14.139357   |\n",
      "| episodes                | 5610        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 4.44e+03    |\n",
      "| n_updates               | 1924708     |\n",
      "| policy_loss             | -429.21298  |\n",
      "| qf1_loss                | 26.468697   |\n",
      "| qf2_loss                | 17.65601    |\n",
      "| time_elapsed            | 22960       |\n",
      "| total timesteps         | 1924807     |\n",
      "| value_loss              | 17.503347   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028990516 |\n",
      "| ent_coef_loss           | -7.431856   |\n",
      "| entropy                 | 13.188656   |\n",
      "| episodes                | 5620        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 4.53e+03    |\n",
      "| n_updates               | 1934156     |\n",
      "| policy_loss             | -441.12164  |\n",
      "| qf1_loss                | 9.5643835   |\n",
      "| qf2_loss                | 25.313332   |\n",
      "| time_elapsed            | 23059       |\n",
      "| total timesteps         | 1934255     |\n",
      "| value_loss              | 9.598647    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02880492 |\n",
      "| ent_coef_loss           | 5.2177224  |\n",
      "| entropy                 | 13.771379  |\n",
      "| episodes                | 5630       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 4.45e+03   |\n",
      "| n_updates               | 1941060    |\n",
      "| policy_loss             | -422.13687 |\n",
      "| qf1_loss                | 38.41042   |\n",
      "| qf2_loss                | 47.033062  |\n",
      "| time_elapsed            | 23131      |\n",
      "| total timesteps         | 1941159    |\n",
      "| value_loss              | 26.353107  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028711453 |\n",
      "| ent_coef_loss           | -1.2713827  |\n",
      "| entropy                 | 14.925286   |\n",
      "| episodes                | 5640        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 4.47e+03    |\n",
      "| n_updates               | 1948985     |\n",
      "| policy_loss             | -432.74332  |\n",
      "| qf1_loss                | 11.217673   |\n",
      "| qf2_loss                | 8.852245    |\n",
      "| time_elapsed            | 23221       |\n",
      "| total timesteps         | 1949084     |\n",
      "| value_loss              | 15.504994   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02762309 |\n",
      "| ent_coef_loss           | 5.850043   |\n",
      "| entropy                 | 13.584929  |\n",
      "| episodes                | 5650       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 4.47e+03   |\n",
      "| n_updates               | 1956486    |\n",
      "| policy_loss             | -423.26508 |\n",
      "| qf1_loss                | 47.181435  |\n",
      "| qf2_loss                | 64.13574   |\n",
      "| time_elapsed            | 23302      |\n",
      "| total timesteps         | 1956585    |\n",
      "| value_loss              | 48.16774   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028777286 |\n",
      "| ent_coef_loss           | 0.32543445  |\n",
      "| entropy                 | 15.33695    |\n",
      "| episodes                | 5660        |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 4.59e+03    |\n",
      "| n_updates               | 1965112     |\n",
      "| policy_loss             | -416.77814  |\n",
      "| qf1_loss                | 17.94247    |\n",
      "| qf2_loss                | 12.484608   |\n",
      "| time_elapsed            | 23393       |\n",
      "| total timesteps         | 1965211     |\n",
      "| value_loss              | 9.431281    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029129695 |\n",
      "| ent_coef_loss           | 4.8580723   |\n",
      "| entropy                 | 14.034903   |\n",
      "| episodes                | 5670        |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 4.61e+03    |\n",
      "| n_updates               | 1972674     |\n",
      "| policy_loss             | -414.8836   |\n",
      "| qf1_loss                | 23.737051   |\n",
      "| qf2_loss                | 22.238724   |\n",
      "| time_elapsed            | 23473       |\n",
      "| total timesteps         | 1972773     |\n",
      "| value_loss              | 19.35762    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030003497 |\n",
      "| ent_coef_loss           | 2.3435738   |\n",
      "| entropy                 | 14.388626   |\n",
      "| episodes                | 5680        |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 4.65e+03    |\n",
      "| n_updates               | 1981671     |\n",
      "| policy_loss             | -434.27258  |\n",
      "| qf1_loss                | 15.241843   |\n",
      "| qf2_loss                | 11.215733   |\n",
      "| time_elapsed            | 23568       |\n",
      "| total timesteps         | 1981770     |\n",
      "| value_loss              | 26.884335   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03015129 |\n",
      "| ent_coef_loss           | 2.9091327  |\n",
      "| entropy                 | 13.506798  |\n",
      "| episodes                | 5690       |\n",
      "| fps                     | 84         |\n",
      "| mean 100 episode reward | 4.49e+03   |\n",
      "| n_updates               | 1988143    |\n",
      "| policy_loss             | -412.13266 |\n",
      "| qf1_loss                | 48.854237  |\n",
      "| qf2_loss                | 26.085539  |\n",
      "| time_elapsed            | 23636      |\n",
      "| total timesteps         | 1988242    |\n",
      "| value_loss              | 9.660484   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.026770646 |\n",
      "| ent_coef_loss           | -2.968498   |\n",
      "| entropy                 | 14.392847   |\n",
      "| episodes                | 5700        |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 4.48e+03    |\n",
      "| n_updates               | 1996352     |\n",
      "| policy_loss             | -435.9751   |\n",
      "| qf1_loss                | 30.240345   |\n",
      "| qf2_loss                | 50.42679    |\n",
      "| time_elapsed            | 23723       |\n",
      "| total timesteps         | 1996451     |\n",
      "| value_loss              | 24.18204    |\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# TRAIN THE MODEL\n",
    "model.learn(total_timesteps=int(10e6), log_interval=10)\n",
    "model.save(\"humanoid_10M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading a model without an environment, this model cannot be trained until it has a valid environment.\n",
      "WARNING:tensorflow:From /home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:191: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:200: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/stable_baselines/sac/sac.py:142: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/stable_baselines/common/input.py:25: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/stable_baselines/sac/policies.py:194: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2d6dce4f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2d6dce4f10>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2d6dce4f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2d6dce4f10>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:From /home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/stable_baselines/common/tf_layers.py:57: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From /home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d7417bb90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d7417bb90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d7417bb90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d7417bb90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6dd05090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6dd05090>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6dd05090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6dd05090>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6dce4f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6dce4f10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6dce4f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6dce4f10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6dce4f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6dce4f10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6dce4f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6dce4f10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From /home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/stable_baselines/sac/policies.py:216: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2d6c26f610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2d6c26f610>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2d6c26f610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2d6c26f610>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6c1ff990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6c1ff990>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6c1ff990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6c1ff990>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6c1ff810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6c1ff810>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6c1ff810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6c1ff810>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6c247410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6c247410>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6c247410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6c247410>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6c255290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6c255290>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6c255290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6c255290>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6c253510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6c253510>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6c253510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6c253510>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d911a0250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d911a0250>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d911a0250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d911a0250>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6c253190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6c253190>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6c253190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6c253190>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6debef10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6debef10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6debef10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6debef10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6c10a610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6c10a610>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6c10a610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6c10a610>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2d6c2c9d50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2d6c2c9d50>>: AttributeError: module 'gast' has no attribute 'Num'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2d6c2c9d50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2d6c2c9d50>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d7407ba50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d7407ba50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d7407ba50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d7407ba50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d7407ba50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d7407ba50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d7407ba50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d7407ba50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6debef10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6debef10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6debef10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6debef10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6dd05f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6dd05f10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6dd05f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6dd05f10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6dd05f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6dd05f10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6dd05f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6dd05f10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6dd05f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6dd05f10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6dd05f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6dd05f10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2d911a0250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2d911a0250>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2d911a0250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2d911a0250>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d911a00d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d911a00d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d911a00d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d911a00d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6c2bb710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6c2bb710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6c2bb710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6c2bb710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6dd05710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6dd05710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6dd05710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6dd05710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From /home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/stable_baselines/sac/sac.py:233: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/stable_baselines/sac/sac.py:296: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/stable_baselines/sac/sac.py:316: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "Creating window glfw\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3339: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# RUN THE SAVED MODEL\n",
    "env = gym.make('Humanoid-v2')\n",
    "model = SAC.load(\"humanoid_2M\")\n",
    "\n",
    "for _ in range(10):\n",
    "    obs = env.reset()\n",
    "    for _ in range(1000):\n",
    "        action, _states = model.predict(obs)\n",
    "        obs, rewards, dones, info = env.step(action)\n",
    "        env.render()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800\"\n",
       "            src=\"http://localhost:6006\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fca7455a310>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# DISPLAY THE RESULTS\n",
    "%tensorboard --logdir sac_humanoid_walk_tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task: Stand up from a flat beginning position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:191: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:200: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/stable_baselines/sac/sac.py:142: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/stable_baselines/common/input.py:25: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/stable_baselines/sac/policies.py:194: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f4bd9fb9c90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f4bd9fb9c90>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f4bd9fb9c90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f4bd9fb9c90>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:From /home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/stable_baselines/common/tf_layers.py:57: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From /home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4bd9e65cd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4bd9e65cd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4bd9e65cd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4bd9e65cd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4be56f0490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4be56f0490>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4be56f0490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4be56f0490>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4be5340410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4be5340410>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4be5340410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4be5340410>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4be56f0490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4be56f0490>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4be56f0490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4be56f0490>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From /home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/stable_baselines/sac/policies.py:216: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f4bd843a4d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f4bd843a4d0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f4bd843a4d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f4bd843a4d0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4bd8366390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4bd8366390>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4bd8366390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4bd8366390>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4bd837e450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4bd837e450>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4bd837e450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4bd837e450>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4bd841c4d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4bd841c4d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4bd841c4d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4bd841c4d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4bd8366f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4bd8366f50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4bd8366f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4bd8366f50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4bd8366f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4bd8366f50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4bd8366f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4bd8366f50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4bd834fed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4bd834fed0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4bd834fed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4bd834fed0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4c066f1e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4c066f1e50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4c066f1e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4c066f1e50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4bd8365c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4bd8365c50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4bd8365c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4bd8365c50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4bd8365c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4bd8365c50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4bd8365c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4bd8365c50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f4be56f00d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f4be56f00d0>>: AttributeError: module 'gast' has no attribute 'Num'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f4be56f00d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f4be56f00d0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4bd83a8250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4bd83a8250>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4bd83a8250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4bd83a8250>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4bd83c5b10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4bd83c5b10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4bd83c5b10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4bd83c5b10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4be56f00d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4be56f00d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4be56f00d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4be56f00d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4c066f1e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4c066f1e50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4c066f1e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4c066f1e50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4bd82c2a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4bd82c2a90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4bd82c2a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4bd82c2a90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4bd842a350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4bd842a350>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4bd842a350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4bd842a350>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f4bd841cdd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f4bd841cdd0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f4bd841cdd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f4bd841cdd0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4bd83a8250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4bd83a8250>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4bd83a8250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4bd83a8250>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4bd83a8250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4bd83a8250>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4bd83a8250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4bd83a8250>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4bd83a8290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4bd83a8290>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4bd83a8290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f4bd83a8290>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From /home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/stable_baselines/sac/sac.py:233: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/stable_baselines/sac/sac.py:296: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/stable_baselines/sac/sac.py:316: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "Observation Space Dimensions: 376\n",
      "Action Space Dimensions: 17\n"
     ]
    }
   ],
   "source": [
    "# DEFINE THE ENVIRONMENT/MODEL WITH TUNED PARAMETERS\n",
    "env = gym.make('HumanoidStandup-v2')\n",
    "policy_kwargs = dict(layers=[256, 256])\n",
    "model = SAC(MlpPolicy, env, verbose=1, tensorboard_log=\"./sac_humanoid_standup_tensorboard/\", \n",
    "            policy_kwargs=policy_kwargs, buffer_size=1000000)\n",
    "# PRINT THE STATE SPACE DIMENSIONS\n",
    "obs_dim = env.observation_space.shape[0]\n",
    "act_dim = env.action_space.shape[0]\n",
    "print('Observation Space Dimensions: %d' % obs_dim)\n",
    "print('Action Space Dimensions: %d' % act_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/stable_baselines/common/base_class.py:1143: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TRAIN THE MODEL\n",
    "model.learn(total_timesteps=int(10e6), log_interval=10)\n",
    "model.save(\"humanoid_standup_10M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gym' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ecd16610c515>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# RUN THE SAVED MODEL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'HumanoidStandup-v2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSAC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"humanoid_standup_2M\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gym' is not defined"
     ]
    }
   ],
   "source": [
    "# RUN THE SAVED MODEL\n",
    "env = gym.make('HumanoidStandup-v2')\n",
    "model = SAC.load(\"humanoid_standup_2M\")\n",
    "\n",
    "for _ in range(10):\n",
    "    obs = env.reset()\n",
    "    for _ in range(1000):\n",
    "        action, _states = model.predict(obs)\n",
    "        obs, rewards, dones, info = env.step(action)\n",
    "        env.render()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800\"\n",
       "            src=\"http://localhost:6007\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f4be56f0cd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# DISPLAY THE RESULTS\n",
    "%tensorboard --logdir sac_humanoid_standup_tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task: Teach a 'half-cheetah' a gait to run forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f94947921d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f94947921d0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f94947921d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f94947921d0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f955c6c7d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f955c6c7d90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f955c6c7d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f955c6c7d90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9518407a10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9518407a10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9518407a10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9518407a10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f94947921d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f94947921d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f94947921d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f94947921d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f94947921d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f94947921d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f94947921d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f94947921d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f9518327890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f9518327890>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f9518327890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f9518327890>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9492dbd350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9492dbd350>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9492dbd350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9492dbd350>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9492e3d0d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9492e3d0d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9492e3d0d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9492e3d0d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9492e40f90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9492e40f90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9492e40f90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9492e40f90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9492e451d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9492e451d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9492e451d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9492e451d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f95482feb90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f95482feb90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f95482feb90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f95482feb90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9492dc4f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9492dc4f10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9492dc4f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9492dc4f10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9492dd1750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9492dd1750>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9492dd1750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9492dd1750>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9492dd1750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9492dd1750>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9492dd1750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9492dd1750>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9492e12090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9492e12090>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9492e12090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9492e12090>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f95482feb90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f95482feb90>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f95482feb90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f95482feb90>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9492c944d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9492c944d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9492c944d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9492c944d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9492dd1350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9492dd1350>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9492dd1350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9492dd1350>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f95482feb90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f95482feb90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f95482feb90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f95482feb90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9492e46590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9492e46590>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9492e46590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9492e46590>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f94946bcdd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f94946bcdd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f94946bcdd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f94946bcdd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f94946bcdd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f94946bcdd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f94946bcdd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f94946bcdd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f9492d491d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f9492d491d0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f9492d491d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f9492d491d0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9492deba50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9492deba50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9492deba50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9492deba50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9492deba50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9492deba50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9492deba50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9492deba50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9492debd50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9492debd50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9492debd50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9492debd50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "Observation Space Dimensions: 17\n",
      "Action Space Dimensions: 6\n"
     ]
    }
   ],
   "source": [
    "# DEFINE THE ENVIRONMENT/MODEL WITH TUNED PARAMETERS\n",
    "env = gym.make('HalfCheetah-v2')\n",
    "policy_kwargs = dict(layers=[256, 256])\n",
    "model = SAC(MlpPolicy, env, verbose=1, tensorboard_log=\"./sac_half_cheetah_tensorboard/\", \n",
    "            policy_kwargs=policy_kwargs, buffer_size=1000000)\n",
    "# PRINT THE STATE SPACE DIMENSIONS\n",
    "obs_dim = env.observation_space.shape[0]\n",
    "act_dim = env.action_space.shape[0]\n",
    "print('Observation Space Dimensions: %d' % obs_dim)\n",
    "print('Action Space Dimensions: %d' % act_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.07604485 |\n",
      "| ent_coef_loss           | -17.330658 |\n",
      "| entropy                 | 7.4793625  |\n",
      "| episodes                | 10         |\n",
      "| fps                     | 196        |\n",
      "| mean 100 episode reward | -192       |\n",
      "| n_updates               | 8901       |\n",
      "| policy_loss             | -24.193245 |\n",
      "| qf1_loss                | 0.49310136 |\n",
      "| qf2_loss                | 0.7207223  |\n",
      "| time_elapsed            | 45         |\n",
      "| total timesteps         | 9000       |\n",
      "| value_loss              | 0.37060744 |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.010569485 |\n",
      "| ent_coef_loss           | 0.12154424  |\n",
      "| entropy                 | 4.651023    |\n",
      "| episodes                | 20          |\n",
      "| fps                     | 183         |\n",
      "| mean 100 episode reward | -168        |\n",
      "| n_updates               | 18901       |\n",
      "| policy_loss             | -6.285787   |\n",
      "| qf1_loss                | 0.47626278  |\n",
      "| qf2_loss                | 0.52359134  |\n",
      "| time_elapsed            | 103         |\n",
      "| total timesteps         | 19000       |\n",
      "| value_loss              | 0.12141873  |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02521978 |\n",
      "| ent_coef_loss           | 1.2039753  |\n",
      "| entropy                 | 4.6397448  |\n",
      "| episodes                | 30         |\n",
      "| fps                     | 183        |\n",
      "| mean 100 episode reward | 143        |\n",
      "| n_updates               | 28901      |\n",
      "| policy_loss             | -13.110348 |\n",
      "| qf1_loss                | 0.91650474 |\n",
      "| qf2_loss                | 0.90800196 |\n",
      "| time_elapsed            | 158        |\n",
      "| total timesteps         | 29000      |\n",
      "| value_loss              | 0.49361306 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.04435201 |\n",
      "| ent_coef_loss           | -2.728519  |\n",
      "| entropy                 | 5.4455323  |\n",
      "| episodes                | 40         |\n",
      "| fps                     | 186        |\n",
      "| mean 100 episode reward | 441        |\n",
      "| n_updates               | 38901      |\n",
      "| policy_loss             | -29.135437 |\n",
      "| qf1_loss                | 1.5437018  |\n",
      "| qf2_loss                | 1.9790475  |\n",
      "| time_elapsed            | 208        |\n",
      "| total timesteps         | 39000      |\n",
      "| value_loss              | 1.8723438  |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ent_coef                | 0.0680353 |\n",
      "| ent_coef_loss           | 1.186713  |\n",
      "| entropy                 | 5.041701  |\n",
      "| episodes                | 50        |\n",
      "| fps                     | 185       |\n",
      "| mean 100 episode reward | 778       |\n",
      "| n_updates               | 48901     |\n",
      "| policy_loss             | -57.79456 |\n",
      "| qf1_loss                | 2.6525207 |\n",
      "| qf2_loss                | 2.281654  |\n",
      "| time_elapsed            | 264       |\n",
      "| total timesteps         | 49000     |\n",
      "| value_loss              | 1.3258784 |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.076530226 |\n",
      "| ent_coef_loss           | -1.4942763  |\n",
      "| entropy                 | 5.1869507   |\n",
      "| episodes                | 60          |\n",
      "| fps                     | 187         |\n",
      "| mean 100 episode reward | 1.01e+03    |\n",
      "| n_updates               | 58901       |\n",
      "| policy_loss             | -74.43796   |\n",
      "| qf1_loss                | 4.1544385   |\n",
      "| qf2_loss                | 3.152964    |\n",
      "| time_elapsed            | 313         |\n",
      "| total timesteps         | 59000       |\n",
      "| value_loss              | 1.8476791   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.102349125 |\n",
      "| ent_coef_loss           | -0.8047238  |\n",
      "| entropy                 | 5.2593126   |\n",
      "| episodes                | 70          |\n",
      "| fps                     | 189         |\n",
      "| mean 100 episode reward | 1.28e+03    |\n",
      "| n_updates               | 68901       |\n",
      "| policy_loss             | -97.220505  |\n",
      "| qf1_loss                | 3.8024335   |\n",
      "| qf2_loss                | 3.6682158   |\n",
      "| time_elapsed            | 363         |\n",
      "| total timesteps         | 69000       |\n",
      "| value_loss              | 2.2382274   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.110267594 |\n",
      "| ent_coef_loss           | 1.2460335   |\n",
      "| entropy                 | 5.21364     |\n",
      "| episodes                | 80          |\n",
      "| fps                     | 192         |\n",
      "| mean 100 episode reward | 1.51e+03    |\n",
      "| n_updates               | 78901       |\n",
      "| policy_loss             | -107.32027  |\n",
      "| qf1_loss                | 7.0504355   |\n",
      "| qf2_loss                | 4.9475446   |\n",
      "| time_elapsed            | 411         |\n",
      "| total timesteps         | 79000       |\n",
      "| value_loss              | 2.1582427   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.12546492  |\n",
      "| ent_coef_loss           | 0.02811253  |\n",
      "| entropy                 | 5.0770965   |\n",
      "| episodes                | 90          |\n",
      "| fps                     | 192         |\n",
      "| mean 100 episode reward | 1.69e+03    |\n",
      "| n_updates               | 88901       |\n",
      "| policy_loss             | -120.455284 |\n",
      "| qf1_loss                | 2.4399855   |\n",
      "| qf2_loss                | 3.4382033   |\n",
      "| time_elapsed            | 462         |\n",
      "| total timesteps         | 89000       |\n",
      "| value_loss              | 2.7894592   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.13840649 |\n",
      "| ent_coef_loss           | 1.0429379  |\n",
      "| entropy                 | 5.0673523  |\n",
      "| episodes                | 100        |\n",
      "| fps                     | 193        |\n",
      "| mean 100 episode reward | 1.86e+03   |\n",
      "| n_updates               | 98901      |\n",
      "| policy_loss             | -145.54842 |\n",
      "| qf1_loss                | 8.436375   |\n",
      "| qf2_loss                | 7.2447453  |\n",
      "| time_elapsed            | 512        |\n",
      "| total timesteps         | 99000      |\n",
      "| value_loss              | 5.8566113  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.14928949 |\n",
      "| ent_coef_loss           | 0.44710743 |\n",
      "| entropy                 | 4.9845157  |\n",
      "| episodes                | 110        |\n",
      "| fps                     | 194        |\n",
      "| mean 100 episode reward | 2.21e+03   |\n",
      "| n_updates               | 108901     |\n",
      "| policy_loss             | -148.65337 |\n",
      "| qf1_loss                | 117.89044  |\n",
      "| qf2_loss                | 113.65039  |\n",
      "| time_elapsed            | 561        |\n",
      "| total timesteps         | 109000     |\n",
      "| value_loss              | 3.665557   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.1532456  |\n",
      "| ent_coef_loss           | 0.94031817 |\n",
      "| entropy                 | 4.9719415  |\n",
      "| episodes                | 120        |\n",
      "| fps                     | 195        |\n",
      "| mean 100 episode reward | 2.58e+03   |\n",
      "| n_updates               | 118901     |\n",
      "| policy_loss             | -159.71695 |\n",
      "| qf1_loss                | 4.966581   |\n",
      "| qf2_loss                | 3.9862785  |\n",
      "| time_elapsed            | 609        |\n",
      "| total timesteps         | 119000     |\n",
      "| value_loss              | 3.79738    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.1644368  |\n",
      "| ent_coef_loss           | -1.4052402 |\n",
      "| entropy                 | 5.0044127  |\n",
      "| episodes                | 130        |\n",
      "| fps                     | 196        |\n",
      "| mean 100 episode reward | 2.87e+03   |\n",
      "| n_updates               | 128901     |\n",
      "| policy_loss             | -152.8081  |\n",
      "| qf1_loss                | 4.419156   |\n",
      "| qf2_loss                | 3.334353   |\n",
      "| time_elapsed            | 657        |\n",
      "| total timesteps         | 129000     |\n",
      "| value_loss              | 3.2231872  |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.15630016  |\n",
      "| ent_coef_loss           | -0.08721347 |\n",
      "| entropy                 | 5.106106    |\n",
      "| episodes                | 140         |\n",
      "| fps                     | 196         |\n",
      "| mean 100 episode reward | 3.11e+03    |\n",
      "| n_updates               | 138901      |\n",
      "| policy_loss             | -166.79294  |\n",
      "| qf1_loss                | 5.0205317   |\n",
      "| qf2_loss                | 4.5641537   |\n",
      "| time_elapsed            | 705         |\n",
      "| total timesteps         | 139000      |\n",
      "| value_loss              | 3.1297626   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.16591519  |\n",
      "| ent_coef_loss           | -0.68797415 |\n",
      "| entropy                 | 4.9799533   |\n",
      "| episodes                | 150         |\n",
      "| fps                     | 197         |\n",
      "| mean 100 episode reward | 3.28e+03    |\n",
      "| n_updates               | 148901      |\n",
      "| policy_loss             | -160.01294  |\n",
      "| qf1_loss                | 8.068743    |\n",
      "| qf2_loss                | 6.9991055   |\n",
      "| time_elapsed            | 753         |\n",
      "| total timesteps         | 149000      |\n",
      "| value_loss              | 14.16021    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.16676988  |\n",
      "| ent_coef_loss           | 0.082225844 |\n",
      "| entropy                 | 4.8609443   |\n",
      "| episodes                | 160         |\n",
      "| fps                     | 198         |\n",
      "| mean 100 episode reward | 3.42e+03    |\n",
      "| n_updates               | 158901      |\n",
      "| policy_loss             | -178.53511  |\n",
      "| qf1_loss                | 8.071827    |\n",
      "| qf2_loss                | 6.492406    |\n",
      "| time_elapsed            | 801         |\n",
      "| total timesteps         | 159000      |\n",
      "| value_loss              | 2.4069273   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.17225812 |\n",
      "| ent_coef_loss           | 1.1493611  |\n",
      "| entropy                 | 4.849187   |\n",
      "| episodes                | 170        |\n",
      "| fps                     | 199        |\n",
      "| mean 100 episode reward | 3.53e+03   |\n",
      "| n_updates               | 168901     |\n",
      "| policy_loss             | -179.24106 |\n",
      "| qf1_loss                | 2.4126034  |\n",
      "| qf2_loss                | 2.672649   |\n",
      "| time_elapsed            | 849        |\n",
      "| total timesteps         | 169000     |\n",
      "| value_loss              | 2.267363   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ent_coef                | 0.1719036 |\n",
      "| ent_coef_loss           | 0.3925795 |\n",
      "| entropy                 | 4.7327538 |\n",
      "| episodes                | 180       |\n",
      "| fps                     | 199       |\n",
      "| mean 100 episode reward | 3.59e+03  |\n",
      "| n_updates               | 178901    |\n",
      "| policy_loss             | -184.354  |\n",
      "| qf1_loss                | 9.81619   |\n",
      "| qf2_loss                | 9.857769  |\n",
      "| time_elapsed            | 896       |\n",
      "| total timesteps         | 179000    |\n",
      "| value_loss              | 3.556945  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.17481081 |\n",
      "| ent_coef_loss           | 0.37606016 |\n",
      "| entropy                 | 4.787038   |\n",
      "| episodes                | 190        |\n",
      "| fps                     | 200        |\n",
      "| mean 100 episode reward | 3.67e+03   |\n",
      "| n_updates               | 188901     |\n",
      "| policy_loss             | -190.87372 |\n",
      "| qf1_loss                | 6.564097   |\n",
      "| qf2_loss                | 9.447419   |\n",
      "| time_elapsed            | 944        |\n",
      "| total timesteps         | 189000     |\n",
      "| value_loss              | 2.629815   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.17873387 |\n",
      "| ent_coef_loss           | 0.34456095 |\n",
      "| entropy                 | 4.815675   |\n",
      "| episodes                | 200        |\n",
      "| fps                     | 200        |\n",
      "| mean 100 episode reward | 3.73e+03   |\n",
      "| n_updates               | 198901     |\n",
      "| policy_loss             | -186.2936  |\n",
      "| qf1_loss                | 209.76263  |\n",
      "| qf2_loss                | 216.04712  |\n",
      "| time_elapsed            | 991        |\n",
      "| total timesteps         | 199000     |\n",
      "| value_loss              | 5.058178   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.18364011 |\n",
      "| ent_coef_loss           | 1.5333209  |\n",
      "| entropy                 | 4.8707247  |\n",
      "| episodes                | 210        |\n",
      "| fps                     | 201        |\n",
      "| mean 100 episode reward | 3.79e+03   |\n",
      "| n_updates               | 208901     |\n",
      "| policy_loss             | -196.88493 |\n",
      "| qf1_loss                | 5.0463495  |\n",
      "| qf2_loss                | 6.5626125  |\n",
      "| time_elapsed            | 1039       |\n",
      "| total timesteps         | 209000     |\n",
      "| value_loss              | 6.0914993  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.18153156 |\n",
      "| ent_coef_loss           | -1.137773  |\n",
      "| entropy                 | 4.841273   |\n",
      "| episodes                | 220        |\n",
      "| fps                     | 201        |\n",
      "| mean 100 episode reward | 3.79e+03   |\n",
      "| n_updates               | 218901     |\n",
      "| policy_loss             | -187.85703 |\n",
      "| qf1_loss                | 166.73602  |\n",
      "| qf2_loss                | 158.88017  |\n",
      "| time_elapsed            | 1086       |\n",
      "| total timesteps         | 219000     |\n",
      "| value_loss              | 2.9347992  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.17776541 |\n",
      "| ent_coef_loss           | -1.072587  |\n",
      "| entropy                 | 4.7215514  |\n",
      "| episodes                | 230        |\n",
      "| fps                     | 201        |\n",
      "| mean 100 episode reward | 3.83e+03   |\n",
      "| n_updates               | 228901     |\n",
      "| policy_loss             | -198.26562 |\n",
      "| qf1_loss                | 3.3022175  |\n",
      "| qf2_loss                | 4.6201     |\n",
      "| time_elapsed            | 1134       |\n",
      "| total timesteps         | 229000     |\n",
      "| value_loss              | 4.782053   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.18284723  |\n",
      "| ent_coef_loss           | -0.77489066 |\n",
      "| entropy                 | 4.8364353   |\n",
      "| episodes                | 240         |\n",
      "| fps                     | 202         |\n",
      "| mean 100 episode reward | 3.85e+03    |\n",
      "| n_updates               | 238901      |\n",
      "| policy_loss             | -212.10083  |\n",
      "| qf1_loss                | 3.1304812   |\n",
      "| qf2_loss                | 2.5340843   |\n",
      "| time_elapsed            | 1181        |\n",
      "| total timesteps         | 239000      |\n",
      "| value_loss              | 2.7372577   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.18572202 |\n",
      "| ent_coef_loss           | -1.0744194 |\n",
      "| entropy                 | 4.618149   |\n",
      "| episodes                | 250        |\n",
      "| fps                     | 202        |\n",
      "| mean 100 episode reward | 3.88e+03   |\n",
      "| n_updates               | 248901     |\n",
      "| policy_loss             | -197.18729 |\n",
      "| qf1_loss                | 3.1947567  |\n",
      "| qf2_loss                | 4.512208   |\n",
      "| time_elapsed            | 1229       |\n",
      "| total timesteps         | 249000     |\n",
      "| value_loss              | 2.8911219  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.18522954 |\n",
      "| ent_coef_loss           | -1.0609549 |\n",
      "| entropy                 | 4.884372   |\n",
      "| episodes                | 260        |\n",
      "| fps                     | 202        |\n",
      "| mean 100 episode reward | 3.94e+03   |\n",
      "| n_updates               | 258901     |\n",
      "| policy_loss             | -191.48178 |\n",
      "| qf1_loss                | 4.489633   |\n",
      "| qf2_loss                | 4.3620186  |\n",
      "| time_elapsed            | 1276       |\n",
      "| total timesteps         | 259000     |\n",
      "| value_loss              | 3.5393958  |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.18494786 |\n",
      "| ent_coef_loss           | 0.7711166  |\n",
      "| entropy                 | 4.6790943  |\n",
      "| episodes                | 270        |\n",
      "| fps                     | 203        |\n",
      "| mean 100 episode reward | 3.95e+03   |\n",
      "| n_updates               | 268901     |\n",
      "| policy_loss             | -216.78714 |\n",
      "| qf1_loss                | 62.897022  |\n",
      "| qf2_loss                | 64.33415   |\n",
      "| time_elapsed            | 1323       |\n",
      "| total timesteps         | 269000     |\n",
      "| value_loss              | 8.598521   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.17884952 |\n",
      "| ent_coef_loss           | -0.6759341 |\n",
      "| entropy                 | 4.6750555  |\n",
      "| episodes                | 280        |\n",
      "| fps                     | 203        |\n",
      "| mean 100 episode reward | 4e+03      |\n",
      "| n_updates               | 278901     |\n",
      "| policy_loss             | -212.05246 |\n",
      "| qf1_loss                | 5.63511    |\n",
      "| qf2_loss                | 4.1774     |\n",
      "| time_elapsed            | 1371       |\n",
      "| total timesteps         | 279000     |\n",
      "| value_loss              | 2.26022    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.18394205 |\n",
      "| ent_coef_loss           | -2.4822288 |\n",
      "| entropy                 | 4.5916243  |\n",
      "| episodes                | 290        |\n",
      "| fps                     | 203        |\n",
      "| mean 100 episode reward | 4.01e+03   |\n",
      "| n_updates               | 288901     |\n",
      "| policy_loss             | -206.27884 |\n",
      "| qf1_loss                | 5.433586   |\n",
      "| qf2_loss                | 4.8434134  |\n",
      "| time_elapsed            | 1417       |\n",
      "| total timesteps         | 289000     |\n",
      "| value_loss              | 7.5086517  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.18849191 |\n",
      "| ent_coef_loss           | 0.89726    |\n",
      "| entropy                 | 4.5663786  |\n",
      "| episodes                | 300        |\n",
      "| fps                     | 204        |\n",
      "| mean 100 episode reward | 4.03e+03   |\n",
      "| n_updates               | 298901     |\n",
      "| policy_loss             | -214.63458 |\n",
      "| qf1_loss                | 5.036706   |\n",
      "| qf2_loss                | 2.9656687  |\n",
      "| time_elapsed            | 1465       |\n",
      "| total timesteps         | 299000     |\n",
      "| value_loss              | 4.783534   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.18890285 |\n",
      "| ent_coef_loss           | 0.3907191  |\n",
      "| entropy                 | 4.6292324  |\n",
      "| episodes                | 310        |\n",
      "| fps                     | 204        |\n",
      "| mean 100 episode reward | 4.02e+03   |\n",
      "| n_updates               | 308901     |\n",
      "| policy_loss             | -211.17946 |\n",
      "| qf1_loss                | 4.068042   |\n",
      "| qf2_loss                | 4.3045554  |\n",
      "| time_elapsed            | 1512       |\n",
      "| total timesteps         | 309000     |\n",
      "| value_loss              | 2.6893694  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.1864928   |\n",
      "| ent_coef_loss           | 0.017754346 |\n",
      "| entropy                 | 4.6681643   |\n",
      "| episodes                | 320         |\n",
      "| fps                     | 204         |\n",
      "| mean 100 episode reward | 4.07e+03    |\n",
      "| n_updates               | 318901      |\n",
      "| policy_loss             | -211.56085  |\n",
      "| qf1_loss                | 4.6461487   |\n",
      "| qf2_loss                | 4.4657173   |\n",
      "| time_elapsed            | 1559        |\n",
      "| total timesteps         | 319000      |\n",
      "| value_loss              | 4.8920727   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.18916439 |\n",
      "| ent_coef_loss           | 1.2935114  |\n",
      "| entropy                 | 4.7771354  |\n",
      "| episodes                | 330        |\n",
      "| fps                     | 204        |\n",
      "| mean 100 episode reward | 4.03e+03   |\n",
      "| n_updates               | 328901     |\n",
      "| policy_loss             | -221.32092 |\n",
      "| qf1_loss                | 3.5411386  |\n",
      "| qf2_loss                | 2.8346648  |\n",
      "| time_elapsed            | 1606       |\n",
      "| total timesteps         | 329000     |\n",
      "| value_loss              | 2.6651204  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.1860261  |\n",
      "| ent_coef_loss           | 0.12854904 |\n",
      "| entropy                 | 4.6202087  |\n",
      "| episodes                | 340        |\n",
      "| fps                     | 205        |\n",
      "| mean 100 episode reward | 4.05e+03   |\n",
      "| n_updates               | 338901     |\n",
      "| policy_loss             | -215.53375 |\n",
      "| qf1_loss                | 2.7745445  |\n",
      "| qf2_loss                | 3.2944489  |\n",
      "| time_elapsed            | 1653       |\n",
      "| total timesteps         | 339000     |\n",
      "| value_loss              | 2.0502474  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.1887065  |\n",
      "| ent_coef_loss           | -1.3280978 |\n",
      "| entropy                 | 4.8573513  |\n",
      "| episodes                | 350        |\n",
      "| fps                     | 205        |\n",
      "| mean 100 episode reward | 4.05e+03   |\n",
      "| n_updates               | 348901     |\n",
      "| policy_loss             | -207.6629  |\n",
      "| qf1_loss                | 4.076511   |\n",
      "| qf2_loss                | 4.490508   |\n",
      "| time_elapsed            | 1700       |\n",
      "| total timesteps         | 349000     |\n",
      "| value_loss              | 9.536578   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.19169332 |\n",
      "| ent_coef_loss           | 0.704923   |\n",
      "| entropy                 | 4.4696302  |\n",
      "| episodes                | 360        |\n",
      "| fps                     | 205        |\n",
      "| mean 100 episode reward | 4.07e+03   |\n",
      "| n_updates               | 358901     |\n",
      "| policy_loss             | -231.53754 |\n",
      "| qf1_loss                | 7.347746   |\n",
      "| qf2_loss                | 11.700535  |\n",
      "| time_elapsed            | 1747       |\n",
      "| total timesteps         | 359000     |\n",
      "| value_loss              | 2.5466194  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.1986505  |\n",
      "| ent_coef_loss           | 0.17400678 |\n",
      "| entropy                 | 4.7424064  |\n",
      "| episodes                | 370        |\n",
      "| fps                     | 205        |\n",
      "| mean 100 episode reward | 4.08e+03   |\n",
      "| n_updates               | 368901     |\n",
      "| policy_loss             | -217.09154 |\n",
      "| qf1_loss                | 7.79873    |\n",
      "| qf2_loss                | 6.6687403  |\n",
      "| time_elapsed            | 1794       |\n",
      "| total timesteps         | 369000     |\n",
      "| value_loss              | 5.113085   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.193897   |\n",
      "| ent_coef_loss           | -0.55529   |\n",
      "| entropy                 | 4.7580967  |\n",
      "| episodes                | 380        |\n",
      "| fps                     | 205        |\n",
      "| mean 100 episode reward | 4.06e+03   |\n",
      "| n_updates               | 378901     |\n",
      "| policy_loss             | -220.24698 |\n",
      "| qf1_loss                | 6.949139   |\n",
      "| qf2_loss                | 5.901516   |\n",
      "| time_elapsed            | 1841       |\n",
      "| total timesteps         | 379000     |\n",
      "| value_loss              | 6.5602155  |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ent_coef                | 0.1879292 |\n",
      "| ent_coef_loss           | 0.9931735 |\n",
      "| entropy                 | 4.532167  |\n",
      "| episodes                | 390       |\n",
      "| fps                     | 206       |\n",
      "| mean 100 episode reward | 4.08e+03  |\n",
      "| n_updates               | 388901    |\n",
      "| policy_loss             | -226.1695 |\n",
      "| qf1_loss                | 7.5999866 |\n",
      "| qf2_loss                | 7.4030747 |\n",
      "| time_elapsed            | 1887      |\n",
      "| total timesteps         | 389000    |\n",
      "| value_loss              | 7.5422745 |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.19088471 |\n",
      "| ent_coef_loss           | -0.9209719 |\n",
      "| entropy                 | 4.6244373  |\n",
      "| episodes                | 400        |\n",
      "| fps                     | 206        |\n",
      "| mean 100 episode reward | 4.1e+03    |\n",
      "| n_updates               | 398901     |\n",
      "| policy_loss             | -220.75723 |\n",
      "| qf1_loss                | 5.3222218  |\n",
      "| qf2_loss                | 2.4167664  |\n",
      "| time_elapsed            | 1935       |\n",
      "| total timesteps         | 399000     |\n",
      "| value_loss              | 7.753477   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.18955562 |\n",
      "| ent_coef_loss           | 0.3054495  |\n",
      "| entropy                 | 4.6030445  |\n",
      "| episodes                | 410        |\n",
      "| fps                     | 206        |\n",
      "| mean 100 episode reward | 4.15e+03   |\n",
      "| n_updates               | 408901     |\n",
      "| policy_loss             | -220.16725 |\n",
      "| qf1_loss                | 3.947443   |\n",
      "| qf2_loss                | 3.1153526  |\n",
      "| time_elapsed            | 1981       |\n",
      "| total timesteps         | 409000     |\n",
      "| value_loss              | 7.1240478  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.19243369 |\n",
      "| ent_coef_loss           | 0.5240443  |\n",
      "| entropy                 | 4.555703   |\n",
      "| episodes                | 420        |\n",
      "| fps                     | 206        |\n",
      "| mean 100 episode reward | 4.15e+03   |\n",
      "| n_updates               | 418901     |\n",
      "| policy_loss             | -231.5375  |\n",
      "| qf1_loss                | 5.40043    |\n",
      "| qf2_loss                | 6.578818   |\n",
      "| time_elapsed            | 2030       |\n",
      "| total timesteps         | 419000     |\n",
      "| value_loss              | 4.299249   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.195828   |\n",
      "| ent_coef_loss           | 0.45813873 |\n",
      "| entropy                 | 4.708997   |\n",
      "| episodes                | 430        |\n",
      "| fps                     | 206        |\n",
      "| mean 100 episode reward | 4.22e+03   |\n",
      "| n_updates               | 428901     |\n",
      "| policy_loss             | -240.657   |\n",
      "| qf1_loss                | 534.5826   |\n",
      "| qf2_loss                | 539.52496  |\n",
      "| time_elapsed            | 2077       |\n",
      "| total timesteps         | 429000     |\n",
      "| value_loss              | 2.2609153  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.1913766  |\n",
      "| ent_coef_loss           | 0.9052863  |\n",
      "| entropy                 | 4.286538   |\n",
      "| episodes                | 440        |\n",
      "| fps                     | 206        |\n",
      "| mean 100 episode reward | 4.25e+03   |\n",
      "| n_updates               | 438901     |\n",
      "| policy_loss             | -233.21292 |\n",
      "| qf1_loss                | 3.483478   |\n",
      "| qf2_loss                | 3.3844926  |\n",
      "| time_elapsed            | 2123       |\n",
      "| total timesteps         | 439000     |\n",
      "| value_loss              | 2.8872943  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.1920178  |\n",
      "| ent_coef_loss           | -1.6930137 |\n",
      "| entropy                 | 4.626684   |\n",
      "| episodes                | 450        |\n",
      "| fps                     | 206        |\n",
      "| mean 100 episode reward | 4.29e+03   |\n",
      "| n_updates               | 448901     |\n",
      "| policy_loss             | -241.73756 |\n",
      "| qf1_loss                | 3.549996   |\n",
      "| qf2_loss                | 2.6496253  |\n",
      "| time_elapsed            | 2170       |\n",
      "| total timesteps         | 449000     |\n",
      "| value_loss              | 3.1555166  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.19321941 |\n",
      "| ent_coef_loss           | -1.196662  |\n",
      "| entropy                 | 4.571702   |\n",
      "| episodes                | 460        |\n",
      "| fps                     | 206        |\n",
      "| mean 100 episode reward | 4.31e+03   |\n",
      "| n_updates               | 458901     |\n",
      "| policy_loss             | -217.72108 |\n",
      "| qf1_loss                | 3.0897996  |\n",
      "| qf2_loss                | 3.109222   |\n",
      "| time_elapsed            | 2217       |\n",
      "| total timesteps         | 459000     |\n",
      "| value_loss              | 2.5991359  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.1987678   |\n",
      "| ent_coef_loss           | -0.03939745 |\n",
      "| entropy                 | 4.522096    |\n",
      "| episodes                | 470         |\n",
      "| fps                     | 207         |\n",
      "| mean 100 episode reward | 4.32e+03    |\n",
      "| n_updates               | 468901      |\n",
      "| policy_loss             | -248.19376  |\n",
      "| qf1_loss                | 4.164446    |\n",
      "| qf2_loss                | 4.501725    |\n",
      "| time_elapsed            | 2264        |\n",
      "| total timesteps         | 469000      |\n",
      "| value_loss              | 2.7711096   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.19020396  |\n",
      "| ent_coef_loss           | -0.20199426 |\n",
      "| entropy                 | 4.5389833   |\n",
      "| episodes                | 480         |\n",
      "| fps                     | 207         |\n",
      "| mean 100 episode reward | 4.36e+03    |\n",
      "| n_updates               | 478901      |\n",
      "| policy_loss             | -230.94357  |\n",
      "| qf1_loss                | 2.3601217   |\n",
      "| qf2_loss                | 2.918179    |\n",
      "| time_elapsed            | 2312        |\n",
      "| total timesteps         | 479000      |\n",
      "| value_loss              | 1.9411812   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.18509834 |\n",
      "| ent_coef_loss           | 0.08131176 |\n",
      "| entropy                 | 4.4982233  |\n",
      "| episodes                | 490        |\n",
      "| fps                     | 207        |\n",
      "| mean 100 episode reward | 4.37e+03   |\n",
      "| n_updates               | 488901     |\n",
      "| policy_loss             | -256.252   |\n",
      "| qf1_loss                | 586.0329   |\n",
      "| qf2_loss                | 597.6054   |\n",
      "| time_elapsed            | 2359       |\n",
      "| total timesteps         | 489000     |\n",
      "| value_loss              | 1.961659   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.19444853 |\n",
      "| ent_coef_loss           | 0.17097053 |\n",
      "| entropy                 | 4.49262    |\n",
      "| episodes                | 500        |\n",
      "| fps                     | 207        |\n",
      "| mean 100 episode reward | 4.34e+03   |\n",
      "| n_updates               | 498901     |\n",
      "| policy_loss             | -249.12488 |\n",
      "| qf1_loss                | 3.3254101  |\n",
      "| qf2_loss                | 2.7964745  |\n",
      "| time_elapsed            | 2407       |\n",
      "| total timesteps         | 499000     |\n",
      "| value_loss              | 2.0737617  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.18599904  |\n",
      "| ent_coef_loss           | -0.15326098 |\n",
      "| entropy                 | 4.489464    |\n",
      "| episodes                | 510         |\n",
      "| fps                     | 207         |\n",
      "| mean 100 episode reward | 4.30e+03    |\n",
      "| n_updates               | 508901      |\n",
      "| policy_loss             | -221.92404  |\n",
      "| qf1_loss                | 3.5333848   |\n",
      "| qf2_loss                | 3.631835    |\n",
      "| time_elapsed            | 2456        |\n",
      "| total timesteps         | 509000      |\n",
      "| value_loss              | 2.1354446   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.18659358 |\n",
      "| ent_coef_loss           | 1.0217489  |\n",
      "| entropy                 | 4.5349383  |\n",
      "| episodes                | 520        |\n",
      "| fps                     | 207        |\n",
      "| mean 100 episode reward | 4.32e+03   |\n",
      "| n_updates               | 518901     |\n",
      "| policy_loss             | -234.45306 |\n",
      "| qf1_loss                | 100.799774 |\n",
      "| qf2_loss                | 92.0965    |\n",
      "| time_elapsed            | 2504       |\n",
      "| total timesteps         | 519000     |\n",
      "| value_loss              | 9.789231   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.18748139  |\n",
      "| ent_coef_loss           | -0.29396832 |\n",
      "| entropy                 | 4.6918974   |\n",
      "| episodes                | 530         |\n",
      "| fps                     | 207         |\n",
      "| mean 100 episode reward | 4.31e+03    |\n",
      "| n_updates               | 528901      |\n",
      "| policy_loss             | -242.1696   |\n",
      "| qf1_loss                | 3.5170522   |\n",
      "| qf2_loss                | 3.2531495   |\n",
      "| time_elapsed            | 2553        |\n",
      "| total timesteps         | 529000      |\n",
      "| value_loss              | 2.17911     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.18762223 |\n",
      "| ent_coef_loss           | 0.07374114 |\n",
      "| entropy                 | 4.511552   |\n",
      "| episodes                | 540        |\n",
      "| fps                     | 207        |\n",
      "| mean 100 episode reward | 4.33e+03   |\n",
      "| n_updates               | 538901     |\n",
      "| policy_loss             | -258.81564 |\n",
      "| qf1_loss                | 4.6001253  |\n",
      "| qf2_loss                | 3.4803467  |\n",
      "| time_elapsed            | 2603       |\n",
      "| total timesteps         | 539000     |\n",
      "| value_loss              | 2.2909112  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.192162    |\n",
      "| ent_coef_loss           | -0.42251122 |\n",
      "| entropy                 | 4.3664684   |\n",
      "| episodes                | 550         |\n",
      "| fps                     | 206         |\n",
      "| mean 100 episode reward | 4.25e+03    |\n",
      "| n_updates               | 548901      |\n",
      "| policy_loss             | -240.54588  |\n",
      "| qf1_loss                | 3.79686     |\n",
      "| qf2_loss                | 5.128794    |\n",
      "| time_elapsed            | 2652        |\n",
      "| total timesteps         | 549000      |\n",
      "| value_loss              | 2.5964403   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.19484296 |\n",
      "| ent_coef_loss           | 2.140018   |\n",
      "| entropy                 | 4.4454374  |\n",
      "| episodes                | 560        |\n",
      "| fps                     | 207        |\n",
      "| mean 100 episode reward | 4.26e+03   |\n",
      "| n_updates               | 558901     |\n",
      "| policy_loss             | -243.91661 |\n",
      "| qf1_loss                | 3.845596   |\n",
      "| qf2_loss                | 4.436568   |\n",
      "| time_elapsed            | 2700       |\n",
      "| total timesteps         | 559000     |\n",
      "| value_loss              | 3.4091175  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.19009668 |\n",
      "| ent_coef_loss           | -1.3360937 |\n",
      "| entropy                 | 4.386943   |\n",
      "| episodes                | 570        |\n",
      "| fps                     | 206        |\n",
      "| mean 100 episode reward | 4.27e+03   |\n",
      "| n_updates               | 568901     |\n",
      "| policy_loss             | -234.19775 |\n",
      "| qf1_loss                | 6.0529184  |\n",
      "| qf2_loss                | 8.492258   |\n",
      "| time_elapsed            | 2752       |\n",
      "| total timesteps         | 569000     |\n",
      "| value_loss              | 8.614714   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.18338634 |\n",
      "| ent_coef_loss           | 1.4418314  |\n",
      "| entropy                 | 4.5621233  |\n",
      "| episodes                | 580        |\n",
      "| fps                     | 206        |\n",
      "| mean 100 episode reward | 4.28e+03   |\n",
      "| n_updates               | 578901     |\n",
      "| policy_loss             | -255.85782 |\n",
      "| qf1_loss                | 4.379753   |\n",
      "| qf2_loss                | 2.7415566  |\n",
      "| time_elapsed            | 2799       |\n",
      "| total timesteps         | 579000     |\n",
      "| value_loss              | 8.7293625  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.18003783  |\n",
      "| ent_coef_loss           | -0.03338933 |\n",
      "| entropy                 | 4.324145    |\n",
      "| episodes                | 590         |\n",
      "| fps                     | 206         |\n",
      "| mean 100 episode reward | 4.3e+03     |\n",
      "| n_updates               | 588901      |\n",
      "| policy_loss             | -256.53336  |\n",
      "| qf1_loss                | 2.9900017   |\n",
      "| qf2_loss                | 2.9111319   |\n",
      "| time_elapsed            | 2847        |\n",
      "| total timesteps         | 589000      |\n",
      "| value_loss              | 2.3067007   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.19307725 |\n",
      "| ent_coef_loss           | 0.16213524 |\n",
      "| entropy                 | 4.4938445  |\n",
      "| episodes                | 600        |\n",
      "| fps                     | 206        |\n",
      "| mean 100 episode reward | 4.28e+03   |\n",
      "| n_updates               | 598901     |\n",
      "| policy_loss             | -263.1178  |\n",
      "| qf1_loss                | 3.4527037  |\n",
      "| qf2_loss                | 3.0836778  |\n",
      "| time_elapsed            | 2906       |\n",
      "| total timesteps         | 599000     |\n",
      "| value_loss              | 3.7538517  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.18618198 |\n",
      "| ent_coef_loss           | 1.0365802  |\n",
      "| entropy                 | 4.346398   |\n",
      "| episodes                | 610        |\n",
      "| fps                     | 206        |\n",
      "| mean 100 episode reward | 4.33e+03   |\n",
      "| n_updates               | 608901     |\n",
      "| policy_loss             | -251.95567 |\n",
      "| qf1_loss                | 5.23071    |\n",
      "| qf2_loss                | 5.995371   |\n",
      "| time_elapsed            | 2955       |\n",
      "| total timesteps         | 609000     |\n",
      "| value_loss              | 2.2534223  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.18673056 |\n",
      "| ent_coef_loss           | -0.7389206 |\n",
      "| entropy                 | 4.4663544  |\n",
      "| episodes                | 620        |\n",
      "| fps                     | 206        |\n",
      "| mean 100 episode reward | 4.34e+03   |\n",
      "| n_updates               | 618901     |\n",
      "| policy_loss             | -254.71326 |\n",
      "| qf1_loss                | 4.390173   |\n",
      "| qf2_loss                | 4.0089397  |\n",
      "| time_elapsed            | 3003       |\n",
      "| total timesteps         | 619000     |\n",
      "| value_loss              | 7.262763   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.17713992  |\n",
      "| ent_coef_loss           | -0.56037265 |\n",
      "| entropy                 | 4.478396    |\n",
      "| episodes                | 630         |\n",
      "| fps                     | 206         |\n",
      "| mean 100 episode reward | 4.36e+03    |\n",
      "| n_updates               | 628901      |\n",
      "| policy_loss             | -253.56924  |\n",
      "| qf1_loss                | 3.7532392   |\n",
      "| qf2_loss                | 3.9635708   |\n",
      "| time_elapsed            | 3050        |\n",
      "| total timesteps         | 629000      |\n",
      "| value_loss              | 1.879205    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.18248399 |\n",
      "| ent_coef_loss           | -1.9185333 |\n",
      "| entropy                 | 4.570519   |\n",
      "| episodes                | 640        |\n",
      "| fps                     | 206        |\n",
      "| mean 100 episode reward | 4.35e+03   |\n",
      "| n_updates               | 638901     |\n",
      "| policy_loss             | -252.91837 |\n",
      "| qf1_loss                | 8.3081     |\n",
      "| qf2_loss                | 7.283303   |\n",
      "| time_elapsed            | 3098       |\n",
      "| total timesteps         | 639000     |\n",
      "| value_loss              | 8.299566   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.18294863 |\n",
      "| ent_coef_loss           | -1.0723417 |\n",
      "| entropy                 | 4.452057   |\n",
      "| episodes                | 650        |\n",
      "| fps                     | 206        |\n",
      "| mean 100 episode reward | 4.42e+03   |\n",
      "| n_updates               | 648901     |\n",
      "| policy_loss             | -241.70422 |\n",
      "| qf1_loss                | 3.028592   |\n",
      "| qf2_loss                | 3.2759275  |\n",
      "| time_elapsed            | 3146       |\n",
      "| total timesteps         | 649000     |\n",
      "| value_loss              | 2.605168   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.18732639  |\n",
      "| ent_coef_loss           | -0.46181232 |\n",
      "| entropy                 | 4.512485    |\n",
      "| episodes                | 660         |\n",
      "| fps                     | 206         |\n",
      "| mean 100 episode reward | 4.43e+03    |\n",
      "| n_updates               | 658901      |\n",
      "| policy_loss             | -255.63058  |\n",
      "| qf1_loss                | 4.098049    |\n",
      "| qf2_loss                | 3.581253    |\n",
      "| time_elapsed            | 3194        |\n",
      "| total timesteps         | 659000      |\n",
      "| value_loss              | 2.5091414   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.18743986 |\n",
      "| ent_coef_loss           | -0.7179514 |\n",
      "| entropy                 | 4.4709144  |\n",
      "| episodes                | 670        |\n",
      "| fps                     | 206        |\n",
      "| mean 100 episode reward | 4.45e+03   |\n",
      "| n_updates               | 668901     |\n",
      "| policy_loss             | -233.24715 |\n",
      "| qf1_loss                | 3.2107887  |\n",
      "| qf2_loss                | 3.3036852  |\n",
      "| time_elapsed            | 3241       |\n",
      "| total timesteps         | 669000     |\n",
      "| value_loss              | 5.177147   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.18593404  |\n",
      "| ent_coef_loss           | 0.027634382 |\n",
      "| entropy                 | 4.3469076   |\n",
      "| episodes                | 680         |\n",
      "| fps                     | 206         |\n",
      "| mean 100 episode reward | 4.44e+03    |\n",
      "| n_updates               | 678901      |\n",
      "| policy_loss             | -273.72043  |\n",
      "| qf1_loss                | 2.483846    |\n",
      "| qf2_loss                | 3.5810452   |\n",
      "| time_elapsed            | 3293        |\n",
      "| total timesteps         | 679000      |\n",
      "| value_loss              | 2.3413134   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.1839362  |\n",
      "| ent_coef_loss           | -0.8345227 |\n",
      "| entropy                 | 4.3732033  |\n",
      "| episodes                | 690        |\n",
      "| fps                     | 205        |\n",
      "| mean 100 episode reward | 4.44e+03   |\n",
      "| n_updates               | 688901     |\n",
      "| policy_loss             | -258.88678 |\n",
      "| qf1_loss                | 6.880032   |\n",
      "| qf2_loss                | 6.9344153  |\n",
      "| time_elapsed            | 3345       |\n",
      "| total timesteps         | 689000     |\n",
      "| value_loss              | 21.428951  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.1880851  |\n",
      "| ent_coef_loss           | -0.8863954 |\n",
      "| entropy                 | 4.5229588  |\n",
      "| episodes                | 700        |\n",
      "| fps                     | 205        |\n",
      "| mean 100 episode reward | 4.52e+03   |\n",
      "| n_updates               | 698901     |\n",
      "| policy_loss             | -260.70135 |\n",
      "| qf1_loss                | 6.236595   |\n",
      "| qf2_loss                | 3.8750753  |\n",
      "| time_elapsed            | 3395       |\n",
      "| total timesteps         | 699000     |\n",
      "| value_loss              | 2.935787   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.17951947 |\n",
      "| ent_coef_loss           | 0.26349196 |\n",
      "| entropy                 | 4.505798   |\n",
      "| episodes                | 710        |\n",
      "| fps                     | 205        |\n",
      "| mean 100 episode reward | 4.53e+03   |\n",
      "| n_updates               | 708901     |\n",
      "| policy_loss             | -262.73196 |\n",
      "| qf1_loss                | 5.0717316  |\n",
      "| qf2_loss                | 7.3594723  |\n",
      "| time_elapsed            | 3443       |\n",
      "| total timesteps         | 709000     |\n",
      "| value_loss              | 7.7315097  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.18993893 |\n",
      "| ent_coef_loss           | 0.20821917 |\n",
      "| entropy                 | 4.622612   |\n",
      "| episodes                | 720        |\n",
      "| fps                     | 205        |\n",
      "| mean 100 episode reward | 4.55e+03   |\n",
      "| n_updates               | 718901     |\n",
      "| policy_loss             | -251.25842 |\n",
      "| qf1_loss                | 5.427124   |\n",
      "| qf2_loss                | 4.9342175  |\n",
      "| time_elapsed            | 3490       |\n",
      "| total timesteps         | 719000     |\n",
      "| value_loss              | 3.1753244  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.18259116 |\n",
      "| ent_coef_loss           | 1.4262307  |\n",
      "| entropy                 | 4.1411085  |\n",
      "| episodes                | 730        |\n",
      "| fps                     | 206        |\n",
      "| mean 100 episode reward | 4.55e+03   |\n",
      "| n_updates               | 728901     |\n",
      "| policy_loss             | -266.46448 |\n",
      "| qf1_loss                | 3.1597736  |\n",
      "| qf2_loss                | 4.2212415  |\n",
      "| time_elapsed            | 3538       |\n",
      "| total timesteps         | 729000     |\n",
      "| value_loss              | 2.3868709  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.17298938 |\n",
      "| ent_coef_loss           | -0.4039718 |\n",
      "| entropy                 | 4.2019076  |\n",
      "| episodes                | 740        |\n",
      "| fps                     | 206        |\n",
      "| mean 100 episode reward | 4.55e+03   |\n",
      "| n_updates               | 738901     |\n",
      "| policy_loss             | -275.80365 |\n",
      "| qf1_loss                | 6.591135   |\n",
      "| qf2_loss                | 4.6532583  |\n",
      "| time_elapsed            | 3586       |\n",
      "| total timesteps         | 739000     |\n",
      "| value_loss              | 4.966295   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.18463624 |\n",
      "| ent_coef_loss           | 1.5960922  |\n",
      "| entropy                 | 4.2187414  |\n",
      "| episodes                | 750        |\n",
      "| fps                     | 205        |\n",
      "| mean 100 episode reward | 4.6e+03    |\n",
      "| n_updates               | 748901     |\n",
      "| policy_loss             | -275.09305 |\n",
      "| qf1_loss                | 5.562063   |\n",
      "| qf2_loss                | 5.5585885  |\n",
      "| time_elapsed            | 3637       |\n",
      "| total timesteps         | 749000     |\n",
      "| value_loss              | 3.1025643  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.18631223 |\n",
      "| ent_coef_loss           | 0.11567873 |\n",
      "| entropy                 | 4.255663   |\n",
      "| episodes                | 760        |\n",
      "| fps                     | 205        |\n",
      "| mean 100 episode reward | 4.6e+03    |\n",
      "| n_updates               | 758901     |\n",
      "| policy_loss             | -262.90277 |\n",
      "| qf1_loss                | 2.6790037  |\n",
      "| qf2_loss                | 2.120713   |\n",
      "| time_elapsed            | 3685       |\n",
      "| total timesteps         | 759000     |\n",
      "| value_loss              | 1.9596243  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.18173446 |\n",
      "| ent_coef_loss           | 0.27543122 |\n",
      "| entropy                 | 4.2075024  |\n",
      "| episodes                | 770        |\n",
      "| fps                     | 205        |\n",
      "| mean 100 episode reward | 4.61e+03   |\n",
      "| n_updates               | 768901     |\n",
      "| policy_loss             | -255.67708 |\n",
      "| qf1_loss                | 3.268817   |\n",
      "| qf2_loss                | 2.1787248  |\n",
      "| time_elapsed            | 3733       |\n",
      "| total timesteps         | 769000     |\n",
      "| value_loss              | 3.7190366  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.18707433 |\n",
      "| ent_coef_loss           | 0.3217329  |\n",
      "| entropy                 | 4.2809315  |\n",
      "| episodes                | 780        |\n",
      "| fps                     | 206        |\n",
      "| mean 100 episode reward | 4.65e+03   |\n",
      "| n_updates               | 778901     |\n",
      "| policy_loss             | -278.9576  |\n",
      "| qf1_loss                | 2.1979005  |\n",
      "| qf2_loss                | 2.9281428  |\n",
      "| time_elapsed            | 3780       |\n",
      "| total timesteps         | 779000     |\n",
      "| value_loss              | 3.3007498  |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.18524265 |\n",
      "| ent_coef_loss           | -1.1379983 |\n",
      "| entropy                 | 4.5512986  |\n",
      "| episodes                | 790        |\n",
      "| fps                     | 206        |\n",
      "| mean 100 episode reward | 4.66e+03   |\n",
      "| n_updates               | 788901     |\n",
      "| policy_loss             | -257.1916  |\n",
      "| qf1_loss                | 3.8440912  |\n",
      "| qf2_loss                | 3.2202601  |\n",
      "| time_elapsed            | 3829       |\n",
      "| total timesteps         | 789000     |\n",
      "| value_loss              | 4.589578   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.1791513  |\n",
      "| ent_coef_loss           | 0.6011337  |\n",
      "| entropy                 | 4.09269    |\n",
      "| episodes                | 800        |\n",
      "| fps                     | 205        |\n",
      "| mean 100 episode reward | 4.64e+03   |\n",
      "| n_updates               | 798901     |\n",
      "| policy_loss             | -267.47192 |\n",
      "| qf1_loss                | 3.6103902  |\n",
      "| qf2_loss                | 3.947612   |\n",
      "| time_elapsed            | 3879       |\n",
      "| total timesteps         | 799000     |\n",
      "| value_loss              | 1.9965394  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.17917857 |\n",
      "| ent_coef_loss           | -2.316787  |\n",
      "| entropy                 | 4.2527795  |\n",
      "| episodes                | 810        |\n",
      "| fps                     | 206        |\n",
      "| mean 100 episode reward | 4.65e+03   |\n",
      "| n_updates               | 808901     |\n",
      "| policy_loss             | -247.36478 |\n",
      "| qf1_loss                | 2.7899837  |\n",
      "| qf2_loss                | 3.8800352  |\n",
      "| time_elapsed            | 3926       |\n",
      "| total timesteps         | 809000     |\n",
      "| value_loss              | 3.5204134  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.17991337  |\n",
      "| ent_coef_loss           | -0.59969664 |\n",
      "| entropy                 | 4.3506207   |\n",
      "| episodes                | 820         |\n",
      "| fps                     | 206         |\n",
      "| mean 100 episode reward | 4.67e+03    |\n",
      "| n_updates               | 818901      |\n",
      "| policy_loss             | -272.6002   |\n",
      "| qf1_loss                | 8.249266    |\n",
      "| qf2_loss                | 7.146029    |\n",
      "| time_elapsed            | 3973        |\n",
      "| total timesteps         | 819000      |\n",
      "| value_loss              | 5.6063695   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.18254386 |\n",
      "| ent_coef_loss           | 0.1958155  |\n",
      "| entropy                 | 4.18228    |\n",
      "| episodes                | 830        |\n",
      "| fps                     | 205        |\n",
      "| mean 100 episode reward | 4.68e+03   |\n",
      "| n_updates               | 828901     |\n",
      "| policy_loss             | -275.45612 |\n",
      "| qf1_loss                | 3.0129185  |\n",
      "| qf2_loss                | 3.2760515  |\n",
      "| time_elapsed            | 4025       |\n",
      "| total timesteps         | 829000     |\n",
      "| value_loss              | 3.7805343  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.18177582 |\n",
      "| ent_coef_loss           | -1.7803857 |\n",
      "| entropy                 | 4.27226    |\n",
      "| episodes                | 840        |\n",
      "| fps                     | 205        |\n",
      "| mean 100 episode reward | 4.73e+03   |\n",
      "| n_updates               | 838901     |\n",
      "| policy_loss             | -273.7942  |\n",
      "| qf1_loss                | 11.411298  |\n",
      "| qf2_loss                | 9.464092   |\n",
      "| time_elapsed            | 4075       |\n",
      "| total timesteps         | 839000     |\n",
      "| value_loss              | 2.430025   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.17619002 |\n",
      "| ent_coef_loss           | -0.8443788 |\n",
      "| entropy                 | 4.007185   |\n",
      "| episodes                | 850        |\n",
      "| fps                     | 205        |\n",
      "| mean 100 episode reward | 4.71e+03   |\n",
      "| n_updates               | 848901     |\n",
      "| policy_loss             | -293.4534  |\n",
      "| qf1_loss                | 1.8947163  |\n",
      "| qf2_loss                | 2.00116    |\n",
      "| time_elapsed            | 4128       |\n",
      "| total timesteps         | 849000     |\n",
      "| value_loss              | 2.1749506  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.18660527 |\n",
      "| ent_coef_loss           | 1.481755   |\n",
      "| entropy                 | 4.218499   |\n",
      "| episodes                | 860        |\n",
      "| fps                     | 205        |\n",
      "| mean 100 episode reward | 4.72e+03   |\n",
      "| n_updates               | 858901     |\n",
      "| policy_loss             | -288.23026 |\n",
      "| qf1_loss                | 3.3775816  |\n",
      "| qf2_loss                | 3.8268907  |\n",
      "| time_elapsed            | 4179       |\n",
      "| total timesteps         | 859000     |\n",
      "| value_loss              | 8.589979   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.18874559 |\n",
      "| ent_coef_loss           | 0.63890946 |\n",
      "| entropy                 | 4.242275   |\n",
      "| episodes                | 870        |\n",
      "| fps                     | 205        |\n",
      "| mean 100 episode reward | 4.73e+03   |\n",
      "| n_updates               | 868901     |\n",
      "| policy_loss             | -284.2815  |\n",
      "| qf1_loss                | 3.8553712  |\n",
      "| qf2_loss                | 3.1719651  |\n",
      "| time_elapsed            | 4231       |\n",
      "| total timesteps         | 869000     |\n",
      "| value_loss              | 1.9598107  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.17386998  |\n",
      "| ent_coef_loss           | -0.23987621 |\n",
      "| entropy                 | 4.441866    |\n",
      "| episodes                | 880         |\n",
      "| fps                     | 205         |\n",
      "| mean 100 episode reward | 4.72e+03    |\n",
      "| n_updates               | 878901      |\n",
      "| policy_loss             | -278.97876  |\n",
      "| qf1_loss                | 6.212799    |\n",
      "| qf2_loss                | 5.6085567   |\n",
      "| time_elapsed            | 4284        |\n",
      "| total timesteps         | 879000      |\n",
      "| value_loss              | 3.3254848   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.18133709  |\n",
      "| ent_coef_loss           | -0.61132616 |\n",
      "| entropy                 | 4.2759333   |\n",
      "| episodes                | 890         |\n",
      "| fps                     | 204         |\n",
      "| mean 100 episode reward | 4.73e+03    |\n",
      "| n_updates               | 888901      |\n",
      "| policy_loss             | -278.95547  |\n",
      "| qf1_loss                | 3.401216    |\n",
      "| qf2_loss                | 4.4580374   |\n",
      "| time_elapsed            | 4339        |\n",
      "| total timesteps         | 889000      |\n",
      "| value_loss              | 3.4959269   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.18337685 |\n",
      "| ent_coef_loss           | 0.0294815  |\n",
      "| entropy                 | 4.4477367  |\n",
      "| episodes                | 900        |\n",
      "| fps                     | 204        |\n",
      "| mean 100 episode reward | 4.77e+03   |\n",
      "| n_updates               | 898901     |\n",
      "| policy_loss             | -288.79575 |\n",
      "| qf1_loss                | 6.946045   |\n",
      "| qf2_loss                | 5.7386584  |\n",
      "| time_elapsed            | 4386       |\n",
      "| total timesteps         | 899000     |\n",
      "| value_loss              | 4.5917554  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.17451252 |\n",
      "| ent_coef_loss           | 1.9060397  |\n",
      "| entropy                 | 4.233084   |\n",
      "| episodes                | 910        |\n",
      "| fps                     | 203        |\n",
      "| mean 100 episode reward | 4.78e+03   |\n",
      "| n_updates               | 908901     |\n",
      "| policy_loss             | -288.3791  |\n",
      "| qf1_loss                | 3.67994    |\n",
      "| qf2_loss                | 3.7929718  |\n",
      "| time_elapsed            | 4461       |\n",
      "| total timesteps         | 909000     |\n",
      "| value_loss              | 11.590062  |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.17772746 |\n",
      "| ent_coef_loss           | 1.1230798  |\n",
      "| entropy                 | 4.380637   |\n",
      "| episodes                | 920        |\n",
      "| fps                     | 200        |\n",
      "| mean 100 episode reward | 4.77e+03   |\n",
      "| n_updates               | 918901     |\n",
      "| policy_loss             | -293.44794 |\n",
      "| qf1_loss                | 7.9100013  |\n",
      "| qf2_loss                | 4.6484776  |\n",
      "| time_elapsed            | 4594       |\n",
      "| total timesteps         | 919000     |\n",
      "| value_loss              | 4.862377   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.17634855 |\n",
      "| ent_coef_loss           | -0.7338183 |\n",
      "| entropy                 | 4.2414527  |\n",
      "| episodes                | 930        |\n",
      "| fps                     | 197        |\n",
      "| mean 100 episode reward | 4.78e+03   |\n",
      "| n_updates               | 928901     |\n",
      "| policy_loss             | -263.27557 |\n",
      "| qf1_loss                | 1.722733   |\n",
      "| qf2_loss                | 1.419318   |\n",
      "| time_elapsed            | 4709       |\n",
      "| total timesteps         | 929000     |\n",
      "| value_loss              | 2.4623194  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.18119314 |\n",
      "| ent_coef_loss           | 0.76426566 |\n",
      "| entropy                 | 4.2186327  |\n",
      "| episodes                | 940        |\n",
      "| fps                     | 193        |\n",
      "| mean 100 episode reward | 4.79e+03   |\n",
      "| n_updates               | 938901     |\n",
      "| policy_loss             | -278.9854  |\n",
      "| qf1_loss                | 20.800142  |\n",
      "| qf2_loss                | 16.992548  |\n",
      "| time_elapsed            | 4847       |\n",
      "| total timesteps         | 939000     |\n",
      "| value_loss              | 1.9670272  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.18108532  |\n",
      "| ent_coef_loss           | -0.28354084 |\n",
      "| entropy                 | 4.355917    |\n",
      "| episodes                | 950         |\n",
      "| fps                     | 190         |\n",
      "| mean 100 episode reward | 4.8e+03     |\n",
      "| n_updates               | 948901      |\n",
      "| policy_loss             | -288.32642  |\n",
      "| qf1_loss                | 14.836644   |\n",
      "| qf2_loss                | 15.306114   |\n",
      "| time_elapsed            | 4975        |\n",
      "| total timesteps         | 949000      |\n",
      "| value_loss              | 5.7128577   |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| current_lr              | 0.0003       |\n",
      "| ent_coef                | 0.17681077   |\n",
      "| ent_coef_loss           | -0.036915183 |\n",
      "| entropy                 | 4.113783     |\n",
      "| episodes                | 960          |\n",
      "| fps                     | 187          |\n",
      "| mean 100 episode reward | 4.81e+03     |\n",
      "| n_updates               | 958901       |\n",
      "| policy_loss             | -281.11194   |\n",
      "| qf1_loss                | 5.2825384    |\n",
      "| qf2_loss                | 4.8485107    |\n",
      "| time_elapsed            | 5119         |\n",
      "| total timesteps         | 959000       |\n",
      "| value_loss              | 5.1599507    |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.18506575  |\n",
      "| ent_coef_loss           | -0.40823448 |\n",
      "| entropy                 | 4.289651    |\n",
      "| episodes                | 970         |\n",
      "| fps                     | 183         |\n",
      "| mean 100 episode reward | 4.8e+03     |\n",
      "| n_updates               | 968901      |\n",
      "| policy_loss             | -284.05927  |\n",
      "| qf1_loss                | 658.739     |\n",
      "| qf2_loss                | 653.94977   |\n",
      "| time_elapsed            | 5271        |\n",
      "| total timesteps         | 969000      |\n",
      "| value_loss              | 4.039793    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| current_lr              | 0.0003       |\n",
      "| ent_coef                | 0.17922993   |\n",
      "| ent_coef_loss           | -0.048635393 |\n",
      "| entropy                 | 4.4285917    |\n",
      "| episodes                | 980          |\n",
      "| fps                     | 181          |\n",
      "| mean 100 episode reward | 4.82e+03     |\n",
      "| n_updates               | 978901       |\n",
      "| policy_loss             | -290.27896   |\n",
      "| qf1_loss                | 5.213705     |\n",
      "| qf2_loss                | 3.1335053    |\n",
      "| time_elapsed            | 5406         |\n",
      "| total timesteps         | 979000       |\n",
      "| value_loss              | 5.0778694    |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.18505765 |\n",
      "| ent_coef_loss           | 0.80647117 |\n",
      "| entropy                 | 4.2475834  |\n",
      "| episodes                | 990        |\n",
      "| fps                     | 178        |\n",
      "| mean 100 episode reward | 4.82e+03   |\n",
      "| n_updates               | 988901     |\n",
      "| policy_loss             | -289.39972 |\n",
      "| qf1_loss                | 3.519837   |\n",
      "| qf2_loss                | 2.9490118  |\n",
      "| time_elapsed            | 5551       |\n",
      "| total timesteps         | 989000     |\n",
      "| value_loss              | 4.2909775  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.1830335  |\n",
      "| ent_coef_loss           | -0.6824392 |\n",
      "| entropy                 | 4.6598225  |\n",
      "| episodes                | 1000       |\n",
      "| fps                     | 175        |\n",
      "| mean 100 episode reward | 4.82e+03   |\n",
      "| n_updates               | 998901     |\n",
      "| policy_loss             | -270.97873 |\n",
      "| qf1_loss                | 1.907273   |\n",
      "| qf2_loss                | 1.8426677  |\n",
      "| time_elapsed            | 5700       |\n",
      "| total timesteps         | 999000     |\n",
      "| value_loss              | 2.3912966  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.18748029  |\n",
      "| ent_coef_loss           | -0.42583418 |\n",
      "| entropy                 | 4.216632    |\n",
      "| episodes                | 1010        |\n",
      "| fps                     | 172         |\n",
      "| mean 100 episode reward | 4.82e+03    |\n",
      "| n_updates               | 1008901     |\n",
      "| policy_loss             | -290.9452   |\n",
      "| qf1_loss                | 5.1178217   |\n",
      "| qf2_loss                | 6.5649796   |\n",
      "| time_elapsed            | 5845        |\n",
      "| total timesteps         | 1009000     |\n",
      "| value_loss              | 2.7151752   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.18447566 |\n",
      "| ent_coef_loss           | -0.9148944 |\n",
      "| entropy                 | 4.4399986  |\n",
      "| episodes                | 1020       |\n",
      "| fps                     | 170        |\n",
      "| mean 100 episode reward | 4.79e+03   |\n",
      "| n_updates               | 1018901    |\n",
      "| policy_loss             | -296.97446 |\n",
      "| qf1_loss                | 7.0607123  |\n",
      "| qf2_loss                | 10.193968  |\n",
      "| time_elapsed            | 5986       |\n",
      "| total timesteps         | 1019000    |\n",
      "| value_loss              | 3.3032198  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.17141894 |\n",
      "| ent_coef_loss           | 1.2234869  |\n",
      "| entropy                 | 4.0062675  |\n",
      "| episodes                | 1030       |\n",
      "| fps                     | 168        |\n",
      "| mean 100 episode reward | 4.79e+03   |\n",
      "| n_updates               | 1028901    |\n",
      "| policy_loss             | -294.81265 |\n",
      "| qf1_loss                | 6.0102706  |\n",
      "| qf2_loss                | 6.917439   |\n",
      "| time_elapsed            | 6122       |\n",
      "| total timesteps         | 1029000    |\n",
      "| value_loss              | 5.217174   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.18115191 |\n",
      "| ent_coef_loss           | 0.52174866 |\n",
      "| entropy                 | 4.2259846  |\n",
      "| episodes                | 1040       |\n",
      "| fps                     | 166        |\n",
      "| mean 100 episode reward | 4.81e+03   |\n",
      "| n_updates               | 1038901    |\n",
      "| policy_loss             | -302.43094 |\n",
      "| qf1_loss                | 5.606182   |\n",
      "| qf2_loss                | 3.632982   |\n",
      "| time_elapsed            | 6258       |\n",
      "| total timesteps         | 1039000    |\n",
      "| value_loss              | 6.3570204  |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.1856642  |\n",
      "| ent_coef_loss           | 0.67345524 |\n",
      "| entropy                 | 4.0633345  |\n",
      "| episodes                | 1050       |\n",
      "| fps                     | 163        |\n",
      "| mean 100 episode reward | 4.82e+03   |\n",
      "| n_updates               | 1048901    |\n",
      "| policy_loss             | -298.40082 |\n",
      "| qf1_loss                | 3.2436533  |\n",
      "| qf2_loss                | 4.077197   |\n",
      "| time_elapsed            | 6406       |\n",
      "| total timesteps         | 1049000    |\n",
      "| value_loss              | 2.9596286  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.18270345 |\n",
      "| ent_coef_loss           | -1.6429728 |\n",
      "| entropy                 | 4.1874022  |\n",
      "| episodes                | 1060       |\n",
      "| fps                     | 161        |\n",
      "| mean 100 episode reward | 4.82e+03   |\n",
      "| n_updates               | 1058901    |\n",
      "| policy_loss             | -289.48352 |\n",
      "| qf1_loss                | 760.7777   |\n",
      "| qf2_loss                | 766.4849   |\n",
      "| time_elapsed            | 6560       |\n",
      "| total timesteps         | 1059000    |\n",
      "| value_loss              | 3.1962395  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.18851063 |\n",
      "| ent_coef_loss           | -0.7566197 |\n",
      "| entropy                 | 4.2222958  |\n",
      "| episodes                | 1070       |\n",
      "| fps                     | 159        |\n",
      "| mean 100 episode reward | 4.83e+03   |\n",
      "| n_updates               | 1068901    |\n",
      "| policy_loss             | -290.5399  |\n",
      "| qf1_loss                | 5.4842153  |\n",
      "| qf2_loss                | 4.5016785  |\n",
      "| time_elapsed            | 6706       |\n",
      "| total timesteps         | 1069000    |\n",
      "| value_loss              | 2.776514   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.18501046 |\n",
      "| ent_coef_loss           | 0.4441775  |\n",
      "| entropy                 | 4.4550743  |\n",
      "| episodes                | 1080       |\n",
      "| fps                     | 157        |\n",
      "| mean 100 episode reward | 4.79e+03   |\n",
      "| n_updates               | 1078901    |\n",
      "| policy_loss             | -288.59567 |\n",
      "| qf1_loss                | 3.6611238  |\n",
      "| qf2_loss                | 3.7533662  |\n",
      "| time_elapsed            | 6843       |\n",
      "| total timesteps         | 1079000    |\n",
      "| value_loss              | 2.1029882  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.18753003  |\n",
      "| ent_coef_loss           | -0.82556355 |\n",
      "| entropy                 | 4.4811954   |\n",
      "| episodes                | 1090        |\n",
      "| fps                     | 156         |\n",
      "| mean 100 episode reward | 4.79e+03    |\n",
      "| n_updates               | 1088901     |\n",
      "| policy_loss             | -299.9787   |\n",
      "| qf1_loss                | 16.713009   |\n",
      "| qf2_loss                | 6.967368    |\n",
      "| time_elapsed            | 6978        |\n",
      "| total timesteps         | 1089000     |\n",
      "| value_loss              | 7.4241734   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.1820074  |\n",
      "| ent_coef_loss           | -1.2337644 |\n",
      "| entropy                 | 4.3943033  |\n",
      "| episodes                | 1100       |\n",
      "| fps                     | 154        |\n",
      "| mean 100 episode reward | 4.77e+03   |\n",
      "| n_updates               | 1098901    |\n",
      "| policy_loss             | -271.89282 |\n",
      "| qf1_loss                | 4.9143047  |\n",
      "| qf2_loss                | 4.5043097  |\n",
      "| time_elapsed            | 7114       |\n",
      "| total timesteps         | 1099000    |\n",
      "| value_loss              | 3.5726976  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.18496767  |\n",
      "| ent_coef_loss           | -0.55987275 |\n",
      "| entropy                 | 4.4104466   |\n",
      "| episodes                | 1110        |\n",
      "| fps                     | 152         |\n",
      "| mean 100 episode reward | 4.78e+03    |\n",
      "| n_updates               | 1108901     |\n",
      "| policy_loss             | -293.2434   |\n",
      "| qf1_loss                | 6.458231    |\n",
      "| qf2_loss                | 6.1645293   |\n",
      "| time_elapsed            | 7251        |\n",
      "| total timesteps         | 1109000     |\n",
      "| value_loss              | 10.644243   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.19141552  |\n",
      "| ent_coef_loss           | 0.009071156 |\n",
      "| entropy                 | 4.286725    |\n",
      "| episodes                | 1120        |\n",
      "| fps                     | 151         |\n",
      "| mean 100 episode reward | 4.78e+03    |\n",
      "| n_updates               | 1118901     |\n",
      "| policy_loss             | -302.87476  |\n",
      "| qf1_loss                | 2.8500829   |\n",
      "| qf2_loss                | 2.3792155   |\n",
      "| time_elapsed            | 7389        |\n",
      "| total timesteps         | 1119000     |\n",
      "| value_loss              | 3.9981012   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.17715389 |\n",
      "| ent_coef_loss           | 0.07964221 |\n",
      "| entropy                 | 4.4098673  |\n",
      "| episodes                | 1130       |\n",
      "| fps                     | 150        |\n",
      "| mean 100 episode reward | 4.79e+03   |\n",
      "| n_updates               | 1128901    |\n",
      "| policy_loss             | -293.27832 |\n",
      "| qf1_loss                | 3.8428328  |\n",
      "| qf2_loss                | 3.0573046  |\n",
      "| time_elapsed            | 7523       |\n",
      "| total timesteps         | 1129000    |\n",
      "| value_loss              | 4.8521028  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.1806875  |\n",
      "| ent_coef_loss           | -2.1088083 |\n",
      "| entropy                 | 4.5254145  |\n",
      "| episodes                | 1140       |\n",
      "| fps                     | 148        |\n",
      "| mean 100 episode reward | 4.78e+03   |\n",
      "| n_updates               | 1138901    |\n",
      "| policy_loss             | -305.20172 |\n",
      "| qf1_loss                | 2.2043004  |\n",
      "| qf2_loss                | 2.3765423  |\n",
      "| time_elapsed            | 7659       |\n",
      "| total timesteps         | 1139000    |\n",
      "| value_loss              | 9.197532   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.18088906 |\n",
      "| ent_coef_loss           | -0.3081172 |\n",
      "| entropy                 | 4.4413395  |\n",
      "| episodes                | 1150       |\n",
      "| fps                     | 147        |\n",
      "| mean 100 episode reward | 4.74e+03   |\n",
      "| n_updates               | 1148901    |\n",
      "| policy_loss             | -299.53455 |\n",
      "| qf1_loss                | 4.062504   |\n",
      "| qf2_loss                | 4.069867   |\n",
      "| time_elapsed            | 7796       |\n",
      "| total timesteps         | 1149000    |\n",
      "| value_loss              | 4.0826077  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.17831601 |\n",
      "| ent_coef_loss           | 0.43814385 |\n",
      "| entropy                 | 4.453459   |\n",
      "| episodes                | 1160       |\n",
      "| fps                     | 146        |\n",
      "| mean 100 episode reward | 4.73e+03   |\n",
      "| n_updates               | 1158901    |\n",
      "| policy_loss             | -301.9218  |\n",
      "| qf1_loss                | 4.178674   |\n",
      "| qf2_loss                | 3.7892892  |\n",
      "| time_elapsed            | 7934       |\n",
      "| total timesteps         | 1159000    |\n",
      "| value_loss              | 2.2053957  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.19111589 |\n",
      "| ent_coef_loss           | 2.3905818  |\n",
      "| entropy                 | 4.376666   |\n",
      "| episodes                | 1170       |\n",
      "| fps                     | 144        |\n",
      "| mean 100 episode reward | 4.74e+03   |\n",
      "| n_updates               | 1168901    |\n",
      "| policy_loss             | -309.86066 |\n",
      "| qf1_loss                | 816.088    |\n",
      "| qf2_loss                | 812.6749   |\n",
      "| time_elapsed            | 8082       |\n",
      "| total timesteps         | 1169000    |\n",
      "| value_loss              | 2.064282   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.17677164  |\n",
      "| ent_coef_loss           | -0.12726873 |\n",
      "| entropy                 | 4.357458    |\n",
      "| episodes                | 1180        |\n",
      "| fps                     | 143         |\n",
      "| mean 100 episode reward | 4.73e+03    |\n",
      "| n_updates               | 1178901     |\n",
      "| policy_loss             | -308.5305   |\n",
      "| qf1_loss                | 3.8508925   |\n",
      "| qf2_loss                | 2.7917976   |\n",
      "| time_elapsed            | 8220        |\n",
      "| total timesteps         | 1179000     |\n",
      "| value_loss              | 2.3822446   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.17861773 |\n",
      "| ent_coef_loss           | 0.35954875 |\n",
      "| entropy                 | 4.288933   |\n",
      "| episodes                | 1190       |\n",
      "| fps                     | 142        |\n",
      "| mean 100 episode reward | 4.69e+03   |\n",
      "| n_updates               | 1188901    |\n",
      "| policy_loss             | -306.23322 |\n",
      "| qf1_loss                | 5.66737    |\n",
      "| qf2_loss                | 4.787075   |\n",
      "| time_elapsed            | 8351       |\n",
      "| total timesteps         | 1189000    |\n",
      "| value_loss              | 1.9773265  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.19087987 |\n",
      "| ent_coef_loss           | 0.9901066  |\n",
      "| entropy                 | 4.492124   |\n",
      "| episodes                | 1200       |\n",
      "| fps                     | 141        |\n",
      "| mean 100 episode reward | 4.7e+03    |\n",
      "| n_updates               | 1198901    |\n",
      "| policy_loss             | -301.24677 |\n",
      "| qf1_loss                | 6.8994026  |\n",
      "| qf2_loss                | 7.882416   |\n",
      "| time_elapsed            | 8487       |\n",
      "| total timesteps         | 1199000    |\n",
      "| value_loss              | 7.3555694  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.18578726 |\n",
      "| ent_coef_loss           | 1.7267698  |\n",
      "| entropy                 | 4.4335585  |\n",
      "| episodes                | 1210       |\n",
      "| fps                     | 140        |\n",
      "| mean 100 episode reward | 4.7e+03    |\n",
      "| n_updates               | 1208901    |\n",
      "| policy_loss             | -310.7816  |\n",
      "| qf1_loss                | 3.3315382  |\n",
      "| qf2_loss                | 3.878815   |\n",
      "| time_elapsed            | 8624       |\n",
      "| total timesteps         | 1209000    |\n",
      "| value_loss              | 4.5789986  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.1828397   |\n",
      "| ent_coef_loss           | 0.119240746 |\n",
      "| entropy                 | 4.2426662   |\n",
      "| episodes                | 1220        |\n",
      "| fps                     | 139         |\n",
      "| mean 100 episode reward | 4.73e+03    |\n",
      "| n_updates               | 1218901     |\n",
      "| policy_loss             | -308.29007  |\n",
      "| qf1_loss                | 2.951563    |\n",
      "| qf2_loss                | 2.6045933   |\n",
      "| time_elapsed            | 8763        |\n",
      "| total timesteps         | 1219000     |\n",
      "| value_loss              | 1.989543    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.17459555  |\n",
      "| ent_coef_loss           | -0.03505534 |\n",
      "| entropy                 | 4.323485    |\n",
      "| episodes                | 1230        |\n",
      "| fps                     | 138         |\n",
      "| mean 100 episode reward | 4.72e+03    |\n",
      "| n_updates               | 1228901     |\n",
      "| policy_loss             | -309.53595  |\n",
      "| qf1_loss                | 4.3943796   |\n",
      "| qf2_loss                | 3.6082287   |\n",
      "| time_elapsed            | 8899        |\n",
      "| total timesteps         | 1229000     |\n",
      "| value_loss              | 11.2723675  |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.18205388 |\n",
      "| ent_coef_loss           | 1.7280612  |\n",
      "| entropy                 | 4.524517   |\n",
      "| episodes                | 1240       |\n",
      "| fps                     | 137        |\n",
      "| mean 100 episode reward | 4.71e+03   |\n",
      "| n_updates               | 1238901    |\n",
      "| policy_loss             | -318.11652 |\n",
      "| qf1_loss                | 4.698004   |\n",
      "| qf2_loss                | 4.8089404  |\n",
      "| time_elapsed            | 9031       |\n",
      "| total timesteps         | 1239000    |\n",
      "| value_loss              | 5.198767   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.17899477 |\n",
      "| ent_coef_loss           | -1.9344057 |\n",
      "| entropy                 | 4.302223   |\n",
      "| episodes                | 1250       |\n",
      "| fps                     | 136        |\n",
      "| mean 100 episode reward | 4.74e+03   |\n",
      "| n_updates               | 1248901    |\n",
      "| policy_loss             | -313.8029  |\n",
      "| qf1_loss                | 3.2809887  |\n",
      "| qf2_loss                | 2.733708   |\n",
      "| time_elapsed            | 9167       |\n",
      "| total timesteps         | 1249000    |\n",
      "| value_loss              | 9.937494   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.17147866 |\n",
      "| ent_coef_loss           | -1.004463  |\n",
      "| entropy                 | 4.377244   |\n",
      "| episodes                | 1260       |\n",
      "| fps                     | 135        |\n",
      "| mean 100 episode reward | 4.69e+03   |\n",
      "| n_updates               | 1258901    |\n",
      "| policy_loss             | -296.6333  |\n",
      "| qf1_loss                | 2.9101062  |\n",
      "| qf2_loss                | 3.256868   |\n",
      "| time_elapsed            | 9300       |\n",
      "| total timesteps         | 1259000    |\n",
      "| value_loss              | 1.8897235  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.17956407  |\n",
      "| ent_coef_loss           | -0.18290651 |\n",
      "| entropy                 | 4.413204    |\n",
      "| episodes                | 1270        |\n",
      "| fps                     | 134         |\n",
      "| mean 100 episode reward | 4.7e+03     |\n",
      "| n_updates               | 1268901     |\n",
      "| policy_loss             | -310.389    |\n",
      "| qf1_loss                | 2.6864758   |\n",
      "| qf2_loss                | 2.0736175   |\n",
      "| time_elapsed            | 9428        |\n",
      "| total timesteps         | 1269000     |\n",
      "| value_loss              | 1.4010718   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.17365332  |\n",
      "| ent_coef_loss           | -0.50018156 |\n",
      "| entropy                 | 4.521688    |\n",
      "| episodes                | 1280        |\n",
      "| fps                     | 133         |\n",
      "| mean 100 episode reward | 4.7e+03     |\n",
      "| n_updates               | 1278901     |\n",
      "| policy_loss             | -302.09613  |\n",
      "| qf1_loss                | 2.9160976   |\n",
      "| qf2_loss                | 2.7512503   |\n",
      "| time_elapsed            | 9562        |\n",
      "| total timesteps         | 1279000     |\n",
      "| value_loss              | 4.764579    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.17945126 |\n",
      "| ent_coef_loss           | -0.5817995 |\n",
      "| entropy                 | 4.3463545  |\n",
      "| episodes                | 1290       |\n",
      "| fps                     | 132        |\n",
      "| mean 100 episode reward | 4.74e+03   |\n",
      "| n_updates               | 1288901    |\n",
      "| policy_loss             | -315.03604 |\n",
      "| qf1_loss                | 17.017633  |\n",
      "| qf2_loss                | 21.471338  |\n",
      "| time_elapsed            | 9694       |\n",
      "| total timesteps         | 1289000    |\n",
      "| value_loss              | 7.5149927  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.17635646 |\n",
      "| ent_coef_loss           | 0.29465044 |\n",
      "| entropy                 | 4.236764   |\n",
      "| episodes                | 1300       |\n",
      "| fps                     | 132        |\n",
      "| mean 100 episode reward | 4.71e+03   |\n",
      "| n_updates               | 1298901    |\n",
      "| policy_loss             | -306.98572 |\n",
      "| qf1_loss                | 3.5737238  |\n",
      "| qf2_loss                | 4.0151234  |\n",
      "| time_elapsed            | 9831       |\n",
      "| total timesteps         | 1299000    |\n",
      "| value_loss              | 4.1812325  |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.17941712 |\n",
      "| ent_coef_loss           | 0.98630786 |\n",
      "| entropy                 | 4.314316   |\n",
      "| episodes                | 1310       |\n",
      "| fps                     | 131        |\n",
      "| mean 100 episode reward | 4.71e+03   |\n",
      "| n_updates               | 1308901    |\n",
      "| policy_loss             | -324.00024 |\n",
      "| qf1_loss                | 7.311844   |\n",
      "| qf2_loss                | 6.4838924  |\n",
      "| time_elapsed            | 9976       |\n",
      "| total timesteps         | 1309000    |\n",
      "| value_loss              | 13.264158  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.17176665  |\n",
      "| ent_coef_loss           | -0.24556589 |\n",
      "| entropy                 | 4.2650356   |\n",
      "| episodes                | 1320        |\n",
      "| fps                     | 130         |\n",
      "| mean 100 episode reward | 4.7e+03     |\n",
      "| n_updates               | 1318901     |\n",
      "| policy_loss             | -307.18625  |\n",
      "| qf1_loss                | 5.6935425   |\n",
      "| qf2_loss                | 4.2026253   |\n",
      "| time_elapsed            | 10118       |\n",
      "| total timesteps         | 1319000     |\n",
      "| value_loss              | 11.000777   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.17370132 |\n",
      "| ent_coef_loss           | -1.3740807 |\n",
      "| entropy                 | 4.258237   |\n",
      "| episodes                | 1330       |\n",
      "| fps                     | 129        |\n",
      "| mean 100 episode reward | 4.71e+03   |\n",
      "| n_updates               | 1328901    |\n",
      "| policy_loss             | -306.08206 |\n",
      "| qf1_loss                | 5.3088427  |\n",
      "| qf2_loss                | 4.4559975  |\n",
      "| time_elapsed            | 10256      |\n",
      "| total timesteps         | 1329000    |\n",
      "| value_loss              | 7.0681496  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.17805229  |\n",
      "| ent_coef_loss           | -0.65498847 |\n",
      "| entropy                 | 4.487161    |\n",
      "| episodes                | 1340        |\n",
      "| fps                     | 128         |\n",
      "| mean 100 episode reward | 4.73e+03    |\n",
      "| n_updates               | 1338901     |\n",
      "| policy_loss             | -307.47134  |\n",
      "| qf1_loss                | 1.9826435   |\n",
      "| qf2_loss                | 2.000709    |\n",
      "| time_elapsed            | 10399       |\n",
      "| total timesteps         | 1339000     |\n",
      "| value_loss              | 1.5348929   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.1746061   |\n",
      "| ent_coef_loss           | -0.15827692 |\n",
      "| entropy                 | 4.3479795   |\n",
      "| episodes                | 1350        |\n",
      "| fps                     | 127         |\n",
      "| mean 100 episode reward | 4.73e+03    |\n",
      "| n_updates               | 1348901     |\n",
      "| policy_loss             | -310.8437   |\n",
      "| qf1_loss                | 2.9903917   |\n",
      "| qf2_loss                | 2.3519552   |\n",
      "| time_elapsed            | 10543       |\n",
      "| total timesteps         | 1349000     |\n",
      "| value_loss              | 1.2402416   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.17500804 |\n",
      "| ent_coef_loss           | 0.93102103 |\n",
      "| entropy                 | 4.4268274  |\n",
      "| episodes                | 1360       |\n",
      "| fps                     | 127        |\n",
      "| mean 100 episode reward | 4.8e+03    |\n",
      "| n_updates               | 1358901    |\n",
      "| policy_loss             | -324.12878 |\n",
      "| qf1_loss                | 2.8251176  |\n",
      "| qf2_loss                | 1.7865047  |\n",
      "| time_elapsed            | 10672      |\n",
      "| total timesteps         | 1359000    |\n",
      "| value_loss              | 3.6926785  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.17746873 |\n",
      "| ent_coef_loss           | 0.489496   |\n",
      "| entropy                 | 4.4209957  |\n",
      "| episodes                | 1370       |\n",
      "| fps                     | 126        |\n",
      "| mean 100 episode reward | 4.8e+03    |\n",
      "| n_updates               | 1368901    |\n",
      "| policy_loss             | -320.88437 |\n",
      "| qf1_loss                | 2.676319   |\n",
      "| qf2_loss                | 2.7769415  |\n",
      "| time_elapsed            | 10800      |\n",
      "| total timesteps         | 1369000    |\n",
      "| value_loss              | 3.1795707  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.17699262 |\n",
      "| ent_coef_loss           | 0.0623914  |\n",
      "| entropy                 | 4.311204   |\n",
      "| episodes                | 1380       |\n",
      "| fps                     | 126        |\n",
      "| mean 100 episode reward | 4.84e+03   |\n",
      "| n_updates               | 1378901    |\n",
      "| policy_loss             | -318.0412  |\n",
      "| qf1_loss                | 2.9518833  |\n",
      "| qf2_loss                | 3.4451935  |\n",
      "| time_elapsed            | 10937      |\n",
      "| total timesteps         | 1379000    |\n",
      "| value_loss              | 1.0919949  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.17793994 |\n",
      "| ent_coef_loss           | 0.60378456 |\n",
      "| entropy                 | 4.330788   |\n",
      "| episodes                | 1390       |\n",
      "| fps                     | 125        |\n",
      "| mean 100 episode reward | 4.84e+03   |\n",
      "| n_updates               | 1388901    |\n",
      "| policy_loss             | -314.68048 |\n",
      "| qf1_loss                | 2.6771734  |\n",
      "| qf2_loss                | 2.411577   |\n",
      "| time_elapsed            | 11079      |\n",
      "| total timesteps         | 1389000    |\n",
      "| value_loss              | 2.865615   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.18621644 |\n",
      "| ent_coef_loss           | -1.1159987 |\n",
      "| entropy                 | 4.222791   |\n",
      "| episodes                | 1400       |\n",
      "| fps                     | 124        |\n",
      "| mean 100 episode reward | 4.88e+03   |\n",
      "| n_updates               | 1398901    |\n",
      "| policy_loss             | -315.3355  |\n",
      "| qf1_loss                | 4.7057285  |\n",
      "| qf2_loss                | 5.654916   |\n",
      "| time_elapsed            | 11217      |\n",
      "| total timesteps         | 1399000    |\n",
      "| value_loss              | 2.0709987  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.17315629 |\n",
      "| ent_coef_loss           | -0.9085833 |\n",
      "| entropy                 | 4.2899313  |\n",
      "| episodes                | 1410       |\n",
      "| fps                     | 124        |\n",
      "| mean 100 episode reward | 4.88e+03   |\n",
      "| n_updates               | 1408901    |\n",
      "| policy_loss             | -314.932   |\n",
      "| qf1_loss                | 2.5079896  |\n",
      "| qf2_loss                | 2.2021523  |\n",
      "| time_elapsed            | 11345      |\n",
      "| total timesteps         | 1409000    |\n",
      "| value_loss              | 2.3863597  |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ent_coef                | 0.1729976 |\n",
      "| ent_coef_loss           | 0.6635751 |\n",
      "| entropy                 | 4.2824354 |\n",
      "| episodes                | 1420      |\n",
      "| fps                     | 123       |\n",
      "| mean 100 episode reward | 4.9e+03   |\n",
      "| n_updates               | 1418901   |\n",
      "| policy_loss             | -323.8828 |\n",
      "| qf1_loss                | 3.8147762 |\n",
      "| qf2_loss                | 4.7100134 |\n",
      "| time_elapsed            | 11473     |\n",
      "| total timesteps         | 1419000   |\n",
      "| value_loss              | 2.8979015 |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.18550332 |\n",
      "| ent_coef_loss           | -0.9772273 |\n",
      "| entropy                 | 4.461591   |\n",
      "| episodes                | 1430       |\n",
      "| fps                     | 123        |\n",
      "| mean 100 episode reward | 4.89e+03   |\n",
      "| n_updates               | 1428901    |\n",
      "| policy_loss             | -300.52225 |\n",
      "| qf1_loss                | 4.6401176  |\n",
      "| qf2_loss                | 3.1608276  |\n",
      "| time_elapsed            | 11601      |\n",
      "| total timesteps         | 1429000    |\n",
      "| value_loss              | 1.5011728  |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.1799384  |\n",
      "| ent_coef_loss           | 0.92471254 |\n",
      "| entropy                 | 4.4078207  |\n",
      "| episodes                | 1440       |\n",
      "| fps                     | 122        |\n",
      "| mean 100 episode reward | 4.88e+03   |\n",
      "| n_updates               | 1438901    |\n",
      "| policy_loss             | -306.78738 |\n",
      "| qf1_loss                | 3.867275   |\n",
      "| qf2_loss                | 5.1494904  |\n",
      "| time_elapsed            | 11729      |\n",
      "| total timesteps         | 1439000    |\n",
      "| value_loss              | 3.4941633  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.17173705 |\n",
      "| ent_coef_loss           | 0.95394576 |\n",
      "| entropy                 | 4.3611283  |\n",
      "| episodes                | 1450       |\n",
      "| fps                     | 122        |\n",
      "| mean 100 episode reward | 4.88e+03   |\n",
      "| n_updates               | 1448901    |\n",
      "| policy_loss             | -327.4019  |\n",
      "| qf1_loss                | 5.135725   |\n",
      "| qf2_loss                | 4.1032343  |\n",
      "| time_elapsed            | 11871      |\n",
      "| total timesteps         | 1449000    |\n",
      "| value_loss              | 3.5672727  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.17606893 |\n",
      "| ent_coef_loss           | 0.7044416  |\n",
      "| entropy                 | 4.2280025  |\n",
      "| episodes                | 1460       |\n",
      "| fps                     | 121        |\n",
      "| mean 100 episode reward | 4.87e+03   |\n",
      "| n_updates               | 1458901    |\n",
      "| policy_loss             | -316.18597 |\n",
      "| qf1_loss                | 4.518408   |\n",
      "| qf2_loss                | 6.078766   |\n",
      "| time_elapsed            | 12009      |\n",
      "| total timesteps         | 1459000    |\n",
      "| value_loss              | 2.8420048  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.18092823  |\n",
      "| ent_coef_loss           | -0.39900798 |\n",
      "| entropy                 | 4.2279797   |\n",
      "| episodes                | 1470        |\n",
      "| fps                     | 120         |\n",
      "| mean 100 episode reward | 4.87e+03    |\n",
      "| n_updates               | 1468901     |\n",
      "| policy_loss             | -320.32196  |\n",
      "| qf1_loss                | 3.1795325   |\n",
      "| qf2_loss                | 2.7753897   |\n",
      "| time_elapsed            | 12143       |\n",
      "| total timesteps         | 1469000     |\n",
      "| value_loss              | 1.5681894   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.1843438  |\n",
      "| ent_coef_loss           | 0.30012903 |\n",
      "| entropy                 | 4.455797   |\n",
      "| episodes                | 1480       |\n",
      "| fps                     | 120        |\n",
      "| mean 100 episode reward | 4.87e+03   |\n",
      "| n_updates               | 1478901    |\n",
      "| policy_loss             | -324.57593 |\n",
      "| qf1_loss                | 741.8955   |\n",
      "| qf2_loss                | 735.03973  |\n",
      "| time_elapsed            | 12270      |\n",
      "| total timesteps         | 1479000    |\n",
      "| value_loss              | 2.0466585  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.18022712  |\n",
      "| ent_coef_loss           | -0.42705637 |\n",
      "| entropy                 | 4.476227    |\n",
      "| episodes                | 1490        |\n",
      "| fps                     | 120         |\n",
      "| mean 100 episode reward | 4.87e+03    |\n",
      "| n_updates               | 1488901     |\n",
      "| policy_loss             | -327.3443   |\n",
      "| qf1_loss                | 1.8542511   |\n",
      "| qf2_loss                | 2.364407    |\n",
      "| time_elapsed            | 12396       |\n",
      "| total timesteps         | 1489000     |\n",
      "| value_loss              | 3.712481    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.18132038 |\n",
      "| ent_coef_loss           | 0.3577401  |\n",
      "| entropy                 | 4.5009775  |\n",
      "| episodes                | 1500       |\n",
      "| fps                     | 119        |\n",
      "| mean 100 episode reward | 4.88e+03   |\n",
      "| n_updates               | 1498901    |\n",
      "| policy_loss             | -328.61926 |\n",
      "| qf1_loss                | 4.1737375  |\n",
      "| qf2_loss                | 4.5464807  |\n",
      "| time_elapsed            | 12525      |\n",
      "| total timesteps         | 1499000    |\n",
      "| value_loss              | 2.2020433  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.17967823  |\n",
      "| ent_coef_loss           | -0.40032226 |\n",
      "| entropy                 | 4.1978216   |\n",
      "| episodes                | 1510        |\n",
      "| fps                     | 119         |\n",
      "| mean 100 episode reward | 4.89e+03    |\n",
      "| n_updates               | 1508901     |\n",
      "| policy_loss             | -328.81934  |\n",
      "| qf1_loss                | 6.14275     |\n",
      "| qf2_loss                | 1.978605    |\n",
      "| time_elapsed            | 12658       |\n",
      "| total timesteps         | 1509000     |\n",
      "| value_loss              | 1.7714117   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.17002998 |\n",
      "| ent_coef_loss           | 0.5626205  |\n",
      "| entropy                 | 4.234996   |\n",
      "| episodes                | 1520       |\n",
      "| fps                     | 118        |\n",
      "| mean 100 episode reward | 4.9e+03    |\n",
      "| n_updates               | 1518901    |\n",
      "| policy_loss             | -319.60266 |\n",
      "| qf1_loss                | 3.1725886  |\n",
      "| qf2_loss                | 3.1910863  |\n",
      "| time_elapsed            | 12777      |\n",
      "| total timesteps         | 1519000    |\n",
      "| value_loss              | 2.6412287  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.17400232 |\n",
      "| ent_coef_loss           | 0.72792375 |\n",
      "| entropy                 | 4.54468    |\n",
      "| episodes                | 1530       |\n",
      "| fps                     | 119        |\n",
      "| mean 100 episode reward | 4.91e+03   |\n",
      "| n_updates               | 1528901    |\n",
      "| policy_loss             | -316.555   |\n",
      "| qf1_loss                | 3.7203803  |\n",
      "| qf2_loss                | 2.930448   |\n",
      "| time_elapsed            | 12833      |\n",
      "| total timesteps         | 1529000    |\n",
      "| value_loss              | 1.5502076  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.17876478 |\n",
      "| ent_coef_loss           | 1.1979953  |\n",
      "| entropy                 | 4.4719567  |\n",
      "| episodes                | 1540       |\n",
      "| fps                     | 119        |\n",
      "| mean 100 episode reward | 4.91e+03   |\n",
      "| n_updates               | 1538901    |\n",
      "| policy_loss             | -314.71    |\n",
      "| qf1_loss                | 3.399104   |\n",
      "| qf2_loss                | 2.9672813  |\n",
      "| time_elapsed            | 12890      |\n",
      "| total timesteps         | 1539000    |\n",
      "| value_loss              | 12.165626  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.17819363 |\n",
      "| ent_coef_loss           | 0.33709437 |\n",
      "| entropy                 | 4.3683352  |\n",
      "| episodes                | 1550       |\n",
      "| fps                     | 119        |\n",
      "| mean 100 episode reward | 4.92e+03   |\n",
      "| n_updates               | 1548901    |\n",
      "| policy_loss             | -319.25143 |\n",
      "| qf1_loss                | 3.4806867  |\n",
      "| qf2_loss                | 4.0338755  |\n",
      "| time_elapsed            | 12940      |\n",
      "| total timesteps         | 1549000    |\n",
      "| value_loss              | 3.0066159  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.17633666 |\n",
      "| ent_coef_loss           | 1.7387649  |\n",
      "| entropy                 | 4.162733   |\n",
      "| episodes                | 1560       |\n",
      "| fps                     | 119        |\n",
      "| mean 100 episode reward | 4.93e+03   |\n",
      "| n_updates               | 1558901    |\n",
      "| policy_loss             | -327.40598 |\n",
      "| qf1_loss                | 2.5122232  |\n",
      "| qf2_loss                | 3.1047597  |\n",
      "| time_elapsed            | 13005      |\n",
      "| total timesteps         | 1559000    |\n",
      "| value_loss              | 1.5931649  |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.181264   |\n",
      "| ent_coef_loss           | 0.89816535 |\n",
      "| entropy                 | 4.3499613  |\n",
      "| episodes                | 1570       |\n",
      "| fps                     | 119        |\n",
      "| mean 100 episode reward | 4.93e+03   |\n",
      "| n_updates               | 1568901    |\n",
      "| policy_loss             | -328.73422 |\n",
      "| qf1_loss                | 3.8398209  |\n",
      "| qf2_loss                | 3.1119537  |\n",
      "| time_elapsed            | 13080      |\n",
      "| total timesteps         | 1569000    |\n",
      "| value_loss              | 3.996719   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.18555506 |\n",
      "| ent_coef_loss           | 0.8204219  |\n",
      "| entropy                 | 4.4473777  |\n",
      "| episodes                | 1580       |\n",
      "| fps                     | 120        |\n",
      "| mean 100 episode reward | 4.93e+03   |\n",
      "| n_updates               | 1578901    |\n",
      "| policy_loss             | -324.35495 |\n",
      "| qf1_loss                | 3.5756607  |\n",
      "| qf2_loss                | 5.508414   |\n",
      "| time_elapsed            | 13137      |\n",
      "| total timesteps         | 1579000    |\n",
      "| value_loss              | 12.167901  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.18206862 |\n",
      "| ent_coef_loss           | 0.5057293  |\n",
      "| entropy                 | 4.1825967  |\n",
      "| episodes                | 1590       |\n",
      "| fps                     | 120        |\n",
      "| mean 100 episode reward | 4.94e+03   |\n",
      "| n_updates               | 1588901    |\n",
      "| policy_loss             | -314.54926 |\n",
      "| qf1_loss                | 5.4269977  |\n",
      "| qf2_loss                | 6.880026   |\n",
      "| time_elapsed            | 13199      |\n",
      "| total timesteps         | 1589000    |\n",
      "| value_loss              | 4.3202558  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.1866567  |\n",
      "| ent_coef_loss           | -0.6722286 |\n",
      "| entropy                 | 4.3561935  |\n",
      "| episodes                | 1600       |\n",
      "| fps                     | 120        |\n",
      "| mean 100 episode reward | 4.93e+03   |\n",
      "| n_updates               | 1598901    |\n",
      "| policy_loss             | -318.80127 |\n",
      "| qf1_loss                | 3.0151515  |\n",
      "| qf2_loss                | 2.889759   |\n",
      "| time_elapsed            | 13254      |\n",
      "| total timesteps         | 1599000    |\n",
      "| value_loss              | 2.9728546  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.17013428 |\n",
      "| ent_coef_loss           | 0.07459736 |\n",
      "| entropy                 | 4.2034826  |\n",
      "| episodes                | 1610       |\n",
      "| fps                     | 120        |\n",
      "| mean 100 episode reward | 4.93e+03   |\n",
      "| n_updates               | 1608901    |\n",
      "| policy_loss             | -324.35037 |\n",
      "| qf1_loss                | 2.514597   |\n",
      "| qf2_loss                | 2.3959928  |\n",
      "| time_elapsed            | 13316      |\n",
      "| total timesteps         | 1609000    |\n",
      "| value_loss              | 2.1055622  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.18687885  |\n",
      "| ent_coef_loss           | -0.11169213 |\n",
      "| entropy                 | 4.484935    |\n",
      "| episodes                | 1620        |\n",
      "| fps                     | 121         |\n",
      "| mean 100 episode reward | 4.92e+03    |\n",
      "| n_updates               | 1618901     |\n",
      "| policy_loss             | -318.5321   |\n",
      "| qf1_loss                | 4.501086    |\n",
      "| qf2_loss                | 3.0731282   |\n",
      "| time_elapsed            | 13376       |\n",
      "| total timesteps         | 1619000     |\n",
      "| value_loss              | 7.270707    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| current_lr              | 0.0003       |\n",
      "| ent_coef                | 0.18337613   |\n",
      "| ent_coef_loss           | -0.105318785 |\n",
      "| entropy                 | 4.4140596    |\n",
      "| episodes                | 1630         |\n",
      "| fps                     | 121          |\n",
      "| mean 100 episode reward | 4.92e+03     |\n",
      "| n_updates               | 1628901      |\n",
      "| policy_loss             | -328.80127   |\n",
      "| qf1_loss                | 2.71802      |\n",
      "| qf2_loss                | 2.2421815    |\n",
      "| time_elapsed            | 13440        |\n",
      "| total timesteps         | 1629000      |\n",
      "| value_loss              | 3.565467     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.17576627 |\n",
      "| ent_coef_loss           | -1.5614612 |\n",
      "| entropy                 | 4.5153427  |\n",
      "| episodes                | 1640       |\n",
      "| fps                     | 121        |\n",
      "| mean 100 episode reward | 4.92e+03   |\n",
      "| n_updates               | 1638901    |\n",
      "| policy_loss             | -323.41168 |\n",
      "| qf1_loss                | 3.0653598  |\n",
      "| qf2_loss                | 2.8337762  |\n",
      "| time_elapsed            | 13509      |\n",
      "| total timesteps         | 1639000    |\n",
      "| value_loss              | 5.7975316  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.16910401 |\n",
      "| ent_coef_loss           | -1.1777176 |\n",
      "| entropy                 | 4.586813   |\n",
      "| episodes                | 1650       |\n",
      "| fps                     | 121        |\n",
      "| mean 100 episode reward | 4.92e+03   |\n",
      "| n_updates               | 1648901    |\n",
      "| policy_loss             | -311.30292 |\n",
      "| qf1_loss                | 1.7199613  |\n",
      "| qf2_loss                | 3.1712222  |\n",
      "| time_elapsed            | 13567      |\n",
      "| total timesteps         | 1649000    |\n",
      "| value_loss              | 1.9157975  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.1780241  |\n",
      "| ent_coef_loss           | 0.54551804 |\n",
      "| entropy                 | 4.5182686  |\n",
      "| episodes                | 1660       |\n",
      "| fps                     | 121        |\n",
      "| mean 100 episode reward | 4.92e+03   |\n",
      "| n_updates               | 1658901    |\n",
      "| policy_loss             | -332.08475 |\n",
      "| qf1_loss                | 4.484889   |\n",
      "| qf2_loss                | 3.4375029  |\n",
      "| time_elapsed            | 13623      |\n",
      "| total timesteps         | 1659000    |\n",
      "| value_loss              | 3.392296   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.17603414 |\n",
      "| ent_coef_loss           | -0.5992529 |\n",
      "| entropy                 | 4.335488   |\n",
      "| episodes                | 1670       |\n",
      "| fps                     | 122        |\n",
      "| mean 100 episode reward | 4.88e+03   |\n",
      "| n_updates               | 1668901    |\n",
      "| policy_loss             | -336.6061  |\n",
      "| qf1_loss                | 11.390312  |\n",
      "| qf2_loss                | 7.045532   |\n",
      "| time_elapsed            | 13679      |\n",
      "| total timesteps         | 1669000    |\n",
      "| value_loss              | 1.8434443  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.17746477 |\n",
      "| ent_coef_loss           | 0.36003733 |\n",
      "| entropy                 | 4.3834124  |\n",
      "| episodes                | 1680       |\n",
      "| fps                     | 122        |\n",
      "| mean 100 episode reward | 4.89e+03   |\n",
      "| n_updates               | 1678901    |\n",
      "| policy_loss             | -332.82864 |\n",
      "| qf1_loss                | 3.1585045  |\n",
      "| qf2_loss                | 2.9989145  |\n",
      "| time_elapsed            | 13734      |\n",
      "| total timesteps         | 1679000    |\n",
      "| value_loss              | 2.8860707  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.17836703  |\n",
      "| ent_coef_loss           | -0.99184567 |\n",
      "| entropy                 | 4.451278    |\n",
      "| episodes                | 1690        |\n",
      "| fps                     | 122         |\n",
      "| mean 100 episode reward | 4.9e+03     |\n",
      "| n_updates               | 1688901     |\n",
      "| policy_loss             | -311.6568   |\n",
      "| qf1_loss                | 3.2513728   |\n",
      "| qf2_loss                | 2.313905    |\n",
      "| time_elapsed            | 13785       |\n",
      "| total timesteps         | 1689000     |\n",
      "| value_loss              | 6.225896    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.18437171 |\n",
      "| ent_coef_loss           | -1.555169  |\n",
      "| entropy                 | 4.5410805  |\n",
      "| episodes                | 1700       |\n",
      "| fps                     | 122        |\n",
      "| mean 100 episode reward | 4.9e+03    |\n",
      "| n_updates               | 1698901    |\n",
      "| policy_loss             | -322.0177  |\n",
      "| qf1_loss                | 919.83057  |\n",
      "| qf2_loss                | 912.94336  |\n",
      "| time_elapsed            | 13834      |\n",
      "| total timesteps         | 1699000    |\n",
      "| value_loss              | 6.359398   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.17712645 |\n",
      "| ent_coef_loss           | 1.4838703  |\n",
      "| entropy                 | 4.3579845  |\n",
      "| episodes                | 1710       |\n",
      "| fps                     | 123        |\n",
      "| mean 100 episode reward | 4.9e+03    |\n",
      "| n_updates               | 1708901    |\n",
      "| policy_loss             | -332.84503 |\n",
      "| qf1_loss                | 3.0072584  |\n",
      "| qf2_loss                | 3.7730634  |\n",
      "| time_elapsed            | 13885      |\n",
      "| total timesteps         | 1709000    |\n",
      "| value_loss              | 5.5691557  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.19157541 |\n",
      "| ent_coef_loss           | -0.9540993 |\n",
      "| entropy                 | 4.404004   |\n",
      "| episodes                | 1720       |\n",
      "| fps                     | 123        |\n",
      "| mean 100 episode reward | 4.86e+03   |\n",
      "| n_updates               | 1718901    |\n",
      "| policy_loss             | -335.31967 |\n",
      "| qf1_loss                | 1.8926744  |\n",
      "| qf2_loss                | 2.034655   |\n",
      "| time_elapsed            | 13934      |\n",
      "| total timesteps         | 1719000    |\n",
      "| value_loss              | 2.621173   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.168039   |\n",
      "| ent_coef_loss           | 0.32485414 |\n",
      "| entropy                 | 4.2803144  |\n",
      "| episodes                | 1730       |\n",
      "| fps                     | 123        |\n",
      "| mean 100 episode reward | 4.86e+03   |\n",
      "| n_updates               | 1728901    |\n",
      "| policy_loss             | -334.26968 |\n",
      "| qf1_loss                | 14.450403  |\n",
      "| qf2_loss                | 14.97718   |\n",
      "| time_elapsed            | 13989      |\n",
      "| total timesteps         | 1729000    |\n",
      "| value_loss              | 2.0898504  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.17517532 |\n",
      "| ent_coef_loss           | 0.8046294  |\n",
      "| entropy                 | 4.3701324  |\n",
      "| episodes                | 1740       |\n",
      "| fps                     | 123        |\n",
      "| mean 100 episode reward | 4.86e+03   |\n",
      "| n_updates               | 1738901    |\n",
      "| policy_loss             | -331.3932  |\n",
      "| qf1_loss                | 3.984413   |\n",
      "| qf2_loss                | 2.41439    |\n",
      "| time_elapsed            | 14039      |\n",
      "| total timesteps         | 1739000    |\n",
      "| value_loss              | 3.1248362  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.17827769  |\n",
      "| ent_coef_loss           | -0.90728617 |\n",
      "| entropy                 | 4.6695824   |\n",
      "| episodes                | 1750        |\n",
      "| fps                     | 124         |\n",
      "| mean 100 episode reward | 4.87e+03    |\n",
      "| n_updates               | 1748901     |\n",
      "| policy_loss             | -336.87677  |\n",
      "| qf1_loss                | 1.7475967   |\n",
      "| qf2_loss                | 1.8382022   |\n",
      "| time_elapsed            | 14090       |\n",
      "| total timesteps         | 1749000     |\n",
      "| value_loss              | 1.2978888   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.18256895 |\n",
      "| ent_coef_loss           | 1.0383763  |\n",
      "| entropy                 | 4.193863   |\n",
      "| episodes                | 1760       |\n",
      "| fps                     | 124        |\n",
      "| mean 100 episode reward | 4.86e+03   |\n",
      "| n_updates               | 1758901    |\n",
      "| policy_loss             | -329.70975 |\n",
      "| qf1_loss                | 3.9311202  |\n",
      "| qf2_loss                | 2.9000418  |\n",
      "| time_elapsed            | 14142      |\n",
      "| total timesteps         | 1759000    |\n",
      "| value_loss              | 3.8799102  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.17777126 |\n",
      "| ent_coef_loss           | 0.38092452 |\n",
      "| entropy                 | 4.2948375  |\n",
      "| episodes                | 1770       |\n",
      "| fps                     | 124        |\n",
      "| mean 100 episode reward | 4.91e+03   |\n",
      "| n_updates               | 1768901    |\n",
      "| policy_loss             | -329.18362 |\n",
      "| qf1_loss                | 2.7986689  |\n",
      "| qf2_loss                | 2.5950975  |\n",
      "| time_elapsed            | 14193      |\n",
      "| total timesteps         | 1769000    |\n",
      "| value_loss              | 4.0348086  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.17299885 |\n",
      "| ent_coef_loss           | 1.6474276  |\n",
      "| entropy                 | 4.464868   |\n",
      "| episodes                | 1780       |\n",
      "| fps                     | 124        |\n",
      "| mean 100 episode reward | 4.91e+03   |\n",
      "| n_updates               | 1778901    |\n",
      "| policy_loss             | -329.3581  |\n",
      "| qf1_loss                | 2.406456   |\n",
      "| qf2_loss                | 1.8481562  |\n",
      "| time_elapsed            | 14240      |\n",
      "| total timesteps         | 1779000    |\n",
      "| value_loss              | 3.0461829  |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| current_lr              | 0.0003       |\n",
      "| ent_coef                | 0.16987003   |\n",
      "| ent_coef_loss           | -0.040287986 |\n",
      "| entropy                 | 4.2663136    |\n",
      "| episodes                | 1790         |\n",
      "| fps                     | 125          |\n",
      "| mean 100 episode reward | 4.91e+03     |\n",
      "| n_updates               | 1788901      |\n",
      "| policy_loss             | -333.29245   |\n",
      "| qf1_loss                | 2.876503     |\n",
      "| qf2_loss                | 3.168164     |\n",
      "| time_elapsed            | 14287        |\n",
      "| total timesteps         | 1789000      |\n",
      "| value_loss              | 2.0630054    |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.17029615 |\n",
      "| ent_coef_loss           | 0.17861855 |\n",
      "| entropy                 | 4.3118744  |\n",
      "| episodes                | 1800       |\n",
      "| fps                     | 125        |\n",
      "| mean 100 episode reward | 4.92e+03   |\n",
      "| n_updates               | 1798901    |\n",
      "| policy_loss             | -320.77603 |\n",
      "| qf1_loss                | 3.6441605  |\n",
      "| qf2_loss                | 3.6486242  |\n",
      "| time_elapsed            | 14339      |\n",
      "| total timesteps         | 1799000    |\n",
      "| value_loss              | 15.310188  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.17315386 |\n",
      "| ent_coef_loss           | -1.2740623 |\n",
      "| entropy                 | 4.5325537  |\n",
      "| episodes                | 1810       |\n",
      "| fps                     | 125        |\n",
      "| mean 100 episode reward | 4.89e+03   |\n",
      "| n_updates               | 1808901    |\n",
      "| policy_loss             | -329.86392 |\n",
      "| qf1_loss                | 2.0407553  |\n",
      "| qf2_loss                | 2.1121516  |\n",
      "| time_elapsed            | 14388      |\n",
      "| total timesteps         | 1809000    |\n",
      "| value_loss              | 1.6073381  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.16624255 |\n",
      "| ent_coef_loss           | 1.5744658  |\n",
      "| entropy                 | 4.277008   |\n",
      "| episodes                | 1820       |\n",
      "| fps                     | 125        |\n",
      "| mean 100 episode reward | 4.94e+03   |\n",
      "| n_updates               | 1818901    |\n",
      "| policy_loss             | -331.03207 |\n",
      "| qf1_loss                | 5.0879498  |\n",
      "| qf2_loss                | 5.167717   |\n",
      "| time_elapsed            | 14440      |\n",
      "| total timesteps         | 1819000    |\n",
      "| value_loss              | 8.473216   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.1770494  |\n",
      "| ent_coef_loss           | 0.70660067 |\n",
      "| entropy                 | 4.5409245  |\n",
      "| episodes                | 1830       |\n",
      "| fps                     | 126        |\n",
      "| mean 100 episode reward | 4.96e+03   |\n",
      "| n_updates               | 1828901    |\n",
      "| policy_loss             | -326.312   |\n",
      "| qf1_loss                | 17.06094   |\n",
      "| qf2_loss                | 17.392847  |\n",
      "| time_elapsed            | 14488      |\n",
      "| total timesteps         | 1829000    |\n",
      "| value_loss              | 6.9503317  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.17150363 |\n",
      "| ent_coef_loss           | -0.5938522 |\n",
      "| entropy                 | 4.287821   |\n",
      "| episodes                | 1840       |\n",
      "| fps                     | 126        |\n",
      "| mean 100 episode reward | 4.96e+03   |\n",
      "| n_updates               | 1838901    |\n",
      "| policy_loss             | -333.6386  |\n",
      "| qf1_loss                | 2.9090881  |\n",
      "| qf2_loss                | 2.7685113  |\n",
      "| time_elapsed            | 14536      |\n",
      "| total timesteps         | 1839000    |\n",
      "| value_loss              | 3.50057    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.17617744 |\n",
      "| ent_coef_loss           | 0.62890303 |\n",
      "| entropy                 | 4.146413   |\n",
      "| episodes                | 1850       |\n",
      "| fps                     | 126        |\n",
      "| mean 100 episode reward | 4.95e+03   |\n",
      "| n_updates               | 1848901    |\n",
      "| policy_loss             | -337.46802 |\n",
      "| qf1_loss                | 4.71308    |\n",
      "| qf2_loss                | 4.827237   |\n",
      "| time_elapsed            | 14584      |\n",
      "| total timesteps         | 1849000    |\n",
      "| value_loss              | 7.519025   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.16298369  |\n",
      "| ent_coef_loss           | -0.22336426 |\n",
      "| entropy                 | 4.090256    |\n",
      "| episodes                | 1860        |\n",
      "| fps                     | 127         |\n",
      "| mean 100 episode reward | 4.96e+03    |\n",
      "| n_updates               | 1858901     |\n",
      "| policy_loss             | -335.26727  |\n",
      "| qf1_loss                | 2.9071455   |\n",
      "| qf2_loss                | 3.3499012   |\n",
      "| time_elapsed            | 14634       |\n",
      "| total timesteps         | 1859000     |\n",
      "| value_loss              | 4.400309    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.17805284 |\n",
      "| ent_coef_loss           | -1.4256387 |\n",
      "| entropy                 | 4.365349   |\n",
      "| episodes                | 1870       |\n",
      "| fps                     | 127        |\n",
      "| mean 100 episode reward | 4.96e+03   |\n",
      "| n_updates               | 1868901    |\n",
      "| policy_loss             | -333.84796 |\n",
      "| qf1_loss                | 22.603857  |\n",
      "| qf2_loss                | 23.122934  |\n",
      "| time_elapsed            | 14681      |\n",
      "| total timesteps         | 1869000    |\n",
      "| value_loss              | 2.437392   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.17464736 |\n",
      "| ent_coef_loss           | 1.0709577  |\n",
      "| entropy                 | 4.3619986  |\n",
      "| episodes                | 1880       |\n",
      "| fps                     | 127        |\n",
      "| mean 100 episode reward | 4.97e+03   |\n",
      "| n_updates               | 1878901    |\n",
      "| policy_loss             | -338.245   |\n",
      "| qf1_loss                | 4.7358084  |\n",
      "| qf2_loss                | 4.918112   |\n",
      "| time_elapsed            | 14737      |\n",
      "| total timesteps         | 1879000    |\n",
      "| value_loss              | 2.9733114  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.17045751  |\n",
      "| ent_coef_loss           | -0.39327517 |\n",
      "| entropy                 | 4.5229025   |\n",
      "| episodes                | 1890        |\n",
      "| fps                     | 127         |\n",
      "| mean 100 episode reward | 4.98e+03    |\n",
      "| n_updates               | 1888901     |\n",
      "| policy_loss             | -333.7519   |\n",
      "| qf1_loss                | 4.2922363   |\n",
      "| qf2_loss                | 4.2237883   |\n",
      "| time_elapsed            | 14783       |\n",
      "| total timesteps         | 1889000     |\n",
      "| value_loss              | 5.589058    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.16767474  |\n",
      "| ent_coef_loss           | -0.55594456 |\n",
      "| entropy                 | 4.3559628   |\n",
      "| episodes                | 1900        |\n",
      "| fps                     | 128         |\n",
      "| mean 100 episode reward | 4.98e+03    |\n",
      "| n_updates               | 1898901     |\n",
      "| policy_loss             | -333.967    |\n",
      "| qf1_loss                | 3.5257695   |\n",
      "| qf2_loss                | 4.7994576   |\n",
      "| time_elapsed            | 14832       |\n",
      "| total timesteps         | 1899000     |\n",
      "| value_loss              | 3.3813727   |\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# TRAIN THE MODEL\n",
    "model.learn(total_timesteps=int(3e6), log_interval=10)\n",
    "model.save(\"half_cheetah_3M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gym' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ecd16610c515>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# RUN THE SAVED MODEL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'HumanoidStandup-v2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSAC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"humanoid_standup_2M\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gym' is not defined"
     ]
    }
   ],
   "source": [
    "# RUN THE SAVED MODEL\n",
    "env = gym.make('HumanoidStandup-v2')\n",
    "model = SAC.load(\"humanoid_standup_2M\")\n",
    "\n",
    "for _ in range(10):\n",
    "    obs = env.reset()\n",
    "    for _ in range(1000):\n",
    "        action, _states = model.predict(obs)\n",
    "        obs, rewards, dones, info = env.step(action)\n",
    "        env.render()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800\"\n",
       "            src=\"http://localhost:6009\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f83b606c290>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# DISPLAY THE RESULTS\n",
    "%tensorboard --logdir sac_half_cheetah_tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task: Teach an 'ant-like' quadruped a gait to move forward "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:191: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:200: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/stable_baselines/sac/sac.py:142: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/stable_baselines/common/input.py:25: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/stable_baselines/sac/policies.py:194: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f95562471d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f95562471d0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f95562471d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f95562471d0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:From /home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/stable_baselines/common/tf_layers.py:57: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From /home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f955c55b350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f955c55b350>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f955c55b350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f955c55b350>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9557cc2250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9557cc2250>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9557cc2250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9557cc2250>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9548382210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9548382210>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9548382210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9548382210>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9557cc2250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9557cc2250>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9557cc2250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9557cc2250>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From /home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/stable_baselines/sac/policies.py:216: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f95482df810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f95482df810>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f95482df810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f95482df810>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9548319550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9548319550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9548319550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9548319550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f95483f1f90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f95483f1f90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f95483f1f90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f95483f1f90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f95482df9d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f95482df9d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f95482df9d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f95482df9d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f95482df9d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f95482df9d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f95482df9d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f95482df9d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f95482df9d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f95482df9d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f95482df9d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f95482df9d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f955c723ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f955c723ad0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f955c723ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f955c723ad0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9548367bd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9548367bd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9548367bd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9548367bd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9579706090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9579706090>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9579706090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9579706090>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f95483f0910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f95483f0910>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f95483f0910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f95483f0910>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f955c723ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f955c723ad0>>: AttributeError: module 'gast' has no attribute 'Num'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f955c723ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f955c723ad0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f95483f9990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f95483f9990>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f95483f9990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f95483f9990>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f954838b0d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f954838b0d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f954838b0d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f954838b0d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9548229710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9548229710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9548229710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9548229710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9557033a50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9557033a50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9557033a50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9557033a50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9557033a50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9557033a50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9557033a50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9557033a50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9579705f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9579705f50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9579705f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9579705f50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f9548305650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f9548305650>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f9548305650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f9548305650>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f954838b0d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f954838b0d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f954838b0d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f954838b0d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f954838b0d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f954838b0d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f954838b0d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f954838b0d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f95483f1110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f95483f1110>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f95483f1110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f95483f1110>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From /home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/stable_baselines/sac/sac.py:233: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/stable_baselines/sac/sac.py:296: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/stable_baselines/sac/sac.py:316: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "Observation Space Dimensions: 111\n",
      "Action Space Dimensions: 8\n"
     ]
    }
   ],
   "source": [
    "# DEFINE THE ENVIRONMENT/MODEL WITH TUNED PARAMETERS\n",
    "env = gym.make('Ant-v2')\n",
    "policy_kwargs = dict(layers=[256, 256])\n",
    "model = SAC(MlpPolicy, env, verbose=1, tensorboard_log=\"./sac_ant_tensorboard/\", \n",
    "            policy_kwargs=policy_kwargs, buffer_size=1000000)\n",
    "# PRINT THE STATE SPACE DIMENSIONS\n",
    "obs_dim = env.observation_space.shape[0]\n",
    "act_dim = env.action_space.shape[0]\n",
    "print('Observation Space Dimensions: %d' % obs_dim)\n",
    "print('Action Space Dimensions: %d' % act_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/stable_baselines/common/base_class.py:1143: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.8627882   |\n",
      "| ent_coef_loss           | -1.9477232  |\n",
      "| entropy                 | 10.2698     |\n",
      "| episodes                | 10          |\n",
      "| fps                     | 126         |\n",
      "| mean 100 episode reward | -33.4       |\n",
      "| n_updates               | 485         |\n",
      "| policy_loss             | -11.5777645 |\n",
      "| qf1_loss                | 0.27244824  |\n",
      "| qf2_loss                | 0.2739787   |\n",
      "| time_elapsed            | 4           |\n",
      "| total timesteps         | 584         |\n",
      "| value_loss              | 0.77284145  |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.3999634  |\n",
      "| ent_coef_loss           | -10.746237 |\n",
      "| entropy                 | 9.836305   |\n",
      "| episodes                | 20         |\n",
      "| fps                     | 124        |\n",
      "| mean 100 episode reward | -77.7      |\n",
      "| n_updates               | 3103       |\n",
      "| policy_loss             | -32.161644 |\n",
      "| qf1_loss                | 1.1601512  |\n",
      "| qf2_loss                | 1.4109118  |\n",
      "| time_elapsed            | 25         |\n",
      "| total timesteps         | 3202       |\n",
      "| value_loss              | 2.4828126  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.14348103 |\n",
      "| ent_coef_loss           | -20.598236 |\n",
      "| entropy                 | 8.857039   |\n",
      "| episodes                | 30         |\n",
      "| fps                     | 119        |\n",
      "| mean 100 episode reward | -125       |\n",
      "| n_updates               | 6670       |\n",
      "| policy_loss             | -26.322102 |\n",
      "| qf1_loss                | 0.7194012  |\n",
      "| qf2_loss                | 0.71684164 |\n",
      "| time_elapsed            | 56         |\n",
      "| total timesteps         | 6769       |\n",
      "| value_loss              | 1.0928402  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03991561 |\n",
      "| ent_coef_loss           | -22.773174 |\n",
      "| entropy                 | 4.181686   |\n",
      "| episodes                | 40         |\n",
      "| fps                     | 110        |\n",
      "| mean 100 episode reward | -155       |\n",
      "| n_updates               | 11255      |\n",
      "| policy_loss             | -10.811559 |\n",
      "| qf1_loss                | 0.83176404 |\n",
      "| qf2_loss                | 0.7878916  |\n",
      "| time_elapsed            | 102        |\n",
      "| total timesteps         | 11354      |\n",
      "| value_loss              | 0.5142597  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.015274689 |\n",
      "| ent_coef_loss           | 2.1881733   |\n",
      "| entropy                 | -6.8771563  |\n",
      "| episodes                | 50          |\n",
      "| fps                     | 102         |\n",
      "| mean 100 episode reward | -50.4       |\n",
      "| n_updates               | 20320       |\n",
      "| policy_loss             | -12.061232  |\n",
      "| qf1_loss                | 2.5824592   |\n",
      "| qf2_loss                | 2.5668707   |\n",
      "| time_elapsed            | 198         |\n",
      "| total timesteps         | 20419       |\n",
      "| value_loss              | 0.18190809  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.022902045 |\n",
      "| ent_coef_loss           | 0.73293734  |\n",
      "| entropy                 | -6.8186326  |\n",
      "| episodes                | 60          |\n",
      "| fps                     | 101         |\n",
      "| mean 100 episode reward | 85.1        |\n",
      "| n_updates               | 30320       |\n",
      "| policy_loss             | -25.51247   |\n",
      "| qf1_loss                | 0.18231967  |\n",
      "| qf2_loss                | 0.1574294   |\n",
      "| time_elapsed            | 298         |\n",
      "| total timesteps         | 30419       |\n",
      "| value_loss              | 0.17907009  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.024665402 |\n",
      "| ent_coef_loss           | 0.9849173   |\n",
      "| entropy                 | -6.035687   |\n",
      "| episodes                | 70          |\n",
      "| fps                     | 99          |\n",
      "| mean 100 episode reward | 186         |\n",
      "| n_updates               | 40320       |\n",
      "| policy_loss             | -33.013123  |\n",
      "| qf1_loss                | 0.3052775   |\n",
      "| qf2_loss                | 0.17985974  |\n",
      "| time_elapsed            | 406         |\n",
      "| total timesteps         | 40419       |\n",
      "| value_loss              | 0.26437145  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.024625799 |\n",
      "| ent_coef_loss           | 2.3569303   |\n",
      "| entropy                 | -6.034145   |\n",
      "| episodes                | 80          |\n",
      "| fps                     | 98          |\n",
      "| mean 100 episode reward | 263         |\n",
      "| n_updates               | 50320       |\n",
      "| policy_loss             | -39.697365  |\n",
      "| qf1_loss                | 0.25900316  |\n",
      "| qf2_loss                | 0.22716607  |\n",
      "| time_elapsed            | 512         |\n",
      "| total timesteps         | 50419       |\n",
      "| value_loss              | 0.45050955  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.026971174 |\n",
      "| ent_coef_loss           | 0.86479986  |\n",
      "| entropy                 | -4.5992327  |\n",
      "| episodes                | 90          |\n",
      "| fps                     | 100         |\n",
      "| mean 100 episode reward | 324         |\n",
      "| n_updates               | 60320       |\n",
      "| policy_loss             | -43.530743  |\n",
      "| qf1_loss                | 0.5209969   |\n",
      "| qf2_loss                | 0.27750623  |\n",
      "| time_elapsed            | 601         |\n",
      "| total timesteps         | 60419       |\n",
      "| value_loss              | 0.46627814  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.026817951 |\n",
      "| ent_coef_loss           | -0.52745116 |\n",
      "| entropy                 | -5.260138   |\n",
      "| episodes                | 100         |\n",
      "| fps                     | 103         |\n",
      "| mean 100 episode reward | 341         |\n",
      "| n_updates               | 68804       |\n",
      "| policy_loss             | -45.58017   |\n",
      "| qf1_loss                | 0.11836146  |\n",
      "| qf2_loss                | 0.3892188   |\n",
      "| time_elapsed            | 666         |\n",
      "| total timesteps         | 68903       |\n",
      "| value_loss              | 0.22661419  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.026056312 |\n",
      "| ent_coef_loss           | -1.1160566  |\n",
      "| entropy                 | -5.59061    |\n",
      "| episodes                | 110         |\n",
      "| fps                     | 107         |\n",
      "| mean 100 episode reward | 409         |\n",
      "| n_updates               | 77817       |\n",
      "| policy_loss             | -47.078995  |\n",
      "| qf1_loss                | 0.28085     |\n",
      "| qf2_loss                | 0.18845266  |\n",
      "| time_elapsed            | 723         |\n",
      "| total timesteps         | 77916       |\n",
      "| value_loss              | 0.5619681   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.025992155 |\n",
      "| ent_coef_loss           | 0.7277574   |\n",
      "| entropy                 | -6.5722833  |\n",
      "| episodes                | 120         |\n",
      "| fps                     | 111         |\n",
      "| mean 100 episode reward | 502         |\n",
      "| n_updates               | 87817       |\n",
      "| policy_loss             | -49.24279   |\n",
      "| qf1_loss                | 0.38593146  |\n",
      "| qf2_loss                | 0.40060446  |\n",
      "| time_elapsed            | 786         |\n",
      "| total timesteps         | 87916       |\n",
      "| value_loss              | 1.1924994   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.025968846 |\n",
      "| ent_coef_loss           | 1.9851773   |\n",
      "| entropy                 | -7.4375286  |\n",
      "| episodes                | 130         |\n",
      "| fps                     | 115         |\n",
      "| mean 100 episode reward | 605         |\n",
      "| n_updates               | 97817       |\n",
      "| policy_loss             | -50.29412   |\n",
      "| qf1_loss                | 0.30497742  |\n",
      "| qf2_loss                | 0.13764852  |\n",
      "| time_elapsed            | 849         |\n",
      "| total timesteps         | 97916       |\n",
      "| value_loss              | 0.16871919  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.024720319 |\n",
      "| ent_coef_loss           | 0.013224602 |\n",
      "| entropy                 | -5.7065244  |\n",
      "| episodes                | 140         |\n",
      "| fps                     | 118         |\n",
      "| mean 100 episode reward | 711         |\n",
      "| n_updates               | 107817      |\n",
      "| policy_loss             | -51.92824   |\n",
      "| qf1_loss                | 0.32712835  |\n",
      "| qf2_loss                | 0.25288135  |\n",
      "| time_elapsed            | 913         |\n",
      "| total timesteps         | 107916      |\n",
      "| value_loss              | 0.34127104  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.024197282 |\n",
      "| ent_coef_loss           | -0.26974642 |\n",
      "| entropy                 | -6.5464582  |\n",
      "| episodes                | 150         |\n",
      "| fps                     | 120         |\n",
      "| mean 100 episode reward | 758         |\n",
      "| n_updates               | 117817      |\n",
      "| policy_loss             | -53.88896   |\n",
      "| qf1_loss                | 0.08737109  |\n",
      "| qf2_loss                | 0.049471375 |\n",
      "| time_elapsed            | 977         |\n",
      "| total timesteps         | 117916      |\n",
      "| value_loss              | 0.089210056 |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.023163153 |\n",
      "| ent_coef_loss           | 0.11079049  |\n",
      "| entropy                 | -6.2245226  |\n",
      "| episodes                | 160         |\n",
      "| fps                     | 122         |\n",
      "| mean 100 episode reward | 764         |\n",
      "| n_updates               | 127817      |\n",
      "| policy_loss             | -54.228325  |\n",
      "| qf1_loss                | 0.34262577  |\n",
      "| qf2_loss                | 0.20947912  |\n",
      "| time_elapsed            | 1044        |\n",
      "| total timesteps         | 127916      |\n",
      "| value_loss              | 0.15454647  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.026927022 |\n",
      "| ent_coef_loss           | -1.5392364  |\n",
      "| entropy                 | -7.0919757  |\n",
      "| episodes                | 170         |\n",
      "| fps                     | 124         |\n",
      "| mean 100 episode reward | 762         |\n",
      "| n_updates               | 137817      |\n",
      "| policy_loss             | -55.749943  |\n",
      "| qf1_loss                | 0.2865283   |\n",
      "| qf2_loss                | 0.23257996  |\n",
      "| time_elapsed            | 1107        |\n",
      "| total timesteps         | 137916      |\n",
      "| value_loss              | 0.17570972  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.023141602 |\n",
      "| ent_coef_loss           | -1.6145122  |\n",
      "| entropy                 | -6.4311075  |\n",
      "| episodes                | 180         |\n",
      "| fps                     | 126         |\n",
      "| mean 100 episode reward | 761         |\n",
      "| n_updates               | 147817      |\n",
      "| policy_loss             | -56.020073  |\n",
      "| qf1_loss                | 25.43193    |\n",
      "| qf2_loss                | 25.34668    |\n",
      "| time_elapsed            | 1170        |\n",
      "| total timesteps         | 147916      |\n",
      "| value_loss              | 0.23083845  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.020874396 |\n",
      "| ent_coef_loss           | 2.3855534   |\n",
      "| entropy                 | -6.5144415  |\n",
      "| episodes                | 190         |\n",
      "| fps                     | 128         |\n",
      "| mean 100 episode reward | 762         |\n",
      "| n_updates               | 157817      |\n",
      "| policy_loss             | -55.176903  |\n",
      "| qf1_loss                | 0.18806809  |\n",
      "| qf2_loss                | 0.21862482  |\n",
      "| time_elapsed            | 1224        |\n",
      "| total timesteps         | 157916      |\n",
      "| value_loss              | 0.39377618  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.022338709 |\n",
      "| ent_coef_loss           | -0.51781964 |\n",
      "| entropy                 | -6.68474    |\n",
      "| episodes                | 200         |\n",
      "| fps                     | 131         |\n",
      "| mean 100 episode reward | 797         |\n",
      "| n_updates               | 167817      |\n",
      "| policy_loss             | -57.641384  |\n",
      "| qf1_loss                | 0.117003925 |\n",
      "| qf2_loss                | 0.07618989  |\n",
      "| time_elapsed            | 1279        |\n",
      "| total timesteps         | 167916      |\n",
      "| value_loss              | 0.124566935 |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.022236774 |\n",
      "| ent_coef_loss           | 2.1497674   |\n",
      "| entropy                 | -7.360957   |\n",
      "| episodes                | 210         |\n",
      "| fps                     | 133         |\n",
      "| mean 100 episode reward | 810         |\n",
      "| n_updates               | 177817      |\n",
      "| policy_loss             | -57.750008  |\n",
      "| qf1_loss                | 0.056371644 |\n",
      "| qf2_loss                | 0.058907066 |\n",
      "| time_elapsed            | 1335        |\n",
      "| total timesteps         | 177916      |\n",
      "| value_loss              | 0.095012    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.022871498 |\n",
      "| ent_coef_loss           | 0.38796398  |\n",
      "| entropy                 | -6.647196   |\n",
      "| episodes                | 220         |\n",
      "| fps                     | 133         |\n",
      "| mean 100 episode reward | 813         |\n",
      "| n_updates               | 187817      |\n",
      "| policy_loss             | -58.8407    |\n",
      "| qf1_loss                | 0.32481045  |\n",
      "| qf2_loss                | 0.24787948  |\n",
      "| time_elapsed            | 1403        |\n",
      "| total timesteps         | 187916      |\n",
      "| value_loss              | 1.4602989   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.024148531 |\n",
      "| ent_coef_loss           | 1.8855957   |\n",
      "| entropy                 | -7.086855   |\n",
      "| episodes                | 230         |\n",
      "| fps                     | 134         |\n",
      "| mean 100 episode reward | 814         |\n",
      "| n_updates               | 197817      |\n",
      "| policy_loss             | -59.475372  |\n",
      "| qf1_loss                | 0.14256288  |\n",
      "| qf2_loss                | 0.18278168  |\n",
      "| time_elapsed            | 1468        |\n",
      "| total timesteps         | 197916      |\n",
      "| value_loss              | 0.17264724  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.024267102 |\n",
      "| ent_coef_loss           | 0.4797616   |\n",
      "| entropy                 | -7.0165997  |\n",
      "| episodes                | 240         |\n",
      "| fps                     | 135         |\n",
      "| mean 100 episode reward | 814         |\n",
      "| n_updates               | 207817      |\n",
      "| policy_loss             | -58.985405  |\n",
      "| qf1_loss                | 0.032918416 |\n",
      "| qf2_loss                | 0.050760385 |\n",
      "| time_elapsed            | 1532        |\n",
      "| total timesteps         | 207916      |\n",
      "| value_loss              | 0.048118547 |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.024201483 |\n",
      "| ent_coef_loss           | -0.7991313  |\n",
      "| entropy                 | -7.152743   |\n",
      "| episodes                | 250         |\n",
      "| fps                     | 136         |\n",
      "| mean 100 episode reward | 814         |\n",
      "| n_updates               | 217817      |\n",
      "| policy_loss             | -58.83373   |\n",
      "| qf1_loss                | 0.06275046  |\n",
      "| qf2_loss                | 0.044181906 |\n",
      "| time_elapsed            | 1596        |\n",
      "| total timesteps         | 217916      |\n",
      "| value_loss              | 0.038850404 |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.025058402 |\n",
      "| ent_coef_loss           | -1.9773781  |\n",
      "| entropy                 | -7.095413   |\n",
      "| episodes                | 260         |\n",
      "| fps                     | 136         |\n",
      "| mean 100 episode reward | 816         |\n",
      "| n_updates               | 227817      |\n",
      "| policy_loss             | -59.257843  |\n",
      "| qf1_loss                | 0.027290449 |\n",
      "| qf2_loss                | 0.014171792 |\n",
      "| time_elapsed            | 1663        |\n",
      "| total timesteps         | 227916      |\n",
      "| value_loss              | 0.029510545 |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.023234596 |\n",
      "| ent_coef_loss           | 0.20009741  |\n",
      "| entropy                 | -6.74655    |\n",
      "| episodes                | 270         |\n",
      "| fps                     | 137         |\n",
      "| mean 100 episode reward | 823         |\n",
      "| n_updates               | 237817      |\n",
      "| policy_loss             | -58.912407  |\n",
      "| qf1_loss                | 0.0745229   |\n",
      "| qf2_loss                | 0.07675649  |\n",
      "| time_elapsed            | 1728        |\n",
      "| total timesteps         | 237916      |\n",
      "| value_loss              | 0.088967204 |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.024288323 |\n",
      "| ent_coef_loss           | 1.1582607   |\n",
      "| entropy                 | -7.172522   |\n",
      "| episodes                | 280         |\n",
      "| fps                     | 138         |\n",
      "| mean 100 episode reward | 828         |\n",
      "| n_updates               | 247817      |\n",
      "| policy_loss             | -60.272552  |\n",
      "| qf1_loss                | 24.267141   |\n",
      "| qf2_loss                | 24.500751   |\n",
      "| time_elapsed            | 1792        |\n",
      "| total timesteps         | 247916      |\n",
      "| value_loss              | 0.24306011  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028018564 |\n",
      "| ent_coef_loss           | -3.4438744  |\n",
      "| entropy                 | -6.3750887  |\n",
      "| episodes                | 290         |\n",
      "| fps                     | 139         |\n",
      "| mean 100 episode reward | 832         |\n",
      "| n_updates               | 257817      |\n",
      "| policy_loss             | -59.940956  |\n",
      "| qf1_loss                | 0.16156565  |\n",
      "| qf2_loss                | 0.06576063  |\n",
      "| time_elapsed            | 1855        |\n",
      "| total timesteps         | 257916      |\n",
      "| value_loss              | 0.20534286  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.022791121 |\n",
      "| ent_coef_loss           | -0.30263245 |\n",
      "| entropy                 | -7.072931   |\n",
      "| episodes                | 300         |\n",
      "| fps                     | 139         |\n",
      "| mean 100 episode reward | 833         |\n",
      "| n_updates               | 267817      |\n",
      "| policy_loss             | -59.02337   |\n",
      "| qf1_loss                | 0.03369482  |\n",
      "| qf2_loss                | 0.049475927 |\n",
      "| time_elapsed            | 1919        |\n",
      "| total timesteps         | 267916      |\n",
      "| value_loss              | 0.08843054  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.023619205 |\n",
      "| ent_coef_loss           | -1.0691667  |\n",
      "| entropy                 | -6.140114   |\n",
      "| episodes                | 310         |\n",
      "| fps                     | 140         |\n",
      "| mean 100 episode reward | 834         |\n",
      "| n_updates               | 277817      |\n",
      "| policy_loss             | -59.438957  |\n",
      "| qf1_loss                | 0.39553106  |\n",
      "| qf2_loss                | 0.37194386  |\n",
      "| time_elapsed            | 1984        |\n",
      "| total timesteps         | 277916      |\n",
      "| value_loss              | 0.48454776  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.02558631  |\n",
      "| ent_coef_loss           | -2.5462651  |\n",
      "| entropy                 | -6.877081   |\n",
      "| episodes                | 320         |\n",
      "| fps                     | 140         |\n",
      "| mean 100 episode reward | 836         |\n",
      "| n_updates               | 287817      |\n",
      "| policy_loss             | -59.83044   |\n",
      "| qf1_loss                | 0.032365493 |\n",
      "| qf2_loss                | 0.09322849  |\n",
      "| time_elapsed            | 2047        |\n",
      "| total timesteps         | 287916      |\n",
      "| value_loss              | 0.07052177  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.021418227 |\n",
      "| ent_coef_loss           | -0.5047934  |\n",
      "| entropy                 | -7.3368597  |\n",
      "| episodes                | 330         |\n",
      "| fps                     | 141         |\n",
      "| mean 100 episode reward | 838         |\n",
      "| n_updates               | 297817      |\n",
      "| policy_loss             | -60.301483  |\n",
      "| qf1_loss                | 0.034962386 |\n",
      "| qf2_loss                | 0.041158266 |\n",
      "| time_elapsed            | 2111        |\n",
      "| total timesteps         | 297916      |\n",
      "| value_loss              | 0.061198942 |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.023479762 |\n",
      "| ent_coef_loss           | -0.20810318 |\n",
      "| entropy                 | -7.511878   |\n",
      "| episodes                | 340         |\n",
      "| fps                     | 141         |\n",
      "| mean 100 episode reward | 841         |\n",
      "| n_updates               | 307817      |\n",
      "| policy_loss             | -60.152405  |\n",
      "| qf1_loss                | 0.01691461  |\n",
      "| qf2_loss                | 0.021815378 |\n",
      "| time_elapsed            | 2175        |\n",
      "| total timesteps         | 307916      |\n",
      "| value_loss              | 0.059158966 |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.020606697 |\n",
      "| ent_coef_loss           | -1.9038948  |\n",
      "| entropy                 | -6.9129906  |\n",
      "| episodes                | 350         |\n",
      "| fps                     | 141         |\n",
      "| mean 100 episode reward | 844         |\n",
      "| n_updates               | 317817      |\n",
      "| policy_loss             | -60.830666  |\n",
      "| qf1_loss                | 0.118863896 |\n",
      "| qf2_loss                | 0.10317789  |\n",
      "| time_elapsed            | 2244        |\n",
      "| total timesteps         | 317916      |\n",
      "| value_loss              | 0.01314541  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.021916049 |\n",
      "| ent_coef_loss           | -0.3409056  |\n",
      "| entropy                 | -7.589339   |\n",
      "| episodes                | 360         |\n",
      "| fps                     | 141         |\n",
      "| mean 100 episode reward | 846         |\n",
      "| n_updates               | 327817      |\n",
      "| policy_loss             | -61.606422  |\n",
      "| qf1_loss                | 0.05575387  |\n",
      "| qf2_loss                | 0.114915445 |\n",
      "| time_elapsed            | 2309        |\n",
      "| total timesteps         | 327916      |\n",
      "| value_loss              | 0.031641144 |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.02206492  |\n",
      "| ent_coef_loss           | 1.9932759   |\n",
      "| entropy                 | -7.6622963  |\n",
      "| episodes                | 370         |\n",
      "| fps                     | 142         |\n",
      "| mean 100 episode reward | 847         |\n",
      "| n_updates               | 337817      |\n",
      "| policy_loss             | -61.885887  |\n",
      "| qf1_loss                | 0.1526151   |\n",
      "| qf2_loss                | 0.100434124 |\n",
      "| time_elapsed            | 2376        |\n",
      "| total timesteps         | 337916      |\n",
      "| value_loss              | 0.028615285 |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.02220908  |\n",
      "| ent_coef_loss           | -0.80502725 |\n",
      "| entropy                 | -6.2566586  |\n",
      "| episodes                | 380         |\n",
      "| fps                     | 142         |\n",
      "| mean 100 episode reward | 850         |\n",
      "| n_updates               | 347817      |\n",
      "| policy_loss             | -61.13581   |\n",
      "| qf1_loss                | 0.06672793  |\n",
      "| qf2_loss                | 0.0912727   |\n",
      "| time_elapsed            | 2440        |\n",
      "| total timesteps         | 347916      |\n",
      "| value_loss              | 0.08076918  |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.024194652 |\n",
      "| ent_coef_loss           | -0.4222866  |\n",
      "| entropy                 | -7.10715    |\n",
      "| episodes                | 390         |\n",
      "| fps                     | 143         |\n",
      "| mean 100 episode reward | 850         |\n",
      "| n_updates               | 357817      |\n",
      "| policy_loss             | -61.36615   |\n",
      "| qf1_loss                | 0.059808075 |\n",
      "| qf2_loss                | 0.10714924  |\n",
      "| time_elapsed            | 2501        |\n",
      "| total timesteps         | 357916      |\n",
      "| value_loss              | 0.14159247  |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02397065 |\n",
      "| ent_coef_loss           | -0.4749934 |\n",
      "| entropy                 | -7.394943  |\n",
      "| episodes                | 400        |\n",
      "| fps                     | 143        |\n",
      "| mean 100 episode reward | 848        |\n",
      "| n_updates               | 367817     |\n",
      "| policy_loss             | -61.950474 |\n",
      "| qf1_loss                | 29.919956  |\n",
      "| qf2_loss                | 30.01374   |\n",
      "| time_elapsed            | 2562       |\n",
      "| total timesteps         | 367916     |\n",
      "| value_loss              | 0.03973473 |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.023411917 |\n",
      "| ent_coef_loss           | 0.027218759 |\n",
      "| entropy                 | -7.050561   |\n",
      "| episodes                | 410         |\n",
      "| fps                     | 143         |\n",
      "| mean 100 episode reward | 850         |\n",
      "| n_updates               | 377817      |\n",
      "| policy_loss             | -61.89379   |\n",
      "| qf1_loss                | 28.22317    |\n",
      "| qf2_loss                | 27.986956   |\n",
      "| time_elapsed            | 2629        |\n",
      "| total timesteps         | 377916      |\n",
      "| value_loss              | 0.098889075 |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.021806167 |\n",
      "| ent_coef_loss           | 0.6110893   |\n",
      "| entropy                 | -7.378895   |\n",
      "| episodes                | 420         |\n",
      "| fps                     | 143         |\n",
      "| mean 100 episode reward | 850         |\n",
      "| n_updates               | 387817      |\n",
      "| policy_loss             | -63.656162  |\n",
      "| qf1_loss                | 0.06885572  |\n",
      "| qf2_loss                | 0.044655524 |\n",
      "| time_elapsed            | 2694        |\n",
      "| total timesteps         | 387916      |\n",
      "| value_loss              | 0.111460574 |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.021619355 |\n",
      "| ent_coef_loss           | -1.1904502  |\n",
      "| entropy                 | -7.430649   |\n",
      "| episodes                | 430         |\n",
      "| fps                     | 144         |\n",
      "| mean 100 episode reward | 848         |\n",
      "| n_updates               | 397817      |\n",
      "| policy_loss             | -63.053062  |\n",
      "| qf1_loss                | 0.00986487  |\n",
      "| qf2_loss                | 0.024024315 |\n",
      "| time_elapsed            | 2758        |\n",
      "| total timesteps         | 397916      |\n",
      "| value_loss              | 0.018311027 |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.021723177 |\n",
      "| ent_coef_loss           | -0.95300674 |\n",
      "| entropy                 | -7.3435106  |\n",
      "| episodes                | 440         |\n",
      "| fps                     | 144         |\n",
      "| mean 100 episode reward | 849         |\n",
      "| n_updates               | 407817      |\n",
      "| policy_loss             | -61.97774   |\n",
      "| qf1_loss                | 61.82534    |\n",
      "| qf2_loss                | 61.733467   |\n",
      "| time_elapsed            | 2820        |\n",
      "| total timesteps         | 407916      |\n",
      "| value_loss              | 0.20466876  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.022633107 |\n",
      "| ent_coef_loss           | 2.002111    |\n",
      "| entropy                 | -7.1783047  |\n",
      "| episodes                | 450         |\n",
      "| fps                     | 144         |\n",
      "| mean 100 episode reward | 849         |\n",
      "| n_updates               | 417817      |\n",
      "| policy_loss             | -62.265762  |\n",
      "| qf1_loss                | 0.13911688  |\n",
      "| qf2_loss                | 0.16489801  |\n",
      "| time_elapsed            | 2886        |\n",
      "| total timesteps         | 417916      |\n",
      "| value_loss              | 0.31125078  |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.01996104 |\n",
      "| ent_coef_loss           | 0.7250781  |\n",
      "| entropy                 | -7.1633925 |\n",
      "| episodes                | 460        |\n",
      "| fps                     | 144        |\n",
      "| mean 100 episode reward | 851        |\n",
      "| n_updates               | 427817     |\n",
      "| policy_loss             | -60.821457 |\n",
      "| qf1_loss                | 0.0831956  |\n",
      "| qf2_loss                | 0.06945714 |\n",
      "| time_elapsed            | 2953       |\n",
      "| total timesteps         | 427916     |\n",
      "| value_loss              | 0.84688956 |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.021803271 |\n",
      "| ent_coef_loss           | -0.7116992  |\n",
      "| entropy                 | -6.9719357  |\n",
      "| episodes                | 470         |\n",
      "| fps                     | 145         |\n",
      "| mean 100 episode reward | 854         |\n",
      "| n_updates               | 437817      |\n",
      "| policy_loss             | -63.06272   |\n",
      "| qf1_loss                | 0.06218265  |\n",
      "| qf2_loss                | 0.12959565  |\n",
      "| time_elapsed            | 3016        |\n",
      "| total timesteps         | 437916      |\n",
      "| value_loss              | 0.1512088   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02181291 |\n",
      "| ent_coef_loss           | 0.35613552 |\n",
      "| entropy                 | -7.1064463 |\n",
      "| episodes                | 480        |\n",
      "| fps                     | 145        |\n",
      "| mean 100 episode reward | 854        |\n",
      "| n_updates               | 447817     |\n",
      "| policy_loss             | -61.762566 |\n",
      "| qf1_loss                | 0.26675868 |\n",
      "| qf2_loss                | 0.27860555 |\n",
      "| time_elapsed            | 3082       |\n",
      "| total timesteps         | 447916     |\n",
      "| value_loss              | 0.14789005 |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.021967106 |\n",
      "| ent_coef_loss           | -2.9112492  |\n",
      "| entropy                 | -6.9077287  |\n",
      "| episodes                | 490         |\n",
      "| fps                     | 145         |\n",
      "| mean 100 episode reward | 855         |\n",
      "| n_updates               | 457817      |\n",
      "| policy_loss             | -62.961613  |\n",
      "| qf1_loss                | 0.06916771  |\n",
      "| qf2_loss                | 0.024340324 |\n",
      "| time_elapsed            | 3149        |\n",
      "| total timesteps         | 457916      |\n",
      "| value_loss              | 0.14650568  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.022571579 |\n",
      "| ent_coef_loss           | -0.743191   |\n",
      "| entropy                 | -7.4819794  |\n",
      "| episodes                | 500         |\n",
      "| fps                     | 145         |\n",
      "| mean 100 episode reward | 858         |\n",
      "| n_updates               | 467817      |\n",
      "| policy_loss             | -64.08225   |\n",
      "| qf1_loss                | 0.099534884 |\n",
      "| qf2_loss                | 0.048292294 |\n",
      "| time_elapsed            | 3210        |\n",
      "| total timesteps         | 467916      |\n",
      "| value_loss              | 0.0529992   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.020760173 |\n",
      "| ent_coef_loss           | 0.82872283  |\n",
      "| entropy                 | -7.381426   |\n",
      "| episodes                | 510         |\n",
      "| fps                     | 146         |\n",
      "| mean 100 episode reward | 854         |\n",
      "| n_updates               | 477817      |\n",
      "| policy_loss             | -63.987823  |\n",
      "| qf1_loss                | 31.835089   |\n",
      "| qf2_loss                | 31.79248    |\n",
      "| time_elapsed            | 3273        |\n",
      "| total timesteps         | 477916      |\n",
      "| value_loss              | 0.19581115  |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.019538706 |\n",
      "| ent_coef_loss           | 1.365917    |\n",
      "| entropy                 | -7.435218   |\n",
      "| episodes                | 520         |\n",
      "| fps                     | 146         |\n",
      "| mean 100 episode reward | 856         |\n",
      "| n_updates               | 487817      |\n",
      "| policy_loss             | -63.872063  |\n",
      "| qf1_loss                | 0.0658645   |\n",
      "| qf2_loss                | 0.03173681  |\n",
      "| time_elapsed            | 3335        |\n",
      "| total timesteps         | 487916      |\n",
      "| value_loss              | 0.06487577  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.0212165   |\n",
      "| ent_coef_loss           | -0.5340184  |\n",
      "| entropy                 | -7.402622   |\n",
      "| episodes                | 530         |\n",
      "| fps                     | 146         |\n",
      "| mean 100 episode reward | 856         |\n",
      "| n_updates               | 497817      |\n",
      "| policy_loss             | -63.85962   |\n",
      "| qf1_loss                | 0.058658667 |\n",
      "| qf2_loss                | 0.034899708 |\n",
      "| time_elapsed            | 3399        |\n",
      "| total timesteps         | 497916      |\n",
      "| value_loss              | 0.027013777 |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.023354972 |\n",
      "| ent_coef_loss           | 0.5344672   |\n",
      "| entropy                 | -6.942539   |\n",
      "| episodes                | 540         |\n",
      "| fps                     | 146         |\n",
      "| mean 100 episode reward | 857         |\n",
      "| n_updates               | 507817      |\n",
      "| policy_loss             | -63.27401   |\n",
      "| qf1_loss                | 0.025231967 |\n",
      "| qf2_loss                | 0.042738855 |\n",
      "| time_elapsed            | 3462        |\n",
      "| total timesteps         | 507916      |\n",
      "| value_loss              | 0.05627786  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.018583339 |\n",
      "| ent_coef_loss           | -0.30531633 |\n",
      "| entropy                 | -7.8715982  |\n",
      "| episodes                | 550         |\n",
      "| fps                     | 146         |\n",
      "| mean 100 episode reward | 856         |\n",
      "| n_updates               | 517817      |\n",
      "| policy_loss             | -64.23627   |\n",
      "| qf1_loss                | 0.030807195 |\n",
      "| qf2_loss                | 0.0332995   |\n",
      "| time_elapsed            | 3530        |\n",
      "| total timesteps         | 517916      |\n",
      "| value_loss              | 0.062216483 |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.023252906 |\n",
      "| ent_coef_loss           | 1.1771215   |\n",
      "| entropy                 | -7.347787   |\n",
      "| episodes                | 560         |\n",
      "| fps                     | 146         |\n",
      "| mean 100 episode reward | 857         |\n",
      "| n_updates               | 527817      |\n",
      "| policy_loss             | -64.41757   |\n",
      "| qf1_loss                | 0.016325017 |\n",
      "| qf2_loss                | 0.046166852 |\n",
      "| time_elapsed            | 3599        |\n",
      "| total timesteps         | 527916      |\n",
      "| value_loss              | 0.020685926 |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.022933245 |\n",
      "| ent_coef_loss           | 0.60915387  |\n",
      "| entropy                 | -7.4662538  |\n",
      "| episodes                | 570         |\n",
      "| fps                     | 146         |\n",
      "| mean 100 episode reward | 856         |\n",
      "| n_updates               | 537817      |\n",
      "| policy_loss             | -64.32379   |\n",
      "| qf1_loss                | 0.05780553  |\n",
      "| qf2_loss                | 0.0531684   |\n",
      "| time_elapsed            | 3664        |\n",
      "| total timesteps         | 537916      |\n",
      "| value_loss              | 0.035126477 |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.019940259 |\n",
      "| ent_coef_loss           | 2.1690063   |\n",
      "| entropy                 | -6.6365166  |\n",
      "| episodes                | 580         |\n",
      "| fps                     | 147         |\n",
      "| mean 100 episode reward | 857         |\n",
      "| n_updates               | 547817      |\n",
      "| policy_loss             | -63.28884   |\n",
      "| qf1_loss                | 0.029196342 |\n",
      "| qf2_loss                | 0.07930562  |\n",
      "| time_elapsed            | 3720        |\n",
      "| total timesteps         | 547916      |\n",
      "| value_loss              | 0.038092047 |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.02198679  |\n",
      "| ent_coef_loss           | 1.1793478   |\n",
      "| entropy                 | -7.687219   |\n",
      "| episodes                | 590         |\n",
      "| fps                     | 147         |\n",
      "| mean 100 episode reward | 857         |\n",
      "| n_updates               | 557817      |\n",
      "| policy_loss             | -64.19775   |\n",
      "| qf1_loss                | 0.05484333  |\n",
      "| qf2_loss                | 0.027767772 |\n",
      "| time_elapsed            | 3786        |\n",
      "| total timesteps         | 557916      |\n",
      "| value_loss              | 0.019615898 |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028756984 |\n",
      "| ent_coef_loss           | 1.3430235   |\n",
      "| entropy                 | -7.3928776  |\n",
      "| episodes                | 600         |\n",
      "| fps                     | 147         |\n",
      "| mean 100 episode reward | 857         |\n",
      "| n_updates               | 567817      |\n",
      "| policy_loss             | -63.741104  |\n",
      "| qf1_loss                | 0.103295706 |\n",
      "| qf2_loss                | 0.11242594  |\n",
      "| time_elapsed            | 3858        |\n",
      "| total timesteps         | 567916      |\n",
      "| value_loss              | 0.068978935 |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029520953 |\n",
      "| ent_coef_loss           | 0.45835394  |\n",
      "| entropy                 | -7.597085   |\n",
      "| episodes                | 610         |\n",
      "| fps                     | 147         |\n",
      "| mean 100 episode reward | 861         |\n",
      "| n_updates               | 577817      |\n",
      "| policy_loss             | -61.61033   |\n",
      "| qf1_loss                | 0.19351938  |\n",
      "| qf2_loss                | 0.27314407  |\n",
      "| time_elapsed            | 3925        |\n",
      "| total timesteps         | 577916      |\n",
      "| value_loss              | 0.10525195  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.023694038 |\n",
      "| ent_coef_loss           | -1.3791554  |\n",
      "| entropy                 | -7.315846   |\n",
      "| episodes                | 620         |\n",
      "| fps                     | 147         |\n",
      "| mean 100 episode reward | 863         |\n",
      "| n_updates               | 587817      |\n",
      "| policy_loss             | -61.454952  |\n",
      "| qf1_loss                | 0.024410868 |\n",
      "| qf2_loss                | 0.021541333 |\n",
      "| time_elapsed            | 3990        |\n",
      "| total timesteps         | 587916      |\n",
      "| value_loss              | 0.04220362  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.025310092 |\n",
      "| ent_coef_loss           | -0.68320173 |\n",
      "| entropy                 | -7.219954   |\n",
      "| episodes                | 630         |\n",
      "| fps                     | 147         |\n",
      "| mean 100 episode reward | 865         |\n",
      "| n_updates               | 597817      |\n",
      "| policy_loss             | -62.27334   |\n",
      "| qf1_loss                | 0.028200664 |\n",
      "| qf2_loss                | 0.029164046 |\n",
      "| time_elapsed            | 4047        |\n",
      "| total timesteps         | 597916      |\n",
      "| value_loss              | 0.08640776  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.020655142 |\n",
      "| ent_coef_loss           | -1.5454154  |\n",
      "| entropy                 | -7.2464614  |\n",
      "| episodes                | 640         |\n",
      "| fps                     | 148         |\n",
      "| mean 100 episode reward | 864         |\n",
      "| n_updates               | 607817      |\n",
      "| policy_loss             | -62.51384   |\n",
      "| qf1_loss                | 0.072048694 |\n",
      "| qf2_loss                | 0.051793333 |\n",
      "| time_elapsed            | 4103        |\n",
      "| total timesteps         | 607916      |\n",
      "| value_loss              | 0.02857048  |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.020406652 |\n",
      "| ent_coef_loss           | -1.3768954  |\n",
      "| entropy                 | -6.749963   |\n",
      "| episodes                | 650         |\n",
      "| fps                     | 148         |\n",
      "| mean 100 episode reward | 864         |\n",
      "| n_updates               | 617817      |\n",
      "| policy_loss             | -62.173023  |\n",
      "| qf1_loss                | 0.21574834  |\n",
      "| qf2_loss                | 0.11604495  |\n",
      "| time_elapsed            | 4161        |\n",
      "| total timesteps         | 617916      |\n",
      "| value_loss              | 0.38272592  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.019593151 |\n",
      "| ent_coef_loss           | -0.22362597 |\n",
      "| entropy                 | -7.307099   |\n",
      "| episodes                | 660         |\n",
      "| fps                     | 148         |\n",
      "| mean 100 episode reward | 860         |\n",
      "| n_updates               | 627817      |\n",
      "| policy_loss             | -62.892036  |\n",
      "| qf1_loss                | 1.3000927   |\n",
      "| qf2_loss                | 2.1098685   |\n",
      "| time_elapsed            | 4219        |\n",
      "| total timesteps         | 627916      |\n",
      "| value_loss              | 0.31488138  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.021978771 |\n",
      "| ent_coef_loss           | -0.23507833 |\n",
      "| entropy                 | -6.8423986  |\n",
      "| episodes                | 670         |\n",
      "| fps                     | 148         |\n",
      "| mean 100 episode reward | 857         |\n",
      "| n_updates               | 637817      |\n",
      "| policy_loss             | -64.08023   |\n",
      "| qf1_loss                | 0.044556417 |\n",
      "| qf2_loss                | 0.059472796 |\n",
      "| time_elapsed            | 4288        |\n",
      "| total timesteps         | 637916      |\n",
      "| value_loss              | 0.03430998  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.020614304 |\n",
      "| ent_coef_loss           | 3.295918    |\n",
      "| entropy                 | -8.285292   |\n",
      "| episodes                | 680         |\n",
      "| fps                     | 148         |\n",
      "| mean 100 episode reward | 848         |\n",
      "| n_updates               | 647817      |\n",
      "| policy_loss             | -65.89934   |\n",
      "| qf1_loss                | 0.021494402 |\n",
      "| qf2_loss                | 0.021410767 |\n",
      "| time_elapsed            | 4350        |\n",
      "| total timesteps         | 647916      |\n",
      "| value_loss              | 0.011396768 |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.019596172 |\n",
      "| ent_coef_loss           | -0.24229705 |\n",
      "| entropy                 | -7.2510104  |\n",
      "| episodes                | 690         |\n",
      "| fps                     | 149         |\n",
      "| mean 100 episode reward | 824         |\n",
      "| n_updates               | 657817      |\n",
      "| policy_loss             | -65.13751   |\n",
      "| qf1_loss                | 0.030115098 |\n",
      "| qf2_loss                | 0.02452366  |\n",
      "| time_elapsed            | 4408        |\n",
      "| total timesteps         | 657916      |\n",
      "| value_loss              | 0.015820112 |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.018353363 |\n",
      "| ent_coef_loss           | -2.199669   |\n",
      "| entropy                 | -7.2395406  |\n",
      "| episodes                | 700         |\n",
      "| fps                     | 149         |\n",
      "| mean 100 episode reward | 820         |\n",
      "| n_updates               | 667817      |\n",
      "| policy_loss             | -65.138985  |\n",
      "| qf1_loss                | 0.09123105  |\n",
      "| qf2_loss                | 0.11718272  |\n",
      "| time_elapsed            | 4466        |\n",
      "| total timesteps         | 667916      |\n",
      "| value_loss              | 0.15053926  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.021818096 |\n",
      "| ent_coef_loss           | -0.39935416 |\n",
      "| entropy                 | -6.832531   |\n",
      "| episodes                | 710         |\n",
      "| fps                     | 149         |\n",
      "| mean 100 episode reward | 820         |\n",
      "| n_updates               | 677817      |\n",
      "| policy_loss             | -66.21965   |\n",
      "| qf1_loss                | 0.10156612  |\n",
      "| qf2_loss                | 0.14713317  |\n",
      "| time_elapsed            | 4525        |\n",
      "| total timesteps         | 677916      |\n",
      "| value_loss              | 0.08567907  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029481417 |\n",
      "| ent_coef_loss           | 2.8073282   |\n",
      "| entropy                 | -4.5263042  |\n",
      "| episodes                | 720         |\n",
      "| fps                     | 149         |\n",
      "| mean 100 episode reward | 795         |\n",
      "| n_updates               | 687584      |\n",
      "| policy_loss             | -63.822876  |\n",
      "| qf1_loss                | 0.059669953 |\n",
      "| qf2_loss                | 0.080829546 |\n",
      "| time_elapsed            | 4585        |\n",
      "| total timesteps         | 687683      |\n",
      "| value_loss              | 0.077786595 |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03088039 |\n",
      "| ent_coef_loss           | -2.8975296 |\n",
      "| entropy                 | -5.012399  |\n",
      "| episodes                | 730        |\n",
      "| fps                     | 150        |\n",
      "| mean 100 episode reward | 753        |\n",
      "| n_updates               | 697584     |\n",
      "| policy_loss             | -50.73371  |\n",
      "| qf1_loss                | 0.16923858 |\n",
      "| qf2_loss                | 0.18586642 |\n",
      "| time_elapsed            | 4649       |\n",
      "| total timesteps         | 697683     |\n",
      "| value_loss              | 0.18208371 |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.027514776 |\n",
      "| ent_coef_loss           | 1.4450065   |\n",
      "| entropy                 | -5.442858   |\n",
      "| episodes                | 740         |\n",
      "| fps                     | 150         |\n",
      "| mean 100 episode reward | 736         |\n",
      "| n_updates               | 707584      |\n",
      "| policy_loss             | -46.261017  |\n",
      "| qf1_loss                | 0.04799103  |\n",
      "| qf2_loss                | 0.036895473 |\n",
      "| time_elapsed            | 4705        |\n",
      "| total timesteps         | 707683      |\n",
      "| value_loss              | 0.061584182 |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.018850705 |\n",
      "| ent_coef_loss           | 1.159471    |\n",
      "| entropy                 | -7.385027   |\n",
      "| episodes                | 750         |\n",
      "| fps                     | 150         |\n",
      "| mean 100 episode reward | 729         |\n",
      "| n_updates               | 717584      |\n",
      "| policy_loss             | -52.329628  |\n",
      "| qf1_loss                | 0.44078204  |\n",
      "| qf2_loss                | 0.21832122  |\n",
      "| time_elapsed            | 4763        |\n",
      "| total timesteps         | 717683      |\n",
      "| value_loss              | 0.1017516   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.01838771  |\n",
      "| ent_coef_loss           | -2.7478306  |\n",
      "| entropy                 | -6.4054756  |\n",
      "| episodes                | 760         |\n",
      "| fps                     | 150         |\n",
      "| mean 100 episode reward | 728         |\n",
      "| n_updates               | 727584      |\n",
      "| policy_loss             | -57.06104   |\n",
      "| qf1_loss                | 0.28171092  |\n",
      "| qf2_loss                | 0.060491033 |\n",
      "| time_elapsed            | 4821        |\n",
      "| total timesteps         | 727683      |\n",
      "| value_loss              | 0.20323718  |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.01772986 |\n",
      "| ent_coef_loss           | 0.19134405 |\n",
      "| entropy                 | -6.467084  |\n",
      "| episodes                | 770        |\n",
      "| fps                     | 151        |\n",
      "| mean 100 episode reward | 730        |\n",
      "| n_updates               | 737584     |\n",
      "| policy_loss             | -60.750404 |\n",
      "| qf1_loss                | 0.07631345 |\n",
      "| qf2_loss                | 0.08751716 |\n",
      "| time_elapsed            | 4878       |\n",
      "| total timesteps         | 737683     |\n",
      "| value_loss              | 0.39922887 |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.020097444 |\n",
      "| ent_coef_loss           | 2.5387366   |\n",
      "| entropy                 | -7.3466234  |\n",
      "| episodes                | 780         |\n",
      "| fps                     | 151         |\n",
      "| mean 100 episode reward | 731         |\n",
      "| n_updates               | 747584      |\n",
      "| policy_loss             | -62.607933  |\n",
      "| qf1_loss                | 0.018214596 |\n",
      "| qf2_loss                | 0.027214792 |\n",
      "| time_elapsed            | 4936        |\n",
      "| total timesteps         | 747683      |\n",
      "| value_loss              | 0.012083838 |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.02278382  |\n",
      "| ent_coef_loss           | -3.9263675  |\n",
      "| entropy                 | -5.869876   |\n",
      "| episodes                | 790         |\n",
      "| fps                     | 151         |\n",
      "| mean 100 episode reward | 744         |\n",
      "| n_updates               | 757584      |\n",
      "| policy_loss             | -61.276897  |\n",
      "| qf1_loss                | 0.052111063 |\n",
      "| qf2_loss                | 0.057625644 |\n",
      "| time_elapsed            | 4994        |\n",
      "| total timesteps         | 757683      |\n",
      "| value_loss              | 0.1434245   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.018014176 |\n",
      "| ent_coef_loss           | -0.643103   |\n",
      "| entropy                 | -7.191942   |\n",
      "| episodes                | 800         |\n",
      "| fps                     | 151         |\n",
      "| mean 100 episode reward | 743         |\n",
      "| n_updates               | 767584      |\n",
      "| policy_loss             | -61.800552  |\n",
      "| qf1_loss                | 0.087365285 |\n",
      "| qf2_loss                | 0.051641423 |\n",
      "| time_elapsed            | 5053        |\n",
      "| total timesteps         | 767683      |\n",
      "| value_loss              | 0.70735204  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.017039025 |\n",
      "| ent_coef_loss           | -0.10885373 |\n",
      "| entropy                 | -5.954069   |\n",
      "| episodes                | 810         |\n",
      "| fps                     | 152         |\n",
      "| mean 100 episode reward | 733         |\n",
      "| n_updates               | 777584      |\n",
      "| policy_loss             | -61.986214  |\n",
      "| qf1_loss                | 0.07885814  |\n",
      "| qf2_loss                | 0.05243908  |\n",
      "| time_elapsed            | 5112        |\n",
      "| total timesteps         | 777683      |\n",
      "| value_loss              | 0.116296634 |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.019379418 |\n",
      "| ent_coef_loss           | 1.9533064   |\n",
      "| entropy                 | -5.906454   |\n",
      "| episodes                | 820         |\n",
      "| fps                     | 152         |\n",
      "| mean 100 episode reward | 746         |\n",
      "| n_updates               | 787584      |\n",
      "| policy_loss             | -62.081383  |\n",
      "| qf1_loss                | 0.049403504 |\n",
      "| qf2_loss                | 0.035382792 |\n",
      "| time_elapsed            | 5169        |\n",
      "| total timesteps         | 787683      |\n",
      "| value_loss              | 0.055426527 |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.01598278  |\n",
      "| ent_coef_loss           | 1.4293056   |\n",
      "| entropy                 | -7.299488   |\n",
      "| episodes                | 830         |\n",
      "| fps                     | 152         |\n",
      "| mean 100 episode reward | 776         |\n",
      "| n_updates               | 797584      |\n",
      "| policy_loss             | -66.789314  |\n",
      "| qf1_loss                | 35.283714   |\n",
      "| qf2_loss                | 35.273075   |\n",
      "| time_elapsed            | 5228        |\n",
      "| total timesteps         | 797683      |\n",
      "| value_loss              | 0.026524875 |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.017393153 |\n",
      "| ent_coef_loss           | -2.078341   |\n",
      "| entropy                 | -7.2358294  |\n",
      "| episodes                | 840         |\n",
      "| fps                     | 152         |\n",
      "| mean 100 episode reward | 788         |\n",
      "| n_updates               | 807584      |\n",
      "| policy_loss             | -66.66685   |\n",
      "| qf1_loss                | 0.10156448  |\n",
      "| qf2_loss                | 0.11863771  |\n",
      "| time_elapsed            | 5284        |\n",
      "| total timesteps         | 807683      |\n",
      "| value_loss              | 0.19021289  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.016817508 |\n",
      "| ent_coef_loss           | 0.062462255 |\n",
      "| entropy                 | -7.35452    |\n",
      "| episodes                | 850         |\n",
      "| fps                     | 153         |\n",
      "| mean 100 episode reward | 793         |\n",
      "| n_updates               | 817584      |\n",
      "| policy_loss             | -66.81598   |\n",
      "| qf1_loss                | 0.03780917  |\n",
      "| qf2_loss                | 0.029980052 |\n",
      "| time_elapsed            | 5342        |\n",
      "| total timesteps         | 817683      |\n",
      "| value_loss              | 0.27730462  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.018852009 |\n",
      "| ent_coef_loss           | -1.560243   |\n",
      "| entropy                 | -7.3735323  |\n",
      "| episodes                | 860         |\n",
      "| fps                     | 153         |\n",
      "| mean 100 episode reward | 800         |\n",
      "| n_updates               | 827584      |\n",
      "| policy_loss             | -66.61543   |\n",
      "| qf1_loss                | 0.105100445 |\n",
      "| qf2_loss                | 0.102376    |\n",
      "| time_elapsed            | 5399        |\n",
      "| total timesteps         | 827683      |\n",
      "| value_loss              | 0.0986921   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.020559795 |\n",
      "| ent_coef_loss           | 1.3384726   |\n",
      "| entropy                 | -7.7787256  |\n",
      "| episodes                | 870         |\n",
      "| fps                     | 153         |\n",
      "| mean 100 episode reward | 803         |\n",
      "| n_updates               | 837584      |\n",
      "| policy_loss             | -68.57907   |\n",
      "| qf1_loss                | 0.16737343  |\n",
      "| qf2_loss                | 0.15989468  |\n",
      "| time_elapsed            | 5459        |\n",
      "| total timesteps         | 837683      |\n",
      "| value_loss              | 0.60091054  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.020896167 |\n",
      "| ent_coef_loss           | -0.29088455 |\n",
      "| entropy                 | -7.057438   |\n",
      "| episodes                | 880         |\n",
      "| fps                     | 153         |\n",
      "| mean 100 episode reward | 805         |\n",
      "| n_updates               | 847584      |\n",
      "| policy_loss             | -69.90697   |\n",
      "| qf1_loss                | 0.049032852 |\n",
      "| qf2_loss                | 0.08634143  |\n",
      "| time_elapsed            | 5517        |\n",
      "| total timesteps         | 847683      |\n",
      "| value_loss              | 0.02092958  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.019290077 |\n",
      "| ent_coef_loss           | -0.2541964  |\n",
      "| entropy                 | -7.786629   |\n",
      "| episodes                | 890         |\n",
      "| fps                     | 153         |\n",
      "| mean 100 episode reward | 817         |\n",
      "| n_updates               | 857584      |\n",
      "| policy_loss             | -67.57294   |\n",
      "| qf1_loss                | 0.07257967  |\n",
      "| qf2_loss                | 0.15995938  |\n",
      "| time_elapsed            | 5577        |\n",
      "| total timesteps         | 857683      |\n",
      "| value_loss              | 0.056825    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.020140653 |\n",
      "| ent_coef_loss           | 1.5594779   |\n",
      "| entropy                 | -7.160817   |\n",
      "| episodes                | 900         |\n",
      "| fps                     | 153         |\n",
      "| mean 100 episode reward | 825         |\n",
      "| n_updates               | 867584      |\n",
      "| policy_loss             | -68.55543   |\n",
      "| qf1_loss                | 35.713657   |\n",
      "| qf2_loss                | 35.821453   |\n",
      "| time_elapsed            | 5636        |\n",
      "| total timesteps         | 867683      |\n",
      "| value_loss              | 0.045308523 |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.01840777  |\n",
      "| ent_coef_loss           | 2.1937768   |\n",
      "| entropy                 | -7.5095196  |\n",
      "| episodes                | 910         |\n",
      "| fps                     | 154         |\n",
      "| mean 100 episode reward | 841         |\n",
      "| n_updates               | 877584      |\n",
      "| policy_loss             | -67.82031   |\n",
      "| qf1_loss                | 0.08588646  |\n",
      "| qf2_loss                | 0.06717318  |\n",
      "| time_elapsed            | 5696        |\n",
      "| total timesteps         | 877683      |\n",
      "| value_loss              | 0.018980298 |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.018785944 |\n",
      "| ent_coef_loss           | -2.0619843  |\n",
      "| entropy                 | -7.24045    |\n",
      "| episodes                | 920         |\n",
      "| fps                     | 154         |\n",
      "| mean 100 episode reward | 852         |\n",
      "| n_updates               | 887584      |\n",
      "| policy_loss             | -67.66733   |\n",
      "| qf1_loss                | 0.112784766 |\n",
      "| qf2_loss                | 0.06510683  |\n",
      "| time_elapsed            | 5754        |\n",
      "| total timesteps         | 887683      |\n",
      "| value_loss              | 0.04050946  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.018923339 |\n",
      "| ent_coef_loss           | -3.0773711  |\n",
      "| entropy                 | -7.4049144  |\n",
      "| episodes                | 930         |\n",
      "| fps                     | 154         |\n",
      "| mean 100 episode reward | 870         |\n",
      "| n_updates               | 897584      |\n",
      "| policy_loss             | -69.18276   |\n",
      "| qf1_loss                | 0.046341795 |\n",
      "| qf2_loss                | 0.032227702 |\n",
      "| time_elapsed            | 5810        |\n",
      "| total timesteps         | 897683      |\n",
      "| value_loss              | 0.06672285  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.019048171 |\n",
      "| ent_coef_loss           | -1.830567   |\n",
      "| entropy                 | -7.137151   |\n",
      "| episodes                | 940         |\n",
      "| fps                     | 154         |\n",
      "| mean 100 episode reward | 884         |\n",
      "| n_updates               | 907584      |\n",
      "| policy_loss             | -70.54448   |\n",
      "| qf1_loss                | 0.052216638 |\n",
      "| qf2_loss                | 0.031965863 |\n",
      "| time_elapsed            | 5869        |\n",
      "| total timesteps         | 907683      |\n",
      "| value_loss              | 0.18782774  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.02000203  |\n",
      "| ent_coef_loss           | 0.58328587  |\n",
      "| entropy                 | -7.005163   |\n",
      "| episodes                | 950         |\n",
      "| fps                     | 154         |\n",
      "| mean 100 episode reward | 895         |\n",
      "| n_updates               | 917584      |\n",
      "| policy_loss             | -70.22019   |\n",
      "| qf1_loss                | 0.08488994  |\n",
      "| qf2_loss                | 0.091106065 |\n",
      "| time_elapsed            | 5931        |\n",
      "| total timesteps         | 917683      |\n",
      "| value_loss              | 0.14833501  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.019870795 |\n",
      "| ent_coef_loss           | -1.0560322  |\n",
      "| entropy                 | -7.089673   |\n",
      "| episodes                | 960         |\n",
      "| fps                     | 154         |\n",
      "| mean 100 episode reward | 895         |\n",
      "| n_updates               | 927584      |\n",
      "| policy_loss             | -70.14978   |\n",
      "| qf1_loss                | 80.215645   |\n",
      "| qf2_loss                | 80.33943    |\n",
      "| time_elapsed            | 5995        |\n",
      "| total timesteps         | 927683      |\n",
      "| value_loss              | 0.10914186  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.020220103 |\n",
      "| ent_coef_loss           | -1.2791708  |\n",
      "| entropy                 | -6.9255133  |\n",
      "| episodes                | 970         |\n",
      "| fps                     | 154         |\n",
      "| mean 100 episode reward | 901         |\n",
      "| n_updates               | 937584      |\n",
      "| policy_loss             | -71.38007   |\n",
      "| qf1_loss                | 0.053102586 |\n",
      "| qf2_loss                | 0.06576943  |\n",
      "| time_elapsed            | 6056        |\n",
      "| total timesteps         | 937683      |\n",
      "| value_loss              | 0.06333216  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.023708127 |\n",
      "| ent_coef_loss           | -1.42747    |\n",
      "| entropy                 | -5.961846   |\n",
      "| episodes                | 980         |\n",
      "| fps                     | 154         |\n",
      "| mean 100 episode reward | 898         |\n",
      "| n_updates               | 947584      |\n",
      "| policy_loss             | -70.9049    |\n",
      "| qf1_loss                | 0.056901794 |\n",
      "| qf2_loss                | 0.06415135  |\n",
      "| time_elapsed            | 6117        |\n",
      "| total timesteps         | 947683      |\n",
      "| value_loss              | 0.0762575   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.040700234 |\n",
      "| ent_coef_loss           | 0.27881444  |\n",
      "| entropy                 | -3.694519   |\n",
      "| episodes                | 990         |\n",
      "| fps                     | 154         |\n",
      "| mean 100 episode reward | 878         |\n",
      "| n_updates               | 956642      |\n",
      "| policy_loss             | -65.05788   |\n",
      "| qf1_loss                | 0.15772197  |\n",
      "| qf2_loss                | 0.17561448  |\n",
      "| time_elapsed            | 6172        |\n",
      "| total timesteps         | 956741      |\n",
      "| value_loss              | 0.1448167   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03651482 |\n",
      "| ent_coef_loss           | -2.5127807 |\n",
      "| entropy                 | -4.521778  |\n",
      "| episodes                | 1000       |\n",
      "| fps                     | 155        |\n",
      "| mean 100 episode reward | 846        |\n",
      "| n_updates               | 964900     |\n",
      "| policy_loss             | -60.487522 |\n",
      "| qf1_loss                | 0.16994813 |\n",
      "| qf2_loss                | 0.20551896 |\n",
      "| time_elapsed            | 6225       |\n",
      "| total timesteps         | 964999     |\n",
      "| value_loss              | 0.0843207  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.02795946  |\n",
      "| ent_coef_loss           | 1.7853916   |\n",
      "| entropy                 | -5.1702776  |\n",
      "| episodes                | 1010        |\n",
      "| fps                     | 155         |\n",
      "| mean 100 episode reward | 833         |\n",
      "| n_updates               | 974900      |\n",
      "| policy_loss             | -60.436455  |\n",
      "| qf1_loss                | 0.108792305 |\n",
      "| qf2_loss                | 0.10793823  |\n",
      "| time_elapsed            | 6285        |\n",
      "| total timesteps         | 974999      |\n",
      "| value_loss              | 0.18903011  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.021223614 |\n",
      "| ent_coef_loss           | -1.2533094  |\n",
      "| entropy                 | -6.5115366  |\n",
      "| episodes                | 1020        |\n",
      "| fps                     | 155         |\n",
      "| mean 100 episode reward | 808         |\n",
      "| n_updates               | 983956      |\n",
      "| policy_loss             | -65.79992   |\n",
      "| qf1_loss                | 0.10589058  |\n",
      "| qf2_loss                | 0.1460633   |\n",
      "| time_elapsed            | 6341        |\n",
      "| total timesteps         | 984055      |\n",
      "| value_loss              | 0.077154115 |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.026387528 |\n",
      "| ent_coef_loss           | -0.96800476 |\n",
      "| entropy                 | -6.761856   |\n",
      "| episodes                | 1030        |\n",
      "| fps                     | 155         |\n",
      "| mean 100 episode reward | 776         |\n",
      "| n_updates               | 990880      |\n",
      "| policy_loss             | -66.940994  |\n",
      "| qf1_loss                | 0.14591539  |\n",
      "| qf2_loss                | 0.11486299  |\n",
      "| time_elapsed            | 6385        |\n",
      "| total timesteps         | 990979      |\n",
      "| value_loss              | 0.18952627  |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.022762036 |\n",
      "| ent_coef_loss           | -0.39773136 |\n",
      "| entropy                 | -6.395095   |\n",
      "| episodes                | 1040        |\n",
      "| fps                     | 155         |\n",
      "| mean 100 episode reward | 783         |\n",
      "| n_updates               | 1000779     |\n",
      "| policy_loss             | -69.402885  |\n",
      "| qf1_loss                | 0.098799855 |\n",
      "| qf2_loss                | 0.098962076 |\n",
      "| time_elapsed            | 6445        |\n",
      "| total timesteps         | 1000878     |\n",
      "| value_loss              | 0.0988608   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.025670014 |\n",
      "| ent_coef_loss           | 0.37727058  |\n",
      "| entropy                 | -6.1111255  |\n",
      "| episodes                | 1050        |\n",
      "| fps                     | 155         |\n",
      "| mean 100 episode reward | 784         |\n",
      "| n_updates               | 1010779     |\n",
      "| policy_loss             | -71.04898   |\n",
      "| qf1_loss                | 0.07662904  |\n",
      "| qf2_loss                | 0.093659    |\n",
      "| time_elapsed            | 6506        |\n",
      "| total timesteps         | 1010878     |\n",
      "| value_loss              | 0.03763994  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.026034925 |\n",
      "| ent_coef_loss           | -1.7092453  |\n",
      "| entropy                 | -6.7804794  |\n",
      "| episodes                | 1060        |\n",
      "| fps                     | 155         |\n",
      "| mean 100 episode reward | 794         |\n",
      "| n_updates               | 1020779     |\n",
      "| policy_loss             | -74.69301   |\n",
      "| qf1_loss                | 0.04717922  |\n",
      "| qf2_loss                | 0.060693692 |\n",
      "| time_elapsed            | 6565        |\n",
      "| total timesteps         | 1020878     |\n",
      "| value_loss              | 0.028230134 |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.02491147  |\n",
      "| ent_coef_loss           | 0.027125016 |\n",
      "| entropy                 | -6.7255745  |\n",
      "| episodes                | 1070        |\n",
      "| fps                     | 155         |\n",
      "| mean 100 episode reward | 770         |\n",
      "| n_updates               | 1028431     |\n",
      "| policy_loss             | -76.76706   |\n",
      "| qf1_loss                | 0.46346852  |\n",
      "| qf2_loss                | 0.31882483  |\n",
      "| time_elapsed            | 6611        |\n",
      "| total timesteps         | 1028530     |\n",
      "| value_loss              | 0.04809721  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.026031088 |\n",
      "| ent_coef_loss           | -0.19694757 |\n",
      "| entropy                 | -6.9418745  |\n",
      "| episodes                | 1080        |\n",
      "| fps                     | 155         |\n",
      "| mean 100 episode reward | 793         |\n",
      "| n_updates               | 1037182     |\n",
      "| policy_loss             | -76.34355   |\n",
      "| qf1_loss                | 0.10104912  |\n",
      "| qf2_loss                | 0.08297853  |\n",
      "| time_elapsed            | 6663        |\n",
      "| total timesteps         | 1037281     |\n",
      "| value_loss              | 0.03647534  |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02467166 |\n",
      "| ent_coef_loss           | -0.4476089 |\n",
      "| entropy                 | -6.316826  |\n",
      "| episodes                | 1090       |\n",
      "| fps                     | 155        |\n",
      "| mean 100 episode reward | 809        |\n",
      "| n_updates               | 1044315    |\n",
      "| policy_loss             | -75.9796   |\n",
      "| qf1_loss                | 0.23496166 |\n",
      "| qf2_loss                | 0.289449   |\n",
      "| time_elapsed            | 6705       |\n",
      "| total timesteps         | 1044414    |\n",
      "| value_loss              | 0.20529471 |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.024002178 |\n",
      "| ent_coef_loss           | -1.1890873  |\n",
      "| entropy                 | -6.499918   |\n",
      "| episodes                | 1100        |\n",
      "| fps                     | 155         |\n",
      "| mean 100 episode reward | 824         |\n",
      "| n_updates               | 1050685     |\n",
      "| policy_loss             | -78.0587    |\n",
      "| qf1_loss                | 0.30014917  |\n",
      "| qf2_loss                | 0.45440724  |\n",
      "| time_elapsed            | 6744        |\n",
      "| total timesteps         | 1050784     |\n",
      "| value_loss              | 0.1932019   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.027202955 |\n",
      "| ent_coef_loss           | 0.5630528   |\n",
      "| entropy                 | -7.1791925  |\n",
      "| episodes                | 1110        |\n",
      "| fps                     | 155         |\n",
      "| mean 100 episode reward | 859         |\n",
      "| n_updates               | 1060369     |\n",
      "| policy_loss             | -78.47731   |\n",
      "| qf1_loss                | 0.14795059  |\n",
      "| qf2_loss                | 0.116311535 |\n",
      "| time_elapsed            | 6803        |\n",
      "| total timesteps         | 1060468     |\n",
      "| value_loss              | 0.09146789  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.026197888 |\n",
      "| ent_coef_loss           | -1.4119105  |\n",
      "| entropy                 | -6.1383705  |\n",
      "| episodes                | 1120        |\n",
      "| fps                     | 156         |\n",
      "| mean 100 episode reward | 913         |\n",
      "| n_updates               | 1070286     |\n",
      "| policy_loss             | -79.32472   |\n",
      "| qf1_loss                | 0.122018114 |\n",
      "| qf2_loss                | 0.17522515  |\n",
      "| time_elapsed            | 6860        |\n",
      "| total timesteps         | 1070385     |\n",
      "| value_loss              | 0.063787    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.027771823 |\n",
      "| ent_coef_loss           | 1.209595    |\n",
      "| entropy                 | -6.0200777  |\n",
      "| episodes                | 1130        |\n",
      "| fps                     | 156         |\n",
      "| mean 100 episode reward | 972         |\n",
      "| n_updates               | 1080137     |\n",
      "| policy_loss             | -81.15671   |\n",
      "| qf1_loss                | 0.192941    |\n",
      "| qf2_loss                | 0.16638891  |\n",
      "| time_elapsed            | 6919        |\n",
      "| total timesteps         | 1080236     |\n",
      "| value_loss              | 0.13409781  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.026964173 |\n",
      "| ent_coef_loss           | -1.0389488  |\n",
      "| entropy                 | -6.468741   |\n",
      "| episodes                | 1140        |\n",
      "| fps                     | 156         |\n",
      "| mean 100 episode reward | 961         |\n",
      "| n_updates               | 1087662     |\n",
      "| policy_loss             | -83.56471   |\n",
      "| qf1_loss                | 57.512955   |\n",
      "| qf2_loss                | 57.690166   |\n",
      "| time_elapsed            | 6965        |\n",
      "| total timesteps         | 1087761     |\n",
      "| value_loss              | 0.044111475 |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.026910078 |\n",
      "| ent_coef_loss           | 0.68360233  |\n",
      "| entropy                 | -6.6051397  |\n",
      "| episodes                | 1150        |\n",
      "| fps                     | 156         |\n",
      "| mean 100 episode reward | 901         |\n",
      "| n_updates               | 1094394     |\n",
      "| policy_loss             | -79.74129   |\n",
      "| qf1_loss                | 0.12337968  |\n",
      "| qf2_loss                | 0.10536112  |\n",
      "| time_elapsed            | 7005        |\n",
      "| total timesteps         | 1094493     |\n",
      "| value_loss              | 0.101496816 |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.024855774 |\n",
      "| ent_coef_loss           | -1.954526   |\n",
      "| entropy                 | -5.9177036  |\n",
      "| episodes                | 1160        |\n",
      "| fps                     | 156         |\n",
      "| mean 100 episode reward | 884         |\n",
      "| n_updates               | 1104317     |\n",
      "| policy_loss             | -82.971954  |\n",
      "| qf1_loss                | 0.17343497  |\n",
      "| qf2_loss                | 0.19302455  |\n",
      "| time_elapsed            | 7064        |\n",
      "| total timesteps         | 1104416     |\n",
      "| value_loss              | 0.11072004  |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.026795952 |\n",
      "| ent_coef_loss           | -1.2716554  |\n",
      "| entropy                 | -6.4284735  |\n",
      "| episodes                | 1170        |\n",
      "| fps                     | 156         |\n",
      "| mean 100 episode reward | 900         |\n",
      "| n_updates               | 1111850     |\n",
      "| policy_loss             | -85.88194   |\n",
      "| qf1_loss                | 0.11306356  |\n",
      "| qf2_loss                | 0.10690601  |\n",
      "| time_elapsed            | 7109        |\n",
      "| total timesteps         | 1111949     |\n",
      "| value_loss              | 0.19723967  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.024971345 |\n",
      "| ent_coef_loss           | -1.1366775  |\n",
      "| entropy                 | -6.067008   |\n",
      "| episodes                | 1180        |\n",
      "| fps                     | 156         |\n",
      "| mean 100 episode reward | 849         |\n",
      "| n_updates               | 1116298     |\n",
      "| policy_loss             | -83.83292   |\n",
      "| qf1_loss                | 0.6349807   |\n",
      "| qf2_loss                | 0.6254705   |\n",
      "| time_elapsed            | 7137        |\n",
      "| total timesteps         | 1116397     |\n",
      "| value_loss              | 0.5344664   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.025546093 |\n",
      "| ent_coef_loss           | 2.5362067   |\n",
      "| entropy                 | -5.826146   |\n",
      "| episodes                | 1190        |\n",
      "| fps                     | 156         |\n",
      "| mean 100 episode reward | 830         |\n",
      "| n_updates               | 1123813     |\n",
      "| policy_loss             | -83.609116  |\n",
      "| qf1_loss                | 0.8901058   |\n",
      "| qf2_loss                | 1.2843714   |\n",
      "| time_elapsed            | 7187        |\n",
      "| total timesteps         | 1123912     |\n",
      "| value_loss              | 0.1603247   |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| current_lr              | 0.0003       |\n",
      "| ent_coef                | 0.027102623  |\n",
      "| ent_coef_loss           | -0.105047956 |\n",
      "| entropy                 | -6.0340347   |\n",
      "| episodes                | 1200         |\n",
      "| fps                     | 156          |\n",
      "| mean 100 episode reward | 832          |\n",
      "| n_updates               | 1130028      |\n",
      "| policy_loss             | -84.982025   |\n",
      "| qf1_loss                | 0.5069329    |\n",
      "| qf2_loss                | 0.55157876   |\n",
      "| time_elapsed            | 7226         |\n",
      "| total timesteps         | 1130127      |\n",
      "| value_loss              | 0.37233627   |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.02813461  |\n",
      "| ent_coef_loss           | -0.44013175 |\n",
      "| entropy                 | -6.438635   |\n",
      "| episodes                | 1210        |\n",
      "| fps                     | 156         |\n",
      "| mean 100 episode reward | 808         |\n",
      "| n_updates               | 1138039     |\n",
      "| policy_loss             | -85.78801   |\n",
      "| qf1_loss                | 0.2374987   |\n",
      "| qf2_loss                | 0.08288755  |\n",
      "| time_elapsed            | 7275        |\n",
      "| total timesteps         | 1138138     |\n",
      "| value_loss              | 0.30269176  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029289557 |\n",
      "| ent_coef_loss           | -2.1611648  |\n",
      "| entropy                 | -6.211138   |\n",
      "| episodes                | 1220        |\n",
      "| fps                     | 156         |\n",
      "| mean 100 episode reward | 812         |\n",
      "| n_updates               | 1147901     |\n",
      "| policy_loss             | -86.90242   |\n",
      "| qf1_loss                | 0.2483575   |\n",
      "| qf2_loss                | 0.26729578  |\n",
      "| time_elapsed            | 7334        |\n",
      "| total timesteps         | 1148000     |\n",
      "| value_loss              | 0.12753817  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.025902046 |\n",
      "| ent_coef_loss           | 1.371746    |\n",
      "| entropy                 | -6.1495714  |\n",
      "| episodes                | 1230        |\n",
      "| fps                     | 156         |\n",
      "| mean 100 episode reward | 827         |\n",
      "| n_updates               | 1157901     |\n",
      "| policy_loss             | -86.80745   |\n",
      "| qf1_loss                | 0.3121919   |\n",
      "| qf2_loss                | 0.24978091  |\n",
      "| time_elapsed            | 7396        |\n",
      "| total timesteps         | 1158000     |\n",
      "| value_loss              | 0.110284716 |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.02346602  |\n",
      "| ent_coef_loss           | 1.3364563   |\n",
      "| entropy                 | -6.6360145  |\n",
      "| episodes                | 1240        |\n",
      "| fps                     | 156         |\n",
      "| mean 100 episode reward | 874         |\n",
      "| n_updates               | 1167901     |\n",
      "| policy_loss             | -89.19949   |\n",
      "| qf1_loss                | 63.57206    |\n",
      "| qf2_loss                | 63.206467   |\n",
      "| time_elapsed            | 7457        |\n",
      "| total timesteps         | 1168000     |\n",
      "| value_loss              | 0.103037134 |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.026408019 |\n",
      "| ent_coef_loss           | -0.19914043 |\n",
      "| entropy                 | -6.139435   |\n",
      "| episodes                | 1250        |\n",
      "| fps                     | 156         |\n",
      "| mean 100 episode reward | 934         |\n",
      "| n_updates               | 1176586     |\n",
      "| policy_loss             | -88.165436  |\n",
      "| qf1_loss                | 0.42953664  |\n",
      "| qf2_loss                | 0.39004692  |\n",
      "| time_elapsed            | 7510        |\n",
      "| total timesteps         | 1176685     |\n",
      "| value_loss              | 0.07087723  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.024969863 |\n",
      "| ent_coef_loss           | 0.41476527  |\n",
      "| entropy                 | -5.842222   |\n",
      "| episodes                | 1260        |\n",
      "| fps                     | 156         |\n",
      "| mean 100 episode reward | 973         |\n",
      "| n_updates               | 1185920     |\n",
      "| policy_loss             | -90.94856   |\n",
      "| qf1_loss                | 0.31079897  |\n",
      "| qf2_loss                | 0.3087915   |\n",
      "| time_elapsed            | 7565        |\n",
      "| total timesteps         | 1186019     |\n",
      "| value_loss              | 0.08071182  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.023716409 |\n",
      "| ent_coef_loss           | -0.9369947  |\n",
      "| entropy                 | -6.2433615  |\n",
      "| episodes                | 1270        |\n",
      "| fps                     | 156         |\n",
      "| mean 100 episode reward | 1.03e+03    |\n",
      "| n_updates               | 1195920     |\n",
      "| policy_loss             | -92.58536   |\n",
      "| qf1_loss                | 0.36631134  |\n",
      "| qf2_loss                | 0.2589804   |\n",
      "| time_elapsed            | 7623        |\n",
      "| total timesteps         | 1196019     |\n",
      "| value_loss              | 0.31485814  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.027309867 |\n",
      "| ent_coef_loss           | -1.1119657  |\n",
      "| entropy                 | -6.022334   |\n",
      "| episodes                | 1280        |\n",
      "| fps                     | 156         |\n",
      "| mean 100 episode reward | 1.09e+03    |\n",
      "| n_updates               | 1205777     |\n",
      "| policy_loss             | -97.186615  |\n",
      "| qf1_loss                | 72.78443    |\n",
      "| qf2_loss                | 73.38776    |\n",
      "| time_elapsed            | 7680        |\n",
      "| total timesteps         | 1205876     |\n",
      "| value_loss              | 0.5694134   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.025039919 |\n",
      "| ent_coef_loss           | 0.7564688   |\n",
      "| entropy                 | -6.1461105  |\n",
      "| episodes                | 1290        |\n",
      "| fps                     | 157         |\n",
      "| mean 100 episode reward | 1.15e+03    |\n",
      "| n_updates               | 1215004     |\n",
      "| policy_loss             | -94.01532   |\n",
      "| qf1_loss                | 0.25590125  |\n",
      "| qf2_loss                | 0.3696177   |\n",
      "| time_elapsed            | 7734        |\n",
      "| total timesteps         | 1215103     |\n",
      "| value_loss              | 0.102116324 |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.026084885 |\n",
      "| ent_coef_loss           | 0.0705474   |\n",
      "| entropy                 | -4.315837   |\n",
      "| episodes                | 1300        |\n",
      "| fps                     | 157         |\n",
      "| mean 100 episode reward | 1.2e+03     |\n",
      "| n_updates               | 1223944     |\n",
      "| policy_loss             | -93.8876    |\n",
      "| qf1_loss                | 0.3587299   |\n",
      "| qf2_loss                | 0.5561141   |\n",
      "| time_elapsed            | 7786        |\n",
      "| total timesteps         | 1224043     |\n",
      "| value_loss              | 0.26406837  |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02640654 |\n",
      "| ent_coef_loss           | 1.0053328  |\n",
      "| entropy                 | -5.9221625 |\n",
      "| episodes                | 1310       |\n",
      "| fps                     | 157        |\n",
      "| mean 100 episode reward | 1.22e+03   |\n",
      "| n_updates               | 1232159    |\n",
      "| policy_loss             | -97.38256  |\n",
      "| qf1_loss                | 0.49023527 |\n",
      "| qf2_loss                | 0.60188496 |\n",
      "| time_elapsed            | 7833       |\n",
      "| total timesteps         | 1232258    |\n",
      "| value_loss              | 0.32207996 |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.03084282  |\n",
      "| ent_coef_loss           | -0.86671674 |\n",
      "| entropy                 | -5.2021527  |\n",
      "| episodes                | 1320        |\n",
      "| fps                     | 157         |\n",
      "| mean 100 episode reward | 1.22e+03    |\n",
      "| n_updates               | 1239726     |\n",
      "| policy_loss             | -95.02911   |\n",
      "| qf1_loss                | 0.46477956  |\n",
      "| qf2_loss                | 0.4631216   |\n",
      "| time_elapsed            | 7877        |\n",
      "| total timesteps         | 1239825     |\n",
      "| value_loss              | 0.32538787  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.02540756  |\n",
      "| ent_coef_loss           | -0.13073838 |\n",
      "| entropy                 | -5.989627   |\n",
      "| episodes                | 1330        |\n",
      "| fps                     | 157         |\n",
      "| mean 100 episode reward | 1.19e+03    |\n",
      "| n_updates               | 1247470     |\n",
      "| policy_loss             | -101.11038  |\n",
      "| qf1_loss                | 0.31379238  |\n",
      "| qf2_loss                | 0.20928863  |\n",
      "| time_elapsed            | 7922        |\n",
      "| total timesteps         | 1247569     |\n",
      "| value_loss              | 0.059768256 |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.027782684 |\n",
      "| ent_coef_loss           | -0.22088754 |\n",
      "| entropy                 | -5.358672   |\n",
      "| episodes                | 1340        |\n",
      "| fps                     | 157         |\n",
      "| mean 100 episode reward | 1.19e+03    |\n",
      "| n_updates               | 1255781     |\n",
      "| policy_loss             | -98.36093   |\n",
      "| qf1_loss                | 0.42871985  |\n",
      "| qf2_loss                | 1.1260775   |\n",
      "| time_elapsed            | 7970        |\n",
      "| total timesteps         | 1255880     |\n",
      "| value_loss              | 0.3341064   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031198343 |\n",
      "| ent_coef_loss           | -0.35570025 |\n",
      "| entropy                 | -5.1625185  |\n",
      "| episodes                | 1350        |\n",
      "| fps                     | 157         |\n",
      "| mean 100 episode reward | 1.22e+03    |\n",
      "| n_updates               | 1264912     |\n",
      "| policy_loss             | -98.13834   |\n",
      "| qf1_loss                | 78.40038    |\n",
      "| qf2_loss                | 77.76853    |\n",
      "| time_elapsed            | 8026        |\n",
      "| total timesteps         | 1265011     |\n",
      "| value_loss              | 0.14914435  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030652914 |\n",
      "| ent_coef_loss           | -0.5859568  |\n",
      "| entropy                 | -5.0351367  |\n",
      "| episodes                | 1360        |\n",
      "| fps                     | 157         |\n",
      "| mean 100 episode reward | 1.19e+03    |\n",
      "| n_updates               | 1273964     |\n",
      "| policy_loss             | -101.98098  |\n",
      "| qf1_loss                | 0.2795925   |\n",
      "| qf2_loss                | 0.28318346  |\n",
      "| time_elapsed            | 8081        |\n",
      "| total timesteps         | 1274063     |\n",
      "| value_loss              | 0.22107714  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.026195226 |\n",
      "| ent_coef_loss           | 1.1313374   |\n",
      "| entropy                 | -5.3556128  |\n",
      "| episodes                | 1370        |\n",
      "| fps                     | 157         |\n",
      "| mean 100 episode reward | 1.14e+03    |\n",
      "| n_updates               | 1281930     |\n",
      "| policy_loss             | -99.13158   |\n",
      "| qf1_loss                | 0.26122385  |\n",
      "| qf2_loss                | 0.38033307  |\n",
      "| time_elapsed            | 8128        |\n",
      "| total timesteps         | 1282029     |\n",
      "| value_loss              | 0.26100764  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.025883624 |\n",
      "| ent_coef_loss           | 1.333075    |\n",
      "| entropy                 | -6.0051947  |\n",
      "| episodes                | 1380        |\n",
      "| fps                     | 157         |\n",
      "| mean 100 episode reward | 1.18e+03    |\n",
      "| n_updates               | 1291219     |\n",
      "| policy_loss             | -101.65021  |\n",
      "| qf1_loss                | 0.40241328  |\n",
      "| qf2_loss                | 0.2770545   |\n",
      "| time_elapsed            | 8182        |\n",
      "| total timesteps         | 1291318     |\n",
      "| value_loss              | 0.3188631   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.026716296 |\n",
      "| ent_coef_loss           | 0.4402858   |\n",
      "| entropy                 | -5.667962   |\n",
      "| episodes                | 1390        |\n",
      "| fps                     | 157         |\n",
      "| mean 100 episode reward | 1.23e+03    |\n",
      "| n_updates               | 1301219     |\n",
      "| policy_loss             | -102.855156 |\n",
      "| qf1_loss                | 0.24566954  |\n",
      "| qf2_loss                | 0.22396512  |\n",
      "| time_elapsed            | 8241        |\n",
      "| total timesteps         | 1301318     |\n",
      "| value_loss              | 0.22094329  |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02849096 |\n",
      "| ent_coef_loss           | 0.04334855 |\n",
      "| entropy                 | -4.871482  |\n",
      "| episodes                | 1400       |\n",
      "| fps                     | 157        |\n",
      "| mean 100 episode reward | 1.23e+03   |\n",
      "| n_updates               | 1309526    |\n",
      "| policy_loss             | -107.74844 |\n",
      "| qf1_loss                | 1.5329396  |\n",
      "| qf2_loss                | 1.7115414  |\n",
      "| time_elapsed            | 8290       |\n",
      "| total timesteps         | 1309625    |\n",
      "| value_loss              | 0.17274007 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02781101 |\n",
      "| ent_coef_loss           | 3.0424056  |\n",
      "| entropy                 | -4.7532277 |\n",
      "| episodes                | 1410       |\n",
      "| fps                     | 158        |\n",
      "| mean 100 episode reward | 1.21e+03   |\n",
      "| n_updates               | 1315661    |\n",
      "| policy_loss             | -106.86275 |\n",
      "| qf1_loss                | 4.545534   |\n",
      "| qf2_loss                | 4.34076    |\n",
      "| time_elapsed            | 8326       |\n",
      "| total timesteps         | 1315760    |\n",
      "| value_loss              | 0.37009767 |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.02982474  |\n",
      "| ent_coef_loss           | -0.5475749  |\n",
      "| entropy                 | -5.273959   |\n",
      "| episodes                | 1420        |\n",
      "| fps                     | 158         |\n",
      "| mean 100 episode reward | 1.21e+03    |\n",
      "| n_updates               | 1323002     |\n",
      "| policy_loss             | -105.307846 |\n",
      "| qf1_loss                | 0.9080505   |\n",
      "| qf2_loss                | 0.56864387  |\n",
      "| time_elapsed            | 8368        |\n",
      "| total timesteps         | 1323101     |\n",
      "| value_loss              | 0.49991232  |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.033124894 |\n",
      "| ent_coef_loss           | 3.5445905   |\n",
      "| entropy                 | -5.6454806  |\n",
      "| episodes                | 1430        |\n",
      "| fps                     | 158         |\n",
      "| mean 100 episode reward | 1.22e+03    |\n",
      "| n_updates               | 1330766     |\n",
      "| policy_loss             | -109.77927  |\n",
      "| qf1_loss                | 2.1004348   |\n",
      "| qf2_loss                | 2.4137535   |\n",
      "| time_elapsed            | 8413        |\n",
      "| total timesteps         | 1330865     |\n",
      "| value_loss              | 0.47075248  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.033069324 |\n",
      "| ent_coef_loss           | 0.28262156  |\n",
      "| entropy                 | -4.178084   |\n",
      "| episodes                | 1440        |\n",
      "| fps                     | 158         |\n",
      "| mean 100 episode reward | 1.22e+03    |\n",
      "| n_updates               | 1340303     |\n",
      "| policy_loss             | -99.664734  |\n",
      "| qf1_loss                | 0.75026554  |\n",
      "| qf2_loss                | 0.5095517   |\n",
      "| time_elapsed            | 8471        |\n",
      "| total timesteps         | 1340402     |\n",
      "| value_loss              | 0.5290549   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031494286 |\n",
      "| ent_coef_loss           | -2.352385   |\n",
      "| entropy                 | -4.1855917  |\n",
      "| episodes                | 1450        |\n",
      "| fps                     | 158         |\n",
      "| mean 100 episode reward | 1.2e+03     |\n",
      "| n_updates               | 1350303     |\n",
      "| policy_loss             | -108.84828  |\n",
      "| qf1_loss                | 0.6009871   |\n",
      "| qf2_loss                | 0.39742008  |\n",
      "| time_elapsed            | 8530        |\n",
      "| total timesteps         | 1350402     |\n",
      "| value_loss              | 0.21302766  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.033669084 |\n",
      "| ent_coef_loss           | -1.7941446  |\n",
      "| entropy                 | -5.126821   |\n",
      "| episodes                | 1460        |\n",
      "| fps                     | 158         |\n",
      "| mean 100 episode reward | 1.25e+03    |\n",
      "| n_updates               | 1359396     |\n",
      "| policy_loss             | -109.48908  |\n",
      "| qf1_loss                | 1.2098384   |\n",
      "| qf2_loss                | 1.4704025   |\n",
      "| time_elapsed            | 8584        |\n",
      "| total timesteps         | 1359495     |\n",
      "| value_loss              | 0.48582467  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031878196 |\n",
      "| ent_coef_loss           | -2.1498404  |\n",
      "| entropy                 | -4.9133463  |\n",
      "| episodes                | 1470        |\n",
      "| fps                     | 158         |\n",
      "| mean 100 episode reward | 1.29e+03    |\n",
      "| n_updates               | 1367519     |\n",
      "| policy_loss             | -105.5495   |\n",
      "| qf1_loss                | 1.0596746   |\n",
      "| qf2_loss                | 0.8483094   |\n",
      "| time_elapsed            | 8631        |\n",
      "| total timesteps         | 1367618     |\n",
      "| value_loss              | 0.23916003  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031841774 |\n",
      "| ent_coef_loss           | -2.2559009  |\n",
      "| entropy                 | -5.0646358  |\n",
      "| episodes                | 1480        |\n",
      "| fps                     | 158         |\n",
      "| mean 100 episode reward | 1.25e+03    |\n",
      "| n_updates               | 1376688     |\n",
      "| policy_loss             | -112.27217  |\n",
      "| qf1_loss                | 0.39757296  |\n",
      "| qf2_loss                | 0.3477437   |\n",
      "| time_elapsed            | 8681        |\n",
      "| total timesteps         | 1376787     |\n",
      "| value_loss              | 0.17965527  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.033119522 |\n",
      "| ent_coef_loss           | 1.5504425   |\n",
      "| entropy                 | -5.6228533  |\n",
      "| episodes                | 1490        |\n",
      "| fps                     | 158         |\n",
      "| mean 100 episode reward | 1.24e+03    |\n",
      "| n_updates               | 1385438     |\n",
      "| policy_loss             | -112.00499  |\n",
      "| qf1_loss                | 0.8940405   |\n",
      "| qf2_loss                | 1.2443411   |\n",
      "| time_elapsed            | 8728        |\n",
      "| total timesteps         | 1385537     |\n",
      "| value_loss              | 0.46323884  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.02934814  |\n",
      "| ent_coef_loss           | -0.2601434  |\n",
      "| entropy                 | -5.1397133  |\n",
      "| episodes                | 1500        |\n",
      "| fps                     | 158         |\n",
      "| mean 100 episode reward | 1.25e+03    |\n",
      "| n_updates               | 1393536     |\n",
      "| policy_loss             | -112.872856 |\n",
      "| qf1_loss                | 0.8603084   |\n",
      "| qf2_loss                | 0.7030492   |\n",
      "| time_elapsed            | 8771        |\n",
      "| total timesteps         | 1393635     |\n",
      "| value_loss              | 0.23056     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.033649664 |\n",
      "| ent_coef_loss           | 0.31619403  |\n",
      "| entropy                 | -5.4684305  |\n",
      "| episodes                | 1510        |\n",
      "| fps                     | 159         |\n",
      "| mean 100 episode reward | 1.31e+03    |\n",
      "| n_updates               | 1402825     |\n",
      "| policy_loss             | -111.819916 |\n",
      "| qf1_loss                | 2.676626    |\n",
      "| qf2_loss                | 1.5416156   |\n",
      "| time_elapsed            | 8821        |\n",
      "| total timesteps         | 1402924     |\n",
      "| value_loss              | 0.40313417  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030308403 |\n",
      "| ent_coef_loss           | -0.06132114 |\n",
      "| entropy                 | -5.343063   |\n",
      "| episodes                | 1520        |\n",
      "| fps                     | 159         |\n",
      "| mean 100 episode reward | 1.36e+03    |\n",
      "| n_updates               | 1412825     |\n",
      "| policy_loss             | -114.840546 |\n",
      "| qf1_loss                | 0.9905271   |\n",
      "| qf2_loss                | 0.7429253   |\n",
      "| time_elapsed            | 8874        |\n",
      "| total timesteps         | 1412924     |\n",
      "| value_loss              | 0.43631923  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029888326 |\n",
      "| ent_coef_loss           | -1.1570457  |\n",
      "| entropy                 | -5.381544   |\n",
      "| episodes                | 1530        |\n",
      "| fps                     | 159         |\n",
      "| mean 100 episode reward | 1.36e+03    |\n",
      "| n_updates               | 1421092     |\n",
      "| policy_loss             | -108.50937  |\n",
      "| qf1_loss                | 98.960236   |\n",
      "| qf2_loss                | 95.943535   |\n",
      "| time_elapsed            | 8932        |\n",
      "| total timesteps         | 1421191     |\n",
      "| value_loss              | 0.78902996  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030908888 |\n",
      "| ent_coef_loss           | 1.4089787   |\n",
      "| entropy                 | -4.6972094  |\n",
      "| episodes                | 1540        |\n",
      "| fps                     | 159         |\n",
      "| mean 100 episode reward | 1.3e+03     |\n",
      "| n_updates               | 1428063     |\n",
      "| policy_loss             | -96.44081   |\n",
      "| qf1_loss                | 0.5615787   |\n",
      "| qf2_loss                | 0.4091437   |\n",
      "| time_elapsed            | 8972        |\n",
      "| total timesteps         | 1428162     |\n",
      "| value_loss              | 0.51335955  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.03204948  |\n",
      "| ent_coef_loss           | -0.77052575 |\n",
      "| entropy                 | -4.7448893  |\n",
      "| episodes                | 1550        |\n",
      "| fps                     | 159         |\n",
      "| mean 100 episode reward | 1.31e+03    |\n",
      "| n_updates               | 1436478     |\n",
      "| policy_loss             | -113.67874  |\n",
      "| qf1_loss                | 0.64613247  |\n",
      "| qf2_loss                | 0.813614    |\n",
      "| time_elapsed            | 9018        |\n",
      "| total timesteps         | 1436577     |\n",
      "| value_loss              | 0.35733128  |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.033709317 |\n",
      "| ent_coef_loss           | 4.4919786   |\n",
      "| entropy                 | -4.491882   |\n",
      "| episodes                | 1560        |\n",
      "| fps                     | 159         |\n",
      "| mean 100 episode reward | 1.29e+03    |\n",
      "| n_updates               | 1445239     |\n",
      "| policy_loss             | -117.16727  |\n",
      "| qf1_loss                | 0.62397695  |\n",
      "| qf2_loss                | 0.7857995   |\n",
      "| time_elapsed            | 9065        |\n",
      "| total timesteps         | 1445338     |\n",
      "| value_loss              | 0.15367676  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.033072464 |\n",
      "| ent_coef_loss           | -0.07721275 |\n",
      "| entropy                 | -4.754769   |\n",
      "| episodes                | 1570        |\n",
      "| fps                     | 159         |\n",
      "| mean 100 episode reward | 1.3e+03     |\n",
      "| n_updates               | 1454379     |\n",
      "| policy_loss             | -114.20359  |\n",
      "| qf1_loss                | 0.93417686  |\n",
      "| qf2_loss                | 1.1587002   |\n",
      "| time_elapsed            | 9115        |\n",
      "| total timesteps         | 1454478     |\n",
      "| value_loss              | 0.3190052   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029286066 |\n",
      "| ent_coef_loss           | 3.0299962   |\n",
      "| entropy                 | -6.1441355  |\n",
      "| episodes                | 1580        |\n",
      "| fps                     | 159         |\n",
      "| mean 100 episode reward | 1.29e+03    |\n",
      "| n_updates               | 1462206     |\n",
      "| policy_loss             | -122.55354  |\n",
      "| qf1_loss                | 1.7764485   |\n",
      "| qf2_loss                | 2.497406    |\n",
      "| time_elapsed            | 9161        |\n",
      "| total timesteps         | 1462305     |\n",
      "| value_loss              | 1.6018995   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.032658365 |\n",
      "| ent_coef_loss           | -0.5271903  |\n",
      "| entropy                 | -4.9661956  |\n",
      "| episodes                | 1590        |\n",
      "| fps                     | 159         |\n",
      "| mean 100 episode reward | 1.24e+03    |\n",
      "| n_updates               | 1469240     |\n",
      "| policy_loss             | -117.25511  |\n",
      "| qf1_loss                | 0.91247404  |\n",
      "| qf2_loss                | 0.8499923   |\n",
      "| time_elapsed            | 9205        |\n",
      "| total timesteps         | 1469339     |\n",
      "| value_loss              | 0.31851435  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031542268 |\n",
      "| ent_coef_loss           | -0.9853822  |\n",
      "| entropy                 | -5.6527934  |\n",
      "| episodes                | 1600        |\n",
      "| fps                     | 159         |\n",
      "| mean 100 episode reward | 1.24e+03    |\n",
      "| n_updates               | 1477793     |\n",
      "| policy_loss             | -117.72173  |\n",
      "| qf1_loss                | 1.8542203   |\n",
      "| qf2_loss                | 1.7422857   |\n",
      "| time_elapsed            | 9259        |\n",
      "| total timesteps         | 1477892     |\n",
      "| value_loss              | 0.40084308  |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03058377 |\n",
      "| ent_coef_loss           | 1.4634849  |\n",
      "| entropy                 | -4.665301  |\n",
      "| episodes                | 1610       |\n",
      "| fps                     | 159        |\n",
      "| mean 100 episode reward | 1.24e+03   |\n",
      "| n_updates               | 1485850    |\n",
      "| policy_loss             | -115.79056 |\n",
      "| qf1_loss                | 0.39118028 |\n",
      "| qf2_loss                | 0.56023693 |\n",
      "| time_elapsed            | 9320       |\n",
      "| total timesteps         | 1485949    |\n",
      "| value_loss              | 0.2442731  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03200235 |\n",
      "| ent_coef_loss           | -0.8175663 |\n",
      "| entropy                 | -5.375487  |\n",
      "| episodes                | 1620       |\n",
      "| fps                     | 159        |\n",
      "| mean 100 episode reward | 1.2e+03    |\n",
      "| n_updates               | 1493321    |\n",
      "| policy_loss             | -117.16158 |\n",
      "| qf1_loss                | 1.1826028  |\n",
      "| qf2_loss                | 1.4903172  |\n",
      "| time_elapsed            | 9369       |\n",
      "| total timesteps         | 1493420    |\n",
      "| value_loss              | 0.504814   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03079403 |\n",
      "| ent_coef_loss           | -0.9055274 |\n",
      "| entropy                 | -5.2045665 |\n",
      "| episodes                | 1630       |\n",
      "| fps                     | 159        |\n",
      "| mean 100 episode reward | 1.2e+03    |\n",
      "| n_updates               | 1501293    |\n",
      "| policy_loss             | -118.79908 |\n",
      "| qf1_loss                | 1.204565   |\n",
      "| qf2_loss                | 1.4695734  |\n",
      "| time_elapsed            | 9421       |\n",
      "| total timesteps         | 1501392    |\n",
      "| value_loss              | 0.28673372 |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029418204 |\n",
      "| ent_coef_loss           | -0.9070161  |\n",
      "| entropy                 | -5.46729    |\n",
      "| episodes                | 1640        |\n",
      "| fps                     | 159         |\n",
      "| mean 100 episode reward | 1.26e+03    |\n",
      "| n_updates               | 1510115     |\n",
      "| policy_loss             | -113.7841   |\n",
      "| qf1_loss                | 0.991769    |\n",
      "| qf2_loss                | 1.0279298   |\n",
      "| time_elapsed            | 9477        |\n",
      "| total timesteps         | 1510214     |\n",
      "| value_loss              | 0.43140993  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.032387502 |\n",
      "| ent_coef_loss           | -1.4862593  |\n",
      "| entropy                 | -5.56532    |\n",
      "| episodes                | 1650        |\n",
      "| fps                     | 159         |\n",
      "| mean 100 episode reward | 1.24e+03    |\n",
      "| n_updates               | 1517974     |\n",
      "| policy_loss             | -123.30825  |\n",
      "| qf1_loss                | 0.94146675  |\n",
      "| qf2_loss                | 1.2563682   |\n",
      "| time_elapsed            | 9527        |\n",
      "| total timesteps         | 1518073     |\n",
      "| value_loss              | 0.64817667  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.03215746  |\n",
      "| ent_coef_loss           | 0.2936911   |\n",
      "| entropy                 | -4.5666018  |\n",
      "| episodes                | 1660        |\n",
      "| fps                     | 159         |\n",
      "| mean 100 episode reward | 1.26e+03    |\n",
      "| n_updates               | 1526040     |\n",
      "| policy_loss             | -117.057396 |\n",
      "| qf1_loss                | 0.9147524   |\n",
      "| qf2_loss                | 0.8498943   |\n",
      "| time_elapsed            | 9578        |\n",
      "| total timesteps         | 1526139     |\n",
      "| value_loss              | 0.33436155  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.033301834 |\n",
      "| ent_coef_loss           | 0.8214732   |\n",
      "| entropy                 | -5.0653734  |\n",
      "| episodes                | 1670        |\n",
      "| fps                     | 159         |\n",
      "| mean 100 episode reward | 1.24e+03    |\n",
      "| n_updates               | 1533892     |\n",
      "| policy_loss             | -115.85643  |\n",
      "| qf1_loss                | 3.086126    |\n",
      "| qf2_loss                | 2.8087344   |\n",
      "| time_elapsed            | 9629        |\n",
      "| total timesteps         | 1533991     |\n",
      "| value_loss              | 0.7690289   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.032113004 |\n",
      "| ent_coef_loss           | -0.06559503 |\n",
      "| entropy                 | -5.1317797  |\n",
      "| episodes                | 1680        |\n",
      "| fps                     | 159         |\n",
      "| mean 100 episode reward | 1.27e+03    |\n",
      "| n_updates               | 1543148     |\n",
      "| policy_loss             | -115.04266  |\n",
      "| qf1_loss                | 2.549492    |\n",
      "| qf2_loss                | 3.5084481   |\n",
      "| time_elapsed            | 9688        |\n",
      "| total timesteps         | 1543247     |\n",
      "| value_loss              | 1.0980123   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029158859 |\n",
      "| ent_coef_loss           | -0.61146414 |\n",
      "| entropy                 | -4.989443   |\n",
      "| episodes                | 1690        |\n",
      "| fps                     | 159         |\n",
      "| mean 100 episode reward | 1.34e+03    |\n",
      "| n_updates               | 1552127     |\n",
      "| policy_loss             | -118.99074  |\n",
      "| qf1_loss                | 5.9768      |\n",
      "| qf2_loss                | 7.5414286   |\n",
      "| time_elapsed            | 9742        |\n",
      "| total timesteps         | 1552226     |\n",
      "| value_loss              | 0.67591625  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028956613 |\n",
      "| ent_coef_loss           | -0.7842834  |\n",
      "| entropy                 | -5.1328855  |\n",
      "| episodes                | 1700        |\n",
      "| fps                     | 159         |\n",
      "| mean 100 episode reward | 1.35e+03    |\n",
      "| n_updates               | 1562009     |\n",
      "| policy_loss             | -121.18358  |\n",
      "| qf1_loss                | 1.3033764   |\n",
      "| qf2_loss                | 2.68641     |\n",
      "| time_elapsed            | 9807        |\n",
      "| total timesteps         | 1562108     |\n",
      "| value_loss              | 0.31703818  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030290922 |\n",
      "| ent_coef_loss           | 1.3567059   |\n",
      "| entropy                 | -5.6281157  |\n",
      "| episodes                | 1710        |\n",
      "| fps                     | 159         |\n",
      "| mean 100 episode reward | 1.35e+03    |\n",
      "| n_updates               | 1570325     |\n",
      "| policy_loss             | -123.372795 |\n",
      "| qf1_loss                | 1.4722362   |\n",
      "| qf2_loss                | 0.88518375  |\n",
      "| time_elapsed            | 9861        |\n",
      "| total timesteps         | 1570424     |\n",
      "| value_loss              | 0.36164767  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030201098 |\n",
      "| ent_coef_loss           | 0.1256831   |\n",
      "| entropy                 | -5.197062   |\n",
      "| episodes                | 1720        |\n",
      "| fps                     | 159         |\n",
      "| mean 100 episode reward | 1.35e+03    |\n",
      "| n_updates               | 1580325     |\n",
      "| policy_loss             | -121.86795  |\n",
      "| qf1_loss                | 13.133357   |\n",
      "| qf2_loss                | 6.320854    |\n",
      "| time_elapsed            | 9926        |\n",
      "| total timesteps         | 1580424     |\n",
      "| value_loss              | 2.0392623   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.027471337 |\n",
      "| ent_coef_loss           | 1.1924869   |\n",
      "| entropy                 | -4.6990705  |\n",
      "| episodes                | 1730        |\n",
      "| fps                     | 159         |\n",
      "| mean 100 episode reward | 1.39e+03    |\n",
      "| n_updates               | 1588985     |\n",
      "| policy_loss             | -119.55737  |\n",
      "| qf1_loss                | 1.4700832   |\n",
      "| qf2_loss                | 1.4754059   |\n",
      "| time_elapsed            | 9990        |\n",
      "| total timesteps         | 1589084     |\n",
      "| value_loss              | 0.4160065   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030288812 |\n",
      "| ent_coef_loss           | -0.25753343 |\n",
      "| entropy                 | -5.0607805  |\n",
      "| episodes                | 1740        |\n",
      "| fps                     | 158         |\n",
      "| mean 100 episode reward | 1.39e+03    |\n",
      "| n_updates               | 1597573     |\n",
      "| policy_loss             | -127.06378  |\n",
      "| qf1_loss                | 2.2604759   |\n",
      "| qf2_loss                | 6.0071764   |\n",
      "| time_elapsed            | 10053       |\n",
      "| total timesteps         | 1597672     |\n",
      "| value_loss              | 0.29176182  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030282026 |\n",
      "| ent_coef_loss           | 2.4071658   |\n",
      "| entropy                 | -5.857375   |\n",
      "| episodes                | 1750        |\n",
      "| fps                     | 158         |\n",
      "| mean 100 episode reward | 1.4e+03     |\n",
      "| n_updates               | 1605527     |\n",
      "| policy_loss             | -128.73238  |\n",
      "| qf1_loss                | 0.9536626   |\n",
      "| qf2_loss                | 1.1691492   |\n",
      "| time_elapsed            | 10110       |\n",
      "| total timesteps         | 1605626     |\n",
      "| value_loss              | 0.7251083   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030107537 |\n",
      "| ent_coef_loss           | 1.8267424   |\n",
      "| entropy                 | -5.7745495  |\n",
      "| episodes                | 1760        |\n",
      "| fps                     | 158         |\n",
      "| mean 100 episode reward | 1.4e+03     |\n",
      "| n_updates               | 1614726     |\n",
      "| policy_loss             | -117.097176 |\n",
      "| qf1_loss                | 1.0537915   |\n",
      "| qf2_loss                | 0.81904155  |\n",
      "| time_elapsed            | 10178       |\n",
      "| total timesteps         | 1614825     |\n",
      "| value_loss              | 0.9646545   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.033415336 |\n",
      "| ent_coef_loss           | 1.4593385   |\n",
      "| entropy                 | -5.4858813  |\n",
      "| episodes                | 1770        |\n",
      "| fps                     | 158         |\n",
      "| mean 100 episode reward | 1.45e+03    |\n",
      "| n_updates               | 1622705     |\n",
      "| policy_loss             | -123.41203  |\n",
      "| qf1_loss                | 2.1640933   |\n",
      "| qf2_loss                | 3.6178327   |\n",
      "| time_elapsed            | 10236       |\n",
      "| total timesteps         | 1622804     |\n",
      "| value_loss              | 0.8733014   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.027904779 |\n",
      "| ent_coef_loss           | 2.491363    |\n",
      "| entropy                 | -5.3049774  |\n",
      "| episodes                | 1780        |\n",
      "| fps                     | 158         |\n",
      "| mean 100 episode reward | 1.47e+03    |\n",
      "| n_updates               | 1631811     |\n",
      "| policy_loss             | -122.38074  |\n",
      "| qf1_loss                | 170.51836   |\n",
      "| qf2_loss                | 169.60104   |\n",
      "| time_elapsed            | 10300       |\n",
      "| total timesteps         | 1631910     |\n",
      "| value_loss              | 2.6563613   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030789545 |\n",
      "| ent_coef_loss           | 0.56285584  |\n",
      "| entropy                 | -5.0450945  |\n",
      "| episodes                | 1790        |\n",
      "| fps                     | 158         |\n",
      "| mean 100 episode reward | 1.51e+03    |\n",
      "| n_updates               | 1641648     |\n",
      "| policy_loss             | -117.77303  |\n",
      "| qf1_loss                | 1.4379852   |\n",
      "| qf2_loss                | 1.4598597   |\n",
      "| time_elapsed            | 10363       |\n",
      "| total timesteps         | 1641747     |\n",
      "| value_loss              | 0.3949551   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028137295 |\n",
      "| ent_coef_loss           | -1.6662177  |\n",
      "| entropy                 | -5.8918653  |\n",
      "| episodes                | 1800        |\n",
      "| fps                     | 158         |\n",
      "| mean 100 episode reward | 1.49e+03    |\n",
      "| n_updates               | 1649022     |\n",
      "| policy_loss             | -124.42879  |\n",
      "| qf1_loss                | 1.3813951   |\n",
      "| qf2_loss                | 0.8504206   |\n",
      "| time_elapsed            | 10419       |\n",
      "| total timesteps         | 1649121     |\n",
      "| value_loss              | 1.1233535   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030265344 |\n",
      "| ent_coef_loss           | 1.118664    |\n",
      "| entropy                 | -4.6136827  |\n",
      "| episodes                | 1810        |\n",
      "| fps                     | 158         |\n",
      "| mean 100 episode reward | 1.53e+03    |\n",
      "| n_updates               | 1658012     |\n",
      "| policy_loss             | -117.62677  |\n",
      "| qf1_loss                | 1.8206797   |\n",
      "| qf2_loss                | 1.3383647   |\n",
      "| time_elapsed            | 10483       |\n",
      "| total timesteps         | 1658111     |\n",
      "| value_loss              | 0.7108612   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02958759 |\n",
      "| ent_coef_loss           | 0.6717759  |\n",
      "| entropy                 | -4.624345  |\n",
      "| episodes                | 1820       |\n",
      "| fps                     | 158        |\n",
      "| mean 100 episode reward | 1.52e+03   |\n",
      "| n_updates               | 1665178    |\n",
      "| policy_loss             | -128.28215 |\n",
      "| qf1_loss                | 2.0642762  |\n",
      "| qf2_loss                | 1.8819712  |\n",
      "| time_elapsed            | 10534      |\n",
      "| total timesteps         | 1665277    |\n",
      "| value_loss              | 0.40884748 |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030803137 |\n",
      "| ent_coef_loss           | -0.3595178  |\n",
      "| entropy                 | -4.683731   |\n",
      "| episodes                | 1830        |\n",
      "| fps                     | 158         |\n",
      "| mean 100 episode reward | 1.52e+03    |\n",
      "| n_updates               | 1672047     |\n",
      "| policy_loss             | -117.00893  |\n",
      "| qf1_loss                | 3.0302687   |\n",
      "| qf2_loss                | 2.3005586   |\n",
      "| time_elapsed            | 10583       |\n",
      "| total timesteps         | 1672146     |\n",
      "| value_loss              | 0.90171915  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031204347 |\n",
      "| ent_coef_loss           | -4.2359834  |\n",
      "| entropy                 | -4.802756   |\n",
      "| episodes                | 1840        |\n",
      "| fps                     | 157         |\n",
      "| mean 100 episode reward | 1.54e+03    |\n",
      "| n_updates               | 1679938     |\n",
      "| policy_loss             | -120.527954 |\n",
      "| qf1_loss                | 1.3364934   |\n",
      "| qf2_loss                | 1.3857911   |\n",
      "| time_elapsed            | 10638       |\n",
      "| total timesteps         | 1680037     |\n",
      "| value_loss              | 0.38344988  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030053312 |\n",
      "| ent_coef_loss           | -1.45523    |\n",
      "| entropy                 | -4.8894396  |\n",
      "| episodes                | 1850        |\n",
      "| fps                     | 157         |\n",
      "| mean 100 episode reward | 1.59e+03    |\n",
      "| n_updates               | 1688065     |\n",
      "| policy_loss             | -120.63263  |\n",
      "| qf1_loss                | 1.3471667   |\n",
      "| qf2_loss                | 1.6066515   |\n",
      "| time_elapsed            | 10695       |\n",
      "| total timesteps         | 1688164     |\n",
      "| value_loss              | 0.46999592  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030622732 |\n",
      "| ent_coef_loss           | -1.5155044  |\n",
      "| entropy                 | -4.767007   |\n",
      "| episodes                | 1860        |\n",
      "| fps                     | 157         |\n",
      "| mean 100 episode reward | 1.58e+03    |\n",
      "| n_updates               | 1695331     |\n",
      "| policy_loss             | -117.3974   |\n",
      "| qf1_loss                | 1.2927599   |\n",
      "| qf2_loss                | 1.4212921   |\n",
      "| time_elapsed            | 10746       |\n",
      "| total timesteps         | 1695430     |\n",
      "| value_loss              | 0.6599479   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028653832 |\n",
      "| ent_coef_loss           | 0.48298883  |\n",
      "| entropy                 | -5.4179173  |\n",
      "| episodes                | 1870        |\n",
      "| fps                     | 157         |\n",
      "| mean 100 episode reward | 1.56e+03    |\n",
      "| n_updates               | 1702298     |\n",
      "| policy_loss             | -124.779945 |\n",
      "| qf1_loss                | 4.397053    |\n",
      "| qf2_loss                | 4.747698    |\n",
      "| time_elapsed            | 10798       |\n",
      "| total timesteps         | 1702397     |\n",
      "| value_loss              | 0.44728208  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031707928 |\n",
      "| ent_coef_loss           | -0.31861687 |\n",
      "| entropy                 | -5.143884   |\n",
      "| episodes                | 1880        |\n",
      "| fps                     | 157         |\n",
      "| mean 100 episode reward | 1.56e+03    |\n",
      "| n_updates               | 1710251     |\n",
      "| policy_loss             | -130.24567  |\n",
      "| qf1_loss                | 1.3733233   |\n",
      "| qf2_loss                | 2.8115044   |\n",
      "| time_elapsed            | 10856       |\n",
      "| total timesteps         | 1710350     |\n",
      "| value_loss              | 0.9498695   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.032078408 |\n",
      "| ent_coef_loss           | 0.5897721   |\n",
      "| entropy                 | -4.5546966  |\n",
      "| episodes                | 1890        |\n",
      "| fps                     | 157         |\n",
      "| mean 100 episode reward | 1.49e+03    |\n",
      "| n_updates               | 1718347     |\n",
      "| policy_loss             | -125.26855  |\n",
      "| qf1_loss                | 2.1770058   |\n",
      "| qf2_loss                | 1.6789925   |\n",
      "| time_elapsed            | 10914       |\n",
      "| total timesteps         | 1718446     |\n",
      "| value_loss              | 1.0003054   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.033871118 |\n",
      "| ent_coef_loss           | -0.6257235  |\n",
      "| entropy                 | -5.329397   |\n",
      "| episodes                | 1900        |\n",
      "| fps                     | 157         |\n",
      "| mean 100 episode reward | 1.51e+03    |\n",
      "| n_updates               | 1726320     |\n",
      "| policy_loss             | -128.3364   |\n",
      "| qf1_loss                | 5.7098155   |\n",
      "| qf2_loss                | 6.1526523   |\n",
      "| time_elapsed            | 10973       |\n",
      "| total timesteps         | 1726419     |\n",
      "| value_loss              | 1.5279038   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.034144454 |\n",
      "| ent_coef_loss           | -0.33712095 |\n",
      "| entropy                 | -4.833067   |\n",
      "| episodes                | 1910        |\n",
      "| fps                     | 157         |\n",
      "| mean 100 episode reward | 1.53e+03    |\n",
      "| n_updates               | 1735767     |\n",
      "| policy_loss             | -133.86494  |\n",
      "| qf1_loss                | 1.170851    |\n",
      "| qf2_loss                | 1.2974154   |\n",
      "| time_elapsed            | 11042       |\n",
      "| total timesteps         | 1735866     |\n",
      "| value_loss              | 0.810731    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030755473 |\n",
      "| ent_coef_loss           | 1.8675045   |\n",
      "| entropy                 | -5.1629586  |\n",
      "| episodes                | 1920        |\n",
      "| fps                     | 157         |\n",
      "| mean 100 episode reward | 1.59e+03    |\n",
      "| n_updates               | 1745544     |\n",
      "| policy_loss             | -125.58389  |\n",
      "| qf1_loss                | 2.0047529   |\n",
      "| qf2_loss                | 1.765564    |\n",
      "| time_elapsed            | 11113       |\n",
      "| total timesteps         | 1745643     |\n",
      "| value_loss              | 1.5315161   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.032704145 |\n",
      "| ent_coef_loss           | -1.0896958  |\n",
      "| entropy                 | -4.9819107  |\n",
      "| episodes                | 1930        |\n",
      "| fps                     | 157         |\n",
      "| mean 100 episode reward | 1.59e+03    |\n",
      "| n_updates               | 1753865     |\n",
      "| policy_loss             | -115.32063  |\n",
      "| qf1_loss                | 8.147553    |\n",
      "| qf2_loss                | 5.058625    |\n",
      "| time_elapsed            | 11170       |\n",
      "| total timesteps         | 1753964     |\n",
      "| value_loss              | 1.2284067   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028860128 |\n",
      "| ent_coef_loss           | -0.21124804 |\n",
      "| entropy                 | -5.035701   |\n",
      "| episodes                | 1940        |\n",
      "| fps                     | 157         |\n",
      "| mean 100 episode reward | 1.62e+03    |\n",
      "| n_updates               | 1762907     |\n",
      "| policy_loss             | -131.93361  |\n",
      "| qf1_loss                | 1.1257057   |\n",
      "| qf2_loss                | 1.30562     |\n",
      "| time_elapsed            | 11224       |\n",
      "| total timesteps         | 1763006     |\n",
      "| value_loss              | 0.70342875  |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028431349 |\n",
      "| ent_coef_loss           | 0.37827498  |\n",
      "| entropy                 | -5.2178335  |\n",
      "| episodes                | 1950        |\n",
      "| fps                     | 156         |\n",
      "| mean 100 episode reward | 1.6e+03     |\n",
      "| n_updates               | 1770856     |\n",
      "| policy_loss             | -131.57191  |\n",
      "| qf1_loss                | 2.098434    |\n",
      "| qf2_loss                | 1.79597     |\n",
      "| time_elapsed            | 11281       |\n",
      "| total timesteps         | 1770955     |\n",
      "| value_loss              | 1.3599614   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028609557 |\n",
      "| ent_coef_loss           | 0.31301796  |\n",
      "| entropy                 | -5.022274   |\n",
      "| episodes                | 1960        |\n",
      "| fps                     | 156         |\n",
      "| mean 100 episode reward | 1.66e+03    |\n",
      "| n_updates               | 1778970     |\n",
      "| policy_loss             | -128.98198  |\n",
      "| qf1_loss                | 139.49727   |\n",
      "| qf2_loss                | 139.06773   |\n",
      "| time_elapsed            | 11342       |\n",
      "| total timesteps         | 1779069     |\n",
      "| value_loss              | 0.7391999   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030304682 |\n",
      "| ent_coef_loss           | 1.6460781   |\n",
      "| entropy                 | -5.8660617  |\n",
      "| episodes                | 1970        |\n",
      "| fps                     | 156         |\n",
      "| mean 100 episode reward | 1.68e+03    |\n",
      "| n_updates               | 1788970     |\n",
      "| policy_loss             | -141.15353  |\n",
      "| qf1_loss                | 211.66194   |\n",
      "| qf2_loss                | 207.71042   |\n",
      "| time_elapsed            | 11413       |\n",
      "| total timesteps         | 1789069     |\n",
      "| value_loss              | 2.3570166   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03156205 |\n",
      "| ent_coef_loss           | 4.884622   |\n",
      "| entropy                 | -5.530216  |\n",
      "| episodes                | 1980       |\n",
      "| fps                     | 156        |\n",
      "| mean 100 episode reward | 1.71e+03   |\n",
      "| n_updates               | 1798970    |\n",
      "| policy_loss             | -134.91302 |\n",
      "| qf1_loss                | 9.974572   |\n",
      "| qf2_loss                | 3.3360057  |\n",
      "| time_elapsed            | 11484      |\n",
      "| total timesteps         | 1799069    |\n",
      "| value_loss              | 1.764636   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03200688 |\n",
      "| ent_coef_loss           | 1.1116999  |\n",
      "| entropy                 | -5.705166  |\n",
      "| episodes                | 1990       |\n",
      "| fps                     | 156        |\n",
      "| mean 100 episode reward | 1.78e+03   |\n",
      "| n_updates               | 1808113    |\n",
      "| policy_loss             | -132.25067 |\n",
      "| qf1_loss                | 5.8723345  |\n",
      "| qf2_loss                | 4.266667   |\n",
      "| time_elapsed            | 11546      |\n",
      "| total timesteps         | 1808212    |\n",
      "| value_loss              | 0.6473892  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03307229 |\n",
      "| ent_coef_loss           | -1.9262636 |\n",
      "| entropy                 | -5.442677  |\n",
      "| episodes                | 2000       |\n",
      "| fps                     | 156        |\n",
      "| mean 100 episode reward | 1.82e+03   |\n",
      "| n_updates               | 1817313    |\n",
      "| policy_loss             | -128.84775 |\n",
      "| qf1_loss                | 1.9778801  |\n",
      "| qf2_loss                | 1.9365256  |\n",
      "| time_elapsed            | 11609      |\n",
      "| total timesteps         | 1817412    |\n",
      "| value_loss              | 1.052546   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030886369 |\n",
      "| ent_coef_loss           | -1.4173003  |\n",
      "| entropy                 | -4.770594   |\n",
      "| episodes                | 2010        |\n",
      "| fps                     | 156         |\n",
      "| mean 100 episode reward | 1.8e+03     |\n",
      "| n_updates               | 1825633     |\n",
      "| policy_loss             | -122.901505 |\n",
      "| qf1_loss                | 4.123104    |\n",
      "| qf2_loss                | 3.991456    |\n",
      "| time_elapsed            | 11673       |\n",
      "| total timesteps         | 1825732     |\n",
      "| value_loss              | 1.1691022   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03117241 |\n",
      "| ent_coef_loss           | -1.2765228 |\n",
      "| entropy                 | -5.2082458 |\n",
      "| episodes                | 2020       |\n",
      "| fps                     | 155        |\n",
      "| mean 100 episode reward | 1.79e+03   |\n",
      "| n_updates               | 1835107    |\n",
      "| policy_loss             | -136.3705  |\n",
      "| qf1_loss                | 1.441922   |\n",
      "| qf2_loss                | 1.105673   |\n",
      "| time_elapsed            | 11764      |\n",
      "| total timesteps         | 1835206    |\n",
      "| value_loss              | 0.6694446  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.033273265 |\n",
      "| ent_coef_loss           | -1.0211625  |\n",
      "| entropy                 | -5.2431593  |\n",
      "| episodes                | 2030        |\n",
      "| fps                     | 155         |\n",
      "| mean 100 episode reward | 1.87e+03    |\n",
      "| n_updates               | 1845107     |\n",
      "| policy_loss             | -129.00809  |\n",
      "| qf1_loss                | 1.5822635   |\n",
      "| qf2_loss                | 2.0551023   |\n",
      "| time_elapsed            | 11866       |\n",
      "| total timesteps         | 1845206     |\n",
      "| value_loss              | 1.3464148   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030850174 |\n",
      "| ent_coef_loss           | -1.9740485  |\n",
      "| entropy                 | -4.9528885  |\n",
      "| episodes                | 2040        |\n",
      "| fps                     | 154         |\n",
      "| mean 100 episode reward | 1.88e+03    |\n",
      "| n_updates               | 1853644     |\n",
      "| policy_loss             | -137.45918  |\n",
      "| qf1_loss                | 1.3250687   |\n",
      "| qf2_loss                | 1.2356873   |\n",
      "| time_elapsed            | 11965       |\n",
      "| total timesteps         | 1853743     |\n",
      "| value_loss              | 0.5192571   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031016193 |\n",
      "| ent_coef_loss           | -1.4630209  |\n",
      "| entropy                 | -5.1133757  |\n",
      "| episodes                | 2050        |\n",
      "| fps                     | 154         |\n",
      "| mean 100 episode reward | 1.91e+03    |\n",
      "| n_updates               | 1863106     |\n",
      "| policy_loss             | -127.730125 |\n",
      "| qf1_loss                | 3.324933    |\n",
      "| qf2_loss                | 2.6486726   |\n",
      "| time_elapsed            | 12074       |\n",
      "| total timesteps         | 1863205     |\n",
      "| value_loss              | 1.096082    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.034003764 |\n",
      "| ent_coef_loss           | -1.1583937  |\n",
      "| entropy                 | -5.2338505  |\n",
      "| episodes                | 2060        |\n",
      "| fps                     | 153         |\n",
      "| mean 100 episode reward | 1.95e+03    |\n",
      "| n_updates               | 1872942     |\n",
      "| policy_loss             | -135.8343   |\n",
      "| qf1_loss                | 4.3752327   |\n",
      "| qf2_loss                | 3.8012412   |\n",
      "| time_elapsed            | 12188       |\n",
      "| total timesteps         | 1873041     |\n",
      "| value_loss              | 0.8934263   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031811733 |\n",
      "| ent_coef_loss           | -3.0796063  |\n",
      "| entropy                 | -4.7863913  |\n",
      "| episodes                | 2070        |\n",
      "| fps                     | 153         |\n",
      "| mean 100 episode reward | 1.96e+03    |\n",
      "| n_updates               | 1881596     |\n",
      "| policy_loss             | -144.13078  |\n",
      "| qf1_loss                | 1.8855343   |\n",
      "| qf2_loss                | 1.9432093   |\n",
      "| time_elapsed            | 12289       |\n",
      "| total timesteps         | 1881695     |\n",
      "| value_loss              | 0.508915    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.033380117 |\n",
      "| ent_coef_loss           | 0.94530106  |\n",
      "| entropy                 | -5.3058057  |\n",
      "| episodes                | 2080        |\n",
      "| fps                     | 152         |\n",
      "| mean 100 episode reward | 1.94e+03    |\n",
      "| n_updates               | 1889827     |\n",
      "| policy_loss             | -135.18378  |\n",
      "| qf1_loss                | 200.2698    |\n",
      "| qf2_loss                | 201.79382   |\n",
      "| time_elapsed            | 12384       |\n",
      "| total timesteps         | 1889926     |\n",
      "| value_loss              | 1.8472002   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031936493 |\n",
      "| ent_coef_loss           | 0.31423068  |\n",
      "| entropy                 | -5.10779    |\n",
      "| episodes                | 2090        |\n",
      "| fps                     | 152         |\n",
      "| mean 100 episode reward | 1.92e+03    |\n",
      "| n_updates               | 1897219     |\n",
      "| policy_loss             | -135.88892  |\n",
      "| qf1_loss                | 2.9363794   |\n",
      "| qf2_loss                | 3.1807518   |\n",
      "| time_elapsed            | 12466       |\n",
      "| total timesteps         | 1897318     |\n",
      "| value_loss              | 1.0652013   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03371311 |\n",
      "| ent_coef_loss           | 1.4303422  |\n",
      "| entropy                 | -5.092662  |\n",
      "| episodes                | 2100       |\n",
      "| fps                     | 151        |\n",
      "| mean 100 episode reward | 1.9e+03    |\n",
      "| n_updates               | 1904313    |\n",
      "| policy_loss             | -145.58197 |\n",
      "| qf1_loss                | 5.9971848  |\n",
      "| qf2_loss                | 6.8960433  |\n",
      "| time_elapsed            | 12546      |\n",
      "| total timesteps         | 1904412    |\n",
      "| value_loss              | 0.98691916 |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.033825707 |\n",
      "| ent_coef_loss           | 0.8754349   |\n",
      "| entropy                 | -5.7764883  |\n",
      "| episodes                | 2110        |\n",
      "| fps                     | 151         |\n",
      "| mean 100 episode reward | 1.89e+03    |\n",
      "| n_updates               | 1912398     |\n",
      "| policy_loss             | -142.75574  |\n",
      "| qf1_loss                | 204.83798   |\n",
      "| qf2_loss                | 205.01472   |\n",
      "| time_elapsed            | 12638       |\n",
      "| total timesteps         | 1912497     |\n",
      "| value_loss              | 1.397802    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030220589 |\n",
      "| ent_coef_loss           | 0.64087003  |\n",
      "| entropy                 | -5.755829   |\n",
      "| episodes                | 2120        |\n",
      "| fps                     | 150         |\n",
      "| mean 100 episode reward | 1.91e+03    |\n",
      "| n_updates               | 1921170     |\n",
      "| policy_loss             | -153.11865  |\n",
      "| qf1_loss                | 5.071482    |\n",
      "| qf2_loss                | 3.2157335   |\n",
      "| time_elapsed            | 12736       |\n",
      "| total timesteps         | 1921269     |\n",
      "| value_loss              | 3.3346152   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030888563 |\n",
      "| ent_coef_loss           | 1.2302694   |\n",
      "| entropy                 | -5.3332133  |\n",
      "| episodes                | 2130        |\n",
      "| fps                     | 150         |\n",
      "| mean 100 episode reward | 1.85e+03    |\n",
      "| n_updates               | 1930116     |\n",
      "| policy_loss             | -138.84512  |\n",
      "| qf1_loss                | 2.3413482   |\n",
      "| qf2_loss                | 1.8412507   |\n",
      "| time_elapsed            | 12838       |\n",
      "| total timesteps         | 1930215     |\n",
      "| value_loss              | 3.3050935   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.032772925 |\n",
      "| ent_coef_loss           | -1.2716467  |\n",
      "| entropy                 | -5.0266714  |\n",
      "| episodes                | 2140        |\n",
      "| fps                     | 149         |\n",
      "| mean 100 episode reward | 1.82e+03    |\n",
      "| n_updates               | 1938300     |\n",
      "| policy_loss             | -135.76685  |\n",
      "| qf1_loss                | 3.220842    |\n",
      "| qf2_loss                | 5.432745    |\n",
      "| time_elapsed            | 12930       |\n",
      "| total timesteps         | 1938399     |\n",
      "| value_loss              | 1.8712002   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030799229 |\n",
      "| ent_coef_loss           | 0.5570226   |\n",
      "| entropy                 | -5.339053   |\n",
      "| episodes                | 2150        |\n",
      "| fps                     | 149         |\n",
      "| mean 100 episode reward | 1.82e+03    |\n",
      "| n_updates               | 1946984     |\n",
      "| policy_loss             | -132.70833  |\n",
      "| qf1_loss                | 6.0566673   |\n",
      "| qf2_loss                | 5.015235    |\n",
      "| time_elapsed            | 13021       |\n",
      "| total timesteps         | 1947083     |\n",
      "| value_loss              | 1.054899    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029862093 |\n",
      "| ent_coef_loss           | 3.5146222   |\n",
      "| entropy                 | -4.968113   |\n",
      "| episodes                | 2160        |\n",
      "| fps                     | 149         |\n",
      "| mean 100 episode reward | 1.82e+03    |\n",
      "| n_updates               | 1956155     |\n",
      "| policy_loss             | -126.05298  |\n",
      "| qf1_loss                | 4.0221863   |\n",
      "| qf2_loss                | 2.7467399   |\n",
      "| time_elapsed            | 13116       |\n",
      "| total timesteps         | 1956254     |\n",
      "| value_loss              | 1.7100507   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031208498 |\n",
      "| ent_coef_loss           | -0.79181576 |\n",
      "| entropy                 | -5.699954   |\n",
      "| episodes                | 2170        |\n",
      "| fps                     | 148         |\n",
      "| mean 100 episode reward | 1.86e+03    |\n",
      "| n_updates               | 1966155     |\n",
      "| policy_loss             | -150.80617  |\n",
      "| qf1_loss                | 2.5849683   |\n",
      "| qf2_loss                | 2.5532587   |\n",
      "| time_elapsed            | 13221       |\n",
      "| total timesteps         | 1966254     |\n",
      "| value_loss              | 0.99379647  |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03173302 |\n",
      "| ent_coef_loss           | -1.5271802 |\n",
      "| entropy                 | -5.041976  |\n",
      "| episodes                | 2180       |\n",
      "| fps                     | 148        |\n",
      "| mean 100 episode reward | 1.88e+03   |\n",
      "| n_updates               | 1974223    |\n",
      "| policy_loss             | -138.49304 |\n",
      "| qf1_loss                | 2.2612076  |\n",
      "| qf2_loss                | 3.4606037  |\n",
      "| time_elapsed            | 13305      |\n",
      "| total timesteps         | 1974322    |\n",
      "| value_loss              | 0.6584754  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03153626 |\n",
      "| ent_coef_loss           | 0.78202546 |\n",
      "| entropy                 | -4.816411  |\n",
      "| episodes                | 2190       |\n",
      "| fps                     | 147        |\n",
      "| mean 100 episode reward | 1.91e+03   |\n",
      "| n_updates               | 1983833    |\n",
      "| policy_loss             | -145.30968 |\n",
      "| qf1_loss                | 8.879187   |\n",
      "| qf2_loss                | 4.079183   |\n",
      "| time_elapsed            | 13406      |\n",
      "| total timesteps         | 1983932    |\n",
      "| value_loss              | 2.567955   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.03322529  |\n",
      "| ent_coef_loss           | -0.44530913 |\n",
      "| entropy                 | -4.8920374  |\n",
      "| episodes                | 2200        |\n",
      "| fps                     | 147         |\n",
      "| mean 100 episode reward | 1.93e+03    |\n",
      "| n_updates               | 1992681     |\n",
      "| policy_loss             | -147.59552  |\n",
      "| qf1_loss                | 2.2126994   |\n",
      "| qf2_loss                | 2.567769    |\n",
      "| time_elapsed            | 13498       |\n",
      "| total timesteps         | 1992780     |\n",
      "| value_loss              | 0.8715595   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03304843 |\n",
      "| ent_coef_loss           | 0.37589586 |\n",
      "| entropy                 | -5.132483  |\n",
      "| episodes                | 2210       |\n",
      "| fps                     | 147        |\n",
      "| mean 100 episode reward | 1.91e+03   |\n",
      "| n_updates               | 1999648    |\n",
      "| policy_loss             | -147.52568 |\n",
      "| qf1_loss                | 4.931332   |\n",
      "| qf2_loss                | 4.097233   |\n",
      "| time_elapsed            | 13572      |\n",
      "| total timesteps         | 1999747    |\n",
      "| value_loss              | 3.0251255  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.033943567 |\n",
      "| ent_coef_loss           | -0.5527525  |\n",
      "| entropy                 | -4.989653   |\n",
      "| episodes                | 2220        |\n",
      "| fps                     | 146         |\n",
      "| mean 100 episode reward | 1.96e+03    |\n",
      "| n_updates               | 2009630     |\n",
      "| policy_loss             | -152.4373   |\n",
      "| qf1_loss                | 3.6379378   |\n",
      "| qf2_loss                | 3.226278    |\n",
      "| time_elapsed            | 13679       |\n",
      "| total timesteps         | 2009729     |\n",
      "| value_loss              | 1.2237095   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.033158854 |\n",
      "| ent_coef_loss           | 0.23944932  |\n",
      "| entropy                 | -5.113128   |\n",
      "| episodes                | 2230        |\n",
      "| fps                     | 146         |\n",
      "| mean 100 episode reward | 1.98e+03    |\n",
      "| n_updates               | 2017956     |\n",
      "| policy_loss             | -156.75168  |\n",
      "| qf1_loss                | 2.4397764   |\n",
      "| qf2_loss                | 2.490709    |\n",
      "| time_elapsed            | 13773       |\n",
      "| total timesteps         | 2018055     |\n",
      "| value_loss              | 0.67808473  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031129526 |\n",
      "| ent_coef_loss           | 2.018283    |\n",
      "| entropy                 | -5.123418   |\n",
      "| episodes                | 2240        |\n",
      "| fps                     | 146         |\n",
      "| mean 100 episode reward | 2e+03       |\n",
      "| n_updates               | 2025218     |\n",
      "| policy_loss             | -150.1222   |\n",
      "| qf1_loss                | 8.965658    |\n",
      "| qf2_loss                | 13.307665   |\n",
      "| time_elapsed            | 13856       |\n",
      "| total timesteps         | 2025317     |\n",
      "| value_loss              | 5.9388328   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030754711 |\n",
      "| ent_coef_loss           | -0.94085467 |\n",
      "| entropy                 | -5.033827   |\n",
      "| episodes                | 2250        |\n",
      "| fps                     | 145         |\n",
      "| mean 100 episode reward | 2e+03       |\n",
      "| n_updates               | 2033062     |\n",
      "| policy_loss             | -164.95944  |\n",
      "| qf1_loss                | 2.7009273   |\n",
      "| qf2_loss                | 2.5121875   |\n",
      "| time_elapsed            | 13945       |\n",
      "| total timesteps         | 2033161     |\n",
      "| value_loss              | 1.1941292   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030947475 |\n",
      "| ent_coef_loss           | -0.49805868 |\n",
      "| entropy                 | -4.248267   |\n",
      "| episodes                | 2260        |\n",
      "| fps                     | 145         |\n",
      "| mean 100 episode reward | 1.96e+03    |\n",
      "| n_updates               | 2042154     |\n",
      "| policy_loss             | -154.39076  |\n",
      "| qf1_loss                | 3.580771    |\n",
      "| qf2_loss                | 4.237174    |\n",
      "| time_elapsed            | 14049       |\n",
      "| total timesteps         | 2042253     |\n",
      "| value_loss              | 2.9707212   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.033147994 |\n",
      "| ent_coef_loss           | 1.5401723   |\n",
      "| entropy                 | -5.6414785  |\n",
      "| episodes                | 2270        |\n",
      "| fps                     | 145         |\n",
      "| mean 100 episode reward | 1.9e+03     |\n",
      "| n_updates               | 2049597     |\n",
      "| policy_loss             | -158.87386  |\n",
      "| qf1_loss                | 2.5991328   |\n",
      "| qf2_loss                | 3.0925355   |\n",
      "| time_elapsed            | 14135       |\n",
      "| total timesteps         | 2049696     |\n",
      "| value_loss              | 1.126462    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.032611154 |\n",
      "| ent_coef_loss           | 1.7056991   |\n",
      "| entropy                 | -4.6314874  |\n",
      "| episodes                | 2280        |\n",
      "| fps                     | 144         |\n",
      "| mean 100 episode reward | 1.89e+03    |\n",
      "| n_updates               | 2058634     |\n",
      "| policy_loss             | -136.1783   |\n",
      "| qf1_loss                | 2.7800653   |\n",
      "| qf2_loss                | 6.1969624   |\n",
      "| time_elapsed            | 14216       |\n",
      "| total timesteps         | 2058733     |\n",
      "| value_loss              | 2.837749    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03139921 |\n",
      "| ent_coef_loss           | 2.5911243  |\n",
      "| entropy                 | -4.763884  |\n",
      "| episodes                | 2290       |\n",
      "| fps                     | 144        |\n",
      "| mean 100 episode reward | 1.85e+03   |\n",
      "| n_updates               | 2066067    |\n",
      "| policy_loss             | -144.21162 |\n",
      "| qf1_loss                | 10.791794  |\n",
      "| qf2_loss                | 10.9546795 |\n",
      "| time_elapsed            | 14256      |\n",
      "| total timesteps         | 2066166    |\n",
      "| value_loss              | 2.9089706  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03291578 |\n",
      "| ent_coef_loss           | 4.3976774  |\n",
      "| entropy                 | -5.3647738 |\n",
      "| episodes                | 2300       |\n",
      "| fps                     | 145        |\n",
      "| mean 100 episode reward | 1.9e+03    |\n",
      "| n_updates               | 2075470    |\n",
      "| policy_loss             | -162.38553 |\n",
      "| qf1_loss                | 264.22983  |\n",
      "| qf2_loss                | 265.72287  |\n",
      "| time_elapsed            | 14307      |\n",
      "| total timesteps         | 2075569    |\n",
      "| value_loss              | 2.3463435  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.032008283 |\n",
      "| ent_coef_loss           | -0.4912083  |\n",
      "| entropy                 | -5.4696245  |\n",
      "| episodes                | 2310        |\n",
      "| fps                     | 145         |\n",
      "| mean 100 episode reward | 1.95e+03    |\n",
      "| n_updates               | 2084065     |\n",
      "| policy_loss             | -160.03262  |\n",
      "| qf1_loss                | 7.6037855   |\n",
      "| qf2_loss                | 12.569741   |\n",
      "| time_elapsed            | 14360       |\n",
      "| total timesteps         | 2084164     |\n",
      "| value_loss              | 1.824091    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030937266 |\n",
      "| ent_coef_loss           | -1.9755428  |\n",
      "| entropy                 | -4.4195213  |\n",
      "| episodes                | 2320        |\n",
      "| fps                     | 145         |\n",
      "| mean 100 episode reward | 1.87e+03    |\n",
      "| n_updates               | 2091025     |\n",
      "| policy_loss             | -142.60913  |\n",
      "| qf1_loss                | 1.7534883   |\n",
      "| qf2_loss                | 1.1305337   |\n",
      "| time_elapsed            | 14402       |\n",
      "| total timesteps         | 2091124     |\n",
      "| value_loss              | 1.0655327   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.032039266 |\n",
      "| ent_coef_loss           | 0.7701838   |\n",
      "| entropy                 | -5.3250685  |\n",
      "| episodes                | 2330        |\n",
      "| fps                     | 145         |\n",
      "| mean 100 episode reward | 1.88e+03    |\n",
      "| n_updates               | 2099315     |\n",
      "| policy_loss             | -155.06842  |\n",
      "| qf1_loss                | 1.7806462   |\n",
      "| qf2_loss                | 2.1860242   |\n",
      "| time_elapsed            | 14450       |\n",
      "| total timesteps         | 2099414     |\n",
      "| value_loss              | 1.4944634   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030981487 |\n",
      "| ent_coef_loss           | 0.60757834  |\n",
      "| entropy                 | -4.901522   |\n",
      "| episodes                | 2340        |\n",
      "| fps                     | 145         |\n",
      "| mean 100 episode reward | 1.9e+03     |\n",
      "| n_updates               | 2107566     |\n",
      "| policy_loss             | -141.76782  |\n",
      "| qf1_loss                | 2.4065535   |\n",
      "| qf2_loss                | 2.1095958   |\n",
      "| time_elapsed            | 14499       |\n",
      "| total timesteps         | 2107665     |\n",
      "| value_loss              | 1.6316988   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.033491373 |\n",
      "| ent_coef_loss           | 2.9130945   |\n",
      "| entropy                 | -5.092211   |\n",
      "| episodes                | 2350        |\n",
      "| fps                     | 145         |\n",
      "| mean 100 episode reward | 1.93e+03    |\n",
      "| n_updates               | 2116444     |\n",
      "| policy_loss             | -154.07736  |\n",
      "| qf1_loss                | 3.9714475   |\n",
      "| qf2_loss                | 2.1830428   |\n",
      "| time_elapsed            | 14548       |\n",
      "| total timesteps         | 2116543     |\n",
      "| value_loss              | 1.2965674   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.032172006 |\n",
      "| ent_coef_loss           | 1.9804175   |\n",
      "| entropy                 | -4.884064   |\n",
      "| episodes                | 2360        |\n",
      "| fps                     | 145         |\n",
      "| mean 100 episode reward | 1.92e+03    |\n",
      "| n_updates               | 2123747     |\n",
      "| policy_loss             | -159.30019  |\n",
      "| qf1_loss                | 7.402979    |\n",
      "| qf2_loss                | 10.766272   |\n",
      "| time_elapsed            | 14590       |\n",
      "| total timesteps         | 2123846     |\n",
      "| value_loss              | 13.248487   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030480532 |\n",
      "| ent_coef_loss           | -2.0472946  |\n",
      "| entropy                 | -4.745715   |\n",
      "| episodes                | 2370        |\n",
      "| fps                     | 145         |\n",
      "| mean 100 episode reward | 2e+03       |\n",
      "| n_updates               | 2133409     |\n",
      "| policy_loss             | -148.98831  |\n",
      "| qf1_loss                | 40.839813   |\n",
      "| qf2_loss                | 36.366837   |\n",
      "| time_elapsed            | 14647       |\n",
      "| total timesteps         | 2133508     |\n",
      "| value_loss              | 2.6787915   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030576404 |\n",
      "| ent_coef_loss           | -0.1259172  |\n",
      "| entropy                 | -5.2120466  |\n",
      "| episodes                | 2380        |\n",
      "| fps                     | 145         |\n",
      "| mean 100 episode reward | 2.01e+03    |\n",
      "| n_updates               | 2141891     |\n",
      "| policy_loss             | -153.54553  |\n",
      "| qf1_loss                | 7.724887    |\n",
      "| qf2_loss                | 8.569322    |\n",
      "| time_elapsed            | 14694       |\n",
      "| total timesteps         | 2141990     |\n",
      "| value_loss              | 0.9030727   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031089777 |\n",
      "| ent_coef_loss           | 0.1392911   |\n",
      "| entropy                 | -5.694312   |\n",
      "| episodes                | 2390        |\n",
      "| fps                     | 145         |\n",
      "| mean 100 episode reward | 2.08e+03    |\n",
      "| n_updates               | 2151536     |\n",
      "| policy_loss             | -165.53418  |\n",
      "| qf1_loss                | 3.6274881   |\n",
      "| qf2_loss                | 3.3892117   |\n",
      "| time_elapsed            | 14749       |\n",
      "| total timesteps         | 2151635     |\n",
      "| value_loss              | 1.1240251   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.032038007 |\n",
      "| ent_coef_loss           | 0.6201252   |\n",
      "| entropy                 | -5.3814483  |\n",
      "| episodes                | 2400        |\n",
      "| fps                     | 145         |\n",
      "| mean 100 episode reward | 2.09e+03    |\n",
      "| n_updates               | 2161098     |\n",
      "| policy_loss             | -162.11958  |\n",
      "| qf1_loss                | 3.8514504   |\n",
      "| qf2_loss                | 3.5496447   |\n",
      "| time_elapsed            | 14804       |\n",
      "| total timesteps         | 2161197     |\n",
      "| value_loss              | 1.5516994   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.03370545  |\n",
      "| ent_coef_loss           | -0.81456494 |\n",
      "| entropy                 | -5.04982    |\n",
      "| episodes                | 2410        |\n",
      "| fps                     | 146         |\n",
      "| mean 100 episode reward | 2.13e+03    |\n",
      "| n_updates               | 2171098     |\n",
      "| policy_loss             | -149.12668  |\n",
      "| qf1_loss                | 4.0196586   |\n",
      "| qf2_loss                | 3.6136851   |\n",
      "| time_elapsed            | 14858       |\n",
      "| total timesteps         | 2171197     |\n",
      "| value_loss              | 0.95840555  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.03156476  |\n",
      "| ent_coef_loss           | -0.34089243 |\n",
      "| entropy                 | -5.0499477  |\n",
      "| episodes                | 2420        |\n",
      "| fps                     | 146         |\n",
      "| mean 100 episode reward | 2.15e+03    |\n",
      "| n_updates               | 2179385     |\n",
      "| policy_loss             | -144.26392  |\n",
      "| qf1_loss                | 2.9910724   |\n",
      "| qf2_loss                | 2.283113    |\n",
      "| time_elapsed            | 14903       |\n",
      "| total timesteps         | 2179484     |\n",
      "| value_loss              | 1.2807034   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031734284 |\n",
      "| ent_coef_loss           | -2.8123314  |\n",
      "| entropy                 | -4.9374576  |\n",
      "| episodes                | 2430        |\n",
      "| fps                     | 146         |\n",
      "| mean 100 episode reward | 2.16e+03    |\n",
      "| n_updates               | 2188538     |\n",
      "| policy_loss             | -164.82364  |\n",
      "| qf1_loss                | 2.4543467   |\n",
      "| qf2_loss                | 2.0384781   |\n",
      "| time_elapsed            | 14952       |\n",
      "| total timesteps         | 2188637     |\n",
      "| value_loss              | 1.476129    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.033588633 |\n",
      "| ent_coef_loss           | 0.9608916   |\n",
      "| entropy                 | -5.6257257  |\n",
      "| episodes                | 2440        |\n",
      "| fps                     | 146         |\n",
      "| mean 100 episode reward | 2.14e+03    |\n",
      "| n_updates               | 2197011     |\n",
      "| policy_loss             | -168.37799  |\n",
      "| qf1_loss                | 3.0030475   |\n",
      "| qf2_loss                | 2.3312292   |\n",
      "| time_elapsed            | 14998       |\n",
      "| total timesteps         | 2197110     |\n",
      "| value_loss              | 1.3198613   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031916283 |\n",
      "| ent_coef_loss           | -0.7158357  |\n",
      "| entropy                 | -5.534148   |\n",
      "| episodes                | 2450        |\n",
      "| fps                     | 146         |\n",
      "| mean 100 episode reward | 2.16e+03    |\n",
      "| n_updates               | 2206131     |\n",
      "| policy_loss             | -168.12305  |\n",
      "| qf1_loss                | 7.3487277   |\n",
      "| qf2_loss                | 7.7099147   |\n",
      "| time_elapsed            | 15052       |\n",
      "| total timesteps         | 2206230     |\n",
      "| value_loss              | 1.1364765   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.037267327 |\n",
      "| ent_coef_loss           | 1.845365    |\n",
      "| entropy                 | -5.4331093  |\n",
      "| episodes                | 2460        |\n",
      "| fps                     | 146         |\n",
      "| mean 100 episode reward | 2.18e+03    |\n",
      "| n_updates               | 2215450     |\n",
      "| policy_loss             | -167.26947  |\n",
      "| qf1_loss                | 2.5281768   |\n",
      "| qf2_loss                | 2.64368     |\n",
      "| time_elapsed            | 15105       |\n",
      "| total timesteps         | 2215549     |\n",
      "| value_loss              | 2.3659074   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031782895 |\n",
      "| ent_coef_loss           | -0.46279165 |\n",
      "| entropy                 | -5.3009076  |\n",
      "| episodes                | 2470        |\n",
      "| fps                     | 146         |\n",
      "| mean 100 episode reward | 2.14e+03    |\n",
      "| n_updates               | 2224332     |\n",
      "| policy_loss             | -172.35883  |\n",
      "| qf1_loss                | 4.692867    |\n",
      "| qf2_loss                | 2.5602508   |\n",
      "| time_elapsed            | 15161       |\n",
      "| total timesteps         | 2224431     |\n",
      "| value_loss              | 6.570261    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03331311 |\n",
      "| ent_coef_loss           | 1.8866444  |\n",
      "| entropy                 | -5.6043015 |\n",
      "| episodes                | 2480       |\n",
      "| fps                     | 146        |\n",
      "| mean 100 episode reward | 2.17e+03   |\n",
      "| n_updates               | 2233795    |\n",
      "| policy_loss             | -160.80841 |\n",
      "| qf1_loss                | 3.6069322  |\n",
      "| qf2_loss                | 13.611748  |\n",
      "| time_elapsed            | 15215      |\n",
      "| total timesteps         | 2233894    |\n",
      "| value_loss              | 2.2084708  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030446881 |\n",
      "| ent_coef_loss           | -1.1113787  |\n",
      "| entropy                 | -5.319127   |\n",
      "| episodes                | 2490        |\n",
      "| fps                     | 146         |\n",
      "| mean 100 episode reward | 2.08e+03    |\n",
      "| n_updates               | 2242951     |\n",
      "| policy_loss             | -156.53575  |\n",
      "| qf1_loss                | 321.6107    |\n",
      "| qf2_loss                | 323.41876   |\n",
      "| time_elapsed            | 15265       |\n",
      "| total timesteps         | 2243050     |\n",
      "| value_loss              | 3.2852716   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.032067552 |\n",
      "| ent_coef_loss           | 1.0696719   |\n",
      "| entropy                 | -4.8877487  |\n",
      "| episodes                | 2500        |\n",
      "| fps                     | 147         |\n",
      "| mean 100 episode reward | 2.04e+03    |\n",
      "| n_updates               | 2251900     |\n",
      "| policy_loss             | -153.77927  |\n",
      "| qf1_loss                | 2.3438835   |\n",
      "| qf2_loss                | 2.961485    |\n",
      "| time_elapsed            | 15314       |\n",
      "| total timesteps         | 2251999     |\n",
      "| value_loss              | 0.8413286   |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| current_lr              | 0.0003       |\n",
      "| ent_coef                | 0.032334875  |\n",
      "| ent_coef_loss           | -0.022654176 |\n",
      "| entropy                 | -5.7144327   |\n",
      "| episodes                | 2510         |\n",
      "| fps                     | 147          |\n",
      "| mean 100 episode reward | 1.98e+03     |\n",
      "| n_updates               | 2259190      |\n",
      "| policy_loss             | -167.70345   |\n",
      "| qf1_loss                | 2.679729     |\n",
      "| qf2_loss                | 3.0514774    |\n",
      "| time_elapsed            | 15353        |\n",
      "| total timesteps         | 2259289      |\n",
      "| value_loss              | 1.0707281    |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03251845 |\n",
      "| ent_coef_loss           | 0.9995369  |\n",
      "| entropy                 | -5.111475  |\n",
      "| episodes                | 2520       |\n",
      "| fps                     | 147        |\n",
      "| mean 100 episode reward | 2.04e+03   |\n",
      "| n_updates               | 2268591    |\n",
      "| policy_loss             | -178.83511 |\n",
      "| qf1_loss                | 6.832204   |\n",
      "| qf2_loss                | 4.253244   |\n",
      "| time_elapsed            | 15404      |\n",
      "| total timesteps         | 2268690    |\n",
      "| value_loss              | 2.7451591  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.034899034 |\n",
      "| ent_coef_loss           | 0.7164271   |\n",
      "| entropy                 | -5.7057714  |\n",
      "| episodes                | 2530        |\n",
      "| fps                     | 147         |\n",
      "| mean 100 episode reward | 2.04e+03    |\n",
      "| n_updates               | 2277093     |\n",
      "| policy_loss             | -181.61707  |\n",
      "| qf1_loss                | 3.284628    |\n",
      "| qf2_loss                | 3.8323333   |\n",
      "| time_elapsed            | 15455       |\n",
      "| total timesteps         | 2277192     |\n",
      "| value_loss              | 1.1730554   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03358322 |\n",
      "| ent_coef_loss           | -1.1983886 |\n",
      "| entropy                 | -5.363356  |\n",
      "| episodes                | 2540       |\n",
      "| fps                     | 147        |\n",
      "| mean 100 episode reward | 2.02e+03   |\n",
      "| n_updates               | 2285008    |\n",
      "| policy_loss             | -164.16753 |\n",
      "| qf1_loss                | 3.0566216  |\n",
      "| qf2_loss                | 3.4202561  |\n",
      "| time_elapsed            | 15501      |\n",
      "| total timesteps         | 2285107    |\n",
      "| value_loss              | 1.5004203  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.034640625 |\n",
      "| ent_coef_loss           | -0.3465783  |\n",
      "| entropy                 | -5.2129807  |\n",
      "| episodes                | 2550        |\n",
      "| fps                     | 147         |\n",
      "| mean 100 episode reward | 1.99e+03    |\n",
      "| n_updates               | 2293826     |\n",
      "| policy_loss             | -162.014    |\n",
      "| qf1_loss                | 3.1388917   |\n",
      "| qf2_loss                | 2.6223621   |\n",
      "| time_elapsed            | 15556       |\n",
      "| total timesteps         | 2293925     |\n",
      "| value_loss              | 1.211088    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036625113 |\n",
      "| ent_coef_loss           | -2.0798178  |\n",
      "| entropy                 | -5.2898507  |\n",
      "| episodes                | 2560        |\n",
      "| fps                     | 147         |\n",
      "| mean 100 episode reward | 1.98e+03    |\n",
      "| n_updates               | 2301480     |\n",
      "| policy_loss             | -172.04263  |\n",
      "| qf1_loss                | 12.602394   |\n",
      "| qf2_loss                | 5.0006695   |\n",
      "| time_elapsed            | 15600       |\n",
      "| total timesteps         | 2301579     |\n",
      "| value_loss              | 1.3892093   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035654455 |\n",
      "| ent_coef_loss           | -0.40998024 |\n",
      "| entropy                 | -5.2600813  |\n",
      "| episodes                | 2570        |\n",
      "| fps                     | 147         |\n",
      "| mean 100 episode reward | 2.01e+03    |\n",
      "| n_updates               | 2311480     |\n",
      "| policy_loss             | -162.90273  |\n",
      "| qf1_loss                | 2.694265    |\n",
      "| qf2_loss                | 4.44724     |\n",
      "| time_elapsed            | 15655       |\n",
      "| total timesteps         | 2311579     |\n",
      "| value_loss              | 2.8302536   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031429492 |\n",
      "| ent_coef_loss           | 0.031248152 |\n",
      "| entropy                 | -4.5338078  |\n",
      "| episodes                | 2580        |\n",
      "| fps                     | 147         |\n",
      "| mean 100 episode reward | 1.97e+03    |\n",
      "| n_updates               | 2319111     |\n",
      "| policy_loss             | -157.14453  |\n",
      "| qf1_loss                | 13.220908   |\n",
      "| qf2_loss                | 9.374604    |\n",
      "| time_elapsed            | 15697       |\n",
      "| total timesteps         | 2319210     |\n",
      "| value_loss              | 1.9105148   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03330819 |\n",
      "| ent_coef_loss           | 0.49089384 |\n",
      "| entropy                 | -5.685403  |\n",
      "| episodes                | 2590       |\n",
      "| fps                     | 147        |\n",
      "| mean 100 episode reward | 2.06e+03   |\n",
      "| n_updates               | 2327836    |\n",
      "| policy_loss             | -165.16997 |\n",
      "| qf1_loss                | 288.43808  |\n",
      "| qf2_loss                | 288.79623  |\n",
      "| time_elapsed            | 15744      |\n",
      "| total timesteps         | 2327935    |\n",
      "| value_loss              | 3.532671   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03306875 |\n",
      "| ent_coef_loss           | 0.61579186 |\n",
      "| entropy                 | -5.9967265 |\n",
      "| episodes                | 2600       |\n",
      "| fps                     | 147        |\n",
      "| mean 100 episode reward | 2.08e+03   |\n",
      "| n_updates               | 2336287    |\n",
      "| policy_loss             | -179.7958  |\n",
      "| qf1_loss                | 10.638454  |\n",
      "| qf2_loss                | 7.6050076  |\n",
      "| time_elapsed            | 15790      |\n",
      "| total timesteps         | 2336386    |\n",
      "| value_loss              | 3.2407837  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.032146648 |\n",
      "| ent_coef_loss           | -0.6975845  |\n",
      "| entropy                 | -5.3694506  |\n",
      "| episodes                | 2610        |\n",
      "| fps                     | 148         |\n",
      "| mean 100 episode reward | 2.06e+03    |\n",
      "| n_updates               | 2343078     |\n",
      "| policy_loss             | -164.26129  |\n",
      "| qf1_loss                | 4.1255865   |\n",
      "| qf2_loss                | 4.067545    |\n",
      "| time_elapsed            | 15827       |\n",
      "| total timesteps         | 2343177     |\n",
      "| value_loss              | 4.0159593   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.032022007 |\n",
      "| ent_coef_loss           | 0.14452243  |\n",
      "| entropy                 | -5.8328323  |\n",
      "| episodes                | 2620        |\n",
      "| fps                     | 148         |\n",
      "| mean 100 episode reward | 2.04e+03    |\n",
      "| n_updates               | 2351807     |\n",
      "| policy_loss             | -186.31738  |\n",
      "| qf1_loss                | 2.5302467   |\n",
      "| qf2_loss                | 2.2369654   |\n",
      "| time_elapsed            | 15874       |\n",
      "| total timesteps         | 2351906     |\n",
      "| value_loss              | 1.6303995   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03633985 |\n",
      "| ent_coef_loss           | -1.5135884 |\n",
      "| entropy                 | -4.6274223 |\n",
      "| episodes                | 2630       |\n",
      "| fps                     | 148        |\n",
      "| mean 100 episode reward | 2.08e+03   |\n",
      "| n_updates               | 2361501    |\n",
      "| policy_loss             | -158.2193  |\n",
      "| qf1_loss                | 2.2372885  |\n",
      "| qf2_loss                | 2.5528054  |\n",
      "| time_elapsed            | 15926      |\n",
      "| total timesteps         | 2361600    |\n",
      "| value_loss              | 1.2806637  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.033728443 |\n",
      "| ent_coef_loss           | 0.9646966   |\n",
      "| entropy                 | -5.663889   |\n",
      "| episodes                | 2640        |\n",
      "| fps                     | 148         |\n",
      "| mean 100 episode reward | 2.14e+03    |\n",
      "| n_updates               | 2370250     |\n",
      "| policy_loss             | -160.92708  |\n",
      "| qf1_loss                | 1.9503734   |\n",
      "| qf2_loss                | 2.013136    |\n",
      "| time_elapsed            | 15974       |\n",
      "| total timesteps         | 2370349     |\n",
      "| value_loss              | 2.5308013   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035466146 |\n",
      "| ent_coef_loss           | -0.24835724 |\n",
      "| entropy                 | -5.0744686  |\n",
      "| episodes                | 2650        |\n",
      "| fps                     | 148         |\n",
      "| mean 100 episode reward | 2.16e+03    |\n",
      "| n_updates               | 2379267     |\n",
      "| policy_loss             | -166.04596  |\n",
      "| qf1_loss                | 4.2150354   |\n",
      "| qf2_loss                | 3.7678766   |\n",
      "| time_elapsed            | 16022       |\n",
      "| total timesteps         | 2379366     |\n",
      "| value_loss              | 1.3934326   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.034662552 |\n",
      "| ent_coef_loss           | -1.4709368  |\n",
      "| entropy                 | -4.93569    |\n",
      "| episodes                | 2660        |\n",
      "| fps                     | 148         |\n",
      "| mean 100 episode reward | 2.18e+03    |\n",
      "| n_updates               | 2388444     |\n",
      "| policy_loss             | -163.77945  |\n",
      "| qf1_loss                | 24.172262   |\n",
      "| qf2_loss                | 18.21892    |\n",
      "| time_elapsed            | 16072       |\n",
      "| total timesteps         | 2388543     |\n",
      "| value_loss              | 1.4184952   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03242588 |\n",
      "| ent_coef_loss           | 0.46416038 |\n",
      "| entropy                 | -5.0332646 |\n",
      "| episodes                | 2670       |\n",
      "| fps                     | 148        |\n",
      "| mean 100 episode reward | 2.13e+03   |\n",
      "| n_updates               | 2395393    |\n",
      "| policy_loss             | -168.99072 |\n",
      "| qf1_loss                | 12.692639  |\n",
      "| qf2_loss                | 12.812265  |\n",
      "| time_elapsed            | 16109      |\n",
      "| total timesteps         | 2395492    |\n",
      "| value_loss              | 2.4441352  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.032347742 |\n",
      "| ent_coef_loss           | 0.5928581   |\n",
      "| entropy                 | -5.022439   |\n",
      "| episodes                | 2680        |\n",
      "| fps                     | 148         |\n",
      "| mean 100 episode reward | 2.19e+03    |\n",
      "| n_updates               | 2404795     |\n",
      "| policy_loss             | -168.95746  |\n",
      "| qf1_loss                | 1.8982308   |\n",
      "| qf2_loss                | 2.3263097   |\n",
      "| time_elapsed            | 16160       |\n",
      "| total timesteps         | 2404894     |\n",
      "| value_loss              | 0.8937285   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03194024 |\n",
      "| ent_coef_loss           | 0.98672533 |\n",
      "| entropy                 | -5.5975504 |\n",
      "| episodes                | 2690       |\n",
      "| fps                     | 148        |\n",
      "| mean 100 episode reward | 2.16e+03   |\n",
      "| n_updates               | 2414362    |\n",
      "| policy_loss             | -165.14651 |\n",
      "| qf1_loss                | 8.785624   |\n",
      "| qf2_loss                | 8.69117    |\n",
      "| time_elapsed            | 16212      |\n",
      "| total timesteps         | 2414461    |\n",
      "| value_loss              | 2.4017096  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.032149583 |\n",
      "| ent_coef_loss           | 2.668556    |\n",
      "| entropy                 | -5.4443436  |\n",
      "| episodes                | 2700        |\n",
      "| fps                     | 149         |\n",
      "| mean 100 episode reward | 2.18e+03    |\n",
      "| n_updates               | 2424362     |\n",
      "| policy_loss             | -150.40115  |\n",
      "| qf1_loss                | 3.4769945   |\n",
      "| qf2_loss                | 3.7467055   |\n",
      "| time_elapsed            | 16266       |\n",
      "| total timesteps         | 2424461     |\n",
      "| value_loss              | 0.75451076  |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03408256 |\n",
      "| ent_coef_loss           | -2.4887652 |\n",
      "| entropy                 | -5.200348  |\n",
      "| episodes                | 2710       |\n",
      "| fps                     | 149        |\n",
      "| mean 100 episode reward | 2.25e+03   |\n",
      "| n_updates               | 2433096    |\n",
      "| policy_loss             | -178.3604  |\n",
      "| qf1_loss                | 5.7221375  |\n",
      "| qf2_loss                | 5.188405   |\n",
      "| time_elapsed            | 16315      |\n",
      "| total timesteps         | 2433195    |\n",
      "| value_loss              | 1.761965   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03184687 |\n",
      "| ent_coef_loss           | 1.1832142  |\n",
      "| entropy                 | -5.369096  |\n",
      "| episodes                | 2720       |\n",
      "| fps                     | 149        |\n",
      "| mean 100 episode reward | 2.28e+03   |\n",
      "| n_updates               | 2442022    |\n",
      "| policy_loss             | -173.64316 |\n",
      "| qf1_loss                | 5.827858   |\n",
      "| qf2_loss                | 6.847808   |\n",
      "| time_elapsed            | 16365      |\n",
      "| total timesteps         | 2442121    |\n",
      "| value_loss              | 3.7731795  |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03351592 |\n",
      "| ent_coef_loss           | 1.3709221  |\n",
      "| entropy                 | -5.022152  |\n",
      "| episodes                | 2730       |\n",
      "| fps                     | 149        |\n",
      "| mean 100 episode reward | 2.26e+03   |\n",
      "| n_updates               | 2452022    |\n",
      "| policy_loss             | -164.04218 |\n",
      "| qf1_loss                | 6.117859   |\n",
      "| qf2_loss                | 7.229806   |\n",
      "| time_elapsed            | 16422      |\n",
      "| total timesteps         | 2452121    |\n",
      "| value_loss              | 13.778008  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.032565724 |\n",
      "| ent_coef_loss           | -0.25072473 |\n",
      "| entropy                 | -5.560032   |\n",
      "| episodes                | 2740        |\n",
      "| fps                     | 149         |\n",
      "| mean 100 episode reward | 2.31e+03    |\n",
      "| n_updates               | 2461905     |\n",
      "| policy_loss             | -180.11743  |\n",
      "| qf1_loss                | 3.727537    |\n",
      "| qf2_loss                | 1.9467112   |\n",
      "| time_elapsed            | 16476       |\n",
      "| total timesteps         | 2462004     |\n",
      "| value_loss              | 0.86117035  |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03283696 |\n",
      "| ent_coef_loss           | 0.6199405  |\n",
      "| entropy                 | -4.871612  |\n",
      "| episodes                | 2750       |\n",
      "| fps                     | 149        |\n",
      "| mean 100 episode reward | 2.29e+03   |\n",
      "| n_updates               | 2470996    |\n",
      "| policy_loss             | -163.2962  |\n",
      "| qf1_loss                | 7.856747   |\n",
      "| qf2_loss                | 4.7576466  |\n",
      "| time_elapsed            | 16525      |\n",
      "| total timesteps         | 2471095    |\n",
      "| value_loss              | 4.377975   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031165015 |\n",
      "| ent_coef_loss           | -0.5588799  |\n",
      "| entropy                 | -5.573555   |\n",
      "| episodes                | 2760        |\n",
      "| fps                     | 149         |\n",
      "| mean 100 episode reward | 2.29e+03    |\n",
      "| n_updates               | 2479534     |\n",
      "| policy_loss             | -181.76474  |\n",
      "| qf1_loss                | 16.351799   |\n",
      "| qf2_loss                | 10.498632   |\n",
      "| time_elapsed            | 16571       |\n",
      "| total timesteps         | 2479633     |\n",
      "| value_loss              | 2.8488503   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030428812 |\n",
      "| ent_coef_loss           | -0.88985527 |\n",
      "| entropy                 | -5.0655427  |\n",
      "| episodes                | 2770        |\n",
      "| fps                     | 149         |\n",
      "| mean 100 episode reward | 2.34e+03    |\n",
      "| n_updates               | 2489534     |\n",
      "| policy_loss             | -176.29193  |\n",
      "| qf1_loss                | 3.4347553   |\n",
      "| qf2_loss                | 3.5855489   |\n",
      "| time_elapsed            | 16631       |\n",
      "| total timesteps         | 2489633     |\n",
      "| value_loss              | 1.6558      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030810708 |\n",
      "| ent_coef_loss           | 2.0713792   |\n",
      "| entropy                 | -5.301648   |\n",
      "| episodes                | 2780        |\n",
      "| fps                     | 149         |\n",
      "| mean 100 episode reward | 2.28e+03    |\n",
      "| n_updates               | 2497402     |\n",
      "| policy_loss             | -171.03952  |\n",
      "| qf1_loss                | 5.0849943   |\n",
      "| qf2_loss                | 8.479488    |\n",
      "| time_elapsed            | 16678       |\n",
      "| total timesteps         | 2497501     |\n",
      "| value_loss              | 2.6914158   |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ent_coef                | 0.0313497 |\n",
      "| ent_coef_loss           | 1.0705277 |\n",
      "| entropy                 | -5.363523 |\n",
      "| episodes                | 2790      |\n",
      "| fps                     | 149       |\n",
      "| mean 100 episode reward | 2.29e+03  |\n",
      "| n_updates               | 2506035   |\n",
      "| policy_loss             | -182.0346 |\n",
      "| qf1_loss                | 3.9302309 |\n",
      "| qf2_loss                | 4.5662527 |\n",
      "| time_elapsed            | 16725     |\n",
      "| total timesteps         | 2506134   |\n",
      "| value_loss              | 1.2686422 |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03319901 |\n",
      "| ent_coef_loss           | 0.3813619  |\n",
      "| entropy                 | -5.4596825 |\n",
      "| episodes                | 2800       |\n",
      "| fps                     | 149        |\n",
      "| mean 100 episode reward | 2.27e+03   |\n",
      "| n_updates               | 2515275    |\n",
      "| policy_loss             | -172.43481 |\n",
      "| qf1_loss                | 5.7002687  |\n",
      "| qf2_loss                | 3.9693775  |\n",
      "| time_elapsed            | 16775      |\n",
      "| total timesteps         | 2515374    |\n",
      "| value_loss              | 2.6134605  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030225107 |\n",
      "| ent_coef_loss           | 0.38531     |\n",
      "| entropy                 | -4.76371    |\n",
      "| episodes                | 2810        |\n",
      "| fps                     | 150         |\n",
      "| mean 100 episode reward | 2.27e+03    |\n",
      "| n_updates               | 2524719     |\n",
      "| policy_loss             | -175.65398  |\n",
      "| qf1_loss                | 2.7047675   |\n",
      "| qf2_loss                | 2.6573048   |\n",
      "| time_elapsed            | 16826       |\n",
      "| total timesteps         | 2524818     |\n",
      "| value_loss              | 1.4005948   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.034463733 |\n",
      "| ent_coef_loss           | -1.7357421  |\n",
      "| entropy                 | -4.8513956  |\n",
      "| episodes                | 2820        |\n",
      "| fps                     | 150         |\n",
      "| mean 100 episode reward | 2.29e+03    |\n",
      "| n_updates               | 2534239     |\n",
      "| policy_loss             | -151.3329   |\n",
      "| qf1_loss                | 4.371903    |\n",
      "| qf2_loss                | 4.724727    |\n",
      "| time_elapsed            | 16878       |\n",
      "| total timesteps         | 2534338     |\n",
      "| value_loss              | 1.2576399   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.032967284 |\n",
      "| ent_coef_loss           | 1.3984593   |\n",
      "| entropy                 | -5.072652   |\n",
      "| episodes                | 2830        |\n",
      "| fps                     | 150         |\n",
      "| mean 100 episode reward | 2.26e+03    |\n",
      "| n_updates               | 2541883     |\n",
      "| policy_loss             | -174.87413  |\n",
      "| qf1_loss                | 3.6702194   |\n",
      "| qf2_loss                | 3.5088606   |\n",
      "| time_elapsed            | 16923       |\n",
      "| total timesteps         | 2541982     |\n",
      "| value_loss              | 4.010447    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.033523295 |\n",
      "| ent_coef_loss           | 1.2189705   |\n",
      "| entropy                 | -5.320717   |\n",
      "| episodes                | 2840        |\n",
      "| fps                     | 150         |\n",
      "| mean 100 episode reward | 2.19e+03    |\n",
      "| n_updates               | 2549613     |\n",
      "| policy_loss             | -184.08607  |\n",
      "| qf1_loss                | 6.949115    |\n",
      "| qf2_loss                | 6.7555137   |\n",
      "| time_elapsed            | 16965       |\n",
      "| total timesteps         | 2549712     |\n",
      "| value_loss              | 3.7710748   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.03465975  |\n",
      "| ent_coef_loss           | -0.82625127 |\n",
      "| entropy                 | -5.055993   |\n",
      "| episodes                | 2850        |\n",
      "| fps                     | 150         |\n",
      "| mean 100 episode reward | 2.25e+03    |\n",
      "| n_updates               | 2558681     |\n",
      "| policy_loss             | -174.06123  |\n",
      "| qf1_loss                | 3.5555096   |\n",
      "| qf2_loss                | 4.222459    |\n",
      "| time_elapsed            | 17015       |\n",
      "| total timesteps         | 2558780     |\n",
      "| value_loss              | 1.9716266   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03612826 |\n",
      "| ent_coef_loss           | 0.24260193 |\n",
      "| entropy                 | -5.5609827 |\n",
      "| episodes                | 2860       |\n",
      "| fps                     | 150        |\n",
      "| mean 100 episode reward | 2.28e+03   |\n",
      "| n_updates               | 2567769    |\n",
      "| policy_loss             | -180.80884 |\n",
      "| qf1_loss                | 3.8445573  |\n",
      "| qf2_loss                | 6.359374   |\n",
      "| time_elapsed            | 17069      |\n",
      "| total timesteps         | 2567868    |\n",
      "| value_loss              | 0.9102924  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.033831086 |\n",
      "| ent_coef_loss           | 1.0000535   |\n",
      "| entropy                 | -5.77061    |\n",
      "| episodes                | 2870        |\n",
      "| fps                     | 150         |\n",
      "| mean 100 episode reward | 2.3e+03     |\n",
      "| n_updates               | 2576897     |\n",
      "| policy_loss             | -187.03445  |\n",
      "| qf1_loss                | 3.1150148   |\n",
      "| qf2_loss                | 3.788671    |\n",
      "| time_elapsed            | 17129       |\n",
      "| total timesteps         | 2576996     |\n",
      "| value_loss              | 0.71801436  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.03546283  |\n",
      "| ent_coef_loss           | -0.15844798 |\n",
      "| entropy                 | -5.1044154  |\n",
      "| episodes                | 2880        |\n",
      "| fps                     | 150         |\n",
      "| mean 100 episode reward | 2.35e+03    |\n",
      "| n_updates               | 2585877     |\n",
      "| policy_loss             | -186.34871  |\n",
      "| qf1_loss                | 3.3405309   |\n",
      "| qf2_loss                | 2.8695061   |\n",
      "| time_elapsed            | 17184       |\n",
      "| total timesteps         | 2585976     |\n",
      "| value_loss              | 2.204316    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.034485597 |\n",
      "| ent_coef_loss           | 0.52188975  |\n",
      "| entropy                 | -5.500801   |\n",
      "| episodes                | 2890        |\n",
      "| fps                     | 150         |\n",
      "| mean 100 episode reward | 2.41e+03    |\n",
      "| n_updates               | 2595652     |\n",
      "| policy_loss             | -175.25258  |\n",
      "| qf1_loss                | 357.1411    |\n",
      "| qf2_loss                | 347.22812   |\n",
      "| time_elapsed            | 17242       |\n",
      "| total timesteps         | 2595751     |\n",
      "| value_loss              | 7.781297    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| current_lr              | 0.0003       |\n",
      "| ent_coef                | 0.03545006   |\n",
      "| ent_coef_loss           | -0.113909125 |\n",
      "| entropy                 | -4.8823824   |\n",
      "| episodes                | 2900         |\n",
      "| fps                     | 150          |\n",
      "| mean 100 episode reward | 2.35e+03     |\n",
      "| n_updates               | 2602932      |\n",
      "| policy_loss             | -176.93883   |\n",
      "| qf1_loss                | 14.323757    |\n",
      "| qf2_loss                | 15.511879    |\n",
      "| time_elapsed            | 17285        |\n",
      "| total timesteps         | 2603031      |\n",
      "| value_loss              | 1.7790861    |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.034760226 |\n",
      "| ent_coef_loss           | 1.0714359   |\n",
      "| entropy                 | -5.3525534  |\n",
      "| episodes                | 2910        |\n",
      "| fps                     | 150         |\n",
      "| mean 100 episode reward | 2.29e+03    |\n",
      "| n_updates               | 2612545     |\n",
      "| policy_loss             | -187.51695  |\n",
      "| qf1_loss                | 5.2681465   |\n",
      "| qf2_loss                | 12.529058   |\n",
      "| time_elapsed            | 17339       |\n",
      "| total timesteps         | 2612644     |\n",
      "| value_loss              | 8.094715    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.034087274 |\n",
      "| ent_coef_loss           | 0.8212578   |\n",
      "| entropy                 | -4.951387   |\n",
      "| episodes                | 2920        |\n",
      "| fps                     | 150         |\n",
      "| mean 100 episode reward | 2.18e+03    |\n",
      "| n_updates               | 2618019     |\n",
      "| policy_loss             | -179.06073  |\n",
      "| qf1_loss                | 2.4493628   |\n",
      "| qf2_loss                | 2.8033578   |\n",
      "| time_elapsed            | 17370       |\n",
      "| total timesteps         | 2618118     |\n",
      "| value_loss              | 1.5291126   |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| current_lr              | 0.0003       |\n",
      "| ent_coef                | 0.03539223   |\n",
      "| ent_coef_loss           | -0.009156048 |\n",
      "| entropy                 | -5.811455    |\n",
      "| episodes                | 2930         |\n",
      "| fps                     | 150          |\n",
      "| mean 100 episode reward | 2.19e+03     |\n",
      "| n_updates               | 2626554      |\n",
      "| policy_loss             | -185.70668   |\n",
      "| qf1_loss                | 31.897787    |\n",
      "| qf2_loss                | 34.985443    |\n",
      "| time_elapsed            | 17416        |\n",
      "| total timesteps         | 2626653      |\n",
      "| value_loss              | 10.180884    |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036692366 |\n",
      "| ent_coef_loss           | -0.8531623  |\n",
      "| entropy                 | -5.1111717  |\n",
      "| episodes                | 2940        |\n",
      "| fps                     | 150         |\n",
      "| mean 100 episode reward | 2.18e+03    |\n",
      "| n_updates               | 2635358     |\n",
      "| policy_loss             | -175.53386  |\n",
      "| qf1_loss                | 2.251525    |\n",
      "| qf2_loss                | 2.880991    |\n",
      "| time_elapsed            | 17465       |\n",
      "| total timesteps         | 2635457     |\n",
      "| value_loss              | 1.5331156   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.034363683 |\n",
      "| ent_coef_loss           | -0.32251108 |\n",
      "| entropy                 | -4.598411   |\n",
      "| episodes                | 2950        |\n",
      "| fps                     | 150         |\n",
      "| mean 100 episode reward | 2.13e+03    |\n",
      "| n_updates               | 2642829     |\n",
      "| policy_loss             | -176.65785  |\n",
      "| qf1_loss                | 3.0370612   |\n",
      "| qf2_loss                | 1.8885003   |\n",
      "| time_elapsed            | 17507       |\n",
      "| total timesteps         | 2642928     |\n",
      "| value_loss              | 1.0364301   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035145693 |\n",
      "| ent_coef_loss           | -0.4039632  |\n",
      "| entropy                 | -5.0650206  |\n",
      "| episodes                | 2960        |\n",
      "| fps                     | 151         |\n",
      "| mean 100 episode reward | 2.15e+03    |\n",
      "| n_updates               | 2652036     |\n",
      "| policy_loss             | -165.17265  |\n",
      "| qf1_loss                | 4.5620947   |\n",
      "| qf2_loss                | 4.1046333   |\n",
      "| time_elapsed            | 17557       |\n",
      "| total timesteps         | 2652135     |\n",
      "| value_loss              | 0.97298175  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.034892377 |\n",
      "| ent_coef_loss           | -0.90922487 |\n",
      "| entropy                 | -5.1907377  |\n",
      "| episodes                | 2970        |\n",
      "| fps                     | 151         |\n",
      "| mean 100 episode reward | 2.07e+03    |\n",
      "| n_updates               | 2658899     |\n",
      "| policy_loss             | -191.88303  |\n",
      "| qf1_loss                | 14.961004   |\n",
      "| qf2_loss                | 4.4440465   |\n",
      "| time_elapsed            | 17594       |\n",
      "| total timesteps         | 2658998     |\n",
      "| value_loss              | 0.95930684  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035133913 |\n",
      "| ent_coef_loss           | 0.64620996  |\n",
      "| entropy                 | -4.95199    |\n",
      "| episodes                | 2980        |\n",
      "| fps                     | 151         |\n",
      "| mean 100 episode reward | 2.04e+03    |\n",
      "| n_updates               | 2667538     |\n",
      "| policy_loss             | -175.95926  |\n",
      "| qf1_loss                | 3.5412471   |\n",
      "| qf2_loss                | 6.268474    |\n",
      "| time_elapsed            | 17640       |\n",
      "| total timesteps         | 2667637     |\n",
      "| value_loss              | 3.249311    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03732462 |\n",
      "| ent_coef_loss           | -1.5969305 |\n",
      "| entropy                 | -5.3920565 |\n",
      "| episodes                | 2990       |\n",
      "| fps                     | 151        |\n",
      "| mean 100 episode reward | 1.92e+03   |\n",
      "| n_updates               | 2675334    |\n",
      "| policy_loss             | -189.89932 |\n",
      "| qf1_loss                | 2.2744443  |\n",
      "| qf2_loss                | 3.8215842  |\n",
      "| time_elapsed            | 17684      |\n",
      "| total timesteps         | 2675433    |\n",
      "| value_loss              | 5.293475   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036690794 |\n",
      "| ent_coef_loss           | 1.0711858   |\n",
      "| entropy                 | -5.6261945  |\n",
      "| episodes                | 3000        |\n",
      "| fps                     | 151         |\n",
      "| mean 100 episode reward | 1.98e+03    |\n",
      "| n_updates               | 2684098     |\n",
      "| policy_loss             | -188.86438  |\n",
      "| qf1_loss                | 24.996868   |\n",
      "| qf2_loss                | 25.011126   |\n",
      "| time_elapsed            | 17733       |\n",
      "| total timesteps         | 2684197     |\n",
      "| value_loss              | 2.27139     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035164617 |\n",
      "| ent_coef_loss           | 1.2574608   |\n",
      "| entropy                 | -4.974494   |\n",
      "| episodes                | 3010        |\n",
      "| fps                     | 151         |\n",
      "| mean 100 episode reward | 2.06e+03    |\n",
      "| n_updates               | 2693193     |\n",
      "| policy_loss             | -188.76634  |\n",
      "| qf1_loss                | 8.322244    |\n",
      "| qf2_loss                | 6.65187     |\n",
      "| time_elapsed            | 17782       |\n",
      "| total timesteps         | 2693292     |\n",
      "| value_loss              | 10.755984   |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| current_lr              | 0.0003       |\n",
      "| ent_coef                | 0.03743229   |\n",
      "| ent_coef_loss           | -0.011531889 |\n",
      "| entropy                 | -4.8304377   |\n",
      "| episodes                | 3020         |\n",
      "| fps                     | 151          |\n",
      "| mean 100 episode reward | 2.1e+03      |\n",
      "| n_updates               | 2700700      |\n",
      "| policy_loss             | -163.40234   |\n",
      "| qf1_loss                | 6.2035317    |\n",
      "| qf2_loss                | 6.2568235    |\n",
      "| time_elapsed            | 17822        |\n",
      "| total timesteps         | 2700799      |\n",
      "| value_loss              | 2.6802192    |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.034871012 |\n",
      "| ent_coef_loss           | -0.25139225 |\n",
      "| entropy                 | -5.50051    |\n",
      "| episodes                | 3030        |\n",
      "| fps                     | 151         |\n",
      "| mean 100 episode reward | 2.06e+03    |\n",
      "| n_updates               | 2708225     |\n",
      "| policy_loss             | -206.14801  |\n",
      "| qf1_loss                | 4.0987844   |\n",
      "| qf2_loss                | 4.9668517   |\n",
      "| time_elapsed            | 17863       |\n",
      "| total timesteps         | 2708324     |\n",
      "| value_loss              | 1.4358958   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03730986 |\n",
      "| ent_coef_loss           | -2.3370166 |\n",
      "| entropy                 | -4.707823  |\n",
      "| episodes                | 3040       |\n",
      "| fps                     | 151        |\n",
      "| mean 100 episode reward | 2.04e+03   |\n",
      "| n_updates               | 2716577    |\n",
      "| policy_loss             | -168.44382 |\n",
      "| qf1_loss                | 3.2432108  |\n",
      "| qf2_loss                | 2.124971   |\n",
      "| time_elapsed            | 17908      |\n",
      "| total timesteps         | 2716676    |\n",
      "| value_loss              | 1.985424   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035392642 |\n",
      "| ent_coef_loss           | -0.9659754  |\n",
      "| entropy                 | -4.9758654  |\n",
      "| episodes                | 3050        |\n",
      "| fps                     | 151         |\n",
      "| mean 100 episode reward | 2.07e+03    |\n",
      "| n_updates               | 2724959     |\n",
      "| policy_loss             | -182.45442  |\n",
      "| qf1_loss                | 2.7988784   |\n",
      "| qf2_loss                | 3.4608467   |\n",
      "| time_elapsed            | 17953       |\n",
      "| total timesteps         | 2725058     |\n",
      "| value_loss              | 1.5976388   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.038010687 |\n",
      "| ent_coef_loss           | 1.4383914   |\n",
      "| entropy                 | -5.582981   |\n",
      "| episodes                | 3060        |\n",
      "| fps                     | 151         |\n",
      "| mean 100 episode reward | 2.03e+03    |\n",
      "| n_updates               | 2732464     |\n",
      "| policy_loss             | -186.1513   |\n",
      "| qf1_loss                | 8.691352    |\n",
      "| qf2_loss                | 17.770191   |\n",
      "| time_elapsed            | 17999       |\n",
      "| total timesteps         | 2732563     |\n",
      "| value_loss              | 2.268353    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.03701867  |\n",
      "| ent_coef_loss           | -0.36947984 |\n",
      "| entropy                 | -4.4108667  |\n",
      "| episodes                | 3070        |\n",
      "| fps                     | 151         |\n",
      "| mean 100 episode reward | 2.11e+03    |\n",
      "| n_updates               | 2741265     |\n",
      "| policy_loss             | -177.16652  |\n",
      "| qf1_loss                | 3.4959152   |\n",
      "| qf2_loss                | 3.5512547   |\n",
      "| time_elapsed            | 18059       |\n",
      "| total timesteps         | 2741364     |\n",
      "| value_loss              | 2.4717822   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.038591836 |\n",
      "| ent_coef_loss           | -2.1632006  |\n",
      "| entropy                 | -4.905524   |\n",
      "| episodes                | 3080        |\n",
      "| fps                     | 151         |\n",
      "| mean 100 episode reward | 2.09e+03    |\n",
      "| n_updates               | 2748579     |\n",
      "| policy_loss             | -190.48941  |\n",
      "| qf1_loss                | 3.483902    |\n",
      "| qf2_loss                | 3.9571104   |\n",
      "| time_elapsed            | 18107       |\n",
      "| total timesteps         | 2748678     |\n",
      "| value_loss              | 2.4635801   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.039337084 |\n",
      "| ent_coef_loss           | 1.7376366   |\n",
      "| entropy                 | -5.0549097  |\n",
      "| episodes                | 3090        |\n",
      "| fps                     | 151         |\n",
      "| mean 100 episode reward | 2.17e+03    |\n",
      "| n_updates               | 2756594     |\n",
      "| policy_loss             | -189.04419  |\n",
      "| qf1_loss                | 10.673031   |\n",
      "| qf2_loss                | 7.0046883   |\n",
      "| time_elapsed            | 18154       |\n",
      "| total timesteps         | 2756693     |\n",
      "| value_loss              | 2.7072833   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03675369 |\n",
      "| ent_coef_loss           | 0.5818503  |\n",
      "| entropy                 | -5.238709  |\n",
      "| episodes                | 3100       |\n",
      "| fps                     | 151        |\n",
      "| mean 100 episode reward | 2.17e+03   |\n",
      "| n_updates               | 2765190    |\n",
      "| policy_loss             | -191.40005 |\n",
      "| qf1_loss                | 2.500235   |\n",
      "| qf2_loss                | 2.5173335  |\n",
      "| time_elapsed            | 18201      |\n",
      "| total timesteps         | 2765289    |\n",
      "| value_loss              | 1.034595   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.037248824 |\n",
      "| ent_coef_loss           | -1.0347888  |\n",
      "| entropy                 | -5.2819867  |\n",
      "| episodes                | 3110        |\n",
      "| fps                     | 151         |\n",
      "| mean 100 episode reward | 2.12e+03    |\n",
      "| n_updates               | 2773647     |\n",
      "| policy_loss             | -188.05276  |\n",
      "| qf1_loss                | 4.862604    |\n",
      "| qf2_loss                | 4.847091    |\n",
      "| time_elapsed            | 18256       |\n",
      "| total timesteps         | 2773746     |\n",
      "| value_loss              | 1.5165544   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.040348463 |\n",
      "| ent_coef_loss           | 0.8958877   |\n",
      "| entropy                 | -5.039214   |\n",
      "| episodes                | 3120        |\n",
      "| fps                     | 152         |\n",
      "| mean 100 episode reward | 2.17e+03    |\n",
      "| n_updates               | 2782392     |\n",
      "| policy_loss             | -179.75784  |\n",
      "| qf1_loss                | 9.540182    |\n",
      "| qf2_loss                | 11.9161215  |\n",
      "| time_elapsed            | 18305       |\n",
      "| total timesteps         | 2782491     |\n",
      "| value_loss              | 5.7610035   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.037194308 |\n",
      "| ent_coef_loss           | -1.4255781  |\n",
      "| entropy                 | -4.6021667  |\n",
      "| episodes                | 3130        |\n",
      "| fps                     | 151         |\n",
      "| mean 100 episode reward | 2.15e+03    |\n",
      "| n_updates               | 2789512     |\n",
      "| policy_loss             | -183.30173  |\n",
      "| qf1_loss                | 6.630463    |\n",
      "| qf2_loss                | 6.301257    |\n",
      "| time_elapsed            | 18352       |\n",
      "| total timesteps         | 2789611     |\n",
      "| value_loss              | 1.5834862   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03899395 |\n",
      "| ent_coef_loss           | -2.3500392 |\n",
      "| entropy                 | -4.4541454 |\n",
      "| episodes                | 3140       |\n",
      "| fps                     | 152        |\n",
      "| mean 100 episode reward | 2.22e+03   |\n",
      "| n_updates               | 2798727    |\n",
      "| policy_loss             | -198.69855 |\n",
      "| qf1_loss                | 3.1242576  |\n",
      "| qf2_loss                | 4.549654   |\n",
      "| time_elapsed            | 18405      |\n",
      "| total timesteps         | 2798826    |\n",
      "| value_loss              | 2.2522032  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03856934 |\n",
      "| ent_coef_loss           | 0.3775658  |\n",
      "| entropy                 | -4.9696493 |\n",
      "| episodes                | 3150       |\n",
      "| fps                     | 152        |\n",
      "| mean 100 episode reward | 2.23e+03   |\n",
      "| n_updates               | 2807588    |\n",
      "| policy_loss             | -195.72934 |\n",
      "| qf1_loss                | 4.266346   |\n",
      "| qf2_loss                | 4.4644756  |\n",
      "| time_elapsed            | 18458      |\n",
      "| total timesteps         | 2807687    |\n",
      "| value_loss              | 2.8710117  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.038742624 |\n",
      "| ent_coef_loss           | -2.6198504  |\n",
      "| entropy                 | -4.9848437  |\n",
      "| episodes                | 3160        |\n",
      "| fps                     | 152         |\n",
      "| mean 100 episode reward | 2.27e+03    |\n",
      "| n_updates               | 2816648     |\n",
      "| policy_loss             | -195.879    |\n",
      "| qf1_loss                | 6.693898    |\n",
      "| qf2_loss                | 5.751447    |\n",
      "| time_elapsed            | 18517       |\n",
      "| total timesteps         | 2816747     |\n",
      "| value_loss              | 0.9177903   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03801879 |\n",
      "| ent_coef_loss           | 0.36473727 |\n",
      "| entropy                 | -4.408284  |\n",
      "| episodes                | 3170       |\n",
      "| fps                     | 152        |\n",
      "| mean 100 episode reward | 2.21e+03   |\n",
      "| n_updates               | 2824009    |\n",
      "| policy_loss             | -168.94394 |\n",
      "| qf1_loss                | 2.7057834  |\n",
      "| qf2_loss                | 3.1919603  |\n",
      "| time_elapsed            | 18567      |\n",
      "| total timesteps         | 2824108    |\n",
      "| value_loss              | 2.2751741  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.0384106  |\n",
      "| ent_coef_loss           | 0.14535773 |\n",
      "| entropy                 | -5.2274103 |\n",
      "| episodes                | 3180       |\n",
      "| fps                     | 152        |\n",
      "| mean 100 episode reward | 2.28e+03   |\n",
      "| n_updates               | 2832377    |\n",
      "| policy_loss             | -190.26965 |\n",
      "| qf1_loss                | 22.862144  |\n",
      "| qf2_loss                | 21.986797  |\n",
      "| time_elapsed            | 18621      |\n",
      "| total timesteps         | 2832476    |\n",
      "| value_loss              | 1.6886356  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.037235167 |\n",
      "| ent_coef_loss           | 1.9076446   |\n",
      "| entropy                 | -4.8055153  |\n",
      "| episodes                | 3190        |\n",
      "| fps                     | 152         |\n",
      "| mean 100 episode reward | 2.33e+03    |\n",
      "| n_updates               | 2842120     |\n",
      "| policy_loss             | -188.73126  |\n",
      "| qf1_loss                | 4.6973853   |\n",
      "| qf2_loss                | 3.6939778   |\n",
      "| time_elapsed            | 18680       |\n",
      "| total timesteps         | 2842219     |\n",
      "| value_loss              | 1.5070702   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.039761964 |\n",
      "| ent_coef_loss           | 1.097435    |\n",
      "| entropy                 | -5.7976875  |\n",
      "| episodes                | 3200        |\n",
      "| fps                     | 152         |\n",
      "| mean 100 episode reward | 2.36e+03    |\n",
      "| n_updates               | 2851805     |\n",
      "| policy_loss             | -194.60664  |\n",
      "| qf1_loss                | 3.7753463   |\n",
      "| qf2_loss                | 5.121071    |\n",
      "| time_elapsed            | 18737       |\n",
      "| total timesteps         | 2851904     |\n",
      "| value_loss              | 2.1985745   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03755711 |\n",
      "| ent_coef_loss           | 0.34827033 |\n",
      "| entropy                 | -4.9984136 |\n",
      "| episodes                | 3210       |\n",
      "| fps                     | 152        |\n",
      "| mean 100 episode reward | 2.4e+03    |\n",
      "| n_updates               | 2860570    |\n",
      "| policy_loss             | -192.45961 |\n",
      "| qf1_loss                | 15.444163  |\n",
      "| qf2_loss                | 24.311289  |\n",
      "| time_elapsed            | 18791      |\n",
      "| total timesteps         | 2860669    |\n",
      "| value_loss              | 2.523078   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03657949 |\n",
      "| ent_coef_loss           | -1.2412517 |\n",
      "| entropy                 | -4.4642067 |\n",
      "| episodes                | 3220       |\n",
      "| fps                     | 152        |\n",
      "| mean 100 episode reward | 2.41e+03   |\n",
      "| n_updates               | 2868874    |\n",
      "| policy_loss             | -183.87994 |\n",
      "| qf1_loss                | 10.260212  |\n",
      "| qf2_loss                | 5.5889993  |\n",
      "| time_elapsed            | 18839      |\n",
      "| total timesteps         | 2868973    |\n",
      "| value_loss              | 1.2027962  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035902437 |\n",
      "| ent_coef_loss           | 0.6893631   |\n",
      "| entropy                 | -5.0493097  |\n",
      "| episodes                | 3230        |\n",
      "| fps                     | 152         |\n",
      "| mean 100 episode reward | 2.49e+03    |\n",
      "| n_updates               | 2876678     |\n",
      "| policy_loss             | -188.59818  |\n",
      "| qf1_loss                | 3.536287    |\n",
      "| qf2_loss                | 5.2716026   |\n",
      "| time_elapsed            | 18883       |\n",
      "| total timesteps         | 2876777     |\n",
      "| value_loss              | 4.483589    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.038920604 |\n",
      "| ent_coef_loss           | -0.36261886 |\n",
      "| entropy                 | -4.3653097  |\n",
      "| episodes                | 3240        |\n",
      "| fps                     | 152         |\n",
      "| mean 100 episode reward | 2.48e+03    |\n",
      "| n_updates               | 2885651     |\n",
      "| policy_loss             | -180.07639  |\n",
      "| qf1_loss                | 6.9575405   |\n",
      "| qf2_loss                | 15.815085   |\n",
      "| time_elapsed            | 18936       |\n",
      "| total timesteps         | 2885750     |\n",
      "| value_loss              | 1.8016337   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036279157 |\n",
      "| ent_coef_loss           | -0.26944178 |\n",
      "| entropy                 | -4.339868   |\n",
      "| episodes                | 3250        |\n",
      "| fps                     | 152         |\n",
      "| mean 100 episode reward | 2.49e+03    |\n",
      "| n_updates               | 2895075     |\n",
      "| policy_loss             | -186.19708  |\n",
      "| qf1_loss                | 8.731039    |\n",
      "| qf2_loss                | 7.1513104   |\n",
      "| time_elapsed            | 18991       |\n",
      "| total timesteps         | 2895174     |\n",
      "| value_loss              | 3.0754287   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03906086 |\n",
      "| ent_coef_loss           | -1.7350556 |\n",
      "| entropy                 | -4.4854665 |\n",
      "| episodes                | 3260       |\n",
      "| fps                     | 152        |\n",
      "| mean 100 episode reward | 2.41e+03   |\n",
      "| n_updates               | 2904583    |\n",
      "| policy_loss             | -187.52623 |\n",
      "| qf1_loss                | 2.883277   |\n",
      "| qf2_loss                | 1.6965036  |\n",
      "| time_elapsed            | 19049      |\n",
      "| total timesteps         | 2904682    |\n",
      "| value_loss              | 2.2644708  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.037590336 |\n",
      "| ent_coef_loss           | 0.60437477  |\n",
      "| entropy                 | -4.4118714  |\n",
      "| episodes                | 3270        |\n",
      "| fps                     | 152         |\n",
      "| mean 100 episode reward | 2.38e+03    |\n",
      "| n_updates               | 2911657     |\n",
      "| policy_loss             | -192.67702  |\n",
      "| qf1_loss                | 9.308485    |\n",
      "| qf2_loss                | 9.389862    |\n",
      "| time_elapsed            | 19094       |\n",
      "| total timesteps         | 2911756     |\n",
      "| value_loss              | 1.1668838   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036061127 |\n",
      "| ent_coef_loss           | -0.9325883  |\n",
      "| entropy                 | -4.8237457  |\n",
      "| episodes                | 3280        |\n",
      "| fps                     | 152         |\n",
      "| mean 100 episode reward | 2.38e+03    |\n",
      "| n_updates               | 2920177     |\n",
      "| policy_loss             | -198.55147  |\n",
      "| qf1_loss                | 3.435756    |\n",
      "| qf2_loss                | 5.278674    |\n",
      "| time_elapsed            | 19145       |\n",
      "| total timesteps         | 2920276     |\n",
      "| value_loss              | 1.4442905   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036651134 |\n",
      "| ent_coef_loss           | -0.42460638 |\n",
      "| entropy                 | -5.4251833  |\n",
      "| episodes                | 3290        |\n",
      "| fps                     | 152         |\n",
      "| mean 100 episode reward | 2.37e+03    |\n",
      "| n_updates               | 2929482     |\n",
      "| policy_loss             | -189.67352  |\n",
      "| qf1_loss                | 6.3272834   |\n",
      "| qf2_loss                | 13.325173   |\n",
      "| time_elapsed            | 19200       |\n",
      "| total timesteps         | 2929581     |\n",
      "| value_loss              | 2.3299212   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.039676245 |\n",
      "| ent_coef_loss           | -1.0623579  |\n",
      "| entropy                 | -4.7316256  |\n",
      "| episodes                | 3300        |\n",
      "| fps                     | 152         |\n",
      "| mean 100 episode reward | 2.31e+03    |\n",
      "| n_updates               | 2936979     |\n",
      "| policy_loss             | -203.39825  |\n",
      "| qf1_loss                | 4.777767    |\n",
      "| qf2_loss                | 4.3707333   |\n",
      "| time_elapsed            | 19242       |\n",
      "| total timesteps         | 2937078     |\n",
      "| value_loss              | 1.4393018   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.037980095 |\n",
      "| ent_coef_loss           | 0.48257464  |\n",
      "| entropy                 | -4.9627366  |\n",
      "| episodes                | 3310        |\n",
      "| fps                     | 152         |\n",
      "| mean 100 episode reward | 2.34e+03    |\n",
      "| n_updates               | 2946340     |\n",
      "| policy_loss             | -196.17166  |\n",
      "| qf1_loss                | 2.3182006   |\n",
      "| qf2_loss                | 2.472803    |\n",
      "| time_elapsed            | 19294       |\n",
      "| total timesteps         | 2946439     |\n",
      "| value_loss              | 0.69558877  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.037936583 |\n",
      "| ent_coef_loss           | -0.7759227  |\n",
      "| entropy                 | -4.7091823  |\n",
      "| episodes                | 3320        |\n",
      "| fps                     | 152         |\n",
      "| mean 100 episode reward | 2.33e+03    |\n",
      "| n_updates               | 2954185     |\n",
      "| policy_loss             | -193.22131  |\n",
      "| qf1_loss                | 8.357019    |\n",
      "| qf2_loss                | 11.625275   |\n",
      "| time_elapsed            | 19339       |\n",
      "| total timesteps         | 2954284     |\n",
      "| value_loss              | 2.242957    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.039331842 |\n",
      "| ent_coef_loss           | 1.7171059   |\n",
      "| entropy                 | -5.0367827  |\n",
      "| episodes                | 3330        |\n",
      "| fps                     | 152         |\n",
      "| mean 100 episode reward | 2.32e+03    |\n",
      "| n_updates               | 2962415     |\n",
      "| policy_loss             | -194.64249  |\n",
      "| qf1_loss                | 2.5184417   |\n",
      "| qf2_loss                | 2.5340476   |\n",
      "| time_elapsed            | 19394       |\n",
      "| total timesteps         | 2962514     |\n",
      "| value_loss              | 1.071565    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.039154585 |\n",
      "| ent_coef_loss           | 2.1355965   |\n",
      "| entropy                 | -5.4140377  |\n",
      "| episodes                | 3340        |\n",
      "| fps                     | 152         |\n",
      "| mean 100 episode reward | 2.26e+03    |\n",
      "| n_updates               | 2969435     |\n",
      "| policy_loss             | -206.4967   |\n",
      "| qf1_loss                | 3.589178    |\n",
      "| qf2_loss                | 2.8167646   |\n",
      "| time_elapsed            | 19439       |\n",
      "| total timesteps         | 2969534     |\n",
      "| value_loss              | 1.5683985   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03703783 |\n",
      "| ent_coef_loss           | 1.471623   |\n",
      "| entropy                 | -5.018791  |\n",
      "| episodes                | 3350       |\n",
      "| fps                     | 152        |\n",
      "| mean 100 episode reward | 2.27e+03   |\n",
      "| n_updates               | 2978664    |\n",
      "| policy_loss             | -195.10564 |\n",
      "| qf1_loss                | 2.564628   |\n",
      "| qf2_loss                | 2.423963   |\n",
      "| time_elapsed            | 19499      |\n",
      "| total timesteps         | 2978763    |\n",
      "| value_loss              | 1.6310706  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.040825304 |\n",
      "| ent_coef_loss           | -0.21585366 |\n",
      "| entropy                 | -5.280818   |\n",
      "| episodes                | 3360        |\n",
      "| fps                     | 152         |\n",
      "| mean 100 episode reward | 2.34e+03    |\n",
      "| n_updates               | 2987303     |\n",
      "| policy_loss             | -201.16327  |\n",
      "| qf1_loss                | 9.237206    |\n",
      "| qf2_loss                | 8.16797     |\n",
      "| time_elapsed            | 19558       |\n",
      "| total timesteps         | 2987402     |\n",
      "| value_loss              | 2.0417373   |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| current_lr              | 0.0003       |\n",
      "| ent_coef                | 0.03982956   |\n",
      "| ent_coef_loss           | -0.098439455 |\n",
      "| entropy                 | -5.10535     |\n",
      "| episodes                | 3370         |\n",
      "| fps                     | 152          |\n",
      "| mean 100 episode reward | 2.4e+03      |\n",
      "| n_updates               | 2996680      |\n",
      "| policy_loss             | -191.33508   |\n",
      "| qf1_loss                | 5.146684     |\n",
      "| qf2_loss                | 9.183151     |\n",
      "| time_elapsed            | 19622        |\n",
      "| total timesteps         | 2996779      |\n",
      "| value_loss              | 2.734717     |\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# TRAIN THE MODEL\n",
    "model.learn(total_timesteps=int(3e6), log_interval=10)\n",
    "model.save(\"ant_3M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading a model without an environment, this model cannot be trained until it has a valid environment.\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2cf4179650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2cf4179650>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2cf4179650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2cf4179650>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d7417b690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d7417b690>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d7417b690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d7417b690>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d2066b050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d2066b050>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d2066b050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d2066b050>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d2066b050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d2066b050>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d2066b050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d2066b050>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d2066b050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d2066b050>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d2066b050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d2066b050>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2cf418d3d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2cf418d3d0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2cf418d3d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2cf418d3d0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf4111f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf4111f10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf4111f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf4111f10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6c1af6d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6c1af6d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6c1af6d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6c1af6d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6c0a3750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6c0a3750>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6c0a3750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2d6c0a3750>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf419bb10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf419bb10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf419bb10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf419bb10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf40c1dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf40c1dd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf40c1dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf40c1dd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf419b7d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf419b7d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf419b7d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf419b7d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf419b7d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf419b7d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf419b7d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf419b7d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf418d990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf418d990>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf418d990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf418d990>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf4111f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf4111f10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf4111f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf4111f10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2cf448cf10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2cf448cf10>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2cf448cf10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2cf448cf10>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf4191690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf4191690>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf4191690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf4191690>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf411d390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf411d390>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf411d390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf411d390>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf448cf10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf448cf10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf448cf10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf448cf10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf419b7d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf419b7d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf419b7d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf419b7d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cec193b90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cec193b90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cec193b90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cec193b90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf40c1dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf40c1dd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf40c1dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf40c1dd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2cf4191ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2cf4191ad0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2cf4191ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f2cf4191ad0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf418d990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf418d990>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf418d990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf418d990>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf418d990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf418d990>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf418d990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cf418d990>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cec0f9050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cec0f9050>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cec0f9050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f2cec0f9050>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    }
   ],
   "source": [
    "# RUN THE SAVED MODEL\n",
    "env = gym.make('Ant-v2')\n",
    "model = SAC.load(\"ant_3M\")\n",
    "\n",
    "images = []\n",
    "obs = env.reset()\n",
    "for _ in range(350):\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, dones, info = env.step(action)\n",
    "    images.append(env.render(mode='rgb_array'))\n",
    "env.close()\n",
    "    \n",
    "#imageio.mimsave('ant_sac.gif', [np.array(img) for i, img in enumerate(images) if i%2 == 0], fps=29)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800\"\n",
       "            src=\"http://localhost:6006\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f95e433b350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# DISPLAY THE RESULTS\n",
    "%tensorboard --logdir sac_ant_tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
