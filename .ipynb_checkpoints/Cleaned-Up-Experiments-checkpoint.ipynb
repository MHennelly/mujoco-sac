{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-Mocap Simulation Efforts\n",
    "\n",
    "This notebook contains the work we've towards simulating realistic gaits since pivoting at the start of Week 9.\n",
    "\n",
    "To give some context, the focus of these efforts was to determine how visually realistic the learned gaits through non-mocap methods would appear to be for different models. We also experimented with achieving more and more optimal trained agents, which lead to us shifting training from PPO to SAC as discussed in the project report. Below you will find both the scripts we wrote to train our model and data/graphs collected from training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "from stable_baselines.sac.policies import MlpPolicy\n",
    "from stable_baselines import SAC\n",
    "\n",
    "%load_ext tensorboard # Needed for the graphs displayed below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task: Walk as far forward as possible without falling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f329133cdd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f329133cdd0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f329133cdd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f329133cdd0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3291d7da90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3291d7da90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3291d7da90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3291d7da90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3291d7d150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3291d7d150>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3291d7d150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3291d7d150>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f329133cdd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f329133cdd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f329133cdd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f329133cdd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f329133cdd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f329133cdd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f329133cdd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f329133cdd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f32bc20bc90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f32bc20bc90>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f32bc20bc90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f32bc20bc90>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f32bc3363d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f32bc3363d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f32bc3363d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f32bc3363d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f32bc1d8490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f32bc1d8490>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f32bc1d8490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f32bc1d8490>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f32bc34f190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f32bc34f190>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f32bc34f190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f32bc34f190>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f32bc1d8e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f32bc1d8e90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f32bc1d8e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f32bc1d8e90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f329395ee50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f329395ee50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f329395ee50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f329395ee50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f33d448a610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f33d448a610>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f33d448a610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f33d448a610>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f32bc302dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f32bc302dd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f32bc302dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f32bc302dd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3291d33dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3291d33dd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3291d33dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3291d33dd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f32bc34fa50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f32bc34fa50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f32bc34fa50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f32bc34fa50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f32bc133e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f32bc133e50>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f32bc133e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f32bc133e50>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f32939b3790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f32939b3790>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f32939b3790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f32939b3790>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f33402a9710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f33402a9710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f33402a9710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f33402a9710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f32bc133e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f32bc133e50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f32bc133e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f32bc133e50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3341d7d850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3341d7d850>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3341d7d850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3341d7d850>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3293942210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3293942210>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3293942210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3293942210>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f33402a9710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f33402a9710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f33402a9710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f33402a9710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f32bc336410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f32bc336410>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f32bc336410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f32bc336410>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f329386d710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f329386d710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f329386d710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f329386d710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3362cd9050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3362cd9050>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3362cd9050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3362cd9050>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f32bc336650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f32bc336650>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f32bc336650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f32bc336650>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    }
   ],
   "source": [
    "# DEFINE THE ENVIRONMENT/MODEL WITH TUNED PARAMETERS\n",
    "env = gym.make('Humanoid-v2')\n",
    "policy_kwargs = dict(layers=[256, 256])\n",
    "model = SAC(MlpPolicy, env, verbose=1, tensorboard_log=\"./sac_humanoid_walk_tensorboard/\", \n",
    "            policy_kwargs=policy_kwargs, buffer_size=1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 1.0125033  |\n",
      "| ent_coef_loss           | 0.06119744 |\n",
      "| entropy                 | 20.704313  |\n",
      "| episodes                | 10         |\n",
      "| fps                     | 97         |\n",
      "| mean 100 episode reward | 98.4       |\n",
      "| n_updates               | 80         |\n",
      "| policy_loss             | 22.465284  |\n",
      "| qf1_loss                | 11.124978  |\n",
      "| qf2_loss                | 8.203977   |\n",
      "| time_elapsed            | 1          |\n",
      "| total timesteps         | 179        |\n",
      "| value_loss              | 174.56766  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.9544133  |\n",
      "| ent_coef_loss           | -1.1572626 |\n",
      "| entropy                 | 20.403168  |\n",
      "| episodes                | 20         |\n",
      "| fps                     | 94         |\n",
      "| mean 100 episode reward | 108        |\n",
      "| n_updates               | 316        |\n",
      "| policy_loss             | -2.3990934 |\n",
      "| qf1_loss                | 0.51813656 |\n",
      "| qf2_loss                | 0.5467812  |\n",
      "| time_elapsed            | 4          |\n",
      "| total timesteps         | 415        |\n",
      "| value_loss              | 10.668219  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.8891577   |\n",
      "| ent_coef_loss           | -3.0752764  |\n",
      "| entropy                 | 21.700241   |\n",
      "| episodes                | 30          |\n",
      "| fps                     | 88          |\n",
      "| mean 100 episode reward | 107         |\n",
      "| n_updates               | 525         |\n",
      "| policy_loss             | -14.2423315 |\n",
      "| qf1_loss                | 0.70251644  |\n",
      "| qf2_loss                | 0.6889137   |\n",
      "| time_elapsed            | 7           |\n",
      "| total timesteps         | 624         |\n",
      "| value_loss              | 5.3352      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.8115706  |\n",
      "| ent_coef_loss           | -5.916248  |\n",
      "| entropy                 | 23.042986  |\n",
      "| episodes                | 40         |\n",
      "| fps                     | 88         |\n",
      "| mean 100 episode reward | 113        |\n",
      "| n_updates               | 794        |\n",
      "| policy_loss             | -29.005184 |\n",
      "| qf1_loss                | 1.2019413  |\n",
      "| qf2_loss                | 1.1649554  |\n",
      "| time_elapsed            | 10         |\n",
      "| total timesteps         | 893        |\n",
      "| value_loss              | 2.4184105  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.7393683  |\n",
      "| ent_coef_loss           | -8.613232  |\n",
      "| entropy                 | 22.716064  |\n",
      "| episodes                | 50         |\n",
      "| fps                     | 87         |\n",
      "| mean 100 episode reward | 119        |\n",
      "| n_updates               | 1076       |\n",
      "| policy_loss             | -40.725273 |\n",
      "| qf1_loss                | 3.622107   |\n",
      "| qf2_loss                | 3.279561   |\n",
      "| time_elapsed            | 13         |\n",
      "| total timesteps         | 1175       |\n",
      "| value_loss              | 4.5796423  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.6888414  |\n",
      "| ent_coef_loss           | -10.592568 |\n",
      "| entropy                 | 22.489193  |\n",
      "| episodes                | 60         |\n",
      "| fps                     | 86         |\n",
      "| mean 100 episode reward | 118        |\n",
      "| n_updates               | 1297       |\n",
      "| policy_loss             | -50.334282 |\n",
      "| qf1_loss                | 2.6979723  |\n",
      "| qf2_loss                | 2.7989557  |\n",
      "| time_elapsed            | 16         |\n",
      "| total timesteps         | 1396       |\n",
      "| value_loss              | 5.4930654  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.62427056 |\n",
      "| ent_coef_loss           | -13.403842 |\n",
      "| entropy                 | 22.108063  |\n",
      "| episodes                | 70         |\n",
      "| fps                     | 86         |\n",
      "| mean 100 episode reward | 123        |\n",
      "| n_updates               | 1611       |\n",
      "| policy_loss             | -62.88182  |\n",
      "| qf1_loss                | 4.1122417  |\n",
      "| qf2_loss                | 3.619776   |\n",
      "| time_elapsed            | 19         |\n",
      "| total timesteps         | 1710       |\n",
      "| value_loss              | 10.349296  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.56952125 |\n",
      "| ent_coef_loss           | -15.776991 |\n",
      "| entropy                 | 21.762817  |\n",
      "| episodes                | 80         |\n",
      "| fps                     | 86         |\n",
      "| mean 100 episode reward | 127        |\n",
      "| n_updates               | 1910       |\n",
      "| policy_loss             | -71.248245 |\n",
      "| qf1_loss                | 6.4287796  |\n",
      "| qf2_loss                | 7.911027   |\n",
      "| time_elapsed            | 23         |\n",
      "| total timesteps         | 2009       |\n",
      "| value_loss              | 20.334583  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.4767425  |\n",
      "| ent_coef_loss           | -18.844227 |\n",
      "| entropy                 | 20.878826  |\n",
      "| episodes                | 90         |\n",
      "| fps                     | 87         |\n",
      "| mean 100 episode reward | 150        |\n",
      "| n_updates               | 2529       |\n",
      "| policy_loss             | -92.92145  |\n",
      "| qf1_loss                | 9.190144   |\n",
      "| qf2_loss                | 7.6697125  |\n",
      "| time_elapsed            | 30         |\n",
      "| total timesteps         | 2628       |\n",
      "| value_loss              | 20.027836  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.40211478  |\n",
      "| ent_coef_loss           | -22.043222  |\n",
      "| entropy                 | 20.203209   |\n",
      "| episodes                | 100         |\n",
      "| fps                     | 87          |\n",
      "| mean 100 episode reward | 166         |\n",
      "| n_updates               | 3134        |\n",
      "| policy_loss             | -112.467896 |\n",
      "| qf1_loss                | 11.829196   |\n",
      "| qf2_loss                | 11.159112   |\n",
      "| time_elapsed            | 36          |\n",
      "| total timesteps         | 3233        |\n",
      "| value_loss              | 17.997143   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.33293605 |\n",
      "| ent_coef_loss           | -24.982601 |\n",
      "| entropy                 | 20.049065  |\n",
      "| episodes                | 110        |\n",
      "| fps                     | 87         |\n",
      "| mean 100 episode reward | 189        |\n",
      "| n_updates               | 3817       |\n",
      "| policy_loss             | -131.8073  |\n",
      "| qf1_loss                | 17.377613  |\n",
      "| qf2_loss                | 12.465757  |\n",
      "| time_elapsed            | 44         |\n",
      "| total timesteps         | 3916       |\n",
      "| value_loss              | 15.478849  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.29728726 |\n",
      "| ent_coef_loss           | -25.666069 |\n",
      "| entropy                 | 19.63733   |\n",
      "| episodes                | 120        |\n",
      "| fps                     | 87         |\n",
      "| mean 100 episode reward | 198        |\n",
      "| n_updates               | 4237       |\n",
      "| policy_loss             | -140.4714  |\n",
      "| qf1_loss                | 14.375568  |\n",
      "| qf2_loss                | 17.754604  |\n",
      "| time_elapsed            | 49         |\n",
      "| total timesteps         | 4336       |\n",
      "| value_loss              | 19.468287  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.2523827  |\n",
      "| ent_coef_loss           | -27.12737  |\n",
      "| entropy                 | 19.214508  |\n",
      "| episodes                | 130        |\n",
      "| fps                     | 87         |\n",
      "| mean 100 episode reward | 218        |\n",
      "| n_updates               | 4846       |\n",
      "| policy_loss             | -137.58263 |\n",
      "| qf1_loss                | 25.793324  |\n",
      "| qf2_loss                | 24.253765  |\n",
      "| time_elapsed            | 56         |\n",
      "| total timesteps         | 4945       |\n",
      "| value_loss              | 19.377977  |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.21295615 |\n",
      "| ent_coef_loss           | -29.209871 |\n",
      "| entropy                 | 18.89505   |\n",
      "| episodes                | 140        |\n",
      "| fps                     | 87         |\n",
      "| mean 100 episode reward | 238        |\n",
      "| n_updates               | 5479       |\n",
      "| policy_loss             | -156.94156 |\n",
      "| qf1_loss                | 16.031916  |\n",
      "| qf2_loss                | 12.033306  |\n",
      "| time_elapsed            | 63         |\n",
      "| total timesteps         | 5578       |\n",
      "| value_loss              | 33.884926  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.18249518 |\n",
      "| ent_coef_loss           | -32.414444 |\n",
      "| entropy                 | 18.825909  |\n",
      "| episodes                | 150        |\n",
      "| fps                     | 87         |\n",
      "| mean 100 episode reward | 252        |\n",
      "| n_updates               | 6042       |\n",
      "| policy_loss             | -162.18289 |\n",
      "| qf1_loss                | 30.098217  |\n",
      "| qf2_loss                | 38.950745  |\n",
      "| time_elapsed            | 70         |\n",
      "| total timesteps         | 6141       |\n",
      "| value_loss              | 22.57944   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.15254408 |\n",
      "| ent_coef_loss           | -27.628506 |\n",
      "| entropy                 | 18.200464  |\n",
      "| episodes                | 160        |\n",
      "| fps                     | 87         |\n",
      "| mean 100 episode reward | 277        |\n",
      "| n_updates               | 6704       |\n",
      "| policy_loss             | -154.98166 |\n",
      "| qf1_loss                | 18.055695  |\n",
      "| qf2_loss                | 24.94688   |\n",
      "| time_elapsed            | 77         |\n",
      "| total timesteps         | 6803       |\n",
      "| value_loss              | 22.368639  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.13118824 |\n",
      "| ent_coef_loss           | -30.602484 |\n",
      "| entropy                 | 18.01033   |\n",
      "| episodes                | 170        |\n",
      "| fps                     | 86         |\n",
      "| mean 100 episode reward | 292        |\n",
      "| n_updates               | 7286       |\n",
      "| policy_loss             | -166.12207 |\n",
      "| qf1_loss                | 21.22596   |\n",
      "| qf2_loss                | 22.273788  |\n",
      "| time_elapsed            | 84         |\n",
      "| total timesteps         | 7385       |\n",
      "| value_loss              | 26.313612  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.11490361 |\n",
      "| ent_coef_loss           | -29.836452 |\n",
      "| entropy                 | 17.558891  |\n",
      "| episodes                | 180        |\n",
      "| fps                     | 86         |\n",
      "| mean 100 episode reward | 304        |\n",
      "| n_updates               | 7790       |\n",
      "| policy_loss             | -166.04343 |\n",
      "| qf1_loss                | 18.31955   |\n",
      "| qf2_loss                | 14.394957  |\n",
      "| time_elapsed            | 91         |\n",
      "| total timesteps         | 7889       |\n",
      "| value_loss              | 16.28587   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.09793598 |\n",
      "| ent_coef_loss           | -27.269707 |\n",
      "| entropy                 | 17.354301  |\n",
      "| episodes                | 190        |\n",
      "| fps                     | 86         |\n",
      "| mean 100 episode reward | 305        |\n",
      "| n_updates               | 8430       |\n",
      "| policy_loss             | -177.32858 |\n",
      "| qf1_loss                | 13.253316  |\n",
      "| qf2_loss                | 17.871521  |\n",
      "| time_elapsed            | 98         |\n",
      "| total timesteps         | 8529       |\n",
      "| value_loss              | 15.269998  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.08384285 |\n",
      "| ent_coef_loss           | -28.546589 |\n",
      "| entropy                 | 17.259373  |\n",
      "| episodes                | 200        |\n",
      "| fps                     | 84         |\n",
      "| mean 100 episode reward | 305        |\n",
      "| n_updates               | 9062       |\n",
      "| policy_loss             | -181.84647 |\n",
      "| qf1_loss                | 20.222431  |\n",
      "| qf2_loss                | 18.010527  |\n",
      "| time_elapsed            | 107        |\n",
      "| total timesteps         | 9161       |\n",
      "| value_loss              | 19.043793  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.070702486 |\n",
      "| ent_coef_loss           | -24.564644  |\n",
      "| entropy                 | 16.905891   |\n",
      "| episodes                | 210         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 306         |\n",
      "| n_updates               | 9764        |\n",
      "| policy_loss             | -173.4393   |\n",
      "| qf1_loss                | 25.69077    |\n",
      "| qf2_loss                | 24.23481    |\n",
      "| time_elapsed            | 116         |\n",
      "| total timesteps         | 9863        |\n",
      "| value_loss              | 30.879848   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.06042513 |\n",
      "| ent_coef_loss           | -17.903103 |\n",
      "| entropy                 | 16.065002  |\n",
      "| episodes                | 220        |\n",
      "| fps                     | 85         |\n",
      "| mean 100 episode reward | 319        |\n",
      "| n_updates               | 10492      |\n",
      "| policy_loss             | -173.39142 |\n",
      "| qf1_loss                | 27.072964  |\n",
      "| qf2_loss                | 29.223164  |\n",
      "| time_elapsed            | 124        |\n",
      "| total timesteps         | 10591      |\n",
      "| value_loss              | 15.484298  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.052604783 |\n",
      "| ent_coef_loss           | -15.768726  |\n",
      "| entropy                 | 16.442316   |\n",
      "| episodes                | 230         |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 324         |\n",
      "| n_updates               | 11188       |\n",
      "| policy_loss             | -193.73581  |\n",
      "| qf1_loss                | 15.858789   |\n",
      "| qf2_loss                | 20.433746   |\n",
      "| time_elapsed            | 132         |\n",
      "| total timesteps         | 11287       |\n",
      "| value_loss              | 30.895166   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.04740392 |\n",
      "| ent_coef_loss           | -8.710045  |\n",
      "| entropy                 | 15.350883  |\n",
      "| episodes                | 240        |\n",
      "| fps                     | 85         |\n",
      "| mean 100 episode reward | 325        |\n",
      "| n_updates               | 11828      |\n",
      "| policy_loss             | -160.25937 |\n",
      "| qf1_loss                | 26.523512  |\n",
      "| qf2_loss                | 22.681032  |\n",
      "| time_elapsed            | 140        |\n",
      "| total timesteps         | 11927      |\n",
      "| value_loss              | 48.61867   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.042913496 |\n",
      "| ent_coef_loss           | -8.88969    |\n",
      "| entropy                 | 15.228067   |\n",
      "| episodes                | 250         |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 329         |\n",
      "| n_updates               | 12495       |\n",
      "| policy_loss             | -177.51395  |\n",
      "| qf1_loss                | 25.267555   |\n",
      "| qf2_loss                | 23.372738   |\n",
      "| time_elapsed            | 148         |\n",
      "| total timesteps         | 12594       |\n",
      "| value_loss              | 17.455212   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03895132 |\n",
      "| ent_coef_loss           | -1.9013168 |\n",
      "| entropy                 | 15.29756   |\n",
      "| episodes                | 260        |\n",
      "| fps                     | 85         |\n",
      "| mean 100 episode reward | 331        |\n",
      "| n_updates               | 13200      |\n",
      "| policy_loss             | -174.34492 |\n",
      "| qf1_loss                | 20.992893  |\n",
      "| qf2_loss                | 21.55784   |\n",
      "| time_elapsed            | 156        |\n",
      "| total timesteps         | 13299      |\n",
      "| value_loss              | 21.641598  |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.034614637 |\n",
      "| ent_coef_loss           | -8.215527   |\n",
      "| entropy                 | 15.240572   |\n",
      "| episodes                | 270         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 335         |\n",
      "| n_updates               | 13886       |\n",
      "| policy_loss             | -173.10144  |\n",
      "| qf1_loss                | 37.088688   |\n",
      "| qf2_loss                | 41.026405   |\n",
      "| time_elapsed            | 164         |\n",
      "| total timesteps         | 13985       |\n",
      "| value_loss              | 50.987045   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.033174377 |\n",
      "| ent_coef_loss           | -4.037989   |\n",
      "| entropy                 | 15.20296    |\n",
      "| episodes                | 280         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 342         |\n",
      "| n_updates               | 14538       |\n",
      "| policy_loss             | -161.33522  |\n",
      "| qf1_loss                | 30.464998   |\n",
      "| qf2_loss                | 31.075954   |\n",
      "| time_elapsed            | 172         |\n",
      "| total timesteps         | 14637       |\n",
      "| value_loss              | 26.430822   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.033046357 |\n",
      "| ent_coef_loss           | 4.510425    |\n",
      "| entropy                 | 14.817541   |\n",
      "| episodes                | 290         |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 341         |\n",
      "| n_updates               | 15176       |\n",
      "| policy_loss             | -148.55542  |\n",
      "| qf1_loss                | 26.26422    |\n",
      "| qf2_loss                | 28.17683    |\n",
      "| time_elapsed            | 179         |\n",
      "| total timesteps         | 15275       |\n",
      "| value_loss              | 26.110825   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.032739382 |\n",
      "| ent_coef_loss           | 2.7368808   |\n",
      "| entropy                 | 14.672256   |\n",
      "| episodes                | 300         |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 340         |\n",
      "| n_updates               | 15734       |\n",
      "| policy_loss             | -165.23859  |\n",
      "| qf1_loss                | 21.91856    |\n",
      "| qf2_loss                | 23.270452   |\n",
      "| time_elapsed            | 186         |\n",
      "| total timesteps         | 15833       |\n",
      "| value_loss              | 18.093607   |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| current_lr              | 0.0003       |\n",
      "| ent_coef                | 0.03208289   |\n",
      "| ent_coef_loss           | -0.095465064 |\n",
      "| entropy                 | 14.8334055   |\n",
      "| episodes                | 310          |\n",
      "| fps                     | 84           |\n",
      "| mean 100 episode reward | 341          |\n",
      "| n_updates               | 16402        |\n",
      "| policy_loss             | -180.74248   |\n",
      "| qf1_loss                | 29.932617    |\n",
      "| qf2_loss                | 24.77969     |\n",
      "| time_elapsed            | 194          |\n",
      "| total timesteps         | 16501        |\n",
      "| value_loss              | 41.195457    |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030630251 |\n",
      "| ent_coef_loss           | 1.0768744   |\n",
      "| entropy                 | 14.952648   |\n",
      "| episodes                | 320         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 341         |\n",
      "| n_updates               | 17054       |\n",
      "| policy_loss             | -168.07895  |\n",
      "| qf1_loss                | 23.649698   |\n",
      "| qf2_loss                | 28.791582   |\n",
      "| time_elapsed            | 201         |\n",
      "| total timesteps         | 17153       |\n",
      "| value_loss              | 19.426285   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031135954 |\n",
      "| ent_coef_loss           | 6.947121    |\n",
      "| entropy                 | 14.584168   |\n",
      "| episodes                | 330         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 341         |\n",
      "| n_updates               | 17725       |\n",
      "| policy_loss             | -162.26657  |\n",
      "| qf1_loss                | 25.703625   |\n",
      "| qf2_loss                | 18.435188   |\n",
      "| time_elapsed            | 210         |\n",
      "| total timesteps         | 17824       |\n",
      "| value_loss              | 43.311386   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.032728408 |\n",
      "| ent_coef_loss           | 3.390902    |\n",
      "| entropy                 | 14.676775   |\n",
      "| episodes                | 340         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 346         |\n",
      "| n_updates               | 18478       |\n",
      "| policy_loss             | -157.97499  |\n",
      "| qf1_loss                | 13.732407   |\n",
      "| qf2_loss                | 12.021284   |\n",
      "| time_elapsed            | 218         |\n",
      "| total timesteps         | 18577       |\n",
      "| value_loss              | 15.629811   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.030682   |\n",
      "| ent_coef_loss           | -4.1557207 |\n",
      "| entropy                 | 14.7995205 |\n",
      "| episodes                | 350        |\n",
      "| fps                     | 84         |\n",
      "| mean 100 episode reward | 348        |\n",
      "| n_updates               | 19131      |\n",
      "| policy_loss             | -161.29086 |\n",
      "| qf1_loss                | 21.738556  |\n",
      "| qf2_loss                | 15.610068  |\n",
      "| time_elapsed            | 226        |\n",
      "| total timesteps         | 19230      |\n",
      "| value_loss              | 10.056982  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028289106 |\n",
      "| ent_coef_loss           | 2.2079372   |\n",
      "| entropy                 | 14.547414   |\n",
      "| episodes                | 360         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 341         |\n",
      "| n_updates               | 19727       |\n",
      "| policy_loss             | -151.51096  |\n",
      "| qf1_loss                | 25.241892   |\n",
      "| qf2_loss                | 34.342102   |\n",
      "| time_elapsed            | 233         |\n",
      "| total timesteps         | 19826       |\n",
      "| value_loss              | 16.510027   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.026911765 |\n",
      "| ent_coef_loss           | 6.4005184   |\n",
      "| entropy                 | 14.2589245  |\n",
      "| episodes                | 370         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 345         |\n",
      "| n_updates               | 20508       |\n",
      "| policy_loss             | -147.1713   |\n",
      "| qf1_loss                | 10.796417   |\n",
      "| qf2_loss                | 12.395942   |\n",
      "| time_elapsed            | 242         |\n",
      "| total timesteps         | 20607       |\n",
      "| value_loss              | 13.097912   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028452838 |\n",
      "| ent_coef_loss           | -6.3728113  |\n",
      "| entropy                 | 14.955286   |\n",
      "| episodes                | 380         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 344         |\n",
      "| n_updates               | 21141       |\n",
      "| policy_loss             | -151.08305  |\n",
      "| qf1_loss                | 17.232067   |\n",
      "| qf2_loss                | 13.577698   |\n",
      "| time_elapsed            | 250         |\n",
      "| total timesteps         | 21240       |\n",
      "| value_loss              | 13.358202   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.027033307 |\n",
      "| ent_coef_loss           | 2.5431812   |\n",
      "| entropy                 | 14.47817    |\n",
      "| episodes                | 390         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 343         |\n",
      "| n_updates               | 21750       |\n",
      "| policy_loss             | -141.7665   |\n",
      "| qf1_loss                | 16.410782   |\n",
      "| qf2_loss                | 12.473917   |\n",
      "| time_elapsed            | 258         |\n",
      "| total timesteps         | 21849       |\n",
      "| value_loss              | 17.088127   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.026362928 |\n",
      "| ent_coef_loss           | -9.37888    |\n",
      "| entropy                 | 14.606434   |\n",
      "| episodes                | 400         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 357         |\n",
      "| n_updates               | 22589       |\n",
      "| policy_loss             | -135.58908  |\n",
      "| qf1_loss                | 12.199048   |\n",
      "| qf2_loss                | 15.35365    |\n",
      "| time_elapsed            | 268         |\n",
      "| total timesteps         | 22688       |\n",
      "| value_loss              | 30.521551   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.026057212 |\n",
      "| ent_coef_loss           | -1.4226665  |\n",
      "| entropy                 | 14.728348   |\n",
      "| episodes                | 410         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 362         |\n",
      "| n_updates               | 23342       |\n",
      "| policy_loss             | -153.4196   |\n",
      "| qf1_loss                | 12.087395   |\n",
      "| qf2_loss                | 18.09408    |\n",
      "| time_elapsed            | 277         |\n",
      "| total timesteps         | 23441       |\n",
      "| value_loss              | 12.881041   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.025476098 |\n",
      "| ent_coef_loss           | -3.3333855  |\n",
      "| entropy                 | 14.255647   |\n",
      "| episodes                | 420         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 370         |\n",
      "| n_updates               | 24198       |\n",
      "| policy_loss             | -141.0019   |\n",
      "| qf1_loss                | 21.4388     |\n",
      "| qf2_loss                | 21.200886   |\n",
      "| time_elapsed            | 287         |\n",
      "| total timesteps         | 24297       |\n",
      "| value_loss              | 24.233612   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.025081282 |\n",
      "| ent_coef_loss           | -3.0086808  |\n",
      "| entropy                 | 14.46191    |\n",
      "| episodes                | 430         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 371         |\n",
      "| n_updates               | 24853       |\n",
      "| policy_loss             | -140.43692  |\n",
      "| qf1_loss                | 11.198189   |\n",
      "| qf2_loss                | 13.508974   |\n",
      "| time_elapsed            | 294         |\n",
      "| total timesteps         | 24952       |\n",
      "| value_loss              | 12.402882   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.024374893 |\n",
      "| ent_coef_loss           | -6.769656   |\n",
      "| entropy                 | 14.556588   |\n",
      "| episodes                | 440         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 372         |\n",
      "| n_updates               | 25604       |\n",
      "| policy_loss             | -140.41684  |\n",
      "| qf1_loss                | 23.783472   |\n",
      "| qf2_loss                | 16.667923   |\n",
      "| time_elapsed            | 303         |\n",
      "| total timesteps         | 25703       |\n",
      "| value_loss              | 23.284893   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.024839826 |\n",
      "| ent_coef_loss           | 3.8391738   |\n",
      "| entropy                 | 14.650056   |\n",
      "| episodes                | 450         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 379         |\n",
      "| n_updates               | 26403       |\n",
      "| policy_loss             | -134.3405   |\n",
      "| qf1_loss                | 22.014538   |\n",
      "| qf2_loss                | 16.878626   |\n",
      "| time_elapsed            | 313         |\n",
      "| total timesteps         | 26502       |\n",
      "| value_loss              | 22.393276   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.024432033 |\n",
      "| ent_coef_loss           | 1.7038181   |\n",
      "| entropy                 | 14.481007   |\n",
      "| episodes                | 460         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 389         |\n",
      "| n_updates               | 27185       |\n",
      "| policy_loss             | -158.15817  |\n",
      "| qf1_loss                | 15.582773   |\n",
      "| qf2_loss                | 11.567409   |\n",
      "| time_elapsed            | 322         |\n",
      "| total timesteps         | 27284       |\n",
      "| value_loss              | 15.232784   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.023771655 |\n",
      "| ent_coef_loss           | 2.91747     |\n",
      "| entropy                 | 14.334192   |\n",
      "| episodes                | 470         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 390         |\n",
      "| n_updates               | 27939       |\n",
      "| policy_loss             | -151.45811  |\n",
      "| qf1_loss                | 10.378284   |\n",
      "| qf2_loss                | 9.888224    |\n",
      "| time_elapsed            | 331         |\n",
      "| total timesteps         | 28038       |\n",
      "| value_loss              | 11.279968   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.023334123 |\n",
      "| ent_coef_loss           | 2.179316    |\n",
      "| entropy                 | 14.710414   |\n",
      "| episodes                | 480         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 394         |\n",
      "| n_updates               | 28641       |\n",
      "| policy_loss             | -137.30954  |\n",
      "| qf1_loss                | 13.260685   |\n",
      "| qf2_loss                | 14.4116955  |\n",
      "| time_elapsed            | 339         |\n",
      "| total timesteps         | 28740       |\n",
      "| value_loss              | 16.230568   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.023894476 |\n",
      "| ent_coef_loss           | -4.435982   |\n",
      "| entropy                 | 14.357632   |\n",
      "| episodes                | 490         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 395         |\n",
      "| n_updates               | 29286       |\n",
      "| policy_loss             | -146.38998  |\n",
      "| qf1_loss                | 11.066259   |\n",
      "| qf2_loss                | 11.56292    |\n",
      "| time_elapsed            | 347         |\n",
      "| total timesteps         | 29385       |\n",
      "| value_loss              | 11.300538   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.025803056 |\n",
      "| ent_coef_loss           | 4.7244945   |\n",
      "| entropy                 | 14.69162    |\n",
      "| episodes                | 500         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 384         |\n",
      "| n_updates               | 29888       |\n",
      "| policy_loss             | -143.97833  |\n",
      "| qf1_loss                | 9.59837     |\n",
      "| qf2_loss                | 7.6874447   |\n",
      "| time_elapsed            | 354         |\n",
      "| total timesteps         | 29987       |\n",
      "| value_loss              | 8.179801    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02484245 |\n",
      "| ent_coef_loss           | -1.20201   |\n",
      "| entropy                 | 14.643574  |\n",
      "| episodes                | 510        |\n",
      "| fps                     | 84         |\n",
      "| mean 100 episode reward | 375        |\n",
      "| n_updates               | 30478      |\n",
      "| policy_loss             | -142.85545 |\n",
      "| qf1_loss                | 7.3137197  |\n",
      "| qf2_loss                | 8.174442   |\n",
      "| time_elapsed            | 361        |\n",
      "| total timesteps         | 30577      |\n",
      "| value_loss              | 11.880911  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02360865 |\n",
      "| ent_coef_loss           | 2.156072   |\n",
      "| entropy                 | 14.48136   |\n",
      "| episodes                | 520        |\n",
      "| fps                     | 84         |\n",
      "| mean 100 episode reward | 365        |\n",
      "| n_updates               | 31089      |\n",
      "| policy_loss             | -132.22705 |\n",
      "| qf1_loss                | 10.271678  |\n",
      "| qf2_loss                | 10.556091  |\n",
      "| time_elapsed            | 368        |\n",
      "| total timesteps         | 31188      |\n",
      "| value_loss              | 11.804316  |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02345964 |\n",
      "| ent_coef_loss           | 8.760165   |\n",
      "| entropy                 | 14.863079  |\n",
      "| episodes                | 530        |\n",
      "| fps                     | 84         |\n",
      "| mean 100 episode reward | 367        |\n",
      "| n_updates               | 31817      |\n",
      "| policy_loss             | -160.20456 |\n",
      "| qf1_loss                | 10.708256  |\n",
      "| qf2_loss                | 12.858675  |\n",
      "| time_elapsed            | 377        |\n",
      "| total timesteps         | 31916      |\n",
      "| value_loss              | 9.410799   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.022857789 |\n",
      "| ent_coef_loss           | -0.46138573 |\n",
      "| entropy                 | 14.51716    |\n",
      "| episodes                | 540         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 365         |\n",
      "| n_updates               | 32546       |\n",
      "| policy_loss             | -140.9625   |\n",
      "| qf1_loss                | 17.35345    |\n",
      "| qf2_loss                | 16.978088   |\n",
      "| time_elapsed            | 385         |\n",
      "| total timesteps         | 32645       |\n",
      "| value_loss              | 23.724155   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.022296865 |\n",
      "| ent_coef_loss           | 3.4612005   |\n",
      "| entropy                 | 13.8328285  |\n",
      "| episodes                | 550         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 358         |\n",
      "| n_updates               | 33215       |\n",
      "| policy_loss             | -144.33084  |\n",
      "| qf1_loss                | 10.985901   |\n",
      "| qf2_loss                | 10.531967   |\n",
      "| time_elapsed            | 393         |\n",
      "| total timesteps         | 33314       |\n",
      "| value_loss              | 5.656151    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02353079 |\n",
      "| ent_coef_loss           | -3.2424304 |\n",
      "| entropy                 | 14.646822  |\n",
      "| episodes                | 560        |\n",
      "| fps                     | 84         |\n",
      "| mean 100 episode reward | 359        |\n",
      "| n_updates               | 34031      |\n",
      "| policy_loss             | -150.36542 |\n",
      "| qf1_loss                | 12.026604  |\n",
      "| qf2_loss                | 19.674736  |\n",
      "| time_elapsed            | 403        |\n",
      "| total timesteps         | 34130      |\n",
      "| value_loss              | 13.71878   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02338927 |\n",
      "| ent_coef_loss           | 7.486129   |\n",
      "| entropy                 | 14.844045  |\n",
      "| episodes                | 570        |\n",
      "| fps                     | 84         |\n",
      "| mean 100 episode reward | 360        |\n",
      "| n_updates               | 34819      |\n",
      "| policy_loss             | -145.51083 |\n",
      "| qf1_loss                | 8.494654   |\n",
      "| qf2_loss                | 11.125505  |\n",
      "| time_elapsed            | 412        |\n",
      "| total timesteps         | 34918      |\n",
      "| value_loss              | 12.154156  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.022511456 |\n",
      "| ent_coef_loss           | -6.5699987  |\n",
      "| entropy                 | 14.67705    |\n",
      "| episodes                | 580         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 368         |\n",
      "| n_updates               | 35666       |\n",
      "| policy_loss             | -132.69957  |\n",
      "| qf1_loss                | 7.843907    |\n",
      "| qf2_loss                | 9.17316     |\n",
      "| time_elapsed            | 422         |\n",
      "| total timesteps         | 35765       |\n",
      "| value_loss              | 7.6894207   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.022647573 |\n",
      "| ent_coef_loss           | 7.490626    |\n",
      "| entropy                 | 14.6204815  |\n",
      "| episodes                | 590         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 374         |\n",
      "| n_updates               | 36412       |\n",
      "| policy_loss             | -144.29868  |\n",
      "| qf1_loss                | 12.541809   |\n",
      "| qf2_loss                | 10.643619   |\n",
      "| time_elapsed            | 431         |\n",
      "| total timesteps         | 36511       |\n",
      "| value_loss              | 11.571001   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02282266 |\n",
      "| ent_coef_loss           | 10.702605  |\n",
      "| entropy                 | 14.731488  |\n",
      "| episodes                | 600        |\n",
      "| fps                     | 84         |\n",
      "| mean 100 episode reward | 379        |\n",
      "| n_updates               | 37112      |\n",
      "| policy_loss             | -159.10071 |\n",
      "| qf1_loss                | 10.443103  |\n",
      "| qf2_loss                | 14.121983  |\n",
      "| time_elapsed            | 439        |\n",
      "| total timesteps         | 37211      |\n",
      "| value_loss              | 12.441357  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02349482 |\n",
      "| ent_coef_loss           | -2.9316096 |\n",
      "| entropy                 | 14.803289  |\n",
      "| episodes                | 610        |\n",
      "| fps                     | 84         |\n",
      "| mean 100 episode reward | 382        |\n",
      "| n_updates               | 37764      |\n",
      "| policy_loss             | -145.04208 |\n",
      "| qf1_loss                | 8.61368    |\n",
      "| qf2_loss                | 7.6837797  |\n",
      "| time_elapsed            | 447        |\n",
      "| total timesteps         | 37863      |\n",
      "| value_loss              | 7.9445267  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.021718258 |\n",
      "| ent_coef_loss           | 10.10428    |\n",
      "| entropy                 | 14.138486   |\n",
      "| episodes                | 620         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 391         |\n",
      "| n_updates               | 38549       |\n",
      "| policy_loss             | -130.62341  |\n",
      "| qf1_loss                | 8.182379    |\n",
      "| qf2_loss                | 11.732786   |\n",
      "| time_elapsed            | 456         |\n",
      "| total timesteps         | 38648       |\n",
      "| value_loss              | 6.1676407   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.022029072 |\n",
      "| ent_coef_loss           | -3.0416088  |\n",
      "| entropy                 | 15.301498   |\n",
      "| episodes                | 630         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 398         |\n",
      "| n_updates               | 39387       |\n",
      "| policy_loss             | -142.19052  |\n",
      "| qf1_loss                | 8.336       |\n",
      "| qf2_loss                | 10.60507    |\n",
      "| time_elapsed            | 466         |\n",
      "| total timesteps         | 39486       |\n",
      "| value_loss              | 11.422369   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02108372 |\n",
      "| ent_coef_loss           | 2.343679   |\n",
      "| entropy                 | 14.73439   |\n",
      "| episodes                | 640        |\n",
      "| fps                     | 84         |\n",
      "| mean 100 episode reward | 406        |\n",
      "| n_updates               | 40244      |\n",
      "| policy_loss             | -151.48656 |\n",
      "| qf1_loss                | 7.950203   |\n",
      "| qf2_loss                | 6.763062   |\n",
      "| time_elapsed            | 476        |\n",
      "| total timesteps         | 40343      |\n",
      "| value_loss              | 8.29808    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.021089818 |\n",
      "| ent_coef_loss           | 6.626378    |\n",
      "| entropy                 | 13.822533   |\n",
      "| episodes                | 650         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 409         |\n",
      "| n_updates               | 40951       |\n",
      "| policy_loss             | -147.57472  |\n",
      "| qf1_loss                | 11.151835   |\n",
      "| qf2_loss                | 11.181138   |\n",
      "| time_elapsed            | 484         |\n",
      "| total timesteps         | 41050       |\n",
      "| value_loss              | 11.040905   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02111207 |\n",
      "| ent_coef_loss           | -3.9263606 |\n",
      "| entropy                 | 14.916639  |\n",
      "| episodes                | 660        |\n",
      "| fps                     | 84         |\n",
      "| mean 100 episode reward | 406        |\n",
      "| n_updates               | 41678      |\n",
      "| policy_loss             | -150.51184 |\n",
      "| qf1_loss                | 6.4043946  |\n",
      "| qf2_loss                | 8.534687   |\n",
      "| time_elapsed            | 493        |\n",
      "| total timesteps         | 41777      |\n",
      "| value_loss              | 5.54049    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.020920517 |\n",
      "| ent_coef_loss           | 6.5396233   |\n",
      "| entropy                 | 14.575903   |\n",
      "| episodes                | 670         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 402         |\n",
      "| n_updates               | 42379       |\n",
      "| policy_loss             | -139.5477   |\n",
      "| qf1_loss                | 9.526787    |\n",
      "| qf2_loss                | 9.901844    |\n",
      "| time_elapsed            | 501         |\n",
      "| total timesteps         | 42478       |\n",
      "| value_loss              | 6.900326    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.021471104 |\n",
      "| ent_coef_loss           | -5.0965166  |\n",
      "| entropy                 | 14.620501   |\n",
      "| episodes                | 680         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 398         |\n",
      "| n_updates               | 43156       |\n",
      "| policy_loss             | -128.18236  |\n",
      "| qf1_loss                | 12.367277   |\n",
      "| qf2_loss                | 12.123291   |\n",
      "| time_elapsed            | 510         |\n",
      "| total timesteps         | 43255       |\n",
      "| value_loss              | 16.25853    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.020990273 |\n",
      "| ent_coef_loss           | -7.5475397  |\n",
      "| entropy                 | 14.289497   |\n",
      "| episodes                | 690         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 396         |\n",
      "| n_updates               | 43881       |\n",
      "| policy_loss             | -148.11758  |\n",
      "| qf1_loss                | 10.557983   |\n",
      "| qf2_loss                | 8.748049    |\n",
      "| time_elapsed            | 519         |\n",
      "| total timesteps         | 43980       |\n",
      "| value_loss              | 8.38941     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.021351136 |\n",
      "| ent_coef_loss           | 3.0421622   |\n",
      "| entropy                 | 14.507201   |\n",
      "| episodes                | 700         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 404         |\n",
      "| n_updates               | 44719       |\n",
      "| policy_loss             | -145.95415  |\n",
      "| qf1_loss                | 6.7552137   |\n",
      "| qf2_loss                | 9.197535    |\n",
      "| time_elapsed            | 528         |\n",
      "| total timesteps         | 44818       |\n",
      "| value_loss              | 7.678665    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02042998 |\n",
      "| ent_coef_loss           | -3.766633  |\n",
      "| entropy                 | 14.946854  |\n",
      "| episodes                | 710        |\n",
      "| fps                     | 84         |\n",
      "| mean 100 episode reward | 408        |\n",
      "| n_updates               | 45443      |\n",
      "| policy_loss             | -133.09146 |\n",
      "| qf1_loss                | 7.8345213  |\n",
      "| qf2_loss                | 12.636549  |\n",
      "| time_elapsed            | 537        |\n",
      "| total timesteps         | 45542      |\n",
      "| value_loss              | 13.145618  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.020136172 |\n",
      "| ent_coef_loss           | -0.47509742 |\n",
      "| entropy                 | 14.486801   |\n",
      "| episodes                | 720         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 409         |\n",
      "| n_updates               | 46272       |\n",
      "| policy_loss             | -150.68243  |\n",
      "| qf1_loss                | 11.624931   |\n",
      "| qf2_loss                | 9.907316    |\n",
      "| time_elapsed            | 549         |\n",
      "| total timesteps         | 46371       |\n",
      "| value_loss              | 11.997977   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.019923778 |\n",
      "| ent_coef_loss           | -4.1080265  |\n",
      "| entropy                 | 15.171011   |\n",
      "| episodes                | 730         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 409         |\n",
      "| n_updates               | 47133       |\n",
      "| policy_loss             | -146.23218  |\n",
      "| qf1_loss                | 7.213092    |\n",
      "| qf2_loss                | 8.7460785   |\n",
      "| time_elapsed            | 559         |\n",
      "| total timesteps         | 47232       |\n",
      "| value_loss              | 7.111809    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.020990249 |\n",
      "| ent_coef_loss           | 5.5455523   |\n",
      "| entropy                 | 14.29958    |\n",
      "| episodes                | 740         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 412         |\n",
      "| n_updates               | 48069       |\n",
      "| policy_loss             | -134.2474   |\n",
      "| qf1_loss                | 8.928366    |\n",
      "| qf2_loss                | 7.5645275   |\n",
      "| time_elapsed            | 570         |\n",
      "| total timesteps         | 48168       |\n",
      "| value_loss              | 7.0399485   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.020371938 |\n",
      "| ent_coef_loss           | 2.5898635   |\n",
      "| entropy                 | 13.988668   |\n",
      "| episodes                | 750         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 416         |\n",
      "| n_updates               | 48872       |\n",
      "| policy_loss             | -153.96233  |\n",
      "| qf1_loss                | 11.34597    |\n",
      "| qf2_loss                | 11.370853   |\n",
      "| time_elapsed            | 580         |\n",
      "| total timesteps         | 48971       |\n",
      "| value_loss              | 13.663446   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02024594 |\n",
      "| ent_coef_loss           | -7.845292  |\n",
      "| entropy                 | 14.610966  |\n",
      "| episodes                | 760        |\n",
      "| fps                     | 84         |\n",
      "| mean 100 episode reward | 417        |\n",
      "| n_updates               | 49626      |\n",
      "| policy_loss             | -146.33258 |\n",
      "| qf1_loss                | 9.77622    |\n",
      "| qf2_loss                | 11.577167  |\n",
      "| time_elapsed            | 589        |\n",
      "| total timesteps         | 49725      |\n",
      "| value_loss              | 19.253288  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.021168187 |\n",
      "| ent_coef_loss           | -2.7607274  |\n",
      "| entropy                 | 14.221828   |\n",
      "| episodes                | 770         |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 425         |\n",
      "| n_updates               | 50503       |\n",
      "| policy_loss             | -144.69568  |\n",
      "| qf1_loss                | 8.706518    |\n",
      "| qf2_loss                | 9.625148    |\n",
      "| time_elapsed            | 599         |\n",
      "| total timesteps         | 50602       |\n",
      "| value_loss              | 7.2458353   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02068694 |\n",
      "| ent_coef_loss           | 3.2789805  |\n",
      "| entropy                 | 14.33873   |\n",
      "| episodes                | 780        |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 422        |\n",
      "| n_updates               | 51250      |\n",
      "| policy_loss             | -147.58362 |\n",
      "| qf1_loss                | 10.634875  |\n",
      "| qf2_loss                | 9.856796   |\n",
      "| time_elapsed            | 613        |\n",
      "| total timesteps         | 51349      |\n",
      "| value_loss              | 8.175265   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.0195836  |\n",
      "| ent_coef_loss           | 5.817676   |\n",
      "| entropy                 | 14.099024  |\n",
      "| episodes                | 790        |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 428        |\n",
      "| n_updates               | 52117      |\n",
      "| policy_loss             | -156.18253 |\n",
      "| qf1_loss                | 9.894957   |\n",
      "| qf2_loss                | 11.857658  |\n",
      "| time_elapsed            | 624        |\n",
      "| total timesteps         | 52216      |\n",
      "| value_loss              | 6.3636813  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.01969059 |\n",
      "| ent_coef_loss           | -0.7623328 |\n",
      "| entropy                 | 14.413048  |\n",
      "| episodes                | 800        |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 418        |\n",
      "| n_updates               | 52814      |\n",
      "| policy_loss             | -128.5365  |\n",
      "| qf1_loss                | 5.6439743  |\n",
      "| qf2_loss                | 7.3846064  |\n",
      "| time_elapsed            | 632        |\n",
      "| total timesteps         | 52913      |\n",
      "| value_loss              | 5.9773965  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.01940481 |\n",
      "| ent_coef_loss           | -6.948046  |\n",
      "| entropy                 | 14.701941  |\n",
      "| episodes                | 810        |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 423        |\n",
      "| n_updates               | 53621      |\n",
      "| policy_loss             | -135.06918 |\n",
      "| qf1_loss                | 6.8755455  |\n",
      "| qf2_loss                | 9.041778   |\n",
      "| time_elapsed            | 641        |\n",
      "| total timesteps         | 53720      |\n",
      "| value_loss              | 6.38319    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.019667571 |\n",
      "| ent_coef_loss           | 1.2676356   |\n",
      "| entropy                 | 14.418239   |\n",
      "| episodes                | 820         |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 424         |\n",
      "| n_updates               | 54452       |\n",
      "| policy_loss             | -131.51016  |\n",
      "| qf1_loss                | 5.437169    |\n",
      "| qf2_loss                | 3.8791142   |\n",
      "| time_elapsed            | 651         |\n",
      "| total timesteps         | 54551       |\n",
      "| value_loss              | 7.4240627   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.019244567 |\n",
      "| ent_coef_loss           | 3.6681342   |\n",
      "| entropy                 | 14.634224   |\n",
      "| episodes                | 830         |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 428         |\n",
      "| n_updates               | 55383       |\n",
      "| policy_loss             | -150.36809  |\n",
      "| qf1_loss                | 9.589024    |\n",
      "| qf2_loss                | 6.4272738   |\n",
      "| time_elapsed            | 662         |\n",
      "| total timesteps         | 55482       |\n",
      "| value_loss              | 5.736169    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.019319737 |\n",
      "| ent_coef_loss           | -2.7570066  |\n",
      "| entropy                 | 13.8168125  |\n",
      "| episodes                | 840         |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 432         |\n",
      "| n_updates               | 56376       |\n",
      "| policy_loss             | -134.4628   |\n",
      "| qf1_loss                | 7.9675865   |\n",
      "| qf2_loss                | 8.315899    |\n",
      "| time_elapsed            | 675         |\n",
      "| total timesteps         | 56475       |\n",
      "| value_loss              | 7.7707148   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.01959799 |\n",
      "| ent_coef_loss           | -0.4833989 |\n",
      "| entropy                 | 14.275812  |\n",
      "| episodes                | 850        |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 431        |\n",
      "| n_updates               | 57216      |\n",
      "| policy_loss             | -147.86713 |\n",
      "| qf1_loss                | 10.926787  |\n",
      "| qf2_loss                | 7.646709   |\n",
      "| time_elapsed            | 685        |\n",
      "| total timesteps         | 57315      |\n",
      "| value_loss              | 7.7136984  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.01864925 |\n",
      "| ent_coef_loss           | -1.3180374 |\n",
      "| entropy                 | 13.702561  |\n",
      "| episodes                | 860        |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 431        |\n",
      "| n_updates               | 58020      |\n",
      "| policy_loss             | -149.28983 |\n",
      "| qf1_loss                | 6.313385   |\n",
      "| qf2_loss                | 10.708382  |\n",
      "| time_elapsed            | 695        |\n",
      "| total timesteps         | 58119      |\n",
      "| value_loss              | 8.079536   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.01936209 |\n",
      "| ent_coef_loss           | -1.9242351 |\n",
      "| entropy                 | 13.978514  |\n",
      "| episodes                | 870        |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 427        |\n",
      "| n_updates               | 58890      |\n",
      "| policy_loss             | -150.79245 |\n",
      "| qf1_loss                | 11.900009  |\n",
      "| qf2_loss                | 7.8115363  |\n",
      "| time_elapsed            | 707        |\n",
      "| total timesteps         | 58989      |\n",
      "| value_loss              | 5.8150787  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.020040609 |\n",
      "| ent_coef_loss           | -0.72536254 |\n",
      "| entropy                 | 14.881411   |\n",
      "| episodes                | 880         |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 438         |\n",
      "| n_updates               | 59853       |\n",
      "| policy_loss             | -127.50573  |\n",
      "| qf1_loss                | 5.578719    |\n",
      "| qf2_loss                | 6.1859097   |\n",
      "| time_elapsed            | 719         |\n",
      "| total timesteps         | 59952       |\n",
      "| value_loss              | 4.207038    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.019639658 |\n",
      "| ent_coef_loss           | -0.54431033 |\n",
      "| entropy                 | 14.224201   |\n",
      "| episodes                | 890         |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 435         |\n",
      "| n_updates               | 60636       |\n",
      "| policy_loss             | -144.66882  |\n",
      "| qf1_loss                | 13.039801   |\n",
      "| qf2_loss                | 8.913351    |\n",
      "| time_elapsed            | 730         |\n",
      "| total timesteps         | 60735       |\n",
      "| value_loss              | 6.100926    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.020635817 |\n",
      "| ent_coef_loss           | -5.002112   |\n",
      "| entropy                 | 14.36463    |\n",
      "| episodes                | 900         |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 447         |\n",
      "| n_updates               | 61570       |\n",
      "| policy_loss             | -162.51163  |\n",
      "| qf1_loss                | 6.796918    |\n",
      "| qf2_loss                | 7.3936095   |\n",
      "| time_elapsed            | 741         |\n",
      "| total timesteps         | 61669       |\n",
      "| value_loss              | 7.6544237   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.020377675 |\n",
      "| ent_coef_loss           | 3.161664    |\n",
      "| entropy                 | 14.710535   |\n",
      "| episodes                | 910         |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 454         |\n",
      "| n_updates               | 62564       |\n",
      "| policy_loss             | -151.06088  |\n",
      "| qf1_loss                | 6.883707    |\n",
      "| qf2_loss                | 8.568787    |\n",
      "| time_elapsed            | 753         |\n",
      "| total timesteps         | 62663       |\n",
      "| value_loss              | 9.175472    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.020037962 |\n",
      "| ent_coef_loss           | 6.1514173   |\n",
      "| entropy                 | 14.525033   |\n",
      "| episodes                | 920         |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 459         |\n",
      "| n_updates               | 63531       |\n",
      "| policy_loss             | -131.87897  |\n",
      "| qf1_loss                | 9.435118    |\n",
      "| qf2_loss                | 9.309918    |\n",
      "| time_elapsed            | 765         |\n",
      "| total timesteps         | 63630       |\n",
      "| value_loss              | 8.996816    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.019466816 |\n",
      "| ent_coef_loss           | 1.3782105   |\n",
      "| entropy                 | 14.206264   |\n",
      "| episodes                | 930         |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 456         |\n",
      "| n_updates               | 64450       |\n",
      "| policy_loss             | -139.76022  |\n",
      "| qf1_loss                | 9.988564    |\n",
      "| qf2_loss                | 8.125635    |\n",
      "| time_elapsed            | 777         |\n",
      "| total timesteps         | 64549       |\n",
      "| value_loss              | 7.5016785   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.019914428 |\n",
      "| ent_coef_loss           | 4.0951333   |\n",
      "| entropy                 | 13.956382   |\n",
      "| episodes                | 940         |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 456         |\n",
      "| n_updates               | 65516       |\n",
      "| policy_loss             | -168.15712  |\n",
      "| qf1_loss                | 12.784153   |\n",
      "| qf2_loss                | 13.348814   |\n",
      "| time_elapsed            | 791         |\n",
      "| total timesteps         | 65615       |\n",
      "| value_loss              | 8.36985     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.0202206  |\n",
      "| ent_coef_loss           | -4.384291  |\n",
      "| entropy                 | 14.392784  |\n",
      "| episodes                | 950        |\n",
      "| fps                     | 82         |\n",
      "| mean 100 episode reward | 452        |\n",
      "| n_updates               | 66331      |\n",
      "| policy_loss             | -141.09529 |\n",
      "| qf1_loss                | 9.096476   |\n",
      "| qf2_loss                | 9.376747   |\n",
      "| time_elapsed            | 802        |\n",
      "| total timesteps         | 66430      |\n",
      "| value_loss              | 5.338047   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.020388065 |\n",
      "| ent_coef_loss           | 12.876976   |\n",
      "| entropy                 | 14.192883   |\n",
      "| episodes                | 960         |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 459         |\n",
      "| n_updates               | 67297       |\n",
      "| policy_loss             | -143.29541  |\n",
      "| qf1_loss                | 9.485785    |\n",
      "| qf2_loss                | 7.6415634   |\n",
      "| time_elapsed            | 818         |\n",
      "| total timesteps         | 67396       |\n",
      "| value_loss              | 8.975731    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.020299915 |\n",
      "| ent_coef_loss           | 5.1260843   |\n",
      "| entropy                 | 14.311816   |\n",
      "| episodes                | 970         |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 460         |\n",
      "| n_updates               | 68146       |\n",
      "| policy_loss             | -161.39026  |\n",
      "| qf1_loss                | 9.248813    |\n",
      "| qf2_loss                | 10.127536   |\n",
      "| time_elapsed            | 828         |\n",
      "| total timesteps         | 68245       |\n",
      "| value_loss              | 6.772669    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.020285875 |\n",
      "| ent_coef_loss           | -2.2738657  |\n",
      "| entropy                 | 14.393362   |\n",
      "| episodes                | 980         |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 446         |\n",
      "| n_updates               | 68880       |\n",
      "| policy_loss             | -153.5069   |\n",
      "| qf1_loss                | 8.241764    |\n",
      "| qf2_loss                | 6.2833076   |\n",
      "| time_elapsed            | 837         |\n",
      "| total timesteps         | 68979       |\n",
      "| value_loss              | 6.5904493   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.019445283 |\n",
      "| ent_coef_loss           | -4.3819833  |\n",
      "| entropy                 | 14.282099   |\n",
      "| episodes                | 990         |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 445         |\n",
      "| n_updates               | 69723       |\n",
      "| policy_loss             | -165.75389  |\n",
      "| qf1_loss                | 10.440579   |\n",
      "| qf2_loss                | 8.6284685   |\n",
      "| time_elapsed            | 848         |\n",
      "| total timesteps         | 69822       |\n",
      "| value_loss              | 8.234003    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02016911 |\n",
      "| ent_coef_loss           | 1.444995   |\n",
      "| entropy                 | 14.641018  |\n",
      "| episodes                | 1000       |\n",
      "| fps                     | 82         |\n",
      "| mean 100 episode reward | 438        |\n",
      "| n_updates               | 70580      |\n",
      "| policy_loss             | -148.04758 |\n",
      "| qf1_loss                | 12.723666  |\n",
      "| qf2_loss                | 12.598084  |\n",
      "| time_elapsed            | 858        |\n",
      "| total timesteps         | 70679      |\n",
      "| value_loss              | 8.256583   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.019472698 |\n",
      "| ent_coef_loss           | -2.01864    |\n",
      "| entropy                 | 13.407592   |\n",
      "| episodes                | 1010        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 434         |\n",
      "| n_updates               | 71495       |\n",
      "| policy_loss             | -167.04565  |\n",
      "| qf1_loss                | 9.173526    |\n",
      "| qf2_loss                | 13.142884   |\n",
      "| time_elapsed            | 872         |\n",
      "| total timesteps         | 71594       |\n",
      "| value_loss              | 7.7036223   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.018894201 |\n",
      "| ent_coef_loss           | -6.400751   |\n",
      "| entropy                 | 13.799065   |\n",
      "| episodes                | 1020        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 427         |\n",
      "| n_updates               | 72349       |\n",
      "| policy_loss             | -179.30724  |\n",
      "| qf1_loss                | 11.114944   |\n",
      "| qf2_loss                | 10.904814   |\n",
      "| time_elapsed            | 886         |\n",
      "| total timesteps         | 72448       |\n",
      "| value_loss              | 9.4454975   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.019780466 |\n",
      "| ent_coef_loss           | -2.4265208  |\n",
      "| entropy                 | 13.929414   |\n",
      "| episodes                | 1030        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 425         |\n",
      "| n_updates               | 73233       |\n",
      "| policy_loss             | -157.38013  |\n",
      "| qf1_loss                | 14.341403   |\n",
      "| qf2_loss                | 11.321016   |\n",
      "| time_elapsed            | 899         |\n",
      "| total timesteps         | 73332       |\n",
      "| value_loss              | 6.7636046   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.019091163 |\n",
      "| ent_coef_loss           | 0.008064806 |\n",
      "| entropy                 | 14.268941   |\n",
      "| episodes                | 1040        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 417         |\n",
      "| n_updates               | 74093       |\n",
      "| policy_loss             | -166.13297  |\n",
      "| qf1_loss                | 7.3835287   |\n",
      "| qf2_loss                | 10.656995   |\n",
      "| time_elapsed            | 909         |\n",
      "| total timesteps         | 74192       |\n",
      "| value_loss              | 9.70038     |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.020101517 |\n",
      "| ent_coef_loss           | 3.1416376   |\n",
      "| entropy                 | 13.722512   |\n",
      "| episodes                | 1050        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 418         |\n",
      "| n_updates               | 74837       |\n",
      "| policy_loss             | -160.04816  |\n",
      "| qf1_loss                | 9.237646    |\n",
      "| qf2_loss                | 11.386145   |\n",
      "| time_elapsed            | 918         |\n",
      "| total timesteps         | 74936       |\n",
      "| value_loss              | 15.129594   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.020263908 |\n",
      "| ent_coef_loss           | 2.2702003   |\n",
      "| entropy                 | 13.851796   |\n",
      "| episodes                | 1060        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 419         |\n",
      "| n_updates               | 75808       |\n",
      "| policy_loss             | -153.09561  |\n",
      "| qf1_loss                | 9.10459     |\n",
      "| qf2_loss                | 9.326268    |\n",
      "| time_elapsed            | 930         |\n",
      "| total timesteps         | 75907       |\n",
      "| value_loss              | 8.952335    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.018977465 |\n",
      "| ent_coef_loss           | 4.540391    |\n",
      "| entropy                 | 13.738131   |\n",
      "| episodes                | 1070        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 422         |\n",
      "| n_updates               | 76702       |\n",
      "| policy_loss             | -160.51144  |\n",
      "| qf1_loss                | 6.2301426   |\n",
      "| qf2_loss                | 7.630122    |\n",
      "| time_elapsed            | 941         |\n",
      "| total timesteps         | 76801       |\n",
      "| value_loss              | 10.058994   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.018455049 |\n",
      "| ent_coef_loss           | 6.452741    |\n",
      "| entropy                 | 13.884153   |\n",
      "| episodes                | 1080        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 432         |\n",
      "| n_updates               | 77659       |\n",
      "| policy_loss             | -159.085    |\n",
      "| qf1_loss                | 9.090539    |\n",
      "| qf2_loss                | 11.675827   |\n",
      "| time_elapsed            | 953         |\n",
      "| total timesteps         | 77758       |\n",
      "| value_loss              | 12.978197   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.018242136 |\n",
      "| ent_coef_loss           | 4.324501    |\n",
      "| entropy                 | 13.685806   |\n",
      "| episodes                | 1090        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 442         |\n",
      "| n_updates               | 78660       |\n",
      "| policy_loss             | -145.54086  |\n",
      "| qf1_loss                | 11.954312   |\n",
      "| qf2_loss                | 9.516485    |\n",
      "| time_elapsed            | 965         |\n",
      "| total timesteps         | 78759       |\n",
      "| value_loss              | 10.9593525  |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.01865858 |\n",
      "| ent_coef_loss           | 8.101477   |\n",
      "| entropy                 | 13.803178  |\n",
      "| episodes                | 1100       |\n",
      "| fps                     | 81         |\n",
      "| mean 100 episode reward | 443        |\n",
      "| n_updates               | 79525      |\n",
      "| policy_loss             | -164.1921  |\n",
      "| qf1_loss                | 8.184504   |\n",
      "| qf2_loss                | 11.98036   |\n",
      "| time_elapsed            | 975        |\n",
      "| total timesteps         | 79624      |\n",
      "| value_loss              | 8.147497   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.018406838 |\n",
      "| ent_coef_loss           | -1.6056132  |\n",
      "| entropy                 | 14.273842   |\n",
      "| episodes                | 1110        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 443         |\n",
      "| n_updates               | 80428       |\n",
      "| policy_loss             | -162.25537  |\n",
      "| qf1_loss                | 7.3219795   |\n",
      "| qf2_loss                | 10.565304   |\n",
      "| time_elapsed            | 986         |\n",
      "| total timesteps         | 80527       |\n",
      "| value_loss              | 8.677317    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.018792924 |\n",
      "| ent_coef_loss           | -3.3364909  |\n",
      "| entropy                 | 13.586833   |\n",
      "| episodes                | 1120        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 454         |\n",
      "| n_updates               | 81541       |\n",
      "| policy_loss             | -154.0402   |\n",
      "| qf1_loss                | 12.788303   |\n",
      "| qf2_loss                | 7.0246325   |\n",
      "| time_elapsed            | 999         |\n",
      "| total timesteps         | 81640       |\n",
      "| value_loss              | 7.036372    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.019043848 |\n",
      "| ent_coef_loss           | 1.9503099   |\n",
      "| entropy                 | 14.307323   |\n",
      "| episodes                | 1130        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 455         |\n",
      "| n_updates               | 82478       |\n",
      "| policy_loss             | -154.3505   |\n",
      "| qf1_loss                | 9.928292    |\n",
      "| qf2_loss                | 14.025568   |\n",
      "| time_elapsed            | 1011        |\n",
      "| total timesteps         | 82577       |\n",
      "| value_loss              | 9.283243    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.019090977 |\n",
      "| ent_coef_loss           | -6.5883245  |\n",
      "| entropy                 | 14.030952   |\n",
      "| episodes                | 1140        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 449         |\n",
      "| n_updates               | 83245       |\n",
      "| policy_loss             | -156.98761  |\n",
      "| qf1_loss                | 6.3727865   |\n",
      "| qf2_loss                | 6.1309414   |\n",
      "| time_elapsed            | 1021        |\n",
      "| total timesteps         | 83344       |\n",
      "| value_loss              | 6.90069     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.018610328 |\n",
      "| ent_coef_loss           | -2.807592   |\n",
      "| entropy                 | 13.173039   |\n",
      "| episodes                | 1150        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 458         |\n",
      "| n_updates               | 84180       |\n",
      "| policy_loss             | -161.91728  |\n",
      "| qf1_loss                | 15.912395   |\n",
      "| qf2_loss                | 17.83324    |\n",
      "| time_elapsed            | 1033        |\n",
      "| total timesteps         | 84279       |\n",
      "| value_loss              | 11.182377   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.01980263 |\n",
      "| ent_coef_loss           | -4.456785  |\n",
      "| entropy                 | 14.431728  |\n",
      "| episodes                | 1160       |\n",
      "| fps                     | 81         |\n",
      "| mean 100 episode reward | 458        |\n",
      "| n_updates               | 85163      |\n",
      "| policy_loss             | -166.54892 |\n",
      "| qf1_loss                | 7.936171   |\n",
      "| qf2_loss                | 5.5473614  |\n",
      "| time_elapsed            | 1045       |\n",
      "| total timesteps         | 85262      |\n",
      "| value_loss              | 5.2485094  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.01890951 |\n",
      "| ent_coef_loss           | 1.2494016  |\n",
      "| entropy                 | 14.407334  |\n",
      "| episodes                | 1170       |\n",
      "| fps                     | 81         |\n",
      "| mean 100 episode reward | 461        |\n",
      "| n_updates               | 86097      |\n",
      "| policy_loss             | -159.3458  |\n",
      "| qf1_loss                | 9.695527   |\n",
      "| qf2_loss                | 8.851833   |\n",
      "| time_elapsed            | 1055       |\n",
      "| total timesteps         | 86196      |\n",
      "| value_loss              | 10.109938  |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.018651247 |\n",
      "| ent_coef_loss           | -4.556013   |\n",
      "| entropy                 | 14.131436   |\n",
      "| episodes                | 1180        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 475         |\n",
      "| n_updates               | 87279       |\n",
      "| policy_loss             | -157.82835  |\n",
      "| qf1_loss                | 12.037783   |\n",
      "| qf2_loss                | 9.379263    |\n",
      "| time_elapsed            | 1070        |\n",
      "| total timesteps         | 87378       |\n",
      "| value_loss              | 13.330234   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.01911511 |\n",
      "| ent_coef_loss           | -3.373487  |\n",
      "| entropy                 | 14.054893  |\n",
      "| episodes                | 1190       |\n",
      "| fps                     | 81         |\n",
      "| mean 100 episode reward | 469        |\n",
      "| n_updates               | 88131      |\n",
      "| policy_loss             | -144.96109 |\n",
      "| qf1_loss                | 8.279404   |\n",
      "| qf2_loss                | 9.92012    |\n",
      "| time_elapsed            | 1080       |\n",
      "| total timesteps         | 88230      |\n",
      "| value_loss              | 6.062558   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.019172447 |\n",
      "| ent_coef_loss           | 4.384152    |\n",
      "| entropy                 | 13.66209    |\n",
      "| episodes                | 1200        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 481         |\n",
      "| n_updates               | 89177       |\n",
      "| policy_loss             | -162.46893  |\n",
      "| qf1_loss                | 9.77994     |\n",
      "| qf2_loss                | 10.659842   |\n",
      "| time_elapsed            | 1092        |\n",
      "| total timesteps         | 89276       |\n",
      "| value_loss              | 6.946389    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.020010358 |\n",
      "| ent_coef_loss           | 1.6483922   |\n",
      "| entropy                 | 14.147065   |\n",
      "| episodes                | 1210        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 482         |\n",
      "| n_updates               | 90037       |\n",
      "| policy_loss             | -156.99489  |\n",
      "| qf1_loss                | 7.8851786   |\n",
      "| qf2_loss                | 7.605009    |\n",
      "| time_elapsed            | 1104        |\n",
      "| total timesteps         | 90136       |\n",
      "| value_loss              | 7.524032    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.019453032 |\n",
      "| ent_coef_loss           | 5.278385    |\n",
      "| entropy                 | 14.510665   |\n",
      "| episodes                | 1220        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 472         |\n",
      "| n_updates               | 90916       |\n",
      "| policy_loss             | -158.39407  |\n",
      "| qf1_loss                | 13.216995   |\n",
      "| qf2_loss                | 13.602888   |\n",
      "| time_elapsed            | 1116        |\n",
      "| total timesteps         | 91015       |\n",
      "| value_loss              | 6.732079    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.019953495 |\n",
      "| ent_coef_loss           | -1.8175408  |\n",
      "| entropy                 | 14.006584   |\n",
      "| episodes                | 1230        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 471         |\n",
      "| n_updates               | 91747       |\n",
      "| policy_loss             | -172.63396  |\n",
      "| qf1_loss                | 10.364583   |\n",
      "| qf2_loss                | 12.697238   |\n",
      "| time_elapsed            | 1126        |\n",
      "| total timesteps         | 91846       |\n",
      "| value_loss              | 7.7601004   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.019471463 |\n",
      "| ent_coef_loss           | 1.4123157   |\n",
      "| entropy                 | 13.718323   |\n",
      "| episodes                | 1240        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 480         |\n",
      "| n_updates               | 92623       |\n",
      "| policy_loss             | -170.48969  |\n",
      "| qf1_loss                | 9.74843     |\n",
      "| qf2_loss                | 7.178283    |\n",
      "| time_elapsed            | 1137        |\n",
      "| total timesteps         | 92722       |\n",
      "| value_loss              | 7.271837    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.019693965 |\n",
      "| ent_coef_loss           | -10.654989  |\n",
      "| entropy                 | 14.38703    |\n",
      "| episodes                | 1250        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 479         |\n",
      "| n_updates               | 93530       |\n",
      "| policy_loss             | -164.14626  |\n",
      "| qf1_loss                | 9.2001095   |\n",
      "| qf2_loss                | 6.8070436   |\n",
      "| time_elapsed            | 1148        |\n",
      "| total timesteps         | 93629       |\n",
      "| value_loss              | 6.5813837   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.019699328 |\n",
      "| ent_coef_loss           | -5.944031   |\n",
      "| entropy                 | 14.178559   |\n",
      "| episodes                | 1260        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 483         |\n",
      "| n_updates               | 94565       |\n",
      "| policy_loss             | -140.3081   |\n",
      "| qf1_loss                | 14.122512   |\n",
      "| qf2_loss                | 11.304325   |\n",
      "| time_elapsed            | 1161        |\n",
      "| total timesteps         | 94664       |\n",
      "| value_loss              | 6.122779    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.019902306 |\n",
      "| ent_coef_loss           | -0.704185   |\n",
      "| entropy                 | 14.375464   |\n",
      "| episodes                | 1270        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 483         |\n",
      "| n_updates               | 95481       |\n",
      "| policy_loss             | -144.07695  |\n",
      "| qf1_loss                | 8.776283    |\n",
      "| qf2_loss                | 8.511045    |\n",
      "| time_elapsed            | 1172        |\n",
      "| total timesteps         | 95580       |\n",
      "| value_loss              | 8.73132     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.019537207 |\n",
      "| ent_coef_loss           | -6.723821   |\n",
      "| entropy                 | 13.827469   |\n",
      "| episodes                | 1280        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 473         |\n",
      "| n_updates               | 96483       |\n",
      "| policy_loss             | -164.87112  |\n",
      "| qf1_loss                | 9.838817    |\n",
      "| qf2_loss                | 7.9658713   |\n",
      "| time_elapsed            | 1184        |\n",
      "| total timesteps         | 96582       |\n",
      "| value_loss              | 6.9604244   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02011356 |\n",
      "| ent_coef_loss           | 1.8521492  |\n",
      "| entropy                 | 14.5467205 |\n",
      "| episodes                | 1290       |\n",
      "| fps                     | 81         |\n",
      "| mean 100 episode reward | 470        |\n",
      "| n_updates               | 97279      |\n",
      "| policy_loss             | -162.0352  |\n",
      "| qf1_loss                | 8.517492   |\n",
      "| qf2_loss                | 7.8249917  |\n",
      "| time_elapsed            | 1193       |\n",
      "| total timesteps         | 97378      |\n",
      "| value_loss              | 7.3590755  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.019644829 |\n",
      "| ent_coef_loss           | 7.8747606   |\n",
      "| entropy                 | 14.077526   |\n",
      "| episodes                | 1300        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 462         |\n",
      "| n_updates               | 98140       |\n",
      "| policy_loss             | -144.51184  |\n",
      "| qf1_loss                | 8.866682    |\n",
      "| qf2_loss                | 10.491572   |\n",
      "| time_elapsed            | 1203        |\n",
      "| total timesteps         | 98239       |\n",
      "| value_loss              | 7.3805676   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.01961873 |\n",
      "| ent_coef_loss           | -1.9158077 |\n",
      "| entropy                 | 14.016521  |\n",
      "| episodes                | 1310       |\n",
      "| fps                     | 81         |\n",
      "| mean 100 episode reward | 469        |\n",
      "| n_updates               | 99210      |\n",
      "| policy_loss             | -165.45087 |\n",
      "| qf1_loss                | 8.1846285  |\n",
      "| qf2_loss                | 10.68044   |\n",
      "| time_elapsed            | 1216       |\n",
      "| total timesteps         | 99309      |\n",
      "| value_loss              | 6.167562   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.019552207 |\n",
      "| ent_coef_loss           | 7.219985    |\n",
      "| entropy                 | 14.475283   |\n",
      "| episodes                | 1320        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 480         |\n",
      "| n_updates               | 100298      |\n",
      "| policy_loss             | -162.76318  |\n",
      "| qf1_loss                | 11.94825    |\n",
      "| qf2_loss                | 11.7158985  |\n",
      "| time_elapsed            | 1229        |\n",
      "| total timesteps         | 100397      |\n",
      "| value_loss              | 11.764445   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.020506954 |\n",
      "| ent_coef_loss           | -9.659663   |\n",
      "| entropy                 | 14.105703   |\n",
      "| episodes                | 1330        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 499         |\n",
      "| n_updates               | 101572      |\n",
      "| policy_loss             | -160.88803  |\n",
      "| qf1_loss                | 11.687912   |\n",
      "| qf2_loss                | 7.802469    |\n",
      "| time_elapsed            | 1245        |\n",
      "| total timesteps         | 101671      |\n",
      "| value_loss              | 12.098127   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.01987485 |\n",
      "| ent_coef_loss           | 3.173627   |\n",
      "| entropy                 | 13.777264  |\n",
      "| episodes                | 1340       |\n",
      "| fps                     | 81         |\n",
      "| mean 100 episode reward | 502        |\n",
      "| n_updates               | 102580     |\n",
      "| policy_loss             | -165.7189  |\n",
      "| qf1_loss                | 11.963858  |\n",
      "| qf2_loss                | 7.3717537  |\n",
      "| time_elapsed            | 1259       |\n",
      "| total timesteps         | 102679     |\n",
      "| value_loss              | 9.684525   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.01969659 |\n",
      "| ent_coef_loss           | 0.5246248  |\n",
      "| entropy                 | 13.939337  |\n",
      "| episodes                | 1350       |\n",
      "| fps                     | 81         |\n",
      "| mean 100 episode reward | 507        |\n",
      "| n_updates               | 103618     |\n",
      "| policy_loss             | -155.5649  |\n",
      "| qf1_loss                | 9.57124    |\n",
      "| qf2_loss                | 12.114518  |\n",
      "| time_elapsed            | 1272       |\n",
      "| total timesteps         | 103717     |\n",
      "| value_loss              | 7.606074   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.01870827 |\n",
      "| ent_coef_loss           | 3.6053355  |\n",
      "| entropy                 | 13.982212  |\n",
      "| episodes                | 1360       |\n",
      "| fps                     | 81         |\n",
      "| mean 100 episode reward | 497        |\n",
      "| n_updates               | 104492     |\n",
      "| policy_loss             | -158.57    |\n",
      "| qf1_loss                | 10.718254  |\n",
      "| qf2_loss                | 10.809731  |\n",
      "| time_elapsed            | 1282       |\n",
      "| total timesteps         | 104591     |\n",
      "| value_loss              | 9.651854   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02076003 |\n",
      "| ent_coef_loss           | -4.501604  |\n",
      "| entropy                 | 14.171442  |\n",
      "| episodes                | 1370       |\n",
      "| fps                     | 81         |\n",
      "| mean 100 episode reward | 507        |\n",
      "| n_updates               | 105641     |\n",
      "| policy_loss             | -173.64966 |\n",
      "| qf1_loss                | 8.845429   |\n",
      "| qf2_loss                | 7.696664   |\n",
      "| time_elapsed            | 1295       |\n",
      "| total timesteps         | 105740     |\n",
      "| value_loss              | 6.283388   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02079948 |\n",
      "| ent_coef_loss           | -2.944419  |\n",
      "| entropy                 | 14.537357  |\n",
      "| episodes                | 1380       |\n",
      "| fps                     | 81         |\n",
      "| mean 100 episode reward | 508        |\n",
      "| n_updates               | 106701     |\n",
      "| policy_loss             | -154.24298 |\n",
      "| qf1_loss                | 12.86026   |\n",
      "| qf2_loss                | 12.183821  |\n",
      "| time_elapsed            | 1308       |\n",
      "| total timesteps         | 106800     |\n",
      "| value_loss              | 9.595011   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.020735068 |\n",
      "| ent_coef_loss           | 2.402624    |\n",
      "| entropy                 | 14.087012   |\n",
      "| episodes                | 1390        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 520         |\n",
      "| n_updates               | 107755      |\n",
      "| policy_loss             | -175.94824  |\n",
      "| qf1_loss                | 7.435195    |\n",
      "| qf2_loss                | 8.804233    |\n",
      "| time_elapsed            | 1320        |\n",
      "| total timesteps         | 107854      |\n",
      "| value_loss              | 4.893235    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02007394 |\n",
      "| ent_coef_loss           | -10.373407 |\n",
      "| entropy                 | 14.063377  |\n",
      "| episodes                | 1400       |\n",
      "| fps                     | 81         |\n",
      "| mean 100 episode reward | 533        |\n",
      "| n_updates               | 108875     |\n",
      "| policy_loss             | -161.54291 |\n",
      "| qf1_loss                | 9.472658   |\n",
      "| qf2_loss                | 10.721687  |\n",
      "| time_elapsed            | 1333       |\n",
      "| total timesteps         | 108974     |\n",
      "| value_loss              | 5.594591   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.02101689  |\n",
      "| ent_coef_loss           | 0.017517567 |\n",
      "| entropy                 | 14.585074   |\n",
      "| episodes                | 1410        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 533         |\n",
      "| n_updates               | 109906      |\n",
      "| policy_loss             | -156.76189  |\n",
      "| qf1_loss                | 15.009857   |\n",
      "| qf2_loss                | 15.162796   |\n",
      "| time_elapsed            | 1345        |\n",
      "| total timesteps         | 110005      |\n",
      "| value_loss              | 7.889426    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.0202999  |\n",
      "| ent_coef_loss           | -11.755862 |\n",
      "| entropy                 | 14.591982  |\n",
      "| episodes                | 1420       |\n",
      "| fps                     | 81         |\n",
      "| mean 100 episode reward | 527        |\n",
      "| n_updates               | 110874     |\n",
      "| policy_loss             | -160.04779 |\n",
      "| qf1_loss                | 9.515841   |\n",
      "| qf2_loss                | 11.012466  |\n",
      "| time_elapsed            | 1356       |\n",
      "| total timesteps         | 110973     |\n",
      "| value_loss              | 3.2405062  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02055168 |\n",
      "| ent_coef_loss           | -1.6632085 |\n",
      "| entropy                 | 13.859793  |\n",
      "| episodes                | 1430       |\n",
      "| fps                     | 81         |\n",
      "| mean 100 episode reward | 505        |\n",
      "| n_updates               | 111680     |\n",
      "| policy_loss             | -177.22444 |\n",
      "| qf1_loss                | 9.308351   |\n",
      "| qf2_loss                | 6.9932156  |\n",
      "| time_elapsed            | 1365       |\n",
      "| total timesteps         | 111779     |\n",
      "| value_loss              | 8.571508   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.020172188 |\n",
      "| ent_coef_loss           | -4.1439753  |\n",
      "| entropy                 | 14.109295   |\n",
      "| episodes                | 1440        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 511         |\n",
      "| n_updates               | 112782      |\n",
      "| policy_loss             | -167.24106  |\n",
      "| qf1_loss                | 9.847499    |\n",
      "| qf2_loss                | 8.819744    |\n",
      "| time_elapsed            | 1378        |\n",
      "| total timesteps         | 112881      |\n",
      "| value_loss              | 8.573309    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.020059645 |\n",
      "| ent_coef_loss           | 3.5800712   |\n",
      "| entropy                 | 14.011251   |\n",
      "| episodes                | 1450        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 515         |\n",
      "| n_updates               | 113908      |\n",
      "| policy_loss             | -155.04901  |\n",
      "| qf1_loss                | 11.946683   |\n",
      "| qf2_loss                | 13.213059   |\n",
      "| time_elapsed            | 1391        |\n",
      "| total timesteps         | 114007      |\n",
      "| value_loss              | 6.5918455   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.020872878 |\n",
      "| ent_coef_loss           | -2.6218219  |\n",
      "| entropy                 | 14.143831   |\n",
      "| episodes                | 1460        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 522         |\n",
      "| n_updates               | 114907      |\n",
      "| policy_loss             | -171.95856  |\n",
      "| qf1_loss                | 12.127285   |\n",
      "| qf2_loss                | 14.567734   |\n",
      "| time_elapsed            | 1402        |\n",
      "| total timesteps         | 115006      |\n",
      "| value_loss              | 11.234425   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.021203084 |\n",
      "| ent_coef_loss           | 4.3149724   |\n",
      "| entropy                 | 14.075466   |\n",
      "| episodes                | 1470        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 528         |\n",
      "| n_updates               | 116139      |\n",
      "| policy_loss             | -178.54718  |\n",
      "| qf1_loss                | 7.206277    |\n",
      "| qf2_loss                | 6.147005    |\n",
      "| time_elapsed            | 1416        |\n",
      "| total timesteps         | 116238      |\n",
      "| value_loss              | 6.6868916   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.021946501 |\n",
      "| ent_coef_loss           | 5.9899445   |\n",
      "| entropy                 | 13.949565   |\n",
      "| episodes                | 1480        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 523         |\n",
      "| n_updates               | 117014      |\n",
      "| policy_loss             | -181.16576  |\n",
      "| qf1_loss                | 10.657665   |\n",
      "| qf2_loss                | 5.7829847   |\n",
      "| time_elapsed            | 1426        |\n",
      "| total timesteps         | 117113      |\n",
      "| value_loss              | 8.2187195   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.021064099 |\n",
      "| ent_coef_loss           | 1.3776398   |\n",
      "| entropy                 | 14.148672   |\n",
      "| episodes                | 1490        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 524         |\n",
      "| n_updates               | 118074      |\n",
      "| policy_loss             | -156.37405  |\n",
      "| qf1_loss                | 7.7124386   |\n",
      "| qf2_loss                | 12.797891   |\n",
      "| time_elapsed            | 1438        |\n",
      "| total timesteps         | 118173      |\n",
      "| value_loss              | 10.711477   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.021042079 |\n",
      "| ent_coef_loss           | 1.463474    |\n",
      "| entropy                 | 14.152603   |\n",
      "| episodes                | 1500        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 526         |\n",
      "| n_updates               | 119232      |\n",
      "| policy_loss             | -169.2893   |\n",
      "| qf1_loss                | 10.142771   |\n",
      "| qf2_loss                | 11.451086   |\n",
      "| time_elapsed            | 1451        |\n",
      "| total timesteps         | 119331      |\n",
      "| value_loss              | 5.9522123   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.022807777 |\n",
      "| ent_coef_loss           | -6.65958    |\n",
      "| entropy                 | 14.895884   |\n",
      "| episodes                | 1510        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 528         |\n",
      "| n_updates               | 120314      |\n",
      "| policy_loss             | -154.7767   |\n",
      "| qf1_loss                | 9.818714    |\n",
      "| qf2_loss                | 10.230194   |\n",
      "| time_elapsed            | 1463        |\n",
      "| total timesteps         | 120413      |\n",
      "| value_loss              | 7.8683825   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.021609595 |\n",
      "| ent_coef_loss           | -1.0256782  |\n",
      "| entropy                 | 14.609728   |\n",
      "| episodes                | 1520        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 532         |\n",
      "| n_updates               | 121358      |\n",
      "| policy_loss             | -155.42122  |\n",
      "| qf1_loss                | 13.068403   |\n",
      "| qf2_loss                | 12.912933   |\n",
      "| time_elapsed            | 1475        |\n",
      "| total timesteps         | 121457      |\n",
      "| value_loss              | 13.66609    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02123921 |\n",
      "| ent_coef_loss           | 5.9780836  |\n",
      "| entropy                 | 14.775944  |\n",
      "| episodes                | 1530       |\n",
      "| fps                     | 82         |\n",
      "| mean 100 episode reward | 549        |\n",
      "| n_updates               | 122510     |\n",
      "| policy_loss             | -157.3099  |\n",
      "| qf1_loss                | 9.084165   |\n",
      "| qf2_loss                | 9.860333   |\n",
      "| time_elapsed            | 1487       |\n",
      "| total timesteps         | 122609     |\n",
      "| value_loss              | 7.94549    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.021899406 |\n",
      "| ent_coef_loss           | -4.4916735  |\n",
      "| entropy                 | 15.0327215  |\n",
      "| episodes                | 1540        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 569         |\n",
      "| n_updates               | 124050      |\n",
      "| policy_loss             | -163.76544  |\n",
      "| qf1_loss                | 13.833818   |\n",
      "| qf2_loss                | 13.718651   |\n",
      "| time_elapsed            | 1504        |\n",
      "| total timesteps         | 124149      |\n",
      "| value_loss              | 11.765288   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.021728875 |\n",
      "| ent_coef_loss           | 4.5610337   |\n",
      "| entropy                 | 14.066531   |\n",
      "| episodes                | 1550        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 572         |\n",
      "| n_updates               | 125269      |\n",
      "| policy_loss             | -171.3074   |\n",
      "| qf1_loss                | 10.666922   |\n",
      "| qf2_loss                | 9.287508    |\n",
      "| time_elapsed            | 1518        |\n",
      "| total timesteps         | 125368      |\n",
      "| value_loss              | 6.1683455   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.021745449 |\n",
      "| ent_coef_loss           | 1.8181372   |\n",
      "| entropy                 | 14.375391   |\n",
      "| episodes                | 1560        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 587         |\n",
      "| n_updates               | 126510      |\n",
      "| policy_loss             | -168.70786  |\n",
      "| qf1_loss                | 13.863511   |\n",
      "| qf2_loss                | 14.945701   |\n",
      "| time_elapsed            | 1532        |\n",
      "| total timesteps         | 126609      |\n",
      "| value_loss              | 7.958078    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.021854691 |\n",
      "| ent_coef_loss           | 10.252174   |\n",
      "| entropy                 | 14.087208   |\n",
      "| episodes                | 1570        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 584         |\n",
      "| n_updates               | 127696      |\n",
      "| policy_loss             | -174.08969  |\n",
      "| qf1_loss                | 11.697836   |\n",
      "| qf2_loss                | 11.466039   |\n",
      "| time_elapsed            | 1546        |\n",
      "| total timesteps         | 127795      |\n",
      "| value_loss              | 5.6389265   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.021884589 |\n",
      "| ent_coef_loss           | -4.7579403  |\n",
      "| entropy                 | 13.993997   |\n",
      "| episodes                | 1580        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 588         |\n",
      "| n_updates               | 128728      |\n",
      "| policy_loss             | -157.98367  |\n",
      "| qf1_loss                | 9.712808    |\n",
      "| qf2_loss                | 11.707916   |\n",
      "| time_elapsed            | 1559        |\n",
      "| total timesteps         | 128827      |\n",
      "| value_loss              | 13.161597   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.022240184 |\n",
      "| ent_coef_loss           | 5.8806376   |\n",
      "| entropy                 | 14.273108   |\n",
      "| episodes                | 1590        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 595         |\n",
      "| n_updates               | 129891      |\n",
      "| policy_loss             | -171.2031   |\n",
      "| qf1_loss                | 14.672164   |\n",
      "| qf2_loss                | 12.646503   |\n",
      "| time_elapsed            | 1574        |\n",
      "| total timesteps         | 129990      |\n",
      "| value_loss              | 11.513425   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.021577429 |\n",
      "| ent_coef_loss           | 3.2553544   |\n",
      "| entropy                 | 14.621109   |\n",
      "| episodes                | 1600        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 602         |\n",
      "| n_updates               | 131188      |\n",
      "| policy_loss             | -177.7374   |\n",
      "| qf1_loss                | 17.584394   |\n",
      "| qf2_loss                | 12.761179   |\n",
      "| time_elapsed            | 1588        |\n",
      "| total timesteps         | 131287      |\n",
      "| value_loss              | 10.828772   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.022635153 |\n",
      "| ent_coef_loss           | 9.692633    |\n",
      "| entropy                 | 14.568547   |\n",
      "| episodes                | 1610        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 595         |\n",
      "| n_updates               | 132129      |\n",
      "| policy_loss             | -168.3563   |\n",
      "| qf1_loss                | 21.695244   |\n",
      "| qf2_loss                | 14.938593   |\n",
      "| time_elapsed            | 1599        |\n",
      "| total timesteps         | 132228      |\n",
      "| value_loss              | 12.402203   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.021589387 |\n",
      "| ent_coef_loss           | -2.2470925  |\n",
      "| entropy                 | 14.238678   |\n",
      "| episodes                | 1620        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 602         |\n",
      "| n_updates               | 133359      |\n",
      "| policy_loss             | -162.7974   |\n",
      "| qf1_loss                | 9.830048    |\n",
      "| qf2_loss                | 16.237581   |\n",
      "| time_elapsed            | 1613        |\n",
      "| total timesteps         | 133458      |\n",
      "| value_loss              | 13.927931   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.021270279 |\n",
      "| ent_coef_loss           | -0.90941143 |\n",
      "| entropy                 | 14.386622   |\n",
      "| episodes                | 1630        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 600         |\n",
      "| n_updates               | 134483      |\n",
      "| policy_loss             | -194.61273  |\n",
      "| qf1_loss                | 18.946373   |\n",
      "| qf2_loss                | 15.20015    |\n",
      "| time_elapsed            | 1626        |\n",
      "| total timesteps         | 134582      |\n",
      "| value_loss              | 11.804801   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02182447 |\n",
      "| ent_coef_loss           | 0.82120514 |\n",
      "| entropy                 | 14.563338  |\n",
      "| episodes                | 1640       |\n",
      "| fps                     | 82         |\n",
      "| mean 100 episode reward | 604        |\n",
      "| n_updates               | 136030     |\n",
      "| policy_loss             | -166.21463 |\n",
      "| qf1_loss                | 9.059507   |\n",
      "| qf2_loss                | 11.588492  |\n",
      "| time_elapsed            | 1644       |\n",
      "| total timesteps         | 136129     |\n",
      "| value_loss              | 14.5263195 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.021357   |\n",
      "| ent_coef_loss           | -8.871094  |\n",
      "| entropy                 | 15.019145  |\n",
      "| episodes                | 1650       |\n",
      "| fps                     | 82         |\n",
      "| mean 100 episode reward | 599        |\n",
      "| n_updates               | 137112     |\n",
      "| policy_loss             | -152.64105 |\n",
      "| qf1_loss                | 8.054073   |\n",
      "| qf2_loss                | 12.275957  |\n",
      "| time_elapsed            | 1656       |\n",
      "| total timesteps         | 137211     |\n",
      "| value_loss              | 7.0633197  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.021794248 |\n",
      "| ent_coef_loss           | -5.617288   |\n",
      "| entropy                 | 14.064852   |\n",
      "| episodes                | 1660        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 598         |\n",
      "| n_updates               | 138391      |\n",
      "| policy_loss             | -189.6407   |\n",
      "| qf1_loss                | 10.484167   |\n",
      "| qf2_loss                | 11.303812   |\n",
      "| time_elapsed            | 1671        |\n",
      "| total timesteps         | 138490      |\n",
      "| value_loss              | 7.910592    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.022291964 |\n",
      "| ent_coef_loss           | 2.1733003   |\n",
      "| entropy                 | 13.848441   |\n",
      "| episodes                | 1670        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 617         |\n",
      "| n_updates               | 139941      |\n",
      "| policy_loss             | -173.31107  |\n",
      "| qf1_loss                | 15.579199   |\n",
      "| qf2_loss                | 17.763409   |\n",
      "| time_elapsed            | 1689        |\n",
      "| total timesteps         | 140040      |\n",
      "| value_loss              | 8.263042    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.022338465 |\n",
      "| ent_coef_loss           | -6.203889   |\n",
      "| entropy                 | 13.98444    |\n",
      "| episodes                | 1680        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 616         |\n",
      "| n_updates               | 140968      |\n",
      "| policy_loss             | -184.08441  |\n",
      "| qf1_loss                | 9.843754    |\n",
      "| qf2_loss                | 12.005376   |\n",
      "| time_elapsed            | 1701        |\n",
      "| total timesteps         | 141067      |\n",
      "| value_loss              | 8.859737    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.022625204 |\n",
      "| ent_coef_loss           | -1.0347106  |\n",
      "| entropy                 | 14.859694   |\n",
      "| episodes                | 1690        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 608         |\n",
      "| n_updates               | 142090      |\n",
      "| policy_loss             | -164.15967  |\n",
      "| qf1_loss                | 10.480379   |\n",
      "| qf2_loss                | 7.5341134   |\n",
      "| time_elapsed            | 1713        |\n",
      "| total timesteps         | 142189      |\n",
      "| value_loss              | 13.280217   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02267449 |\n",
      "| ent_coef_loss           | 2.6617682  |\n",
      "| entropy                 | 14.564955  |\n",
      "| episodes                | 1700       |\n",
      "| fps                     | 82         |\n",
      "| mean 100 episode reward | 603        |\n",
      "| n_updates               | 143355     |\n",
      "| policy_loss             | -172.85701 |\n",
      "| qf1_loss                | 12.463733  |\n",
      "| qf2_loss                | 20.294323  |\n",
      "| time_elapsed            | 1728       |\n",
      "| total timesteps         | 143454     |\n",
      "| value_loss              | 16.317646  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.023216456 |\n",
      "| ent_coef_loss           | -3.8325965  |\n",
      "| entropy                 | 14.862577   |\n",
      "| episodes                | 1710        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 628         |\n",
      "| n_updates               | 144780      |\n",
      "| policy_loss             | -163.7557   |\n",
      "| qf1_loss                | 8.5497875   |\n",
      "| qf2_loss                | 6.8346305   |\n",
      "| time_elapsed            | 1744        |\n",
      "| total timesteps         | 144879      |\n",
      "| value_loss              | 7.198472    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.023808347 |\n",
      "| ent_coef_loss           | -4.080044   |\n",
      "| entropy                 | 14.308163   |\n",
      "| episodes                | 1720        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 638         |\n",
      "| n_updates               | 146189      |\n",
      "| policy_loss             | -196.18576  |\n",
      "| qf1_loss                | 14.833855   |\n",
      "| qf2_loss                | 16.60403    |\n",
      "| time_elapsed            | 1761        |\n",
      "| total timesteps         | 146288      |\n",
      "| value_loss              | 12.076156   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02428391 |\n",
      "| ent_coef_loss           | -1.6918635 |\n",
      "| entropy                 | 14.286198  |\n",
      "| episodes                | 1730       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 646        |\n",
      "| n_updates               | 147424     |\n",
      "| policy_loss             | -171.10114 |\n",
      "| qf1_loss                | 7.4244633  |\n",
      "| qf2_loss                | 8.505354   |\n",
      "| time_elapsed            | 1775       |\n",
      "| total timesteps         | 147523     |\n",
      "| value_loss              | 5.346156   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.024304282 |\n",
      "| ent_coef_loss           | -3.4378052  |\n",
      "| entropy                 | 14.917103   |\n",
      "| episodes                | 1740        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 636         |\n",
      "| n_updates               | 148828      |\n",
      "| policy_loss             | -156.11064  |\n",
      "| qf1_loss                | 13.157606   |\n",
      "| qf2_loss                | 12.818549   |\n",
      "| time_elapsed            | 1792        |\n",
      "| total timesteps         | 148927      |\n",
      "| value_loss              | 8.430997    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.025140638 |\n",
      "| ent_coef_loss           | -2.3808205  |\n",
      "| entropy                 | 14.652432   |\n",
      "| episodes                | 1750        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 653         |\n",
      "| n_updates               | 150221      |\n",
      "| policy_loss             | -158.37564  |\n",
      "| qf1_loss                | 11.601957   |\n",
      "| qf2_loss                | 11.169577   |\n",
      "| time_elapsed            | 1810        |\n",
      "| total timesteps         | 150320      |\n",
      "| value_loss              | 10.587664   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.025730198 |\n",
      "| ent_coef_loss           | -4.635492   |\n",
      "| entropy                 | 14.306897   |\n",
      "| episodes                | 1760        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 652         |\n",
      "| n_updates               | 151463      |\n",
      "| policy_loss             | -169.49019  |\n",
      "| qf1_loss                | 15.09385    |\n",
      "| qf2_loss                | 10.629342   |\n",
      "| time_elapsed            | 1825        |\n",
      "| total timesteps         | 151562      |\n",
      "| value_loss              | 17.570911   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.024371916 |\n",
      "| ent_coef_loss           | -3.7028656  |\n",
      "| entropy                 | 14.349073   |\n",
      "| episodes                | 1770        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 628         |\n",
      "| n_updates               | 152568      |\n",
      "| policy_loss             | -175.13931  |\n",
      "| qf1_loss                | 9.980883    |\n",
      "| qf2_loss                | 15.489935   |\n",
      "| time_elapsed            | 1838        |\n",
      "| total timesteps         | 152667      |\n",
      "| value_loss              | 11.749472   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02423692 |\n",
      "| ent_coef_loss           | 1.0685169  |\n",
      "| entropy                 | 14.559077  |\n",
      "| episodes                | 1780       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 649        |\n",
      "| n_updates               | 154006     |\n",
      "| policy_loss             | -187.54701 |\n",
      "| qf1_loss                | 8.554914   |\n",
      "| qf2_loss                | 9.511713   |\n",
      "| time_elapsed            | 1855       |\n",
      "| total timesteps         | 154105     |\n",
      "| value_loss              | 12.582363  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.023833547 |\n",
      "| ent_coef_loss           | 1.3111792   |\n",
      "| entropy                 | 14.591619   |\n",
      "| episodes                | 1790        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 656         |\n",
      "| n_updates               | 155181      |\n",
      "| policy_loss             | -176.39186  |\n",
      "| qf1_loss                | 19.891645   |\n",
      "| qf2_loss                | 22.404968   |\n",
      "| time_elapsed            | 1869        |\n",
      "| total timesteps         | 155280      |\n",
      "| value_loss              | 11.556727   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.023821719 |\n",
      "| ent_coef_loss           | 0.944692    |\n",
      "| entropy                 | 13.998661   |\n",
      "| episodes                | 1800        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 652         |\n",
      "| n_updates               | 156333      |\n",
      "| policy_loss             | -186.3259   |\n",
      "| qf1_loss                | 9.8209505   |\n",
      "| qf2_loss                | 12.211185   |\n",
      "| time_elapsed            | 1883        |\n",
      "| total timesteps         | 156432      |\n",
      "| value_loss              | 8.321795    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.023871932 |\n",
      "| ent_coef_loss           | 2.2623959   |\n",
      "| entropy                 | 13.762995   |\n",
      "| episodes                | 1810        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 651         |\n",
      "| n_updates               | 157724      |\n",
      "| policy_loss             | -198.53708  |\n",
      "| qf1_loss                | 12.144512   |\n",
      "| qf2_loss                | 11.9616995  |\n",
      "| time_elapsed            | 1901        |\n",
      "| total timesteps         | 157823      |\n",
      "| value_loss              | 11.796014   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02481393 |\n",
      "| ent_coef_loss           | -1.5348933 |\n",
      "| entropy                 | 13.973993  |\n",
      "| episodes                | 1820       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 631        |\n",
      "| n_updates               | 158778     |\n",
      "| policy_loss             | -192.34988 |\n",
      "| qf1_loss                | 12.622112  |\n",
      "| qf2_loss                | 12.432493  |\n",
      "| time_elapsed            | 1913       |\n",
      "| total timesteps         | 158877     |\n",
      "| value_loss              | 13.617054  |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.025403362 |\n",
      "| ent_coef_loss           | 1.0383785   |\n",
      "| entropy                 | 14.67302    |\n",
      "| episodes                | 1830        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 635         |\n",
      "| n_updates               | 160096      |\n",
      "| policy_loss             | -188.39058  |\n",
      "| qf1_loss                | 10.775896   |\n",
      "| qf2_loss                | 10.491465   |\n",
      "| time_elapsed            | 1929        |\n",
      "| total timesteps         | 160195      |\n",
      "| value_loss              | 5.5978837   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.024729798 |\n",
      "| ent_coef_loss           | 7.954749    |\n",
      "| entropy                 | 14.163939   |\n",
      "| episodes                | 1840        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 635         |\n",
      "| n_updates               | 161503      |\n",
      "| policy_loss             | -166.97507  |\n",
      "| qf1_loss                | 14.64398    |\n",
      "| qf2_loss                | 12.842567   |\n",
      "| time_elapsed            | 1946        |\n",
      "| total timesteps         | 161602      |\n",
      "| value_loss              | 11.60369    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.025264785 |\n",
      "| ent_coef_loss           | -2.2920232  |\n",
      "| entropy                 | 14.336289   |\n",
      "| episodes                | 1850        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 633         |\n",
      "| n_updates               | 162940      |\n",
      "| policy_loss             | -178.58685  |\n",
      "| qf1_loss                | 13.826582   |\n",
      "| qf2_loss                | 10.61829    |\n",
      "| time_elapsed            | 1962        |\n",
      "| total timesteps         | 163039      |\n",
      "| value_loss              | 20.319279   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.024992991 |\n",
      "| ent_coef_loss           | -1.8404796  |\n",
      "| entropy                 | 14.453218   |\n",
      "| episodes                | 1860        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 639         |\n",
      "| n_updates               | 164311      |\n",
      "| policy_loss             | -171.207    |\n",
      "| qf1_loss                | 13.225038   |\n",
      "| qf2_loss                | 16.712923   |\n",
      "| time_elapsed            | 1978        |\n",
      "| total timesteps         | 164410      |\n",
      "| value_loss              | 22.500546   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02434814 |\n",
      "| ent_coef_loss           | 2.314576   |\n",
      "| entropy                 | 14.306799  |\n",
      "| episodes                | 1870       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 649        |\n",
      "| n_updates               | 165547     |\n",
      "| policy_loss             | -164.88684 |\n",
      "| qf1_loss                | 11.188612  |\n",
      "| qf2_loss                | 8.586008   |\n",
      "| time_elapsed            | 1993       |\n",
      "| total timesteps         | 165646     |\n",
      "| value_loss              | 11.230442  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.023572551 |\n",
      "| ent_coef_loss           | -0.17970908 |\n",
      "| entropy                 | 14.324713   |\n",
      "| episodes                | 1880        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 637         |\n",
      "| n_updates               | 166756      |\n",
      "| policy_loss             | -174.57736  |\n",
      "| qf1_loss                | 11.856771   |\n",
      "| qf2_loss                | 16.329735   |\n",
      "| time_elapsed            | 2007        |\n",
      "| total timesteps         | 166855      |\n",
      "| value_loss              | 11.181612   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.024529897 |\n",
      "| ent_coef_loss           | -3.6827514  |\n",
      "| entropy                 | 14.932859   |\n",
      "| episodes                | 1890        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 645         |\n",
      "| n_updates               | 168111      |\n",
      "| policy_loss             | -174.124    |\n",
      "| qf1_loss                | 11.218939   |\n",
      "| qf2_loss                | 10.310883   |\n",
      "| time_elapsed            | 2023        |\n",
      "| total timesteps         | 168210      |\n",
      "| value_loss              | 10.16668    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.025152065 |\n",
      "| ent_coef_loss           | -7.4432592  |\n",
      "| entropy                 | 15.198528   |\n",
      "| episodes                | 1900        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 648         |\n",
      "| n_updates               | 169287      |\n",
      "| policy_loss             | -168.68567  |\n",
      "| qf1_loss                | 10.542976   |\n",
      "| qf2_loss                | 11.355822   |\n",
      "| time_elapsed            | 2037        |\n",
      "| total timesteps         | 169386      |\n",
      "| value_loss              | 10.485597   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02501233 |\n",
      "| ent_coef_loss           | 6.641528   |\n",
      "| entropy                 | 14.282267  |\n",
      "| episodes                | 1910       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 648        |\n",
      "| n_updates               | 170689     |\n",
      "| policy_loss             | -182.4336  |\n",
      "| qf1_loss                | 14.736694  |\n",
      "| qf2_loss                | 13.272818  |\n",
      "| time_elapsed            | 2054       |\n",
      "| total timesteps         | 170788     |\n",
      "| value_loss              | 10.695801  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.025844492 |\n",
      "| ent_coef_loss           | -1.027495   |\n",
      "| entropy                 | 14.189255   |\n",
      "| episodes                | 1920        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 672         |\n",
      "| n_updates               | 172197      |\n",
      "| policy_loss             | -186.79543  |\n",
      "| qf1_loss                | 12.471725   |\n",
      "| qf2_loss                | 13.749929   |\n",
      "| time_elapsed            | 2071        |\n",
      "| total timesteps         | 172296      |\n",
      "| value_loss              | 14.284832   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.026717251 |\n",
      "| ent_coef_loss           | 7.3872232   |\n",
      "| entropy                 | 14.56212    |\n",
      "| episodes                | 1930        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 678         |\n",
      "| n_updates               | 173661      |\n",
      "| policy_loss             | -174.9939   |\n",
      "| qf1_loss                | 16.81496    |\n",
      "| qf2_loss                | 13.745334   |\n",
      "| time_elapsed            | 2089        |\n",
      "| total timesteps         | 173760      |\n",
      "| value_loss              | 11.70886    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02622491 |\n",
      "| ent_coef_loss           | 2.3274326  |\n",
      "| entropy                 | 14.339713  |\n",
      "| episodes                | 1940       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 675        |\n",
      "| n_updates               | 174973     |\n",
      "| policy_loss             | -177.04938 |\n",
      "| qf1_loss                | 26.542921  |\n",
      "| qf2_loss                | 17.266037  |\n",
      "| time_elapsed            | 2104       |\n",
      "| total timesteps         | 175072     |\n",
      "| value_loss              | 13.268026  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.026258895 |\n",
      "| ent_coef_loss           | -4.1575027  |\n",
      "| entropy                 | 14.548979   |\n",
      "| episodes                | 1950        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 681         |\n",
      "| n_updates               | 176443      |\n",
      "| policy_loss             | -176.3745   |\n",
      "| qf1_loss                | 13.157121   |\n",
      "| qf2_loss                | 15.952522   |\n",
      "| time_elapsed            | 2120        |\n",
      "| total timesteps         | 176542      |\n",
      "| value_loss              | 13.175455   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.024816705 |\n",
      "| ent_coef_loss           | 2.7036355   |\n",
      "| entropy                 | 14.360016   |\n",
      "| episodes                | 1960        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 688         |\n",
      "| n_updates               | 177917      |\n",
      "| policy_loss             | -198.94154  |\n",
      "| qf1_loss                | 10.875999   |\n",
      "| qf2_loss                | 10.9692955  |\n",
      "| time_elapsed            | 2136        |\n",
      "| total timesteps         | 178016      |\n",
      "| value_loss              | 8.991541    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02555347 |\n",
      "| ent_coef_loss           | -5.0055532 |\n",
      "| entropy                 | 14.194661  |\n",
      "| episodes                | 1970       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 687        |\n",
      "| n_updates               | 179123     |\n",
      "| policy_loss             | -192.05356 |\n",
      "| qf1_loss                | 16.922796  |\n",
      "| qf2_loss                | 16.911625  |\n",
      "| time_elapsed            | 2149       |\n",
      "| total timesteps         | 179222     |\n",
      "| value_loss              | 8.612157   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.025547463 |\n",
      "| ent_coef_loss           | 5.7502685   |\n",
      "| entropy                 | 13.937789   |\n",
      "| episodes                | 1980        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 695         |\n",
      "| n_updates               | 180430      |\n",
      "| policy_loss             | -171.60832  |\n",
      "| qf1_loss                | 15.652312   |\n",
      "| qf2_loss                | 11.493585   |\n",
      "| time_elapsed            | 2164        |\n",
      "| total timesteps         | 180529      |\n",
      "| value_loss              | 9.207185    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.025385974 |\n",
      "| ent_coef_loss           | 4.63295     |\n",
      "| entropy                 | 13.594534   |\n",
      "| episodes                | 1990        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 711         |\n",
      "| n_updates               | 182040      |\n",
      "| policy_loss             | -191.39334  |\n",
      "| qf1_loss                | 17.84109    |\n",
      "| qf2_loss                | 15.771383   |\n",
      "| time_elapsed            | 2184        |\n",
      "| total timesteps         | 182139      |\n",
      "| value_loss              | 14.927735   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.026399653 |\n",
      "| ent_coef_loss           | 3.0559974   |\n",
      "| entropy                 | 13.684661   |\n",
      "| episodes                | 2000        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 701         |\n",
      "| n_updates               | 183031      |\n",
      "| policy_loss             | -212.47702  |\n",
      "| qf1_loss                | 21.356895   |\n",
      "| qf2_loss                | 15.822674   |\n",
      "| time_elapsed            | 2196        |\n",
      "| total timesteps         | 183130      |\n",
      "| value_loss              | 11.880592   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.027161263 |\n",
      "| ent_coef_loss           | 0.26861334  |\n",
      "| entropy                 | 14.682964   |\n",
      "| episodes                | 2010        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 709         |\n",
      "| n_updates               | 184545      |\n",
      "| policy_loss             | -174.242    |\n",
      "| qf1_loss                | 18.304186   |\n",
      "| qf2_loss                | 16.666992   |\n",
      "| time_elapsed            | 2213        |\n",
      "| total timesteps         | 184644      |\n",
      "| value_loss              | 11.116484   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.027088076 |\n",
      "| ent_coef_loss           | 3.0961218   |\n",
      "| entropy                 | 14.1838     |\n",
      "| episodes                | 2020        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 701         |\n",
      "| n_updates               | 185848      |\n",
      "| policy_loss             | -191.34607  |\n",
      "| qf1_loss                | 13.660524   |\n",
      "| qf2_loss                | 22.304775   |\n",
      "| time_elapsed            | 2227        |\n",
      "| total timesteps         | 185947      |\n",
      "| value_loss              | 22.920544   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02781806 |\n",
      "| ent_coef_loss           | 10.943294  |\n",
      "| entropy                 | 13.718428  |\n",
      "| episodes                | 2030       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 682        |\n",
      "| n_updates               | 186901     |\n",
      "| policy_loss             | -199.95496 |\n",
      "| qf1_loss                | 21.530323  |\n",
      "| qf2_loss                | 20.733177  |\n",
      "| time_elapsed            | 2239       |\n",
      "| total timesteps         | 187000     |\n",
      "| value_loss              | 14.146317  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02667568 |\n",
      "| ent_coef_loss           | -1.3993138 |\n",
      "| entropy                 | 14.818403  |\n",
      "| episodes                | 2040       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 667        |\n",
      "| n_updates               | 187947     |\n",
      "| policy_loss             | -168.89767 |\n",
      "| qf1_loss                | 10.723822  |\n",
      "| qf2_loss                | 11.629926  |\n",
      "| time_elapsed            | 2251       |\n",
      "| total timesteps         | 188046     |\n",
      "| value_loss              | 11.51826   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.027575806 |\n",
      "| ent_coef_loss           | -6.060593   |\n",
      "| entropy                 | 14.926925   |\n",
      "| episodes                | 2050        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 672         |\n",
      "| n_updates               | 189529      |\n",
      "| policy_loss             | -191.0657   |\n",
      "| qf1_loss                | 15.686653   |\n",
      "| qf2_loss                | 14.625753   |\n",
      "| time_elapsed            | 2269        |\n",
      "| total timesteps         | 189628      |\n",
      "| value_loss              | 10.582542   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028243493 |\n",
      "| ent_coef_loss           | -2.7502122  |\n",
      "| entropy                 | 14.5097275  |\n",
      "| episodes                | 2060        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 677         |\n",
      "| n_updates               | 191129      |\n",
      "| policy_loss             | -170.4784   |\n",
      "| qf1_loss                | 16.76844    |\n",
      "| qf2_loss                | 14.905441   |\n",
      "| time_elapsed            | 2288        |\n",
      "| total timesteps         | 191228      |\n",
      "| value_loss              | 8.789458    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02747767 |\n",
      "| ent_coef_loss           | -19.500374 |\n",
      "| entropy                 | 14.683467  |\n",
      "| episodes                | 2070       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 692        |\n",
      "| n_updates               | 192749     |\n",
      "| policy_loss             | -191.64554 |\n",
      "| qf1_loss                | 12.119638  |\n",
      "| qf2_loss                | 12.337578  |\n",
      "| time_elapsed            | 2306       |\n",
      "| total timesteps         | 192848     |\n",
      "| value_loss              | 12.605509  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.027830478 |\n",
      "| ent_coef_loss           | -1.9017576  |\n",
      "| entropy                 | 14.043648   |\n",
      "| episodes                | 2080        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 698         |\n",
      "| n_updates               | 194194      |\n",
      "| policy_loss             | -193.29565  |\n",
      "| qf1_loss                | 10.393009   |\n",
      "| qf2_loss                | 12.986513   |\n",
      "| time_elapsed            | 2322        |\n",
      "| total timesteps         | 194293      |\n",
      "| value_loss              | 5.922474    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.027005613 |\n",
      "| ent_coef_loss           | 1.356554    |\n",
      "| entropy                 | 14.211111   |\n",
      "| episodes                | 2090        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 676         |\n",
      "| n_updates               | 195395      |\n",
      "| policy_loss             | -196.23822  |\n",
      "| qf1_loss                | 13.026674   |\n",
      "| qf2_loss                | 16.747437   |\n",
      "| time_elapsed            | 2336        |\n",
      "| total timesteps         | 195494      |\n",
      "| value_loss              | 8.841707    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.027444653 |\n",
      "| ent_coef_loss           | 1.7154655   |\n",
      "| entropy                 | 14.744289   |\n",
      "| episodes                | 2100        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 702         |\n",
      "| n_updates               | 196923      |\n",
      "| policy_loss             | -180.41713  |\n",
      "| qf1_loss                | 17.311127   |\n",
      "| qf2_loss                | 19.20626    |\n",
      "| time_elapsed            | 2354        |\n",
      "| total timesteps         | 197022      |\n",
      "| value_loss              | 22.800217   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028255805 |\n",
      "| ent_coef_loss           | 1.869623    |\n",
      "| entropy                 | 14.42283    |\n",
      "| episodes                | 2110        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 688         |\n",
      "| n_updates               | 198142      |\n",
      "| policy_loss             | -170.45383  |\n",
      "| qf1_loss                | 13.544975   |\n",
      "| qf2_loss                | 12.091161   |\n",
      "| time_elapsed            | 2367        |\n",
      "| total timesteps         | 198241      |\n",
      "| value_loss              | 8.757269    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028472062 |\n",
      "| ent_coef_loss           | 4.4339657   |\n",
      "| entropy                 | 14.0739565  |\n",
      "| episodes                | 2120        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 692         |\n",
      "| n_updates               | 199525      |\n",
      "| policy_loss             | -204.93597  |\n",
      "| qf1_loss                | 14.034366   |\n",
      "| qf2_loss                | 10.927919   |\n",
      "| time_elapsed            | 2384        |\n",
      "| total timesteps         | 199624      |\n",
      "| value_loss              | 9.207018    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02802882 |\n",
      "| ent_coef_loss           | 1.2319654  |\n",
      "| entropy                 | 14.243269  |\n",
      "| episodes                | 2130       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 714        |\n",
      "| n_updates               | 201030     |\n",
      "| policy_loss             | -193.89139 |\n",
      "| qf1_loss                | 18.914354  |\n",
      "| qf2_loss                | 10.415092  |\n",
      "| time_elapsed            | 2402       |\n",
      "| total timesteps         | 201129     |\n",
      "| value_loss              | 11.37945   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028506275 |\n",
      "| ent_coef_loss           | 5.672721    |\n",
      "| entropy                 | 14.217222   |\n",
      "| episodes                | 2140        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 750         |\n",
      "| n_updates               | 202806      |\n",
      "| policy_loss             | -199.30063  |\n",
      "| qf1_loss                | 30.105215   |\n",
      "| qf2_loss                | 26.846176   |\n",
      "| time_elapsed            | 2422        |\n",
      "| total timesteps         | 202905      |\n",
      "| value_loss              | 18.307844   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029172884 |\n",
      "| ent_coef_loss           | 4.811089    |\n",
      "| entropy                 | 14.595144   |\n",
      "| episodes                | 2150        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 754         |\n",
      "| n_updates               | 204441      |\n",
      "| policy_loss             | -206.39044  |\n",
      "| qf1_loss                | 11.450836   |\n",
      "| qf2_loss                | 12.268326   |\n",
      "| time_elapsed            | 2440        |\n",
      "| total timesteps         | 204540      |\n",
      "| value_loss              | 16.898537   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028470026 |\n",
      "| ent_coef_loss           | -8.729003   |\n",
      "| entropy                 | 14.788562   |\n",
      "| episodes                | 2160        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 749         |\n",
      "| n_updates               | 205927      |\n",
      "| policy_loss             | -202.04166  |\n",
      "| qf1_loss                | 18.546547   |\n",
      "| qf2_loss                | 20.01476    |\n",
      "| time_elapsed            | 2459        |\n",
      "| total timesteps         | 206026      |\n",
      "| value_loss              | 9.30625     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02847025 |\n",
      "| ent_coef_loss           | -4.462369  |\n",
      "| entropy                 | 14.683218  |\n",
      "| episodes                | 2170       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 735        |\n",
      "| n_updates               | 207231     |\n",
      "| policy_loss             | -196.43669 |\n",
      "| qf1_loss                | 14.5858555 |\n",
      "| qf2_loss                | 11.252096  |\n",
      "| time_elapsed            | 2475       |\n",
      "| total timesteps         | 207330     |\n",
      "| value_loss              | 14.946774  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028811708 |\n",
      "| ent_coef_loss           | -4.9174414  |\n",
      "| entropy                 | 14.550729   |\n",
      "| episodes                | 2180        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 727         |\n",
      "| n_updates               | 208586      |\n",
      "| policy_loss             | -198.08655  |\n",
      "| qf1_loss                | 11.707621   |\n",
      "| qf2_loss                | 13.665365   |\n",
      "| time_elapsed            | 2490        |\n",
      "| total timesteps         | 208685      |\n",
      "| value_loss              | 10.528481   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028363476 |\n",
      "| ent_coef_loss           | 2.7484283   |\n",
      "| entropy                 | 14.00968    |\n",
      "| episodes                | 2190        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 742         |\n",
      "| n_updates               | 210135      |\n",
      "| policy_loss             | -204.35968  |\n",
      "| qf1_loss                | 13.92291    |\n",
      "| qf2_loss                | 16.450375   |\n",
      "| time_elapsed            | 2507        |\n",
      "| total timesteps         | 210234      |\n",
      "| value_loss              | 6.0489473   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029345104 |\n",
      "| ent_coef_loss           | -7.9840713  |\n",
      "| entropy                 | 14.778465   |\n",
      "| episodes                | 2200        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 715         |\n",
      "| n_updates               | 211138      |\n",
      "| policy_loss             | -189.92307  |\n",
      "| qf1_loss                | 13.736845   |\n",
      "| qf2_loss                | 13.312      |\n",
      "| time_elapsed            | 2519        |\n",
      "| total timesteps         | 211237      |\n",
      "| value_loss              | 16.069508   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029400723 |\n",
      "| ent_coef_loss           | 6.5816574   |\n",
      "| entropy                 | 13.682611   |\n",
      "| episodes                | 2210        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 717         |\n",
      "| n_updates               | 212461      |\n",
      "| policy_loss             | -225.29996  |\n",
      "| qf1_loss                | 19.29541    |\n",
      "| qf2_loss                | 18.075382   |\n",
      "| time_elapsed            | 2534        |\n",
      "| total timesteps         | 212560      |\n",
      "| value_loss              | 23.380182   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028630137 |\n",
      "| ent_coef_loss           | 1.367549    |\n",
      "| entropy                 | 14.484201   |\n",
      "| episodes                | 2220        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 706         |\n",
      "| n_updates               | 213626      |\n",
      "| policy_loss             | -193.60297  |\n",
      "| qf1_loss                | 22.198212   |\n",
      "| qf2_loss                | 20.824247   |\n",
      "| time_elapsed            | 2547        |\n",
      "| total timesteps         | 213725      |\n",
      "| value_loss              | 8.71564     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029931005 |\n",
      "| ent_coef_loss           | -2.2275922  |\n",
      "| entropy                 | 14.862116   |\n",
      "| episodes                | 2230        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 728         |\n",
      "| n_updates               | 215495      |\n",
      "| policy_loss             | -190.44359  |\n",
      "| qf1_loss                | 18.796747   |\n",
      "| qf2_loss                | 16.176804   |\n",
      "| time_elapsed            | 2568        |\n",
      "| total timesteps         | 215594      |\n",
      "| value_loss              | 11.2231865  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029978378 |\n",
      "| ent_coef_loss           | -3.1240277  |\n",
      "| entropy                 | 14.222283   |\n",
      "| episodes                | 2240        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 712         |\n",
      "| n_updates               | 216934      |\n",
      "| policy_loss             | -202.60272  |\n",
      "| qf1_loss                | 30.26477    |\n",
      "| qf2_loss                | 23.617937   |\n",
      "| time_elapsed            | 2585        |\n",
      "| total timesteps         | 217033      |\n",
      "| value_loss              | 14.539797   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029891783 |\n",
      "| ent_coef_loss           | -1.6986125  |\n",
      "| entropy                 | 14.895342   |\n",
      "| episodes                | 2250        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 703         |\n",
      "| n_updates               | 218408      |\n",
      "| policy_loss             | -203.58427  |\n",
      "| qf1_loss                | 19.315155   |\n",
      "| qf2_loss                | 20.773777   |\n",
      "| time_elapsed            | 2604        |\n",
      "| total timesteps         | 218507      |\n",
      "| value_loss              | 14.031309   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030624768 |\n",
      "| ent_coef_loss           | -9.930386   |\n",
      "| entropy                 | 14.898289   |\n",
      "| episodes                | 2260        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 710         |\n",
      "| n_updates               | 220003      |\n",
      "| policy_loss             | -202.17464  |\n",
      "| qf1_loss                | 17.249542   |\n",
      "| qf2_loss                | 10.341377   |\n",
      "| time_elapsed            | 2621        |\n",
      "| total timesteps         | 220102      |\n",
      "| value_loss              | 9.886293    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030627973 |\n",
      "| ent_coef_loss           | 2.1574445   |\n",
      "| entropy                 | 13.746074   |\n",
      "| episodes                | 2270        |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 725         |\n",
      "| n_updates               | 221550      |\n",
      "| policy_loss             | -207.20677  |\n",
      "| qf1_loss                | 18.473686   |\n",
      "| qf2_loss                | 19.556282   |\n",
      "| time_elapsed            | 2638        |\n",
      "| total timesteps         | 221649      |\n",
      "| value_loss              | 21.330942   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030244274 |\n",
      "| ent_coef_loss           | -1.0537395  |\n",
      "| entropy                 | 14.82908    |\n",
      "| episodes                | 2280        |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 728         |\n",
      "| n_updates               | 222884      |\n",
      "| policy_loss             | -204.7322   |\n",
      "| qf1_loss                | 15.726856   |\n",
      "| qf2_loss                | 18.409979   |\n",
      "| time_elapsed            | 2653        |\n",
      "| total timesteps         | 222983      |\n",
      "| value_loss              | 12.535695   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031017147 |\n",
      "| ent_coef_loss           | 1.6126572   |\n",
      "| entropy                 | 14.289879   |\n",
      "| episodes                | 2290        |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 730         |\n",
      "| n_updates               | 224425      |\n",
      "| policy_loss             | -191.27449  |\n",
      "| qf1_loss                | 13.776123   |\n",
      "| qf2_loss                | 11.410454   |\n",
      "| time_elapsed            | 2670        |\n",
      "| total timesteps         | 224524      |\n",
      "| value_loss              | 19.463537   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03154635 |\n",
      "| ent_coef_loss           | 10.361381  |\n",
      "| entropy                 | 14.272766  |\n",
      "| episodes                | 2300       |\n",
      "| fps                     | 84         |\n",
      "| mean 100 episode reward | 754        |\n",
      "| n_updates               | 225901     |\n",
      "| policy_loss             | -203.60127 |\n",
      "| qf1_loss                | 27.293266  |\n",
      "| qf2_loss                | 21.999287  |\n",
      "| time_elapsed            | 2685       |\n",
      "| total timesteps         | 226000     |\n",
      "| value_loss              | 9.676245   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.0310821  |\n",
      "| ent_coef_loss           | 1.768805   |\n",
      "| entropy                 | 14.539597  |\n",
      "| episodes                | 2310       |\n",
      "| fps                     | 84         |\n",
      "| mean 100 episode reward | 752        |\n",
      "| n_updates               | 227154     |\n",
      "| policy_loss             | -209.98457 |\n",
      "| qf1_loss                | 32.07435   |\n",
      "| qf2_loss                | 24.969383  |\n",
      "| time_elapsed            | 2698       |\n",
      "| total timesteps         | 227253     |\n",
      "| value_loss              | 13.245318  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030725878 |\n",
      "| ent_coef_loss           | -3.8751616  |\n",
      "| entropy                 | 15.19584    |\n",
      "| episodes                | 2320        |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 790         |\n",
      "| n_updates               | 229159      |\n",
      "| policy_loss             | -194.73636  |\n",
      "| qf1_loss                | 17.170021   |\n",
      "| qf2_loss                | 14.754725   |\n",
      "| time_elapsed            | 2719        |\n",
      "| total timesteps         | 229258      |\n",
      "| value_loss              | 5.9511986   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031184362 |\n",
      "| ent_coef_loss           | -2.227676   |\n",
      "| entropy                 | 14.653955   |\n",
      "| episodes                | 2330        |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 793         |\n",
      "| n_updates               | 231108      |\n",
      "| policy_loss             | -196.355    |\n",
      "| qf1_loss                | 10.599629   |\n",
      "| qf2_loss                | 9.957336    |\n",
      "| time_elapsed            | 2740        |\n",
      "| total timesteps         | 231207      |\n",
      "| value_loss              | 10.163292   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030060828 |\n",
      "| ent_coef_loss           | -1.2433388  |\n",
      "| entropy                 | 13.883796   |\n",
      "| episodes                | 2340        |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 799         |\n",
      "| n_updates               | 232735      |\n",
      "| policy_loss             | -219.7012   |\n",
      "| qf1_loss                | 23.122093   |\n",
      "| qf2_loss                | 29.898134   |\n",
      "| time_elapsed            | 2758        |\n",
      "| total timesteps         | 232834      |\n",
      "| value_loss              | 18.17745    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.032047678 |\n",
      "| ent_coef_loss           | -0.2857238  |\n",
      "| entropy                 | 14.773907   |\n",
      "| episodes                | 2350        |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 787         |\n",
      "| n_updates               | 233971      |\n",
      "| policy_loss             | -202.5552   |\n",
      "| qf1_loss                | 21.652813   |\n",
      "| qf2_loss                | 23.207275   |\n",
      "| time_elapsed            | 2771        |\n",
      "| total timesteps         | 234070      |\n",
      "| value_loss              | 19.748571   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031414926 |\n",
      "| ent_coef_loss           | 6.5624857   |\n",
      "| entropy                 | 13.967148   |\n",
      "| episodes                | 2360        |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 827         |\n",
      "| n_updates               | 236389      |\n",
      "| policy_loss             | -190.88489  |\n",
      "| qf1_loss                | 13.033174   |\n",
      "| qf2_loss                | 10.513069   |\n",
      "| time_elapsed            | 2797        |\n",
      "| total timesteps         | 236488      |\n",
      "| value_loss              | 16.958267   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031403366 |\n",
      "| ent_coef_loss           | -4.341761   |\n",
      "| entropy                 | 14.384861   |\n",
      "| episodes                | 2370        |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 842         |\n",
      "| n_updates               | 238292      |\n",
      "| policy_loss             | -192.4173   |\n",
      "| qf1_loss                | 13.127241   |\n",
      "| qf2_loss                | 16.467644   |\n",
      "| time_elapsed            | 2820        |\n",
      "| total timesteps         | 238391      |\n",
      "| value_loss              | 8.567742    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031915095 |\n",
      "| ent_coef_loss           | -4.9190674  |\n",
      "| entropy                 | 14.789514   |\n",
      "| episodes                | 2380        |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 852         |\n",
      "| n_updates               | 239874      |\n",
      "| policy_loss             | -197.3899   |\n",
      "| qf1_loss                | 15.338716   |\n",
      "| qf2_loss                | 19.163437   |\n",
      "| time_elapsed            | 2837        |\n",
      "| total timesteps         | 239973      |\n",
      "| value_loss              | 7.282838    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031346947 |\n",
      "| ent_coef_loss           | -8.642336   |\n",
      "| entropy                 | 14.901524   |\n",
      "| episodes                | 2390        |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 860         |\n",
      "| n_updates               | 241555      |\n",
      "| policy_loss             | -171.83282  |\n",
      "| qf1_loss                | 12.755266   |\n",
      "| qf2_loss                | 21.044754   |\n",
      "| time_elapsed            | 2854        |\n",
      "| total timesteps         | 241654      |\n",
      "| value_loss              | 14.78702    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031372234 |\n",
      "| ent_coef_loss           | -5.607807   |\n",
      "| entropy                 | 14.747271   |\n",
      "| episodes                | 2400        |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 859         |\n",
      "| n_updates               | 242995      |\n",
      "| policy_loss             | -200.78441  |\n",
      "| qf1_loss                | 20.239109   |\n",
      "| qf2_loss                | 25.179226   |\n",
      "| time_elapsed            | 2869        |\n",
      "| total timesteps         | 243094      |\n",
      "| value_loss              | 18.584345   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03192368 |\n",
      "| ent_coef_loss           | 4.000783   |\n",
      "| entropy                 | 14.7119255 |\n",
      "| episodes                | 2410       |\n",
      "| fps                     | 84         |\n",
      "| mean 100 episode reward | 858        |\n",
      "| n_updates               | 244198     |\n",
      "| policy_loss             | -187.74475 |\n",
      "| qf1_loss                | 14.708235  |\n",
      "| qf2_loss                | 22.002277  |\n",
      "| time_elapsed            | 2881       |\n",
      "| total timesteps         | 244297     |\n",
      "| value_loss              | 16.05232   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.032517   |\n",
      "| ent_coef_loss           | 4.272448   |\n",
      "| entropy                 | 14.20905   |\n",
      "| episodes                | 2420       |\n",
      "| fps                     | 84         |\n",
      "| mean 100 episode reward | 828        |\n",
      "| n_updates               | 245524     |\n",
      "| policy_loss             | -230.96089 |\n",
      "| qf1_loss                | 22.683088  |\n",
      "| qf2_loss                | 18.599293  |\n",
      "| time_elapsed            | 2895       |\n",
      "| total timesteps         | 245623     |\n",
      "| value_loss              | 11.0971985 |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.032218896 |\n",
      "| ent_coef_loss           | -0.6245457  |\n",
      "| entropy                 | 14.801079   |\n",
      "| episodes                | 2430        |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 845         |\n",
      "| n_updates               | 247793      |\n",
      "| policy_loss             | -190.83281  |\n",
      "| qf1_loss                | 17.567049   |\n",
      "| qf2_loss                | 15.043467   |\n",
      "| time_elapsed            | 2918        |\n",
      "| total timesteps         | 247892      |\n",
      "| value_loss              | 17.750378   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03298024 |\n",
      "| ent_coef_loss           | -7.8043084 |\n",
      "| entropy                 | 14.733273  |\n",
      "| episodes                | 2440       |\n",
      "| fps                     | 84         |\n",
      "| mean 100 episode reward | 850        |\n",
      "| n_updates               | 249462     |\n",
      "| policy_loss             | -212.86653 |\n",
      "| qf1_loss                | 20.049725  |\n",
      "| qf2_loss                | 25.134403  |\n",
      "| time_elapsed            | 2936       |\n",
      "| total timesteps         | 249561     |\n",
      "| value_loss              | 13.59548   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.032664005 |\n",
      "| ent_coef_loss           | -6.3482857  |\n",
      "| entropy                 | 14.556084   |\n",
      "| episodes                | 2450        |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 865         |\n",
      "| n_updates               | 250971      |\n",
      "| policy_loss             | -214.38638  |\n",
      "| qf1_loss                | 23.664124   |\n",
      "| qf2_loss                | 21.019106   |\n",
      "| time_elapsed            | 2951        |\n",
      "| total timesteps         | 251070      |\n",
      "| value_loss              | 10.009308   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03279208 |\n",
      "| ent_coef_loss           | -6.8391733 |\n",
      "| entropy                 | 14.50598   |\n",
      "| episodes                | 2460       |\n",
      "| fps                     | 85         |\n",
      "| mean 100 episode reward | 840        |\n",
      "| n_updates               | 252896     |\n",
      "| policy_loss             | -207.15073 |\n",
      "| qf1_loss                | 17.124123  |\n",
      "| qf2_loss                | 16.355843  |\n",
      "| time_elapsed            | 2972       |\n",
      "| total timesteps         | 252995     |\n",
      "| value_loss              | 12.478087  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.032974925 |\n",
      "| ent_coef_loss           | -9.028177   |\n",
      "| entropy                 | 14.859552   |\n",
      "| episodes                | 2470        |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 828         |\n",
      "| n_updates               | 254522      |\n",
      "| policy_loss             | -214.19159  |\n",
      "| qf1_loss                | 24.757595   |\n",
      "| qf2_loss                | 23.523624   |\n",
      "| time_elapsed            | 2991        |\n",
      "| total timesteps         | 254621      |\n",
      "| value_loss              | 13.049879   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03169588 |\n",
      "| ent_coef_loss           | 8.472141   |\n",
      "| entropy                 | 14.012999  |\n",
      "| episodes                | 2480       |\n",
      "| fps                     | 85         |\n",
      "| mean 100 episode reward | 845        |\n",
      "| n_updates               | 256431     |\n",
      "| policy_loss             | -206.37323 |\n",
      "| qf1_loss                | 14.906103  |\n",
      "| qf2_loss                | 16.658484  |\n",
      "| time_elapsed            | 3011       |\n",
      "| total timesteps         | 256530     |\n",
      "| value_loss              | 25.834759  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.034261048 |\n",
      "| ent_coef_loss           | 1.6934528   |\n",
      "| entropy                 | 14.779165   |\n",
      "| episodes                | 2490        |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 829         |\n",
      "| n_updates               | 257789      |\n",
      "| policy_loss             | -235.39273  |\n",
      "| qf1_loss                | 14.634723   |\n",
      "| qf2_loss                | 22.302074   |\n",
      "| time_elapsed            | 3027        |\n",
      "| total timesteps         | 257888      |\n",
      "| value_loss              | 18.339443   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.032511357 |\n",
      "| ent_coef_loss           | 0.22655153  |\n",
      "| entropy                 | 13.628399   |\n",
      "| episodes                | 2500        |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 838         |\n",
      "| n_updates               | 259483      |\n",
      "| policy_loss             | -209.65994  |\n",
      "| qf1_loss                | 20.560204   |\n",
      "| qf2_loss                | 22.072634   |\n",
      "| time_elapsed            | 3045        |\n",
      "| total timesteps         | 259582      |\n",
      "| value_loss              | 12.510516   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031121481 |\n",
      "| ent_coef_loss           | -3.620656   |\n",
      "| entropy                 | 14.6409855  |\n",
      "| episodes                | 2510        |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 903         |\n",
      "| n_updates               | 262010      |\n",
      "| policy_loss             | -204.04498  |\n",
      "| qf1_loss                | 17.549488   |\n",
      "| qf2_loss                | 23.06605    |\n",
      "| time_elapsed            | 3075        |\n",
      "| total timesteps         | 262109      |\n",
      "| value_loss              | 14.653355   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.032740194 |\n",
      "| ent_coef_loss           | -3.071032   |\n",
      "| entropy                 | 14.036766   |\n",
      "| episodes                | 2520        |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 936         |\n",
      "| n_updates               | 264049      |\n",
      "| policy_loss             | -203.24353  |\n",
      "| qf1_loss                | 22.914272   |\n",
      "| qf2_loss                | 18.540913   |\n",
      "| time_elapsed            | 3096        |\n",
      "| total timesteps         | 264148      |\n",
      "| value_loss              | 17.4897     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.032189965 |\n",
      "| ent_coef_loss           | 0.44049275  |\n",
      "| entropy                 | 13.859234   |\n",
      "| episodes                | 2530        |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 936         |\n",
      "| n_updates               | 266337      |\n",
      "| policy_loss             | -218.85466  |\n",
      "| qf1_loss                | 24.875494   |\n",
      "| qf2_loss                | 19.659363   |\n",
      "| time_elapsed            | 3120        |\n",
      "| total timesteps         | 266436      |\n",
      "| value_loss              | 15.573429   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03316908 |\n",
      "| ent_coef_loss           | 1.6169822  |\n",
      "| entropy                 | 14.271088  |\n",
      "| episodes                | 2540       |\n",
      "| fps                     | 85         |\n",
      "| mean 100 episode reward | 957        |\n",
      "| n_updates               | 268445     |\n",
      "| policy_loss             | -220.30917 |\n",
      "| qf1_loss                | 24.990728  |\n",
      "| qf2_loss                | 18.818764  |\n",
      "| time_elapsed            | 3142       |\n",
      "| total timesteps         | 268544     |\n",
      "| value_loss              | 11.520169  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.032159988 |\n",
      "| ent_coef_loss           | -1.7820938  |\n",
      "| entropy                 | 14.3030815  |\n",
      "| episodes                | 2550        |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 974         |\n",
      "| n_updates               | 270309      |\n",
      "| policy_loss             | -214.52289  |\n",
      "| qf1_loss                | 25.074203   |\n",
      "| qf2_loss                | 19.662752   |\n",
      "| time_elapsed            | 3161        |\n",
      "| total timesteps         | 270408      |\n",
      "| value_loss              | 9.517488    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03247468 |\n",
      "| ent_coef_loss           | 1.150799   |\n",
      "| entropy                 | 13.779242  |\n",
      "| episodes                | 2560       |\n",
      "| fps                     | 85         |\n",
      "| mean 100 episode reward | 1.03e+03   |\n",
      "| n_updates               | 273324     |\n",
      "| policy_loss             | -214.77759 |\n",
      "| qf1_loss                | 17.806011  |\n",
      "| qf2_loss                | 20.82716   |\n",
      "| time_elapsed            | 3192       |\n",
      "| total timesteps         | 273423     |\n",
      "| value_loss              | 9.587427   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03396496 |\n",
      "| ent_coef_loss           | -6.0377045 |\n",
      "| entropy                 | 15.28479   |\n",
      "| episodes                | 2570       |\n",
      "| fps                     | 85         |\n",
      "| mean 100 episode reward | 1.06e+03   |\n",
      "| n_updates               | 275561     |\n",
      "| policy_loss             | -230.72662 |\n",
      "| qf1_loss                | 16.250908  |\n",
      "| qf2_loss                | 18.265858  |\n",
      "| time_elapsed            | 3215       |\n",
      "| total timesteps         | 275660     |\n",
      "| value_loss              | 10.537747  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.033368852 |\n",
      "| ent_coef_loss           | -5.9048686  |\n",
      "| entropy                 | 13.954583   |\n",
      "| episodes                | 2580        |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 1.08e+03    |\n",
      "| n_updates               | 277807      |\n",
      "| policy_loss             | -219.43326  |\n",
      "| qf1_loss                | 17.276121   |\n",
      "| qf2_loss                | 16.295212   |\n",
      "| time_elapsed            | 3239        |\n",
      "| total timesteps         | 277906      |\n",
      "| value_loss              | 12.421591   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03416965 |\n",
      "| ent_coef_loss           | 3.6600697  |\n",
      "| entropy                 | 14.111429  |\n",
      "| episodes                | 2590       |\n",
      "| fps                     | 85         |\n",
      "| mean 100 episode reward | 1.12e+03   |\n",
      "| n_updates               | 279953     |\n",
      "| policy_loss             | -204.82489 |\n",
      "| qf1_loss                | 20.388615  |\n",
      "| qf2_loss                | 15.817951  |\n",
      "| time_elapsed            | 3263       |\n",
      "| total timesteps         | 280052     |\n",
      "| value_loss              | 21.417343  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.033244934 |\n",
      "| ent_coef_loss           | -5.771246   |\n",
      "| entropy                 | 14.617327   |\n",
      "| episodes                | 2600        |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 1.15e+03    |\n",
      "| n_updates               | 282121      |\n",
      "| policy_loss             | -204.91953  |\n",
      "| qf1_loss                | 22.628052   |\n",
      "| qf2_loss                | 20.136738   |\n",
      "| time_elapsed            | 3288        |\n",
      "| total timesteps         | 282220      |\n",
      "| value_loss              | 11.199917   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.033204462 |\n",
      "| ent_coef_loss           | -4.409906   |\n",
      "| entropy                 | 14.352977   |\n",
      "| episodes                | 2610        |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 1.14e+03    |\n",
      "| n_updates               | 284285      |\n",
      "| policy_loss             | -228.30515  |\n",
      "| qf1_loss                | 15.729067   |\n",
      "| qf2_loss                | 14.471083   |\n",
      "| time_elapsed            | 3310        |\n",
      "| total timesteps         | 284384      |\n",
      "| value_loss              | 15.70075    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03464734 |\n",
      "| ent_coef_loss           | 2.9685683  |\n",
      "| entropy                 | 13.7981    |\n",
      "| episodes                | 2620       |\n",
      "| fps                     | 85         |\n",
      "| mean 100 episode reward | 1.14e+03   |\n",
      "| n_updates               | 286279     |\n",
      "| policy_loss             | -230.94188 |\n",
      "| qf1_loss                | 45.080097  |\n",
      "| qf2_loss                | 25.467758  |\n",
      "| time_elapsed            | 3330       |\n",
      "| total timesteps         | 286378     |\n",
      "| value_loss              | 58.886726  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035411496 |\n",
      "| ent_coef_loss           | 3.7423148   |\n",
      "| entropy                 | 13.94529    |\n",
      "| episodes                | 2630        |\n",
      "| fps                     | 86          |\n",
      "| mean 100 episode reward | 1.12e+03    |\n",
      "| n_updates               | 288247      |\n",
      "| policy_loss             | -204.18893  |\n",
      "| qf1_loss                | 15.365349   |\n",
      "| qf2_loss                | 13.346051   |\n",
      "| time_elapsed            | 3351        |\n",
      "| total timesteps         | 288346      |\n",
      "| value_loss              | 14.806957   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.034905307 |\n",
      "| ent_coef_loss           | -2.560594   |\n",
      "| entropy                 | 14.517075   |\n",
      "| episodes                | 2640        |\n",
      "| fps                     | 86          |\n",
      "| mean 100 episode reward | 1.15e+03    |\n",
      "| n_updates               | 291079      |\n",
      "| policy_loss             | -229.22443  |\n",
      "| qf1_loss                | 24.806969   |\n",
      "| qf2_loss                | 26.414059   |\n",
      "| time_elapsed            | 3380        |\n",
      "| total timesteps         | 291178      |\n",
      "| value_loss              | 16.897404   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.03426623  |\n",
      "| ent_coef_loss           | -0.13562179 |\n",
      "| entropy                 | 14.237202   |\n",
      "| episodes                | 2650        |\n",
      "| fps                     | 86          |\n",
      "| mean 100 episode reward | 1.21e+03    |\n",
      "| n_updates               | 294137      |\n",
      "| policy_loss             | -247.68839  |\n",
      "| qf1_loss                | 18.853203   |\n",
      "| qf2_loss                | 13.486107   |\n",
      "| time_elapsed            | 3415        |\n",
      "| total timesteps         | 294236      |\n",
      "| value_loss              | 16.205482   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.034599066 |\n",
      "| ent_coef_loss           | 16.332607   |\n",
      "| entropy                 | 13.601641   |\n",
      "| episodes                | 2660        |\n",
      "| fps                     | 86          |\n",
      "| mean 100 episode reward | 1.2e+03     |\n",
      "| n_updates               | 296913      |\n",
      "| policy_loss             | -255.04776  |\n",
      "| qf1_loss                | 29.187513   |\n",
      "| qf2_loss                | 29.622807   |\n",
      "| time_elapsed            | 3445        |\n",
      "| total timesteps         | 297012      |\n",
      "| value_loss              | 11.357231   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.032544184 |\n",
      "| ent_coef_loss           | -10.303692  |\n",
      "| entropy                 | 14.269972   |\n",
      "| episodes                | 2670        |\n",
      "| fps                     | 86          |\n",
      "| mean 100 episode reward | 1.17e+03    |\n",
      "| n_updates               | 298703      |\n",
      "| policy_loss             | -220.15546  |\n",
      "| qf1_loss                | 28.391464   |\n",
      "| qf2_loss                | 35.22182    |\n",
      "| time_elapsed            | 3464        |\n",
      "| total timesteps         | 298802      |\n",
      "| value_loss              | 12.403453   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.033783626 |\n",
      "| ent_coef_loss           | -12.221984  |\n",
      "| entropy                 | 14.347954   |\n",
      "| episodes                | 2680        |\n",
      "| fps                     | 86          |\n",
      "| mean 100 episode reward | 1.18e+03    |\n",
      "| n_updates               | 301189      |\n",
      "| policy_loss             | -223.29439  |\n",
      "| qf1_loss                | 17.710976   |\n",
      "| qf2_loss                | 23.054068   |\n",
      "| time_elapsed            | 3489        |\n",
      "| total timesteps         | 301288      |\n",
      "| value_loss              | 13.968718   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.033843245 |\n",
      "| ent_coef_loss           | 4.2181816   |\n",
      "| entropy                 | 13.635207   |\n",
      "| episodes                | 2690        |\n",
      "| fps                     | 86          |\n",
      "| mean 100 episode reward | 1.19e+03    |\n",
      "| n_updates               | 303552      |\n",
      "| policy_loss             | -220.97488  |\n",
      "| qf1_loss                | 18.861025   |\n",
      "| qf2_loss                | 21.315392   |\n",
      "| time_elapsed            | 3519        |\n",
      "| total timesteps         | 303651      |\n",
      "| value_loss              | 10.559311   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035186935 |\n",
      "| ent_coef_loss           | 5.887736    |\n",
      "| entropy                 | 14.3312435  |\n",
      "| episodes                | 2700        |\n",
      "| fps                     | 86          |\n",
      "| mean 100 episode reward | 1.2e+03     |\n",
      "| n_updates               | 305842      |\n",
      "| policy_loss             | -211.78476  |\n",
      "| qf1_loss                | 26.968607   |\n",
      "| qf2_loss                | 31.854652   |\n",
      "| time_elapsed            | 3549        |\n",
      "| total timesteps         | 305941      |\n",
      "| value_loss              | 45.0279     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.034045786 |\n",
      "| ent_coef_loss           | -11.472035  |\n",
      "| entropy                 | 14.692821   |\n",
      "| episodes                | 2710        |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 1.25e+03    |\n",
      "| n_updates               | 309027      |\n",
      "| policy_loss             | -209.50546  |\n",
      "| qf1_loss                | 16.537405   |\n",
      "| qf2_loss                | 14.720251   |\n",
      "| time_elapsed            | 3595        |\n",
      "| total timesteps         | 309126      |\n",
      "| value_loss              | 11.277486   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.034528576 |\n",
      "| ent_coef_loss           | -4.2728157  |\n",
      "| entropy                 | 14.306927   |\n",
      "| episodes                | 2720        |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 1.28e+03    |\n",
      "| n_updates               | 311481      |\n",
      "| policy_loss             | -251.03366  |\n",
      "| qf1_loss                | 27.327152   |\n",
      "| qf2_loss                | 26.424257   |\n",
      "| time_elapsed            | 3626        |\n",
      "| total timesteps         | 311580      |\n",
      "| value_loss              | 14.7596855  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.034049124 |\n",
      "| ent_coef_loss           | 2.4542994   |\n",
      "| entropy                 | 14.638479   |\n",
      "| episodes                | 2730        |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 1.3e+03     |\n",
      "| n_updates               | 314026      |\n",
      "| policy_loss             | -242.56622  |\n",
      "| qf1_loss                | 21.266342   |\n",
      "| qf2_loss                | 29.374266   |\n",
      "| time_elapsed            | 3660        |\n",
      "| total timesteps         | 314125      |\n",
      "| value_loss              | 12.878658   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035443347 |\n",
      "| ent_coef_loss           | 1.296416    |\n",
      "| entropy                 | 14.118126   |\n",
      "| episodes                | 2740        |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 1.31e+03    |\n",
      "| n_updates               | 316832      |\n",
      "| policy_loss             | -250.76245  |\n",
      "| qf1_loss                | 23.818066   |\n",
      "| qf2_loss                | 21.024256   |\n",
      "| time_elapsed            | 3695        |\n",
      "| total timesteps         | 316931      |\n",
      "| value_loss              | 10.731155   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03451925 |\n",
      "| ent_coef_loss           | -6.885414  |\n",
      "| entropy                 | 14.260357  |\n",
      "| episodes                | 2750       |\n",
      "| fps                     | 85         |\n",
      "| mean 100 episode reward | 1.3e+03    |\n",
      "| n_updates               | 319721     |\n",
      "| policy_loss             | -228.64653 |\n",
      "| qf1_loss                | 20.393555  |\n",
      "| qf2_loss                | 22.954681  |\n",
      "| time_elapsed            | 3733       |\n",
      "| total timesteps         | 319820     |\n",
      "| value_loss              | 16.171204  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.0349224  |\n",
      "| ent_coef_loss           | -5.019112  |\n",
      "| entropy                 | 14.572037  |\n",
      "| episodes                | 2760       |\n",
      "| fps                     | 85         |\n",
      "| mean 100 episode reward | 1.29e+03   |\n",
      "| n_updates               | 322215     |\n",
      "| policy_loss             | -265.51788 |\n",
      "| qf1_loss                | 16.92776   |\n",
      "| qf2_loss                | 15.26357   |\n",
      "| time_elapsed            | 3766       |\n",
      "| total timesteps         | 322314     |\n",
      "| value_loss              | 14.633429  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03574328 |\n",
      "| ent_coef_loss           | 5.0928965  |\n",
      "| entropy                 | 14.372396  |\n",
      "| episodes                | 2770       |\n",
      "| fps                     | 85         |\n",
      "| mean 100 episode reward | 1.36e+03   |\n",
      "| n_updates               | 325454     |\n",
      "| policy_loss             | -231.88821 |\n",
      "| qf1_loss                | 19.032368  |\n",
      "| qf2_loss                | 18.973923  |\n",
      "| time_elapsed            | 3806       |\n",
      "| total timesteps         | 325553     |\n",
      "| value_loss              | 13.3431    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036019597 |\n",
      "| ent_coef_loss           | 2.086008    |\n",
      "| entropy                 | 14.448618   |\n",
      "| episodes                | 2780        |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 1.36e+03    |\n",
      "| n_updates               | 328004      |\n",
      "| policy_loss             | -227.6584   |\n",
      "| qf1_loss                | 29.545311   |\n",
      "| qf2_loss                | 36.73671    |\n",
      "| time_elapsed            | 3839        |\n",
      "| total timesteps         | 328103      |\n",
      "| value_loss              | 24.547993   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03334298 |\n",
      "| ent_coef_loss           | 5.9019065  |\n",
      "| entropy                 | 13.919022  |\n",
      "| episodes                | 2790       |\n",
      "| fps                     | 85         |\n",
      "| mean 100 episode reward | 1.37e+03   |\n",
      "| n_updates               | 330449     |\n",
      "| policy_loss             | -218.93591 |\n",
      "| qf1_loss                | 30.127491  |\n",
      "| qf2_loss                | 26.280111  |\n",
      "| time_elapsed            | 3873       |\n",
      "| total timesteps         | 330548     |\n",
      "| value_loss              | 22.197521  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.034523785 |\n",
      "| ent_coef_loss           | -4.0536857  |\n",
      "| entropy                 | 14.376237   |\n",
      "| episodes                | 2800        |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 1.34e+03    |\n",
      "| n_updates               | 332192      |\n",
      "| policy_loss             | -245.40897  |\n",
      "| qf1_loss                | 17.970995   |\n",
      "| qf2_loss                | 11.861379   |\n",
      "| time_elapsed            | 3895        |\n",
      "| total timesteps         | 332291      |\n",
      "| value_loss              | 36.458885   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03479983 |\n",
      "| ent_coef_loss           | -4.7279224 |\n",
      "| entropy                 | 14.335835  |\n",
      "| episodes                | 2810       |\n",
      "| fps                     | 85         |\n",
      "| mean 100 episode reward | 1.31e+03   |\n",
      "| n_updates               | 334870     |\n",
      "| policy_loss             | -213.58499 |\n",
      "| qf1_loss                | 34.661484  |\n",
      "| qf2_loss                | 20.744183  |\n",
      "| time_elapsed            | 3924       |\n",
      "| total timesteps         | 334969     |\n",
      "| value_loss              | 18.474987  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035209145 |\n",
      "| ent_coef_loss           | 4.1890206   |\n",
      "| entropy                 | 13.614674   |\n",
      "| episodes                | 2820        |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 1.32e+03    |\n",
      "| n_updates               | 337548      |\n",
      "| policy_loss             | -247.50044  |\n",
      "| qf1_loss                | 28.508299   |\n",
      "| qf2_loss                | 36.21926    |\n",
      "| time_elapsed            | 3952        |\n",
      "| total timesteps         | 337647      |\n",
      "| value_loss              | 24.89613    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.033804946 |\n",
      "| ent_coef_loss           | -4.6758747  |\n",
      "| entropy                 | 14.346809   |\n",
      "| episodes                | 2830        |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 1.34e+03    |\n",
      "| n_updates               | 340408      |\n",
      "| policy_loss             | -234.64548  |\n",
      "| qf1_loss                | 14.559048   |\n",
      "| qf2_loss                | 18.83892    |\n",
      "| time_elapsed            | 3982        |\n",
      "| total timesteps         | 340507      |\n",
      "| value_loss              | 15.494921   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.0359645  |\n",
      "| ent_coef_loss           | 4.170557   |\n",
      "| entropy                 | 14.245802  |\n",
      "| episodes                | 2840       |\n",
      "| fps                     | 85         |\n",
      "| mean 100 episode reward | 1.33e+03   |\n",
      "| n_updates               | 343035     |\n",
      "| policy_loss             | -271.62372 |\n",
      "| qf1_loss                | 22.113914  |\n",
      "| qf2_loss                | 33.202614  |\n",
      "| time_elapsed            | 4009       |\n",
      "| total timesteps         | 343134     |\n",
      "| value_loss              | 23.136925  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.034556594 |\n",
      "| ent_coef_loss           | -0.6875967  |\n",
      "| entropy                 | 14.108434   |\n",
      "| episodes                | 2850        |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 1.36e+03    |\n",
      "| n_updates               | 346486      |\n",
      "| policy_loss             | -225.6761   |\n",
      "| qf1_loss                | 19.449348   |\n",
      "| qf2_loss                | 18.701273   |\n",
      "| time_elapsed            | 4044        |\n",
      "| total timesteps         | 346585      |\n",
      "| value_loss              | 15.877823   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035687864 |\n",
      "| ent_coef_loss           | 8.318498    |\n",
      "| entropy                 | 13.253987   |\n",
      "| episodes                | 2860        |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 1.36e+03    |\n",
      "| n_updates               | 349085      |\n",
      "| policy_loss             | -272.80133  |\n",
      "| qf1_loss                | 27.232635   |\n",
      "| qf2_loss                | 23.936611   |\n",
      "| time_elapsed            | 4071        |\n",
      "| total timesteps         | 349184      |\n",
      "| value_loss              | 16.201168   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03544226 |\n",
      "| ent_coef_loss           | 2.3151364  |\n",
      "| entropy                 | 14.032547  |\n",
      "| episodes                | 2870       |\n",
      "| fps                     | 85         |\n",
      "| mean 100 episode reward | 1.32e+03   |\n",
      "| n_updates               | 351556     |\n",
      "| policy_loss             | -261.39484 |\n",
      "| qf1_loss                | 19.124615  |\n",
      "| qf2_loss                | 27.353382  |\n",
      "| time_elapsed            | 4097       |\n",
      "| total timesteps         | 351655     |\n",
      "| value_loss              | 11.358231  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.0356659  |\n",
      "| ent_coef_loss           | -1.3157396 |\n",
      "| entropy                 | 14.046041  |\n",
      "| episodes                | 2880       |\n",
      "| fps                     | 85         |\n",
      "| mean 100 episode reward | 1.34e+03   |\n",
      "| n_updates               | 354391     |\n",
      "| policy_loss             | -235.36436 |\n",
      "| qf1_loss                | 16.477362  |\n",
      "| qf2_loss                | 16.734568  |\n",
      "| time_elapsed            | 4126       |\n",
      "| total timesteps         | 354490     |\n",
      "| value_loss              | 12.674389  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.037399463 |\n",
      "| ent_coef_loss           | -15.9124    |\n",
      "| entropy                 | 15.190786   |\n",
      "| episodes                | 2890        |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 1.38e+03    |\n",
      "| n_updates               | 357462      |\n",
      "| policy_loss             | -240.8618   |\n",
      "| qf1_loss                | 21.4222     |\n",
      "| qf2_loss                | 22.727066   |\n",
      "| time_elapsed            | 4158        |\n",
      "| total timesteps         | 357561      |\n",
      "| value_loss              | 22.084003   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03527788 |\n",
      "| ent_coef_loss           | 4.313955   |\n",
      "| entropy                 | 14.219479  |\n",
      "| episodes                | 2900       |\n",
      "| fps                     | 86         |\n",
      "| mean 100 episode reward | 1.46e+03   |\n",
      "| n_updates               | 360880     |\n",
      "| policy_loss             | -244.93013 |\n",
      "| qf1_loss                | 26.793758  |\n",
      "| qf2_loss                | 22.710684  |\n",
      "| time_elapsed            | 4193       |\n",
      "| total timesteps         | 360979     |\n",
      "| value_loss              | 16.059952  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.034787558 |\n",
      "| ent_coef_loss           | -0.5971302  |\n",
      "| entropy                 | 13.902368   |\n",
      "| episodes                | 2910        |\n",
      "| fps                     | 86          |\n",
      "| mean 100 episode reward | 1.45e+03    |\n",
      "| n_updates               | 363330      |\n",
      "| policy_loss             | -278.96753  |\n",
      "| qf1_loss                | 18.385681   |\n",
      "| qf2_loss                | 19.23883    |\n",
      "| time_elapsed            | 4218        |\n",
      "| total timesteps         | 363429      |\n",
      "| value_loss              | 25.891155   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036203906 |\n",
      "| ent_coef_loss           | 2.1790977   |\n",
      "| entropy                 | 14.20002    |\n",
      "| episodes                | 2920        |\n",
      "| fps                     | 86          |\n",
      "| mean 100 episode reward | 1.47e+03    |\n",
      "| n_updates               | 366308      |\n",
      "| policy_loss             | -266.22943  |\n",
      "| qf1_loss                | 10.512178   |\n",
      "| qf2_loss                | 13.432165   |\n",
      "| time_elapsed            | 4249        |\n",
      "| total timesteps         | 366407      |\n",
      "| value_loss              | 19.23719    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036188725 |\n",
      "| ent_coef_loss           | -7.871543   |\n",
      "| entropy                 | 14.456811   |\n",
      "| episodes                | 2930        |\n",
      "| fps                     | 86          |\n",
      "| mean 100 episode reward | 1.45e+03    |\n",
      "| n_updates               | 368890      |\n",
      "| policy_loss             | -234.40787  |\n",
      "| qf1_loss                | 27.195326   |\n",
      "| qf2_loss                | 23.068588   |\n",
      "| time_elapsed            | 4276        |\n",
      "| total timesteps         | 368989      |\n",
      "| value_loss              | 11.444147   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035535645 |\n",
      "| ent_coef_loss           | 1.1345552   |\n",
      "| entropy                 | 14.014536   |\n",
      "| episodes                | 2940        |\n",
      "| fps                     | 86          |\n",
      "| mean 100 episode reward | 1.5e+03     |\n",
      "| n_updates               | 372489      |\n",
      "| policy_loss             | -262.8407   |\n",
      "| qf1_loss                | 24.209064   |\n",
      "| qf2_loss                | 21.318583   |\n",
      "| time_elapsed            | 4313        |\n",
      "| total timesteps         | 372588      |\n",
      "| value_loss              | 26.630486   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03546743 |\n",
      "| ent_coef_loss           | 2.1900826  |\n",
      "| entropy                 | 13.8145485 |\n",
      "| episodes                | 2950       |\n",
      "| fps                     | 86         |\n",
      "| mean 100 episode reward | 1.47e+03   |\n",
      "| n_updates               | 375130     |\n",
      "| policy_loss             | -266.07532 |\n",
      "| qf1_loss                | 38.165344  |\n",
      "| qf2_loss                | 31.82483   |\n",
      "| time_elapsed            | 4340       |\n",
      "| total timesteps         | 375229     |\n",
      "| value_loss              | 21.679955  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036591947 |\n",
      "| ent_coef_loss           | 4.2992673   |\n",
      "| entropy                 | 14.38721    |\n",
      "| episodes                | 2960        |\n",
      "| fps                     | 86          |\n",
      "| mean 100 episode reward | 1.45e+03    |\n",
      "| n_updates               | 377421      |\n",
      "| policy_loss             | -266.05396  |\n",
      "| qf1_loss                | 24.646019   |\n",
      "| qf2_loss                | 29.14925    |\n",
      "| time_elapsed            | 4364        |\n",
      "| total timesteps         | 377520      |\n",
      "| value_loss              | 15.000055   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035621412 |\n",
      "| ent_coef_loss           | 2.4118662   |\n",
      "| entropy                 | 13.872871   |\n",
      "| episodes                | 2970        |\n",
      "| fps                     | 86          |\n",
      "| mean 100 episode reward | 1.45e+03    |\n",
      "| n_updates               | 379890      |\n",
      "| policy_loss             | -249.63753  |\n",
      "| qf1_loss                | 46.289955   |\n",
      "| qf2_loss                | 38.49798    |\n",
      "| time_elapsed            | 4389        |\n",
      "| total timesteps         | 379989      |\n",
      "| value_loss              | 20.736452   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035701744 |\n",
      "| ent_coef_loss           | -11.830394  |\n",
      "| entropy                 | 14.526136   |\n",
      "| episodes                | 2980        |\n",
      "| fps                     | 86          |\n",
      "| mean 100 episode reward | 1.41e+03    |\n",
      "| n_updates               | 382057      |\n",
      "| policy_loss             | -266.3987   |\n",
      "| qf1_loss                | 21.178589   |\n",
      "| qf2_loss                | 28.248735   |\n",
      "| time_elapsed            | 4412        |\n",
      "| total timesteps         | 382156      |\n",
      "| value_loss              | 21.21868    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036817398 |\n",
      "| ent_coef_loss           | -2.8988767  |\n",
      "| entropy                 | 14.650793   |\n",
      "| episodes                | 2990        |\n",
      "| fps                     | 86          |\n",
      "| mean 100 episode reward | 1.45e+03    |\n",
      "| n_updates               | 385908      |\n",
      "| policy_loss             | -245.66144  |\n",
      "| qf1_loss                | 24.356163   |\n",
      "| qf2_loss                | 27.382185   |\n",
      "| time_elapsed            | 4451        |\n",
      "| total timesteps         | 386007      |\n",
      "| value_loss              | 21.146118   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03557991 |\n",
      "| ent_coef_loss           | 11.05124   |\n",
      "| entropy                 | 13.709602  |\n",
      "| episodes                | 3000       |\n",
      "| fps                     | 86         |\n",
      "| mean 100 episode reward | 1.42e+03   |\n",
      "| n_updates               | 388695     |\n",
      "| policy_loss             | -252.17758 |\n",
      "| qf1_loss                | 43.397682  |\n",
      "| qf2_loss                | 41.258636  |\n",
      "| time_elapsed            | 4480       |\n",
      "| total timesteps         | 388794     |\n",
      "| value_loss              | 39.501205  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035019908 |\n",
      "| ent_coef_loss           | -5.1553345  |\n",
      "| entropy                 | 13.97574    |\n",
      "| episodes                | 3010        |\n",
      "| fps                     | 86          |\n",
      "| mean 100 episode reward | 1.46e+03    |\n",
      "| n_updates               | 391903      |\n",
      "| policy_loss             | -279.3997   |\n",
      "| qf1_loss                | 16.622803   |\n",
      "| qf2_loss                | 18.859867   |\n",
      "| time_elapsed            | 4513        |\n",
      "| total timesteps         | 392002      |\n",
      "| value_loss              | 17.143492   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03516091 |\n",
      "| ent_coef_loss           | 4.1011167  |\n",
      "| entropy                 | 13.999865  |\n",
      "| episodes                | 3020       |\n",
      "| fps                     | 86         |\n",
      "| mean 100 episode reward | 1.45e+03   |\n",
      "| n_updates               | 394674     |\n",
      "| policy_loss             | -260.36853 |\n",
      "| qf1_loss                | 20.399239  |\n",
      "| qf2_loss                | 32.104214  |\n",
      "| time_elapsed            | 4541       |\n",
      "| total timesteps         | 394773     |\n",
      "| value_loss              | 31.492273  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036757685 |\n",
      "| ent_coef_loss           | -6.416581   |\n",
      "| entropy                 | 13.866131   |\n",
      "| episodes                | 3030        |\n",
      "| fps                     | 86          |\n",
      "| mean 100 episode reward | 1.47e+03    |\n",
      "| n_updates               | 397532      |\n",
      "| policy_loss             | -271.06213  |\n",
      "| qf1_loss                | 17.335743   |\n",
      "| qf2_loss                | 14.610231   |\n",
      "| time_elapsed            | 4571        |\n",
      "| total timesteps         | 397631      |\n",
      "| value_loss              | 13.245155   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.033969246 |\n",
      "| ent_coef_loss           | -2.0195885  |\n",
      "| entropy                 | 14.448246   |\n",
      "| episodes                | 3040        |\n",
      "| fps                     | 87          |\n",
      "| mean 100 episode reward | 1.44e+03    |\n",
      "| n_updates               | 400463      |\n",
      "| policy_loss             | -264.184    |\n",
      "| qf1_loss                | 14.678702   |\n",
      "| qf2_loss                | 17.2432     |\n",
      "| time_elapsed            | 4601        |\n",
      "| total timesteps         | 400562      |\n",
      "| value_loss              | 10.395016   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036458455 |\n",
      "| ent_coef_loss           | -0.7441914  |\n",
      "| entropy                 | 14.778381   |\n",
      "| episodes                | 3050        |\n",
      "| fps                     | 87          |\n",
      "| mean 100 episode reward | 1.51e+03    |\n",
      "| n_updates               | 404610      |\n",
      "| policy_loss             | -262.45834  |\n",
      "| qf1_loss                | 37.26213    |\n",
      "| qf2_loss                | 24.588411   |\n",
      "| time_elapsed            | 4643        |\n",
      "| total timesteps         | 404709      |\n",
      "| value_loss              | 22.679287   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03450198 |\n",
      "| ent_coef_loss           | 1.6437392  |\n",
      "| entropy                 | 13.888292  |\n",
      "| episodes                | 3060       |\n",
      "| fps                     | 87         |\n",
      "| mean 100 episode reward | 1.56e+03   |\n",
      "| n_updates               | 407864     |\n",
      "| policy_loss             | -240.77902 |\n",
      "| qf1_loss                | 25.487152  |\n",
      "| qf2_loss                | 28.80857   |\n",
      "| time_elapsed            | 4677       |\n",
      "| total timesteps         | 407963     |\n",
      "| value_loss              | 16.102144  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035842653 |\n",
      "| ent_coef_loss           | -13.896336  |\n",
      "| entropy                 | 14.401157   |\n",
      "| episodes                | 3070        |\n",
      "| fps                     | 87          |\n",
      "| mean 100 episode reward | 1.63e+03    |\n",
      "| n_updates               | 411640      |\n",
      "| policy_loss             | -267.6037   |\n",
      "| qf1_loss                | 30.665298   |\n",
      "| qf2_loss                | 22.124767   |\n",
      "| time_elapsed            | 4716        |\n",
      "| total timesteps         | 411739      |\n",
      "| value_loss              | 12.613925   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03697285 |\n",
      "| ent_coef_loss           | -4.5052214 |\n",
      "| entropy                 | 14.644793  |\n",
      "| episodes                | 3080       |\n",
      "| fps                     | 87         |\n",
      "| mean 100 episode reward | 1.69e+03   |\n",
      "| n_updates               | 414877     |\n",
      "| policy_loss             | -239.93    |\n",
      "| qf1_loss                | 24.728043  |\n",
      "| qf2_loss                | 23.252262  |\n",
      "| time_elapsed            | 4749       |\n",
      "| total timesteps         | 414976     |\n",
      "| value_loss              | 17.835152  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.037059188 |\n",
      "| ent_coef_loss           | 0.16613173  |\n",
      "| entropy                 | 14.280196   |\n",
      "| episodes                | 3090        |\n",
      "| fps                     | 87          |\n",
      "| mean 100 episode reward | 1.62e+03    |\n",
      "| n_updates               | 417362      |\n",
      "| policy_loss             | -274.7544   |\n",
      "| qf1_loss                | 24.873142   |\n",
      "| qf2_loss                | 28.246769   |\n",
      "| time_elapsed            | 4774        |\n",
      "| total timesteps         | 417461      |\n",
      "| value_loss              | 25.844715   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03626231 |\n",
      "| ent_coef_loss           | -2.0843368 |\n",
      "| entropy                 | 14.33119   |\n",
      "| episodes                | 3100       |\n",
      "| fps                     | 87         |\n",
      "| mean 100 episode reward | 1.64e+03   |\n",
      "| n_updates               | 420583     |\n",
      "| policy_loss             | -283.34845 |\n",
      "| qf1_loss                | 15.902502  |\n",
      "| qf2_loss                | 15.937313  |\n",
      "| time_elapsed            | 4808       |\n",
      "| total timesteps         | 420682     |\n",
      "| value_loss              | 12.873383  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.0364978  |\n",
      "| ent_coef_loss           | 0.7202244  |\n",
      "| entropy                 | 14.3160095 |\n",
      "| episodes                | 3110       |\n",
      "| fps                     | 87         |\n",
      "| mean 100 episode reward | 1.66e+03   |\n",
      "| n_updates               | 424255     |\n",
      "| policy_loss             | -282.98306 |\n",
      "| qf1_loss                | 27.047672  |\n",
      "| qf2_loss                | 20.782307  |\n",
      "| time_elapsed            | 4846       |\n",
      "| total timesteps         | 424354     |\n",
      "| value_loss              | 14.751756  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036959346 |\n",
      "| ent_coef_loss           | 2.1685243   |\n",
      "| entropy                 | 13.675584   |\n",
      "| episodes                | 3120        |\n",
      "| fps                     | 87          |\n",
      "| mean 100 episode reward | 1.64e+03    |\n",
      "| n_updates               | 426412      |\n",
      "| policy_loss             | -286.30136  |\n",
      "| qf1_loss                | 37.256756   |\n",
      "| qf2_loss                | 24.24198    |\n",
      "| time_elapsed            | 4867        |\n",
      "| total timesteps         | 426511      |\n",
      "| value_loss              | 17.485464   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035768785 |\n",
      "| ent_coef_loss           | 4.143008    |\n",
      "| entropy                 | 13.937021   |\n",
      "| episodes                | 3130        |\n",
      "| fps                     | 87          |\n",
      "| mean 100 episode reward | 1.69e+03    |\n",
      "| n_updates               | 430240      |\n",
      "| policy_loss             | -262.41327  |\n",
      "| qf1_loss                | 63.21901    |\n",
      "| qf2_loss                | 50.19799    |\n",
      "| time_elapsed            | 4907        |\n",
      "| total timesteps         | 430339      |\n",
      "| value_loss              | 43.217396   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03629561 |\n",
      "| ent_coef_loss           | 4.1929073  |\n",
      "| entropy                 | 14.20621   |\n",
      "| episodes                | 3140       |\n",
      "| fps                     | 87         |\n",
      "| mean 100 episode reward | 1.7e+03    |\n",
      "| n_updates               | 433405     |\n",
      "| policy_loss             | -269.48666 |\n",
      "| qf1_loss                | 32.38251   |\n",
      "| qf2_loss                | 35.36547   |\n",
      "| time_elapsed            | 4939       |\n",
      "| total timesteps         | 433504     |\n",
      "| value_loss              | 28.442936  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03659891 |\n",
      "| ent_coef_loss           | 3.5303354  |\n",
      "| entropy                 | 14.396297  |\n",
      "| episodes                | 3150       |\n",
      "| fps                     | 87         |\n",
      "| mean 100 episode reward | 1.65e+03   |\n",
      "| n_updates               | 436683     |\n",
      "| policy_loss             | -258.9734  |\n",
      "| qf1_loss                | 29.320137  |\n",
      "| qf2_loss                | 18.061218  |\n",
      "| time_elapsed            | 4973       |\n",
      "| total timesteps         | 436782     |\n",
      "| value_loss              | 15.152737  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036502752 |\n",
      "| ent_coef_loss           | 6.269856    |\n",
      "| entropy                 | 13.985421   |\n",
      "| episodes                | 3160        |\n",
      "| fps                     | 87          |\n",
      "| mean 100 episode reward | 1.67e+03    |\n",
      "| n_updates               | 440202      |\n",
      "| policy_loss             | -291.08835  |\n",
      "| qf1_loss                | 40.217354   |\n",
      "| qf2_loss                | 36.686966   |\n",
      "| time_elapsed            | 5009        |\n",
      "| total timesteps         | 440301      |\n",
      "| value_loss              | 19.504547   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036634047 |\n",
      "| ent_coef_loss           | -4.010417   |\n",
      "| entropy                 | 14.348999   |\n",
      "| episodes                | 3170        |\n",
      "| fps                     | 87          |\n",
      "| mean 100 episode reward | 1.61e+03    |\n",
      "| n_updates               | 442840      |\n",
      "| policy_loss             | -249.76491  |\n",
      "| qf1_loss                | 19.24148    |\n",
      "| qf2_loss                | 23.750559   |\n",
      "| time_elapsed            | 5036        |\n",
      "| total timesteps         | 442939      |\n",
      "| value_loss              | 17.29977    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035618287 |\n",
      "| ent_coef_loss           | 2.7916236   |\n",
      "| entropy                 | 14.32233    |\n",
      "| episodes                | 3180        |\n",
      "| fps                     | 88          |\n",
      "| mean 100 episode reward | 1.61e+03    |\n",
      "| n_updates               | 445966      |\n",
      "| policy_loss             | -266.41797  |\n",
      "| qf1_loss                | 29.68191    |\n",
      "| qf2_loss                | 29.956682   |\n",
      "| time_elapsed            | 5068        |\n",
      "| total timesteps         | 446065      |\n",
      "| value_loss              | 13.582044   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036730476 |\n",
      "| ent_coef_loss           | -0.59070086 |\n",
      "| entropy                 | 14.093685   |\n",
      "| episodes                | 3190        |\n",
      "| fps                     | 88          |\n",
      "| mean 100 episode reward | 1.61e+03    |\n",
      "| n_updates               | 448420      |\n",
      "| policy_loss             | -277.10123  |\n",
      "| qf1_loss                | 36.75096    |\n",
      "| qf2_loss                | 27.859465   |\n",
      "| time_elapsed            | 5093        |\n",
      "| total timesteps         | 448519      |\n",
      "| value_loss              | 31.603672   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035752844 |\n",
      "| ent_coef_loss           | 4.6272593   |\n",
      "| entropy                 | 14.015474   |\n",
      "| episodes                | 3200        |\n",
      "| fps                     | 88          |\n",
      "| mean 100 episode reward | 1.57e+03    |\n",
      "| n_updates               | 451013      |\n",
      "| policy_loss             | -257.2032   |\n",
      "| qf1_loss                | 28.820957   |\n",
      "| qf2_loss                | 30.104565   |\n",
      "| time_elapsed            | 5120        |\n",
      "| total timesteps         | 451112      |\n",
      "| value_loss              | 23.502928   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.03612297  |\n",
      "| ent_coef_loss           | -0.70642114 |\n",
      "| entropy                 | 13.933323   |\n",
      "| episodes                | 3210        |\n",
      "| fps                     | 88          |\n",
      "| mean 100 episode reward | 1.54e+03    |\n",
      "| n_updates               | 454000      |\n",
      "| policy_loss             | -288.7337   |\n",
      "| qf1_loss                | 31.402746   |\n",
      "| qf2_loss                | 39.623657   |\n",
      "| time_elapsed            | 5150        |\n",
      "| total timesteps         | 454099      |\n",
      "| value_loss              | 28.064095   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036087763 |\n",
      "| ent_coef_loss           | -2.4387102  |\n",
      "| entropy                 | 14.466444   |\n",
      "| episodes                | 3220        |\n",
      "| fps                     | 88          |\n",
      "| mean 100 episode reward | 1.61e+03    |\n",
      "| n_updates               | 457535      |\n",
      "| policy_loss             | -256.7561   |\n",
      "| qf1_loss                | 26.772812   |\n",
      "| qf2_loss                | 33.998222   |\n",
      "| time_elapsed            | 5187        |\n",
      "| total timesteps         | 457634      |\n",
      "| value_loss              | 21.037548   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035631962 |\n",
      "| ent_coef_loss           | -8.265778   |\n",
      "| entropy                 | 14.723995   |\n",
      "| episodes                | 3230        |\n",
      "| fps                     | 88          |\n",
      "| mean 100 episode reward | 1.59e+03    |\n",
      "| n_updates               | 461098      |\n",
      "| policy_loss             | -278.87183  |\n",
      "| qf1_loss                | 18.364628   |\n",
      "| qf2_loss                | 22.248426   |\n",
      "| time_elapsed            | 5224        |\n",
      "| total timesteps         | 461197      |\n",
      "| value_loss              | 9.309727    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03640184 |\n",
      "| ent_coef_loss           | 16.310787  |\n",
      "| entropy                 | 13.531922  |\n",
      "| episodes                | 3240       |\n",
      "| fps                     | 88         |\n",
      "| mean 100 episode reward | 1.58e+03   |\n",
      "| n_updates               | 463977     |\n",
      "| policy_loss             | -268.68542 |\n",
      "| qf1_loss                | 50.751724  |\n",
      "| qf2_loss                | 55.144867  |\n",
      "| time_elapsed            | 5254       |\n",
      "| total timesteps         | 464076     |\n",
      "| value_loss              | 26.344763  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03615773 |\n",
      "| ent_coef_loss           | -7.049009  |\n",
      "| entropy                 | 14.104278  |\n",
      "| episodes                | 3250       |\n",
      "| fps                     | 88         |\n",
      "| mean 100 episode reward | 1.58e+03   |\n",
      "| n_updates               | 467457     |\n",
      "| policy_loss             | -237.9208  |\n",
      "| qf1_loss                | 27.162855  |\n",
      "| qf2_loss                | 27.54255   |\n",
      "| time_elapsed            | 5290       |\n",
      "| total timesteps         | 467556     |\n",
      "| value_loss              | 22.72063   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.037483383 |\n",
      "| ent_coef_loss           | 1.0392596   |\n",
      "| entropy                 | 14.298502   |\n",
      "| episodes                | 3260        |\n",
      "| fps                     | 88          |\n",
      "| mean 100 episode reward | 1.62e+03    |\n",
      "| n_updates               | 471535      |\n",
      "| policy_loss             | -251.45934  |\n",
      "| qf1_loss                | 18.404839   |\n",
      "| qf2_loss                | 20.09607    |\n",
      "| time_elapsed            | 5332        |\n",
      "| total timesteps         | 471634      |\n",
      "| value_loss              | 21.696196   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035678267 |\n",
      "| ent_coef_loss           | 9.805456    |\n",
      "| entropy                 | 13.497698   |\n",
      "| episodes                | 3270        |\n",
      "| fps                     | 88          |\n",
      "| mean 100 episode reward | 1.62e+03    |\n",
      "| n_updates               | 474142      |\n",
      "| policy_loss             | -285.75345  |\n",
      "| qf1_loss                | 32.95546    |\n",
      "| qf2_loss                | 29.180332   |\n",
      "| time_elapsed            | 5359        |\n",
      "| total timesteps         | 474241      |\n",
      "| value_loss              | 29.411774   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03634601 |\n",
      "| ent_coef_loss           | -0.8967749 |\n",
      "| entropy                 | 14.137215  |\n",
      "| episodes                | 3280       |\n",
      "| fps                     | 88         |\n",
      "| mean 100 episode reward | 1.63e+03   |\n",
      "| n_updates               | 477553     |\n",
      "| policy_loss             | -286.98502 |\n",
      "| qf1_loss                | 23.982683  |\n",
      "| qf2_loss                | 17.069557  |\n",
      "| time_elapsed            | 5394       |\n",
      "| total timesteps         | 477652     |\n",
      "| value_loss              | 12.43185   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03569535 |\n",
      "| ent_coef_loss           | 0.18812072 |\n",
      "| entropy                 | 14.621686  |\n",
      "| episodes                | 3290       |\n",
      "| fps                     | 88         |\n",
      "| mean 100 episode reward | 1.65e+03   |\n",
      "| n_updates               | 480389     |\n",
      "| policy_loss             | -254.39264 |\n",
      "| qf1_loss                | 14.875053  |\n",
      "| qf2_loss                | 21.969162  |\n",
      "| time_elapsed            | 5423       |\n",
      "| total timesteps         | 480488     |\n",
      "| value_loss              | 21.524382  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036334947 |\n",
      "| ent_coef_loss           | -1.2164667  |\n",
      "| entropy                 | 14.690214   |\n",
      "| episodes                | 3300        |\n",
      "| fps                     | 88          |\n",
      "| mean 100 episode reward | 1.76e+03    |\n",
      "| n_updates               | 485029      |\n",
      "| policy_loss             | -273.37946  |\n",
      "| qf1_loss                | 14.060209   |\n",
      "| qf2_loss                | 16.444393   |\n",
      "| time_elapsed            | 5470        |\n",
      "| total timesteps         | 485128      |\n",
      "| value_loss              | 18.155079   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035903525 |\n",
      "| ent_coef_loss           | -2.1011937  |\n",
      "| entropy                 | 14.2814045  |\n",
      "| episodes                | 3310        |\n",
      "| fps                     | 88          |\n",
      "| mean 100 episode reward | 1.75e+03    |\n",
      "| n_updates               | 487735      |\n",
      "| policy_loss             | -303.90204  |\n",
      "| qf1_loss                | 26.616707   |\n",
      "| qf2_loss                | 19.623093   |\n",
      "| time_elapsed            | 5498        |\n",
      "| total timesteps         | 487834      |\n",
      "| value_loss              | 11.837278   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03693293 |\n",
      "| ent_coef_loss           | 0.24420476 |\n",
      "| entropy                 | 14.389158  |\n",
      "| episodes                | 3320       |\n",
      "| fps                     | 88         |\n",
      "| mean 100 episode reward | 1.76e+03   |\n",
      "| n_updates               | 491589     |\n",
      "| policy_loss             | -280.9631  |\n",
      "| qf1_loss                | 19.14418   |\n",
      "| qf2_loss                | 25.78307   |\n",
      "| time_elapsed            | 5538       |\n",
      "| total timesteps         | 491688     |\n",
      "| value_loss              | 18.504017  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036014576 |\n",
      "| ent_coef_loss           | 11.452261   |\n",
      "| entropy                 | 13.701049   |\n",
      "| episodes                | 3330        |\n",
      "| fps                     | 88          |\n",
      "| mean 100 episode reward | 1.71e+03    |\n",
      "| n_updates               | 494154      |\n",
      "| policy_loss             | -288.84607  |\n",
      "| qf1_loss                | 17.870056   |\n",
      "| qf2_loss                | 16.353445   |\n",
      "| time_elapsed            | 5565        |\n",
      "| total timesteps         | 494253      |\n",
      "| value_loss              | 22.60719    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03520015 |\n",
      "| ent_coef_loss           | -3.8023877 |\n",
      "| entropy                 | 14.444155  |\n",
      "| episodes                | 3340       |\n",
      "| fps                     | 88         |\n",
      "| mean 100 episode reward | 1.7e+03    |\n",
      "| n_updates               | 496964     |\n",
      "| policy_loss             | -277.25958 |\n",
      "| qf1_loss                | 22.517666  |\n",
      "| qf2_loss                | 27.904491  |\n",
      "| time_elapsed            | 5594       |\n",
      "| total timesteps         | 497063     |\n",
      "| value_loss              | 15.630865  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03712339 |\n",
      "| ent_coef_loss           | 8.669659   |\n",
      "| entropy                 | 14.063671  |\n",
      "| episodes                | 3350       |\n",
      "| fps                     | 88         |\n",
      "| mean 100 episode reward | 1.66e+03   |\n",
      "| n_updates               | 499506     |\n",
      "| policy_loss             | -288.43054 |\n",
      "| qf1_loss                | 26.99427   |\n",
      "| qf2_loss                | 30.992546  |\n",
      "| time_elapsed            | 5619       |\n",
      "| total timesteps         | 499605     |\n",
      "| value_loss              | 20.339994  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036286052 |\n",
      "| ent_coef_loss           | 2.5525692   |\n",
      "| entropy                 | 14.09613    |\n",
      "| episodes                | 3360        |\n",
      "| fps                     | 88          |\n",
      "| mean 100 episode reward | 1.72e+03    |\n",
      "| n_updates               | 504929      |\n",
      "| policy_loss             | -277.43646  |\n",
      "| qf1_loss                | 14.953323   |\n",
      "| qf2_loss                | 23.900517   |\n",
      "| time_elapsed            | 5675        |\n",
      "| total timesteps         | 505028      |\n",
      "| value_loss              | 13.822123   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.037801675 |\n",
      "| ent_coef_loss           | 17.157598   |\n",
      "| entropy                 | 13.440931   |\n",
      "| episodes                | 3370        |\n",
      "| fps                     | 89          |\n",
      "| mean 100 episode reward | 1.75e+03    |\n",
      "| n_updates               | 508012      |\n",
      "| policy_loss             | -257.8103   |\n",
      "| qf1_loss                | 32.635765   |\n",
      "| qf2_loss                | 36.326973   |\n",
      "| time_elapsed            | 5707        |\n",
      "| total timesteps         | 508111      |\n",
      "| value_loss              | 35.25757    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.037358325 |\n",
      "| ent_coef_loss           | 4.706766    |\n",
      "| entropy                 | 14.049862   |\n",
      "| episodes                | 3380        |\n",
      "| fps                     | 89          |\n",
      "| mean 100 episode reward | 1.72e+03    |\n",
      "| n_updates               | 510857      |\n",
      "| policy_loss             | -260.57605  |\n",
      "| qf1_loss                | 14.948355   |\n",
      "| qf2_loss                | 19.086346   |\n",
      "| time_elapsed            | 5736        |\n",
      "| total timesteps         | 510956      |\n",
      "| value_loss              | 17.57586    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036740165 |\n",
      "| ent_coef_loss           | 10.811926   |\n",
      "| entropy                 | 13.900652   |\n",
      "| episodes                | 3390        |\n",
      "| fps                     | 89          |\n",
      "| mean 100 episode reward | 1.72e+03    |\n",
      "| n_updates               | 513698      |\n",
      "| policy_loss             | -272.53268  |\n",
      "| qf1_loss                | 46.048904   |\n",
      "| qf2_loss                | 25.930641   |\n",
      "| time_elapsed            | 5767        |\n",
      "| total timesteps         | 513797      |\n",
      "| value_loss              | 20.413235   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03798117 |\n",
      "| ent_coef_loss           | -1.7176542 |\n",
      "| entropy                 | 14.184507  |\n",
      "| episodes                | 3400       |\n",
      "| fps                     | 89         |\n",
      "| mean 100 episode reward | 1.64e+03   |\n",
      "| n_updates               | 516691     |\n",
      "| policy_loss             | -266.2097  |\n",
      "| qf1_loss                | 22.163353  |\n",
      "| qf2_loss                | 35.998802  |\n",
      "| time_elapsed            | 5800       |\n",
      "| total timesteps         | 516790     |\n",
      "| value_loss              | 17.977825  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.038064975 |\n",
      "| ent_coef_loss           | 4.672869    |\n",
      "| entropy                 | 13.758293   |\n",
      "| episodes                | 3410        |\n",
      "| fps                     | 89          |\n",
      "| mean 100 episode reward | 1.65e+03    |\n",
      "| n_updates               | 519632      |\n",
      "| policy_loss             | -280.14648  |\n",
      "| qf1_loss                | 31.821291   |\n",
      "| qf2_loss                | 34.824135   |\n",
      "| time_elapsed            | 5832        |\n",
      "| total timesteps         | 519731      |\n",
      "| value_loss              | 20.629917   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03782354 |\n",
      "| ent_coef_loss           | 4.406988   |\n",
      "| entropy                 | 14.118959  |\n",
      "| episodes                | 3420       |\n",
      "| fps                     | 89         |\n",
      "| mean 100 episode reward | 1.64e+03   |\n",
      "| n_updates               | 523164     |\n",
      "| policy_loss             | -253.78455 |\n",
      "| qf1_loss                | 51.065258  |\n",
      "| qf2_loss                | 45.176662  |\n",
      "| time_elapsed            | 5870       |\n",
      "| total timesteps         | 523263     |\n",
      "| value_loss              | 18.28723   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03616186 |\n",
      "| ent_coef_loss           | 3.287141   |\n",
      "| entropy                 | 13.662535  |\n",
      "| episodes                | 3430       |\n",
      "| fps                     | 89         |\n",
      "| mean 100 episode reward | 1.68e+03   |\n",
      "| n_updates               | 526549     |\n",
      "| policy_loss             | -299.02612 |\n",
      "| qf1_loss                | 28.449562  |\n",
      "| qf2_loss                | 24.228495  |\n",
      "| time_elapsed            | 5908       |\n",
      "| total timesteps         | 526648     |\n",
      "| value_loss              | 14.478835  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035840612 |\n",
      "| ent_coef_loss           | 2.049385    |\n",
      "| entropy                 | 14.226403   |\n",
      "| episodes                | 3440        |\n",
      "| fps                     | 89          |\n",
      "| mean 100 episode reward | 1.66e+03    |\n",
      "| n_updates               | 528948      |\n",
      "| policy_loss             | -291.4486   |\n",
      "| qf1_loss                | 33.57301    |\n",
      "| qf2_loss                | 32.78794    |\n",
      "| time_elapsed            | 5936        |\n",
      "| total timesteps         | 529047      |\n",
      "| value_loss              | 19.197077   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03668676 |\n",
      "| ent_coef_loss           | 2.448213   |\n",
      "| entropy                 | 14.3508    |\n",
      "| episodes                | 3450       |\n",
      "| fps                     | 89         |\n",
      "| mean 100 episode reward | 1.71e+03   |\n",
      "| n_updates               | 532347     |\n",
      "| policy_loss             | -256.9474  |\n",
      "| qf1_loss                | 60.68061   |\n",
      "| qf2_loss                | 67.770584  |\n",
      "| time_elapsed            | 5974       |\n",
      "| total timesteps         | 532446     |\n",
      "| value_loss              | 14.698427  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.038639456 |\n",
      "| ent_coef_loss           | -4.7123957  |\n",
      "| entropy                 | 14.267347   |\n",
      "| episodes                | 3460        |\n",
      "| fps                     | 89          |\n",
      "| mean 100 episode reward | 1.61e+03    |\n",
      "| n_updates               | 535718      |\n",
      "| policy_loss             | -275.9572   |\n",
      "| qf1_loss                | 44.647354   |\n",
      "| qf2_loss                | 45.411728   |\n",
      "| time_elapsed            | 6009        |\n",
      "| total timesteps         | 535817      |\n",
      "| value_loss              | 22.821516   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.039359167 |\n",
      "| ent_coef_loss           | -18.72236   |\n",
      "| entropy                 | 14.998098   |\n",
      "| episodes                | 3470        |\n",
      "| fps                     | 89          |\n",
      "| mean 100 episode reward | 1.63e+03    |\n",
      "| n_updates               | 539295      |\n",
      "| policy_loss             | -269.7289   |\n",
      "| qf1_loss                | 25.49629    |\n",
      "| qf2_loss                | 24.445744   |\n",
      "| time_elapsed            | 6046        |\n",
      "| total timesteps         | 539394      |\n",
      "| value_loss              | 17.722755   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.037487894 |\n",
      "| ent_coef_loss           | -8.854601   |\n",
      "| entropy                 | 13.86476    |\n",
      "| episodes                | 3480        |\n",
      "| fps                     | 89          |\n",
      "| mean 100 episode reward | 1.64e+03    |\n",
      "| n_updates               | 542435      |\n",
      "| policy_loss             | -302.36456  |\n",
      "| qf1_loss                | 26.560936   |\n",
      "| qf2_loss                | 28.441517   |\n",
      "| time_elapsed            | 6078        |\n",
      "| total timesteps         | 542534      |\n",
      "| value_loss              | 24.290195   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.038279984 |\n",
      "| ent_coef_loss           | -8.162748   |\n",
      "| entropy                 | 14.329224   |\n",
      "| episodes                | 3490        |\n",
      "| fps                     | 89          |\n",
      "| mean 100 episode reward | 1.67e+03    |\n",
      "| n_updates               | 545744      |\n",
      "| policy_loss             | -281.8244   |\n",
      "| qf1_loss                | 18.83617    |\n",
      "| qf2_loss                | 17.360226   |\n",
      "| time_elapsed            | 6115        |\n",
      "| total timesteps         | 545843      |\n",
      "| value_loss              | 13.279575   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03797595 |\n",
      "| ent_coef_loss           | 1.5742347  |\n",
      "| entropy                 | 13.9104595 |\n",
      "| episodes                | 3500       |\n",
      "| fps                     | 89         |\n",
      "| mean 100 episode reward | 1.77e+03   |\n",
      "| n_updates               | 550800     |\n",
      "| policy_loss             | -299.26215 |\n",
      "| qf1_loss                | 50.424065  |\n",
      "| qf2_loss                | 36.567963  |\n",
      "| time_elapsed            | 6168       |\n",
      "| total timesteps         | 550899     |\n",
      "| value_loss              | 25.662146  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03733462 |\n",
      "| ent_coef_loss           | 8.043416   |\n",
      "| entropy                 | 14.246227  |\n",
      "| episodes                | 3510       |\n",
      "| fps                     | 89         |\n",
      "| mean 100 episode reward | 1.8e+03    |\n",
      "| n_updates               | 554114     |\n",
      "| policy_loss             | -266.0774  |\n",
      "| qf1_loss                | 24.444016  |\n",
      "| qf2_loss                | 29.060532  |\n",
      "| time_elapsed            | 6204       |\n",
      "| total timesteps         | 554213     |\n",
      "| value_loss              | 29.461397  |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036207758 |\n",
      "| ent_coef_loss           | -4.8840065  |\n",
      "| entropy                 | 14.272851   |\n",
      "| episodes                | 3520        |\n",
      "| fps                     | 89          |\n",
      "| mean 100 episode reward | 1.76e+03    |\n",
      "| n_updates               | 556902      |\n",
      "| policy_loss             | -278.7376   |\n",
      "| qf1_loss                | 23.210829   |\n",
      "| qf2_loss                | 24.893444   |\n",
      "| time_elapsed            | 6234        |\n",
      "| total timesteps         | 557001      |\n",
      "| value_loss              | 20.583055   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03762919 |\n",
      "| ent_coef_loss           | 9.801144   |\n",
      "| entropy                 | 13.823221  |\n",
      "| episodes                | 3530       |\n",
      "| fps                     | 89         |\n",
      "| mean 100 episode reward | 1.81e+03   |\n",
      "| n_updates               | 561210     |\n",
      "| policy_loss             | -261.12762 |\n",
      "| qf1_loss                | 25.795776  |\n",
      "| qf2_loss                | 21.745174  |\n",
      "| time_elapsed            | 6290       |\n",
      "| total timesteps         | 561309     |\n",
      "| value_loss              | 26.582214  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035433836 |\n",
      "| ent_coef_loss           | 6.1709166   |\n",
      "| entropy                 | 13.672492   |\n",
      "| episodes                | 3540        |\n",
      "| fps                     | 89          |\n",
      "| mean 100 episode reward | 1.82e+03    |\n",
      "| n_updates               | 563811      |\n",
      "| policy_loss             | -286.35568  |\n",
      "| qf1_loss                | 24.448502   |\n",
      "| qf2_loss                | 11.6170635  |\n",
      "| time_elapsed            | 6322        |\n",
      "| total timesteps         | 563910      |\n",
      "| value_loss              | 10.743255   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.037859302 |\n",
      "| ent_coef_loss           | 0.060370445 |\n",
      "| entropy                 | 14.119455   |\n",
      "| episodes                | 3550        |\n",
      "| fps                     | 89          |\n",
      "| mean 100 episode reward | 1.82e+03    |\n",
      "| n_updates               | 567120      |\n",
      "| policy_loss             | -293.65747  |\n",
      "| qf1_loss                | 18.40963    |\n",
      "| qf2_loss                | 34.150837   |\n",
      "| time_elapsed            | 6363        |\n",
      "| total timesteps         | 567219      |\n",
      "| value_loss              | 12.7762985  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036291882 |\n",
      "| ent_coef_loss           | -3.3447018  |\n",
      "| entropy                 | 14.489204   |\n",
      "| episodes                | 3560        |\n",
      "| fps                     | 89          |\n",
      "| mean 100 episode reward | 1.89e+03    |\n",
      "| n_updates               | 571855      |\n",
      "| policy_loss             | -263.62784  |\n",
      "| qf1_loss                | 20.565323   |\n",
      "| qf2_loss                | 12.911829   |\n",
      "| time_elapsed            | 6421        |\n",
      "| total timesteps         | 571954      |\n",
      "| value_loss              | 18.350136   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03732009 |\n",
      "| ent_coef_loss           | 6.599284   |\n",
      "| entropy                 | 13.549844  |\n",
      "| episodes                | 3570       |\n",
      "| fps                     | 88         |\n",
      "| mean 100 episode reward | 1.99e+03   |\n",
      "| n_updates               | 577244     |\n",
      "| policy_loss             | -295.6412  |\n",
      "| qf1_loss                | 38.867172  |\n",
      "| qf2_loss                | 34.96514   |\n",
      "| time_elapsed            | 6487       |\n",
      "| total timesteps         | 577343     |\n",
      "| value_loss              | 12.665121  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.039269052 |\n",
      "| ent_coef_loss           | -10.454092  |\n",
      "| entropy                 | 14.1930065  |\n",
      "| episodes                | 3580        |\n",
      "| fps                     | 88          |\n",
      "| mean 100 episode reward | 2.03e+03    |\n",
      "| n_updates               | 581188      |\n",
      "| policy_loss             | -322.7318   |\n",
      "| qf1_loss                | 19.668808   |\n",
      "| qf2_loss                | 18.263197   |\n",
      "| time_elapsed            | 6535        |\n",
      "| total timesteps         | 581287      |\n",
      "| value_loss              | 9.421879    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03712047 |\n",
      "| ent_coef_loss           | -2.084992  |\n",
      "| entropy                 | 14.147861  |\n",
      "| episodes                | 3590       |\n",
      "| fps                     | 88         |\n",
      "| mean 100 episode reward | 2.06e+03   |\n",
      "| n_updates               | 585145     |\n",
      "| policy_loss             | -297.63208 |\n",
      "| qf1_loss                | 30.605272  |\n",
      "| qf2_loss                | 24.286903  |\n",
      "| time_elapsed            | 6584       |\n",
      "| total timesteps         | 585244     |\n",
      "| value_loss              | 26.949387  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03743742 |\n",
      "| ent_coef_loss           | 11.597352  |\n",
      "| entropy                 | 13.995575  |\n",
      "| episodes                | 3600       |\n",
      "| fps                     | 88         |\n",
      "| mean 100 episode reward | 1.97e+03   |\n",
      "| n_updates               | 588253     |\n",
      "| policy_loss             | -273.4671  |\n",
      "| qf1_loss                | 33.287163  |\n",
      "| qf2_loss                | 34.52317   |\n",
      "| time_elapsed            | 6623       |\n",
      "| total timesteps         | 588352     |\n",
      "| value_loss              | 39.97649   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03672674 |\n",
      "| ent_coef_loss           | 2.9514475  |\n",
      "| entropy                 | 14.433139  |\n",
      "| episodes                | 3610       |\n",
      "| fps                     | 88         |\n",
      "| mean 100 episode reward | 1.98e+03   |\n",
      "| n_updates               | 591899     |\n",
      "| policy_loss             | -275.8884  |\n",
      "| qf1_loss                | 26.823431  |\n",
      "| qf2_loss                | 33.209835  |\n",
      "| time_elapsed            | 6667       |\n",
      "| total timesteps         | 591998     |\n",
      "| value_loss              | 14.449371  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.0373461  |\n",
      "| ent_coef_loss           | -7.277728  |\n",
      "| entropy                 | 14.854822  |\n",
      "| episodes                | 3620       |\n",
      "| fps                     | 88         |\n",
      "| mean 100 episode reward | 2.07e+03   |\n",
      "| n_updates               | 596404     |\n",
      "| policy_loss             | -314.13635 |\n",
      "| qf1_loss                | 18.160215  |\n",
      "| qf2_loss                | 18.042831  |\n",
      "| time_elapsed            | 6742       |\n",
      "| total timesteps         | 596503     |\n",
      "| value_loss              | 5.614299   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03760295 |\n",
      "| ent_coef_loss           | -1.802835  |\n",
      "| entropy                 | 14.295328  |\n",
      "| episodes                | 3630       |\n",
      "| fps                     | 88         |\n",
      "| mean 100 episode reward | 2.1e+03    |\n",
      "| n_updates               | 601177     |\n",
      "| policy_loss             | -296.2132  |\n",
      "| qf1_loss                | 23.848312  |\n",
      "| qf2_loss                | 34.023544  |\n",
      "| time_elapsed            | 6820       |\n",
      "| total timesteps         | 601276     |\n",
      "| value_loss              | 10.564877  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.038609866 |\n",
      "| ent_coef_loss           | -8.241882   |\n",
      "| entropy                 | 15.1482525  |\n",
      "| episodes                | 3640        |\n",
      "| fps                     | 88          |\n",
      "| mean 100 episode reward | 2.18e+03    |\n",
      "| n_updates               | 605406      |\n",
      "| policy_loss             | -257.07916  |\n",
      "| qf1_loss                | 22.820803   |\n",
      "| qf2_loss                | 26.434948   |\n",
      "| time_elapsed            | 6878        |\n",
      "| total timesteps         | 605505      |\n",
      "| value_loss              | 14.2429085  |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.037362065 |\n",
      "| ent_coef_loss           | 8.284481    |\n",
      "| entropy                 | 14.298344   |\n",
      "| episodes                | 3650        |\n",
      "| fps                     | 87          |\n",
      "| mean 100 episode reward | 2.31e+03    |\n",
      "| n_updates               | 611025      |\n",
      "| policy_loss             | -271.28485  |\n",
      "| qf1_loss                | 48.680904   |\n",
      "| qf2_loss                | 33.29479    |\n",
      "| time_elapsed            | 6952        |\n",
      "| total timesteps         | 611124      |\n",
      "| value_loss              | 25.339237   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036210943 |\n",
      "| ent_coef_loss           | 1.5827245   |\n",
      "| entropy                 | 13.685816   |\n",
      "| episodes                | 3660        |\n",
      "| fps                     | 87          |\n",
      "| mean 100 episode reward | 2.28e+03    |\n",
      "| n_updates               | 615216      |\n",
      "| policy_loss             | -285.7924   |\n",
      "| qf1_loss                | 29.174202   |\n",
      "| qf2_loss                | 24.658691   |\n",
      "| time_elapsed            | 7004        |\n",
      "| total timesteps         | 615315      |\n",
      "| value_loss              | 20.04131    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03644973 |\n",
      "| ent_coef_loss           | -1.2811264 |\n",
      "| entropy                 | 14.200801  |\n",
      "| episodes                | 3670       |\n",
      "| fps                     | 87         |\n",
      "| mean 100 episode reward | 2.24e+03   |\n",
      "| n_updates               | 619816     |\n",
      "| policy_loss             | -278.35535 |\n",
      "| qf1_loss                | 31.631298  |\n",
      "| qf2_loss                | 33.971455  |\n",
      "| time_elapsed            | 7060       |\n",
      "| total timesteps         | 619915     |\n",
      "| value_loss              | 34.88241   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03770013 |\n",
      "| ent_coef_loss           | 2.231055   |\n",
      "| entropy                 | 13.280018  |\n",
      "| episodes                | 3680       |\n",
      "| fps                     | 87         |\n",
      "| mean 100 episode reward | 2.29e+03   |\n",
      "| n_updates               | 624702     |\n",
      "| policy_loss             | -319.51773 |\n",
      "| qf1_loss                | 32.525345  |\n",
      "| qf2_loss                | 15.423413  |\n",
      "| time_elapsed            | 7117       |\n",
      "| total timesteps         | 624801     |\n",
      "| value_loss              | 22.348639  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.037336126 |\n",
      "| ent_coef_loss           | -8.843679   |\n",
      "| entropy                 | 14.899838   |\n",
      "| episodes                | 3690        |\n",
      "| fps                     | 87          |\n",
      "| mean 100 episode reward | 2.31e+03    |\n",
      "| n_updates               | 629052      |\n",
      "| policy_loss             | -316.7096   |\n",
      "| qf1_loss                | 19.671555   |\n",
      "| qf2_loss                | 18.145908   |\n",
      "| time_elapsed            | 7173        |\n",
      "| total timesteps         | 629151      |\n",
      "| value_loss              | 18.00035    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03784167 |\n",
      "| ent_coef_loss           | 1.2253237  |\n",
      "| entropy                 | 14.223976  |\n",
      "| episodes                | 3700       |\n",
      "| fps                     | 87         |\n",
      "| mean 100 episode reward | 2.37e+03   |\n",
      "| n_updates               | 633412     |\n",
      "| policy_loss             | -276.03284 |\n",
      "| qf1_loss                | 29.551838  |\n",
      "| qf2_loss                | 31.866371  |\n",
      "| time_elapsed            | 7234       |\n",
      "| total timesteps         | 633511     |\n",
      "| value_loss              | 11.862334  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.038100492 |\n",
      "| ent_coef_loss           | 2.048367    |\n",
      "| entropy                 | 15.032872   |\n",
      "| episodes                | 3710        |\n",
      "| fps                     | 87          |\n",
      "| mean 100 episode reward | 2.35e+03    |\n",
      "| n_updates               | 636524      |\n",
      "| policy_loss             | -280.8386   |\n",
      "| qf1_loss                | 28.185879   |\n",
      "| qf2_loss                | 34.37014    |\n",
      "| time_elapsed            | 7272        |\n",
      "| total timesteps         | 636623      |\n",
      "| value_loss              | 17.072426   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03706957 |\n",
      "| ent_coef_loss           | -10.749901 |\n",
      "| entropy                 | 14.394156  |\n",
      "| episodes                | 3720       |\n",
      "| fps                     | 87         |\n",
      "| mean 100 episode reward | 2.41e+03   |\n",
      "| n_updates               | 642213     |\n",
      "| policy_loss             | -296.5526  |\n",
      "| qf1_loss                | 21.19337   |\n",
      "| qf2_loss                | 22.358788  |\n",
      "| time_elapsed            | 7343       |\n",
      "| total timesteps         | 642312     |\n",
      "| value_loss              | 31.517042  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03749737 |\n",
      "| ent_coef_loss           | -8.343317  |\n",
      "| entropy                 | 14.793886  |\n",
      "| episodes                | 3730       |\n",
      "| fps                     | 87         |\n",
      "| mean 100 episode reward | 2.47e+03   |\n",
      "| n_updates               | 648173     |\n",
      "| policy_loss             | -310.8169  |\n",
      "| qf1_loss                | 16.837372  |\n",
      "| qf2_loss                | 20.79445   |\n",
      "| time_elapsed            | 7413       |\n",
      "| total timesteps         | 648272     |\n",
      "| value_loss              | 19.609964  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03661575 |\n",
      "| ent_coef_loss           | -3.0472689 |\n",
      "| entropy                 | 14.709182  |\n",
      "| episodes                | 3740       |\n",
      "| fps                     | 87         |\n",
      "| mean 100 episode reward | 2.47e+03   |\n",
      "| n_updates               | 652299     |\n",
      "| policy_loss             | -314.27734 |\n",
      "| qf1_loss                | 25.504204  |\n",
      "| qf2_loss                | 28.222939  |\n",
      "| time_elapsed            | 7466       |\n",
      "| total timesteps         | 652398     |\n",
      "| value_loss              | 36.589516  |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| current_lr              | 0.0003       |\n",
      "| ent_coef                | 0.03743046   |\n",
      "| ent_coef_loss           | -0.045946836 |\n",
      "| entropy                 | 14.09864     |\n",
      "| episodes                | 3750         |\n",
      "| fps                     | 87           |\n",
      "| mean 100 episode reward | 2.43e+03     |\n",
      "| n_updates               | 657239       |\n",
      "| policy_loss             | -298.74896   |\n",
      "| qf1_loss                | 15.740737    |\n",
      "| qf2_loss                | 20.654057    |\n",
      "| time_elapsed            | 7534         |\n",
      "| total timesteps         | 657338       |\n",
      "| value_loss              | 10.604107    |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.03946195  |\n",
      "| ent_coef_loss           | -0.20291066 |\n",
      "| entropy                 | 14.051177   |\n",
      "| episodes                | 3760        |\n",
      "| fps                     | 87          |\n",
      "| mean 100 episode reward | 2.45e+03    |\n",
      "| n_updates               | 661728      |\n",
      "| policy_loss             | -308.8475   |\n",
      "| qf1_loss                | 19.870317   |\n",
      "| qf2_loss                | 24.120811   |\n",
      "| time_elapsed            | 7593        |\n",
      "| total timesteps         | 661827      |\n",
      "| value_loss              | 17.994432   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.038462255 |\n",
      "| ent_coef_loss           | 0.13686919  |\n",
      "| entropy                 | 14.375844   |\n",
      "| episodes                | 3770        |\n",
      "| fps                     | 87          |\n",
      "| mean 100 episode reward | 2.5e+03     |\n",
      "| n_updates               | 667117      |\n",
      "| policy_loss             | -314.39624  |\n",
      "| qf1_loss                | 30.681213   |\n",
      "| qf2_loss                | 37.876614   |\n",
      "| time_elapsed            | 7664        |\n",
      "| total timesteps         | 667216      |\n",
      "| value_loss              | 23.392288   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.038632784 |\n",
      "| ent_coef_loss           | -1.827709   |\n",
      "| entropy                 | 14.673859   |\n",
      "| episodes                | 3780        |\n",
      "| fps                     | 86          |\n",
      "| mean 100 episode reward | 2.59e+03    |\n",
      "| n_updates               | 673564      |\n",
      "| policy_loss             | -286.11237  |\n",
      "| qf1_loss                | 29.005793   |\n",
      "| qf2_loss                | 16.245358   |\n",
      "| time_elapsed            | 7745        |\n",
      "| total timesteps         | 673663      |\n",
      "| value_loss              | 17.398264   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.0383379  |\n",
      "| ent_coef_loss           | -3.291133  |\n",
      "| entropy                 | 14.480913  |\n",
      "| episodes                | 3790       |\n",
      "| fps                     | 86         |\n",
      "| mean 100 episode reward | 2.67e+03   |\n",
      "| n_updates               | 679436     |\n",
      "| policy_loss             | -318.66202 |\n",
      "| qf1_loss                | 29.22526   |\n",
      "| qf2_loss                | 28.242807  |\n",
      "| time_elapsed            | 7820       |\n",
      "| total timesteps         | 679535     |\n",
      "| value_loss              | 20.069729  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03824025 |\n",
      "| ent_coef_loss           | 5.41446    |\n",
      "| entropy                 | 14.118678  |\n",
      "| episodes                | 3800       |\n",
      "| fps                     | 86         |\n",
      "| mean 100 episode reward | 2.77e+03   |\n",
      "| n_updates               | 685619     |\n",
      "| policy_loss             | -325.44647 |\n",
      "| qf1_loss                | 43.60328   |\n",
      "| qf2_loss                | 42.534805  |\n",
      "| time_elapsed            | 7899       |\n",
      "| total timesteps         | 685718     |\n",
      "| value_loss              | 26.27659   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036564738 |\n",
      "| ent_coef_loss           | -2.574391   |\n",
      "| entropy                 | 13.7508545  |\n",
      "| episodes                | 3810        |\n",
      "| fps                     | 86          |\n",
      "| mean 100 episode reward | 2.75e+03    |\n",
      "| n_updates               | 688261      |\n",
      "| policy_loss             | -300.9122   |\n",
      "| qf1_loss                | 30.539274   |\n",
      "| qf2_loss                | 22.240059   |\n",
      "| time_elapsed            | 7934        |\n",
      "| total timesteps         | 688360      |\n",
      "| value_loss              | 11.758034   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03719203 |\n",
      "| ent_coef_loss           | 4.8738346  |\n",
      "| entropy                 | 14.293314  |\n",
      "| episodes                | 3820       |\n",
      "| fps                     | 86         |\n",
      "| mean 100 episode reward | 2.72e+03   |\n",
      "| n_updates               | 693551     |\n",
      "| policy_loss             | -313.56815 |\n",
      "| qf1_loss                | 21.854458  |\n",
      "| qf2_loss                | 23.04597   |\n",
      "| time_elapsed            | 7995       |\n",
      "| total timesteps         | 693650     |\n",
      "| value_loss              | 13.809688  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03741283 |\n",
      "| ent_coef_loss           | 8.103493   |\n",
      "| entropy                 | 14.2149725 |\n",
      "| episodes                | 3830       |\n",
      "| fps                     | 86         |\n",
      "| mean 100 episode reward | 2.62e+03   |\n",
      "| n_updates               | 697673     |\n",
      "| policy_loss             | -348.15997 |\n",
      "| qf1_loss                | 30.508488  |\n",
      "| qf2_loss                | 27.922812  |\n",
      "| time_elapsed            | 8057       |\n",
      "| total timesteps         | 697772     |\n",
      "| value_loss              | 31.348644  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03679997 |\n",
      "| ent_coef_loss           | 1.8479757  |\n",
      "| entropy                 | 14.013671  |\n",
      "| episodes                | 3840       |\n",
      "| fps                     | 86         |\n",
      "| mean 100 episode reward | 2.69e+03   |\n",
      "| n_updates               | 703083     |\n",
      "| policy_loss             | -259.72705 |\n",
      "| qf1_loss                | 30.603804  |\n",
      "| qf2_loss                | 22.126795  |\n",
      "| time_elapsed            | 8132       |\n",
      "| total timesteps         | 703182     |\n",
      "| value_loss              | 35.63307   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.037142865 |\n",
      "| ent_coef_loss           | -3.1250398  |\n",
      "| entropy                 | 14.339994   |\n",
      "| episodes                | 3850        |\n",
      "| fps                     | 86          |\n",
      "| mean 100 episode reward | 2.73e+03    |\n",
      "| n_updates               | 709029      |\n",
      "| policy_loss             | -309.14502  |\n",
      "| qf1_loss                | 14.906836   |\n",
      "| qf2_loss                | 17.382893   |\n",
      "| time_elapsed            | 8227        |\n",
      "| total timesteps         | 709128      |\n",
      "| value_loss              | 16.169237   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035066452 |\n",
      "| ent_coef_loss           | -4.6883664  |\n",
      "| entropy                 | 14.4656515  |\n",
      "| episodes                | 3860        |\n",
      "| fps                     | 86          |\n",
      "| mean 100 episode reward | 2.82e+03    |\n",
      "| n_updates               | 715154      |\n",
      "| policy_loss             | -336.2807   |\n",
      "| qf1_loss                | 43.621143   |\n",
      "| qf2_loss                | 37.120968   |\n",
      "| time_elapsed            | 8316        |\n",
      "| total timesteps         | 715253      |\n",
      "| value_loss              | 26.73154    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.037350263 |\n",
      "| ent_coef_loss           | 3.5041776   |\n",
      "| entropy                 | 14.0865345  |\n",
      "| episodes                | 3870        |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 2.92e+03    |\n",
      "| n_updates               | 722445      |\n",
      "| policy_loss             | -294.5336   |\n",
      "| qf1_loss                | 30.8553     |\n",
      "| qf2_loss                | 24.772621   |\n",
      "| time_elapsed            | 8426        |\n",
      "| total timesteps         | 722544      |\n",
      "| value_loss              | 19.146692   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036554355 |\n",
      "| ent_coef_loss           | -3.4964576  |\n",
      "| entropy                 | 13.830366   |\n",
      "| episodes                | 3880        |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 2.76e+03    |\n",
      "| n_updates               | 725895      |\n",
      "| policy_loss             | -329.8266   |\n",
      "| qf1_loss                | 32.584084   |\n",
      "| qf2_loss                | 31.309864   |\n",
      "| time_elapsed            | 8480        |\n",
      "| total timesteps         | 725994      |\n",
      "| value_loss              | 16.576263   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035896335 |\n",
      "| ent_coef_loss           | -5.967346   |\n",
      "| entropy                 | 14.656326   |\n",
      "| episodes                | 3890        |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 2.68e+03    |\n",
      "| n_updates               | 730319      |\n",
      "| policy_loss             | -299.2425   |\n",
      "| qf1_loss                | 16.16975    |\n",
      "| qf2_loss                | 18.789106   |\n",
      "| time_elapsed            | 8550        |\n",
      "| total timesteps         | 730418      |\n",
      "| value_loss              | 15.22377    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036587443 |\n",
      "| ent_coef_loss           | 5.382058    |\n",
      "| entropy                 | 14.559313   |\n",
      "| episodes                | 3900        |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 2.71e+03    |\n",
      "| n_updates               | 737081      |\n",
      "| policy_loss             | -308.17456  |\n",
      "| qf1_loss                | 18.891628   |\n",
      "| qf2_loss                | 23.594255   |\n",
      "| time_elapsed            | 8655        |\n",
      "| total timesteps         | 737180      |\n",
      "| value_loss              | 17.822973   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03791237 |\n",
      "| ent_coef_loss           | -2.402586  |\n",
      "| entropy                 | 13.7119465 |\n",
      "| episodes                | 3910       |\n",
      "| fps                     | 85         |\n",
      "| mean 100 episode reward | 2.89e+03   |\n",
      "| n_updates               | 743331     |\n",
      "| policy_loss             | -331.50604 |\n",
      "| qf1_loss                | 39.811462  |\n",
      "| qf2_loss                | 53.046463  |\n",
      "| time_elapsed            | 8741       |\n",
      "| total timesteps         | 743430     |\n",
      "| value_loss              | 14.136328  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035781983 |\n",
      "| ent_coef_loss           | -0.16826773 |\n",
      "| entropy                 | 14.148108   |\n",
      "| episodes                | 3920        |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 2.84e+03    |\n",
      "| n_updates               | 747725      |\n",
      "| policy_loss             | -333.49866  |\n",
      "| qf1_loss                | 22.917295   |\n",
      "| qf2_loss                | 15.686949   |\n",
      "| time_elapsed            | 8805        |\n",
      "| total timesteps         | 747824      |\n",
      "| value_loss              | 11.087343   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.038435966 |\n",
      "| ent_coef_loss           | -11.208544  |\n",
      "| entropy                 | 14.649311   |\n",
      "| episodes                | 3930        |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 2.97e+03    |\n",
      "| n_updates               | 754084      |\n",
      "| policy_loss             | -341.40576  |\n",
      "| qf1_loss                | 20.36129    |\n",
      "| qf2_loss                | 12.288735   |\n",
      "| time_elapsed            | 8889        |\n",
      "| total timesteps         | 754183      |\n",
      "| value_loss              | 14.1324625  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.037238907 |\n",
      "| ent_coef_loss           | 16.529865   |\n",
      "| entropy                 | 14.61601    |\n",
      "| episodes                | 3940        |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 3e+03       |\n",
      "| n_updates               | 760000      |\n",
      "| policy_loss             | -330.21005  |\n",
      "| qf1_loss                | 29.940948   |\n",
      "| qf2_loss                | 29.994495   |\n",
      "| time_elapsed            | 8969        |\n",
      "| total timesteps         | 760099      |\n",
      "| value_loss              | 22.361202   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036125038 |\n",
      "| ent_coef_loss           | -2.1431563  |\n",
      "| entropy                 | 14.197622   |\n",
      "| episodes                | 3950        |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 2.99e+03    |\n",
      "| n_updates               | 765607      |\n",
      "| policy_loss             | -348.8032   |\n",
      "| qf1_loss                | 32.9769     |\n",
      "| qf2_loss                | 35.68528    |\n",
      "| time_elapsed            | 9040        |\n",
      "| total timesteps         | 765706      |\n",
      "| value_loss              | 17.894407   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03729103 |\n",
      "| ent_coef_loss           | 1.9851875  |\n",
      "| entropy                 | 13.785604  |\n",
      "| episodes                | 3960       |\n",
      "| fps                     | 84         |\n",
      "| mean 100 episode reward | 3.06e+03   |\n",
      "| n_updates               | 772997     |\n",
      "| policy_loss             | -320.4574  |\n",
      "| qf1_loss                | 21.313034  |\n",
      "| qf2_loss                | 27.72958   |\n",
      "| time_elapsed            | 9131       |\n",
      "| total timesteps         | 773096     |\n",
      "| value_loss              | 15.419067  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.038512286 |\n",
      "| ent_coef_loss           | 3.3452258   |\n",
      "| entropy                 | 14.349675   |\n",
      "| episodes                | 3970        |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 2.99e+03    |\n",
      "| n_updates               | 779039      |\n",
      "| policy_loss             | -302.4318   |\n",
      "| qf1_loss                | 34.637016   |\n",
      "| qf2_loss                | 38.66788    |\n",
      "| time_elapsed            | 9209        |\n",
      "| total timesteps         | 779138      |\n",
      "| value_loss              | 13.782836   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035339274 |\n",
      "| ent_coef_loss           | -10.275114  |\n",
      "| entropy                 | 14.767581   |\n",
      "| episodes                | 3980        |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 3.14e+03    |\n",
      "| n_updates               | 785293      |\n",
      "| policy_loss             | -320.99152  |\n",
      "| qf1_loss                | 31.377752   |\n",
      "| qf2_loss                | 19.90651    |\n",
      "| time_elapsed            | 9286        |\n",
      "| total timesteps         | 785392      |\n",
      "| value_loss              | 25.26191    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03677351 |\n",
      "| ent_coef_loss           | 4.0440483  |\n",
      "| entropy                 | 14.045564  |\n",
      "| episodes                | 3990       |\n",
      "| fps                     | 84         |\n",
      "| mean 100 episode reward | 3.22e+03   |\n",
      "| n_updates               | 791257     |\n",
      "| policy_loss             | -330.97516 |\n",
      "| qf1_loss                | 21.85663   |\n",
      "| qf2_loss                | 20.510578  |\n",
      "| time_elapsed            | 9361       |\n",
      "| total timesteps         | 791356     |\n",
      "| value_loss              | 17.309158  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035472862 |\n",
      "| ent_coef_loss           | -0.6049646  |\n",
      "| entropy                 | 13.980989   |\n",
      "| episodes                | 4000        |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 3.22e+03    |\n",
      "| n_updates               | 797908      |\n",
      "| policy_loss             | -328.6369   |\n",
      "| qf1_loss                | 28.952312   |\n",
      "| qf2_loss                | 32.969868   |\n",
      "| time_elapsed            | 9440        |\n",
      "| total timesteps         | 798007      |\n",
      "| value_loss              | 29.235407   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03740072 |\n",
      "| ent_coef_loss           | 0.6501343  |\n",
      "| entropy                 | 14.122322  |\n",
      "| episodes                | 4010       |\n",
      "| fps                     | 84         |\n",
      "| mean 100 episode reward | 3.22e+03   |\n",
      "| n_updates               | 804102     |\n",
      "| policy_loss             | -320.80255 |\n",
      "| qf1_loss                | 29.962032  |\n",
      "| qf2_loss                | 23.283682  |\n",
      "| time_elapsed            | 9527       |\n",
      "| total timesteps         | 804201     |\n",
      "| value_loss              | 18.053358  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03657279 |\n",
      "| ent_coef_loss           | 4.885437   |\n",
      "| entropy                 | 13.626011  |\n",
      "| episodes                | 4020       |\n",
      "| fps                     | 84         |\n",
      "| mean 100 episode reward | 3.38e+03   |\n",
      "| n_updates               | 811257     |\n",
      "| policy_loss             | -345.17422 |\n",
      "| qf1_loss                | 23.023365  |\n",
      "| qf2_loss                | 38.92733   |\n",
      "| time_elapsed            | 9625       |\n",
      "| total timesteps         | 811356     |\n",
      "| value_loss              | 19.116482  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036644407 |\n",
      "| ent_coef_loss           | 0.5565664   |\n",
      "| entropy                 | 14.524886   |\n",
      "| episodes                | 4030        |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 3.39e+03    |\n",
      "| n_updates               | 817905      |\n",
      "| policy_loss             | -306.34424  |\n",
      "| qf1_loss                | 35.556324   |\n",
      "| qf2_loss                | 37.74778    |\n",
      "| time_elapsed            | 9708        |\n",
      "| total timesteps         | 818004      |\n",
      "| value_loss              | 10.324268   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036069762 |\n",
      "| ent_coef_loss           | 1.3314829   |\n",
      "| entropy                 | 14.136479   |\n",
      "| episodes                | 4040        |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 3.38e+03    |\n",
      "| n_updates               | 823614      |\n",
      "| policy_loss             | -353.62585  |\n",
      "| qf1_loss                | 23.589272   |\n",
      "| qf2_loss                | 15.734314   |\n",
      "| time_elapsed            | 9790        |\n",
      "| total timesteps         | 823713      |\n",
      "| value_loss              | 10.930536   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036388386 |\n",
      "| ent_coef_loss           | 7.2973404   |\n",
      "| entropy                 | 14.12973    |\n",
      "| episodes                | 4050        |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 3.45e+03    |\n",
      "| n_updates               | 830432      |\n",
      "| policy_loss             | -317.44128  |\n",
      "| qf1_loss                | 33.673313   |\n",
      "| qf2_loss                | 33.144554   |\n",
      "| time_elapsed            | 9881        |\n",
      "| total timesteps         | 830531      |\n",
      "| value_loss              | 10.655596   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036290612 |\n",
      "| ent_coef_loss           | 1.7869183   |\n",
      "| entropy                 | 14.994562   |\n",
      "| episodes                | 4060        |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 3.43e+03    |\n",
      "| n_updates               | 837386      |\n",
      "| policy_loss             | -356.86035  |\n",
      "| qf1_loss                | 32.27346    |\n",
      "| qf2_loss                | 21.49914    |\n",
      "| time_elapsed            | 9955        |\n",
      "| total timesteps         | 837485      |\n",
      "| value_loss              | 18.363018   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03553115 |\n",
      "| ent_coef_loss           | -5.6320386 |\n",
      "| entropy                 | 14.659012  |\n",
      "| episodes                | 4070       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 3.5e+03    |\n",
      "| n_updates               | 844918     |\n",
      "| policy_loss             | -342.30188 |\n",
      "| qf1_loss                | 30.174273  |\n",
      "| qf2_loss                | 19.663193  |\n",
      "| time_elapsed            | 10063      |\n",
      "| total timesteps         | 845017     |\n",
      "| value_loss              | 14.232666  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035446238 |\n",
      "| ent_coef_loss           | 5.231277    |\n",
      "| entropy                 | 13.602005   |\n",
      "| episodes                | 4080        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.5e+03     |\n",
      "| n_updates               | 851151      |\n",
      "| policy_loss             | -312.4442   |\n",
      "| qf1_loss                | 45.39889    |\n",
      "| qf2_loss                | 44.759804   |\n",
      "| time_elapsed            | 10144       |\n",
      "| total timesteps         | 851250      |\n",
      "| value_loss              | 25.348228   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03575397 |\n",
      "| ent_coef_loss           | -4.8540773 |\n",
      "| entropy                 | 14.674082  |\n",
      "| episodes                | 4090       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 3.48e+03   |\n",
      "| n_updates               | 856707     |\n",
      "| policy_loss             | -339.4572  |\n",
      "| qf1_loss                | 20.46154   |\n",
      "| qf2_loss                | 21.031006  |\n",
      "| time_elapsed            | 10216      |\n",
      "| total timesteps         | 856806     |\n",
      "| value_loss              | 11.453663  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03531011 |\n",
      "| ent_coef_loss           | 5.5337133  |\n",
      "| entropy                 | 14.367708  |\n",
      "| episodes                | 4100       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 3.44e+03   |\n",
      "| n_updates               | 862590     |\n",
      "| policy_loss             | -324.66125 |\n",
      "| qf1_loss                | 22.342691  |\n",
      "| qf2_loss                | 23.2188    |\n",
      "| time_elapsed            | 10291      |\n",
      "| total timesteps         | 862689     |\n",
      "| value_loss              | 15.190661  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.036289167 |\n",
      "| ent_coef_loss           | 3.3378546   |\n",
      "| entropy                 | 14.442972   |\n",
      "| episodes                | 4110        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.51e+03    |\n",
      "| n_updates               | 870090      |\n",
      "| policy_loss             | -338.50323  |\n",
      "| qf1_loss                | 31.647198   |\n",
      "| qf2_loss                | 23.334446   |\n",
      "| time_elapsed            | 10373       |\n",
      "| total timesteps         | 870189      |\n",
      "| value_loss              | 11.013388   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.034447633 |\n",
      "| ent_coef_loss           | -5.68703    |\n",
      "| entropy                 | 14.542567   |\n",
      "| episodes                | 4120        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.52e+03    |\n",
      "| n_updates               | 877360      |\n",
      "| policy_loss             | -349.18002  |\n",
      "| qf1_loss                | 11.854071   |\n",
      "| qf2_loss                | 13.814597   |\n",
      "| time_elapsed            | 10478       |\n",
      "| total timesteps         | 877459      |\n",
      "| value_loss              | 9.516912    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| current_lr              | 0.0003       |\n",
      "| ent_coef                | 0.03529303   |\n",
      "| ent_coef_loss           | -0.096857786 |\n",
      "| entropy                 | 14.244188    |\n",
      "| episodes                | 4130         |\n",
      "| fps                     | 83           |\n",
      "| mean 100 episode reward | 3.47e+03     |\n",
      "| n_updates               | 882997       |\n",
      "| policy_loss             | -345.01422   |\n",
      "| qf1_loss                | 20.014301    |\n",
      "| qf2_loss                | 25.085781    |\n",
      "| time_elapsed            | 10556        |\n",
      "| total timesteps         | 883096       |\n",
      "| value_loss              | 14.436989    |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03486921 |\n",
      "| ent_coef_loss           | -4.133052  |\n",
      "| entropy                 | 13.378304  |\n",
      "| episodes                | 4140       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 3.59e+03   |\n",
      "| n_updates               | 890836     |\n",
      "| policy_loss             | -357.1911  |\n",
      "| qf1_loss                | 29.096075  |\n",
      "| qf2_loss                | 32.280296  |\n",
      "| time_elapsed            | 10650      |\n",
      "| total timesteps         | 890935     |\n",
      "| value_loss              | 27.292053  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03784119 |\n",
      "| ent_coef_loss           | -2.1857116 |\n",
      "| entropy                 | 14.187202  |\n",
      "| episodes                | 4150       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 3.57e+03   |\n",
      "| n_updates               | 897418     |\n",
      "| policy_loss             | -357.3107  |\n",
      "| qf1_loss                | 41.86605   |\n",
      "| qf2_loss                | 33.918365  |\n",
      "| time_elapsed            | 10733      |\n",
      "| total timesteps         | 897517     |\n",
      "| value_loss              | 22.140594  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03478582 |\n",
      "| ent_coef_loss           | 2.096517   |\n",
      "| entropy                 | 14.430133  |\n",
      "| episodes                | 4160       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 3.57e+03   |\n",
      "| n_updates               | 904221     |\n",
      "| policy_loss             | -336.59534 |\n",
      "| qf1_loss                | 11.007869  |\n",
      "| qf2_loss                | 21.714344  |\n",
      "| time_elapsed            | 10816      |\n",
      "| total timesteps         | 904320     |\n",
      "| value_loss              | 17.018929  |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.0377008  |\n",
      "| ent_coef_loss           | 6.1839786  |\n",
      "| entropy                 | 14.493202  |\n",
      "| episodes                | 4170       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 3.59e+03   |\n",
      "| n_updates               | 912010     |\n",
      "| policy_loss             | -366.35202 |\n",
      "| qf1_loss                | 44.418144  |\n",
      "| qf2_loss                | 43.077236  |\n",
      "| time_elapsed            | 10905      |\n",
      "| total timesteps         | 912109     |\n",
      "| value_loss              | 10.091852  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035857476 |\n",
      "| ent_coef_loss           | -11.331043  |\n",
      "| entropy                 | 14.412275   |\n",
      "| episodes                | 4180        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.66e+03    |\n",
      "| n_updates               | 919442      |\n",
      "| policy_loss             | -363.95248  |\n",
      "| qf1_loss                | 25.15254    |\n",
      "| qf2_loss                | 18.99337    |\n",
      "| time_elapsed            | 11000       |\n",
      "| total timesteps         | 919541      |\n",
      "| value_loss              | 14.697247   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.033897024 |\n",
      "| ent_coef_loss           | 5.393432    |\n",
      "| entropy                 | 13.907408   |\n",
      "| episodes                | 4190        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.73e+03    |\n",
      "| n_updates               | 926303      |\n",
      "| policy_loss             | -284.23138  |\n",
      "| qf1_loss                | 49.421684   |\n",
      "| qf2_loss                | 34.560097   |\n",
      "| time_elapsed            | 11091       |\n",
      "| total timesteps         | 926402      |\n",
      "| value_loss              | 14.320995   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.033541955 |\n",
      "| ent_coef_loss           | -2.5277624  |\n",
      "| entropy                 | 13.925432   |\n",
      "| episodes                | 4200        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.76e+03    |\n",
      "| n_updates               | 932792      |\n",
      "| policy_loss             | -372.85065  |\n",
      "| qf1_loss                | 50.800056   |\n",
      "| qf2_loss                | 41.959686   |\n",
      "| time_elapsed            | 11160       |\n",
      "| total timesteps         | 932891      |\n",
      "| value_loss              | 12.66709    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.033238146 |\n",
      "| ent_coef_loss           | 6.785434    |\n",
      "| entropy                 | 14.159573   |\n",
      "| episodes                | 4210        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.81e+03    |\n",
      "| n_updates               | 941172      |\n",
      "| policy_loss             | -340.8406   |\n",
      "| qf1_loss                | 38.817      |\n",
      "| qf2_loss                | 27.241385   |\n",
      "| time_elapsed            | 11247       |\n",
      "| total timesteps         | 941271      |\n",
      "| value_loss              | 11.520916   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.033378106 |\n",
      "| ent_coef_loss           | -3.119216   |\n",
      "| entropy                 | 14.57606    |\n",
      "| episodes                | 4220        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.85e+03    |\n",
      "| n_updates               | 949128      |\n",
      "| policy_loss             | -369.44293  |\n",
      "| qf1_loss                | 41.41352    |\n",
      "| qf2_loss                | 35.932198   |\n",
      "| time_elapsed            | 11329       |\n",
      "| total timesteps         | 949227      |\n",
      "| value_loss              | 7.2777934   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03480182 |\n",
      "| ent_coef_loss           | 6.34517    |\n",
      "| entropy                 | 13.6602745 |\n",
      "| episodes                | 4230       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 3.91e+03   |\n",
      "| n_updates               | 956065     |\n",
      "| policy_loss             | -380.04926 |\n",
      "| qf1_loss                | 68.915184  |\n",
      "| qf2_loss                | 64.44243   |\n",
      "| time_elapsed            | 11401      |\n",
      "| total timesteps         | 956164     |\n",
      "| value_loss              | 27.911587  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035357606 |\n",
      "| ent_coef_loss           | -0.9245243  |\n",
      "| entropy                 | 14.751389   |\n",
      "| episodes                | 4240        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.82e+03    |\n",
      "| n_updates               | 962141      |\n",
      "| policy_loss             | -352.39148  |\n",
      "| qf1_loss                | 14.846949   |\n",
      "| qf2_loss                | 20.809095   |\n",
      "| time_elapsed            | 11463       |\n",
      "| total timesteps         | 962240      |\n",
      "| value_loss              | 7.5499043   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03552514 |\n",
      "| ent_coef_loss           | 1.6764315  |\n",
      "| entropy                 | 14.5095005 |\n",
      "| episodes                | 4250       |\n",
      "| fps                     | 84         |\n",
      "| mean 100 episode reward | 3.9e+03    |\n",
      "| n_updates               | 970103     |\n",
      "| policy_loss             | -372.7925  |\n",
      "| qf1_loss                | 21.069159  |\n",
      "| qf2_loss                | 17.211815  |\n",
      "| time_elapsed            | 11544      |\n",
      "| total timesteps         | 970202     |\n",
      "| value_loss              | 8.645994   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.034067426 |\n",
      "| ent_coef_loss           | -0.09060168 |\n",
      "| entropy                 | 14.253069   |\n",
      "| episodes                | 4260        |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 3.9e+03     |\n",
      "| n_updates               | 977021      |\n",
      "| policy_loss             | -378.60757  |\n",
      "| qf1_loss                | 11.436849   |\n",
      "| qf2_loss                | 12.113352   |\n",
      "| time_elapsed            | 11619       |\n",
      "| total timesteps         | 977120      |\n",
      "| value_loss              | 18.566349   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.035565402 |\n",
      "| ent_coef_loss           | -1.4173925  |\n",
      "| entropy                 | 14.302273   |\n",
      "| episodes                | 4270        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.98e+03    |\n",
      "| n_updates               | 986242      |\n",
      "| policy_loss             | -361.52515  |\n",
      "| qf1_loss                | 46.4116     |\n",
      "| qf2_loss                | 34.49969    |\n",
      "| time_elapsed            | 11750       |\n",
      "| total timesteps         | 986341      |\n",
      "| value_loss              | 28.616951   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.03547112  |\n",
      "| ent_coef_loss           | 0.030967236 |\n",
      "| entropy                 | 13.7783375  |\n",
      "| episodes                | 4280        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 4.02e+03    |\n",
      "| n_updates               | 994609      |\n",
      "| policy_loss             | -337.5243   |\n",
      "| qf1_loss                | 54.106476   |\n",
      "| qf2_loss                | 47.91198    |\n",
      "| time_elapsed            | 11867       |\n",
      "| total timesteps         | 994708      |\n",
      "| value_loss              | 26.798306   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.032903314 |\n",
      "| ent_coef_loss           | -0.11307335 |\n",
      "| entropy                 | 13.7442875  |\n",
      "| episodes                | 4290        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.97e+03    |\n",
      "| n_updates               | 1000377     |\n",
      "| policy_loss             | -350.17722  |\n",
      "| qf1_loss                | 27.976124   |\n",
      "| qf2_loss                | 29.559675   |\n",
      "| time_elapsed            | 11942       |\n",
      "| total timesteps         | 1000476     |\n",
      "| value_loss              | 11.4160185  |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.032931622 |\n",
      "| ent_coef_loss           | 1.09899     |\n",
      "| entropy                 | 14.206955   |\n",
      "| episodes                | 4300        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.95e+03    |\n",
      "| n_updates               | 1006556     |\n",
      "| policy_loss             | -382.5041   |\n",
      "| qf1_loss                | 7.176057    |\n",
      "| qf2_loss                | 16.449078   |\n",
      "| time_elapsed            | 12024       |\n",
      "| total timesteps         | 1006655     |\n",
      "| value_loss              | 21.143557   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.034302782 |\n",
      "| ent_coef_loss           | -3.8168266  |\n",
      "| entropy                 | 15.025036   |\n",
      "| episodes                | 4310        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.83e+03    |\n",
      "| n_updates               | 1012898     |\n",
      "| policy_loss             | -356.48306  |\n",
      "| qf1_loss                | 14.166665   |\n",
      "| qf2_loss                | 16.072998   |\n",
      "| time_elapsed            | 12107       |\n",
      "| total timesteps         | 1012997     |\n",
      "| value_loss              | 24.009848   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.033293236 |\n",
      "| ent_coef_loss           | -8.272352   |\n",
      "| entropy                 | 14.706566   |\n",
      "| episodes                | 4320        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.83e+03    |\n",
      "| n_updates               | 1020711     |\n",
      "| policy_loss             | -360.49463  |\n",
      "| qf1_loss                | 17.52545    |\n",
      "| qf2_loss                | 16.122028   |\n",
      "| time_elapsed            | 12204       |\n",
      "| total timesteps         | 1020810     |\n",
      "| value_loss              | 10.417657   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.034554947 |\n",
      "| ent_coef_loss           | -12.647502  |\n",
      "| entropy                 | 14.909933   |\n",
      "| episodes                | 4330        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.91e+03    |\n",
      "| n_updates               | 1029171     |\n",
      "| policy_loss             | -355.53003  |\n",
      "| qf1_loss                | 20.959803   |\n",
      "| qf2_loss                | 16.790932   |\n",
      "| time_elapsed            | 12311       |\n",
      "| total timesteps         | 1029270     |\n",
      "| value_loss              | 6.65357     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03460372 |\n",
      "| ent_coef_loss           | -9.605457  |\n",
      "| entropy                 | 14.451521  |\n",
      "| episodes                | 4340       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 4e+03      |\n",
      "| n_updates               | 1037021    |\n",
      "| policy_loss             | -389.57248 |\n",
      "| qf1_loss                | 28.636484  |\n",
      "| qf2_loss                | 18.489033  |\n",
      "| time_elapsed            | 12414      |\n",
      "| total timesteps         | 1037120    |\n",
      "| value_loss              | 19.988565  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03150185 |\n",
      "| ent_coef_loss           | 2.9018626  |\n",
      "| entropy                 | 14.632143  |\n",
      "| episodes                | 4350       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 3.92e+03   |\n",
      "| n_updates               | 1043553    |\n",
      "| policy_loss             | -371.9613  |\n",
      "| qf1_loss                | 17.530245  |\n",
      "| qf2_loss                | 23.836336  |\n",
      "| time_elapsed            | 12496      |\n",
      "| total timesteps         | 1043652    |\n",
      "| value_loss              | 17.888193  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03441447 |\n",
      "| ent_coef_loss           | -3.1768863 |\n",
      "| entropy                 | 14.442696  |\n",
      "| episodes                | 4360       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 3.91e+03   |\n",
      "| n_updates               | 1050206    |\n",
      "| policy_loss             | -351.81738 |\n",
      "| qf1_loss                | 13.528103  |\n",
      "| qf2_loss                | 14.2046995 |\n",
      "| time_elapsed            | 12576      |\n",
      "| total timesteps         | 1050305    |\n",
      "| value_loss              | 19.654463  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.033006836 |\n",
      "| ent_coef_loss           | 2.7545643   |\n",
      "| entropy                 | 14.106201   |\n",
      "| episodes                | 4370        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.71e+03    |\n",
      "| n_updates               | 1055666     |\n",
      "| policy_loss             | -349.28433  |\n",
      "| qf1_loss                | 27.398228   |\n",
      "| qf2_loss                | 29.744295   |\n",
      "| time_elapsed            | 12648       |\n",
      "| total timesteps         | 1055765     |\n",
      "| value_loss              | 18.922153   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.032181595 |\n",
      "| ent_coef_loss           | 5.518394    |\n",
      "| entropy                 | 14.996433   |\n",
      "| episodes                | 4380        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.45e+03    |\n",
      "| n_updates               | 1059137     |\n",
      "| policy_loss             | -355.74164  |\n",
      "| qf1_loss                | 28.44062    |\n",
      "| qf2_loss                | 17.843678   |\n",
      "| time_elapsed            | 12692       |\n",
      "| total timesteps         | 1059236     |\n",
      "| value_loss              | 24.978493   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.032510668 |\n",
      "| ent_coef_loss           | 3.5990639   |\n",
      "| entropy                 | 14.599123   |\n",
      "| episodes                | 4390        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.41e+03    |\n",
      "| n_updates               | 1064094     |\n",
      "| policy_loss             | -389.8944   |\n",
      "| qf1_loss                | 25.919144   |\n",
      "| qf2_loss                | 22.97268    |\n",
      "| time_elapsed            | 12751       |\n",
      "| total timesteps         | 1064193     |\n",
      "| value_loss              | 13.895401   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.032058973 |\n",
      "| ent_coef_loss           | 0.80148196  |\n",
      "| entropy                 | 14.554829   |\n",
      "| episodes                | 4400        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.54e+03    |\n",
      "| n_updates               | 1072660     |\n",
      "| policy_loss             | -366.35413  |\n",
      "| qf1_loss                | 41.756977   |\n",
      "| qf2_loss                | 28.482029   |\n",
      "| time_elapsed            | 12851       |\n",
      "| total timesteps         | 1072759     |\n",
      "| value_loss              | 18.161125   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03290889 |\n",
      "| ent_coef_loss           | 1.5958023  |\n",
      "| entropy                 | 14.697247  |\n",
      "| episodes                | 4410       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 3.51e+03   |\n",
      "| n_updates               | 1078367    |\n",
      "| policy_loss             | -361.59894 |\n",
      "| qf1_loss                | 33.296005  |\n",
      "| qf2_loss                | 21.683685  |\n",
      "| time_elapsed            | 12921      |\n",
      "| total timesteps         | 1078466    |\n",
      "| value_loss              | 12.643597  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.032324363 |\n",
      "| ent_coef_loss           | 7.553064    |\n",
      "| entropy                 | 14.628891   |\n",
      "| episodes                | 4420        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.37e+03    |\n",
      "| n_updates               | 1083593     |\n",
      "| policy_loss             | -345.43225  |\n",
      "| qf1_loss                | 29.38131    |\n",
      "| qf2_loss                | 27.767475   |\n",
      "| time_elapsed            | 12986       |\n",
      "| total timesteps         | 1083692     |\n",
      "| value_loss              | 21.806248   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.0333493  |\n",
      "| ent_coef_loss           | 4.334362   |\n",
      "| entropy                 | 13.478243  |\n",
      "| episodes                | 4430       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 3.01e+03   |\n",
      "| n_updates               | 1085252    |\n",
      "| policy_loss             | -361.03802 |\n",
      "| qf1_loss                | 23.185667  |\n",
      "| qf2_loss                | 18.590303  |\n",
      "| time_elapsed            | 13005      |\n",
      "| total timesteps         | 1085351    |\n",
      "| value_loss              | 28.853842  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031090148 |\n",
      "| ent_coef_loss           | 1.4938004   |\n",
      "| entropy                 | 15.161728   |\n",
      "| episodes                | 4440        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 2.92e+03    |\n",
      "| n_updates               | 1091420     |\n",
      "| policy_loss             | -363.69705  |\n",
      "| qf1_loss                | 12.455484   |\n",
      "| qf2_loss                | 14.341899   |\n",
      "| time_elapsed            | 13084       |\n",
      "| total timesteps         | 1091519     |\n",
      "| value_loss              | 13.978033   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031995084 |\n",
      "| ent_coef_loss           | -12.700774  |\n",
      "| entropy                 | 15.202607   |\n",
      "| episodes                | 4450        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 2.98e+03    |\n",
      "| n_updates               | 1099075     |\n",
      "| policy_loss             | -381.50757  |\n",
      "| qf1_loss                | 10.045204   |\n",
      "| qf2_loss                | 18.41537    |\n",
      "| time_elapsed            | 13180       |\n",
      "| total timesteps         | 1099174     |\n",
      "| value_loss              | 13.985168   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031058224 |\n",
      "| ent_coef_loss           | -1.565969   |\n",
      "| entropy                 | 13.838335   |\n",
      "| episodes                | 4460        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 2.88e+03    |\n",
      "| n_updates               | 1104040     |\n",
      "| policy_loss             | -372.86377  |\n",
      "| qf1_loss                | 28.658297   |\n",
      "| qf2_loss                | 18.978382   |\n",
      "| time_elapsed            | 13239       |\n",
      "| total timesteps         | 1104139     |\n",
      "| value_loss              | 9.855945    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031131389 |\n",
      "| ent_coef_loss           | 0.7691045   |\n",
      "| entropy                 | 14.697379   |\n",
      "| episodes                | 4470        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 2.85e+03    |\n",
      "| n_updates               | 1108859     |\n",
      "| policy_loss             | -380.51733  |\n",
      "| qf1_loss                | 28.854286   |\n",
      "| qf2_loss                | 28.80836    |\n",
      "| time_elapsed            | 13306       |\n",
      "| total timesteps         | 1108958     |\n",
      "| value_loss              | 12.095278   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.033172794 |\n",
      "| ent_coef_loss           | -6.4446387  |\n",
      "| entropy                 | 14.691728   |\n",
      "| episodes                | 4480        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.09e+03    |\n",
      "| n_updates               | 1116927     |\n",
      "| policy_loss             | -361.24597  |\n",
      "| qf1_loss                | 14.524552   |\n",
      "| qf2_loss                | 20.069393   |\n",
      "| time_elapsed            | 13405       |\n",
      "| total timesteps         | 1117026     |\n",
      "| value_loss              | 12.331305   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02951711 |\n",
      "| ent_coef_loss           | 6.1249995  |\n",
      "| entropy                 | 14.76473   |\n",
      "| episodes                | 4490       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 3.21e+03   |\n",
      "| n_updates               | 1124135    |\n",
      "| policy_loss             | -379.51645 |\n",
      "| qf1_loss                | 19.543655  |\n",
      "| qf2_loss                | 22.282175  |\n",
      "| time_elapsed            | 13496      |\n",
      "| total timesteps         | 1124234    |\n",
      "| value_loss              | 15.378317  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029540913 |\n",
      "| ent_coef_loss           | -2.5711737  |\n",
      "| entropy                 | 14.698154   |\n",
      "| episodes                | 4500        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 2.96e+03    |\n",
      "| n_updates               | 1128105     |\n",
      "| policy_loss             | -392.9614   |\n",
      "| qf1_loss                | 18.98739    |\n",
      "| qf2_loss                | 28.508116   |\n",
      "| time_elapsed            | 13547       |\n",
      "| total timesteps         | 1128204     |\n",
      "| value_loss              | 8.356819    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030738635 |\n",
      "| ent_coef_loss           | -4.784898   |\n",
      "| entropy                 | 13.918833   |\n",
      "| episodes                | 4510        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.04e+03    |\n",
      "| n_updates               | 1135112     |\n",
      "| policy_loss             | -387.70862  |\n",
      "| qf1_loss                | 1344.8329   |\n",
      "| qf2_loss                | 1333.7152   |\n",
      "| time_elapsed            | 13634       |\n",
      "| total timesteps         | 1135211     |\n",
      "| value_loss              | 14.353847   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031426974 |\n",
      "| ent_coef_loss           | -11.122457  |\n",
      "| entropy                 | 14.803665   |\n",
      "| episodes                | 4520        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 2.93e+03    |\n",
      "| n_updates               | 1138104     |\n",
      "| policy_loss             | -386.53253  |\n",
      "| qf1_loss                | 23.097174   |\n",
      "| qf2_loss                | 26.831964   |\n",
      "| time_elapsed            | 13670       |\n",
      "| total timesteps         | 1138203     |\n",
      "| value_loss              | 7.7493997   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031910304 |\n",
      "| ent_coef_loss           | 0.59146285  |\n",
      "| entropy                 | 15.2082205  |\n",
      "| episodes                | 4530        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.25e+03    |\n",
      "| n_updates               | 1145729     |\n",
      "| policy_loss             | -380.32263  |\n",
      "| qf1_loss                | 18.968063   |\n",
      "| qf2_loss                | 23.850714   |\n",
      "| time_elapsed            | 13763       |\n",
      "| total timesteps         | 1145828     |\n",
      "| value_loss              | 17.122528   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030199766 |\n",
      "| ent_coef_loss           | 1.8795156   |\n",
      "| entropy                 | 14.18993    |\n",
      "| episodes                | 4540        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.3e+03     |\n",
      "| n_updates               | 1152902     |\n",
      "| policy_loss             | -402.8955   |\n",
      "| qf1_loss                | 10.030003   |\n",
      "| qf2_loss                | 8.887243    |\n",
      "| time_elapsed            | 13850       |\n",
      "| total timesteps         | 1153001     |\n",
      "| value_loss              | 12.448381   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029747069 |\n",
      "| ent_coef_loss           | 1.6373885   |\n",
      "| entropy                 | 14.494099   |\n",
      "| episodes                | 4550        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.24e+03    |\n",
      "| n_updates               | 1159499     |\n",
      "| policy_loss             | -408.25073  |\n",
      "| qf1_loss                | 13.062692   |\n",
      "| qf2_loss                | 11.91711    |\n",
      "| time_elapsed            | 13925       |\n",
      "| total timesteps         | 1159598     |\n",
      "| value_loss              | 7.4555006   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031548403 |\n",
      "| ent_coef_loss           | -8.923805   |\n",
      "| entropy                 | 15.036744   |\n",
      "| episodes                | 4560        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.22e+03    |\n",
      "| n_updates               | 1164006     |\n",
      "| policy_loss             | -389.75464  |\n",
      "| qf1_loss                | 13.231338   |\n",
      "| qf2_loss                | 9.818841    |\n",
      "| time_elapsed            | 13976       |\n",
      "| total timesteps         | 1164105     |\n",
      "| value_loss              | 8.287279    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030821295 |\n",
      "| ent_coef_loss           | -10.210688  |\n",
      "| entropy                 | 14.983618   |\n",
      "| episodes                | 4570        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.31e+03    |\n",
      "| n_updates               | 1170428     |\n",
      "| policy_loss             | -411.2095   |\n",
      "| qf1_loss                | 11.973644   |\n",
      "| qf2_loss                | 13.002394   |\n",
      "| time_elapsed            | 14049       |\n",
      "| total timesteps         | 1170527     |\n",
      "| value_loss              | 9.688807    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02959302 |\n",
      "| ent_coef_loss           | -9.292609  |\n",
      "| entropy                 | 14.048855  |\n",
      "| episodes                | 4580       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 3.2e+03    |\n",
      "| n_updates               | 1176462    |\n",
      "| policy_loss             | -415.39545 |\n",
      "| qf1_loss                | 8.5829525  |\n",
      "| qf2_loss                | 6.5559025  |\n",
      "| time_elapsed            | 14128      |\n",
      "| total timesteps         | 1176561    |\n",
      "| value_loss              | 5.378621   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03225463 |\n",
      "| ent_coef_loss           | -6.7015734 |\n",
      "| entropy                 | 15.152246  |\n",
      "| episodes                | 4590       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 3.11e+03   |\n",
      "| n_updates               | 1182181    |\n",
      "| policy_loss             | -396.4178  |\n",
      "| qf1_loss                | 17.321466  |\n",
      "| qf2_loss                | 20.005253  |\n",
      "| time_elapsed            | 14202      |\n",
      "| total timesteps         | 1182280    |\n",
      "| value_loss              | 9.0949335  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031463027 |\n",
      "| ent_coef_loss           | 0.6830143   |\n",
      "| entropy                 | 14.170125   |\n",
      "| episodes                | 4600        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.13e+03    |\n",
      "| n_updates               | 1186447     |\n",
      "| policy_loss             | -373.41452  |\n",
      "| qf1_loss                | 28.851109   |\n",
      "| qf2_loss                | 39.68699    |\n",
      "| time_elapsed            | 14255       |\n",
      "| total timesteps         | 1186546     |\n",
      "| value_loss              | 17.404713   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029453875 |\n",
      "| ent_coef_loss           | 0.5215547   |\n",
      "| entropy                 | 13.961468   |\n",
      "| episodes                | 4610        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.07e+03    |\n",
      "| n_updates               | 1192571     |\n",
      "| policy_loss             | -385.91235  |\n",
      "| qf1_loss                | 21.159086   |\n",
      "| qf2_loss                | 17.74789    |\n",
      "| time_elapsed            | 14329       |\n",
      "| total timesteps         | 1192670     |\n",
      "| value_loss              | 17.43459    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030518468 |\n",
      "| ent_coef_loss           | 7.055725    |\n",
      "| entropy                 | 14.072962   |\n",
      "| episodes                | 4620        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.22e+03    |\n",
      "| n_updates               | 1198409     |\n",
      "| policy_loss             | -381.02246  |\n",
      "| qf1_loss                | 32.763607   |\n",
      "| qf2_loss                | 24.018454   |\n",
      "| time_elapsed            | 14401       |\n",
      "| total timesteps         | 1198508     |\n",
      "| value_loss              | 21.37151    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029942326 |\n",
      "| ent_coef_loss           | -0.71948385 |\n",
      "| entropy                 | 14.645064   |\n",
      "| episodes                | 4630        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.17e+03    |\n",
      "| n_updates               | 1205258     |\n",
      "| policy_loss             | -416.12628  |\n",
      "| qf1_loss                | 22.227861   |\n",
      "| qf2_loss                | 20.928577   |\n",
      "| time_elapsed            | 14486       |\n",
      "| total timesteps         | 1205357     |\n",
      "| value_loss              | 7.4274874   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.033069003 |\n",
      "| ent_coef_loss           | 0.73905694  |\n",
      "| entropy                 | 14.635466   |\n",
      "| episodes                | 4640        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.17e+03    |\n",
      "| n_updates               | 1212470     |\n",
      "| policy_loss             | -375.70654  |\n",
      "| qf1_loss                | 23.235065   |\n",
      "| qf2_loss                | 17.564278   |\n",
      "| time_elapsed            | 14569       |\n",
      "| total timesteps         | 1212569     |\n",
      "| value_loss              | 24.109272   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03364777 |\n",
      "| ent_coef_loss           | 5.562018   |\n",
      "| entropy                 | 14.57645   |\n",
      "| episodes                | 4650       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 3.07e+03   |\n",
      "| n_updates               | 1217451    |\n",
      "| policy_loss             | -400.4463  |\n",
      "| qf1_loss                | 20.254246  |\n",
      "| qf2_loss                | 25.185192  |\n",
      "| time_elapsed            | 14632      |\n",
      "| total timesteps         | 1217550    |\n",
      "| value_loss              | 17.079546  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.032874055 |\n",
      "| ent_coef_loss           | -8.154174   |\n",
      "| entropy                 | 14.742957   |\n",
      "| episodes                | 4660        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.05e+03    |\n",
      "| n_updates               | 1221647     |\n",
      "| policy_loss             | -413.0006   |\n",
      "| qf1_loss                | 22.61298    |\n",
      "| qf2_loss                | 24.061157   |\n",
      "| time_elapsed            | 14682       |\n",
      "| total timesteps         | 1221746     |\n",
      "| value_loss              | 10.548319   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.032159083 |\n",
      "| ent_coef_loss           | -0.13305998 |\n",
      "| entropy                 | 15.000093   |\n",
      "| episodes                | 4670        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.16e+03    |\n",
      "| n_updates               | 1230173     |\n",
      "| policy_loss             | -382.76218  |\n",
      "| qf1_loss                | 42.8753     |\n",
      "| qf2_loss                | 36.09678    |\n",
      "| time_elapsed            | 14785       |\n",
      "| total timesteps         | 1230272     |\n",
      "| value_loss              | 19.875841   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030964842 |\n",
      "| ent_coef_loss           | -3.004755   |\n",
      "| entropy                 | 14.844395   |\n",
      "| episodes                | 4680        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.33e+03    |\n",
      "| n_updates               | 1239164     |\n",
      "| policy_loss             | -412.63144  |\n",
      "| qf1_loss                | 29.28577    |\n",
      "| qf2_loss                | 18.992268   |\n",
      "| time_elapsed            | 14890       |\n",
      "| total timesteps         | 1239263     |\n",
      "| value_loss              | 11.946696   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.027718937 |\n",
      "| ent_coef_loss           | -6.5352225  |\n",
      "| entropy                 | 13.675625   |\n",
      "| episodes                | 4690        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.5e+03     |\n",
      "| n_updates               | 1247948     |\n",
      "| policy_loss             | -413.52417  |\n",
      "| qf1_loss                | 18.187092   |\n",
      "| qf2_loss                | 26.71135    |\n",
      "| time_elapsed            | 14991       |\n",
      "| total timesteps         | 1248047     |\n",
      "| value_loss              | 17.072006   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028489698 |\n",
      "| ent_coef_loss           | -0.1266368  |\n",
      "| entropy                 | 13.98067    |\n",
      "| episodes                | 4700        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.56e+03    |\n",
      "| n_updates               | 1253213     |\n",
      "| policy_loss             | -409.32883  |\n",
      "| qf1_loss                | 34.713398   |\n",
      "| qf2_loss                | 32.901463   |\n",
      "| time_elapsed            | 15051       |\n",
      "| total timesteps         | 1253312     |\n",
      "| value_loss              | 23.807777   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029441807 |\n",
      "| ent_coef_loss           | 1.7717334   |\n",
      "| entropy                 | 13.64837    |\n",
      "| episodes                | 4710        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.72e+03    |\n",
      "| n_updates               | 1262075     |\n",
      "| policy_loss             | -398.41608  |\n",
      "| qf1_loss                | 11.597394   |\n",
      "| qf2_loss                | 19.534313   |\n",
      "| time_elapsed            | 15154       |\n",
      "| total timesteps         | 1262174     |\n",
      "| value_loss              | 22.947973   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.026796514 |\n",
      "| ent_coef_loss           | 2.550488    |\n",
      "| entropy                 | 13.381535   |\n",
      "| episodes                | 4720        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.88e+03    |\n",
      "| n_updates               | 1270872     |\n",
      "| policy_loss             | -392.32333  |\n",
      "| qf1_loss                | 26.702322   |\n",
      "| qf2_loss                | 11.449345   |\n",
      "| time_elapsed            | 15259       |\n",
      "| total timesteps         | 1270971     |\n",
      "| value_loss              | 14.80231    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030933443 |\n",
      "| ent_coef_loss           | 6.661243    |\n",
      "| entropy                 | 14.372118   |\n",
      "| episodes                | 4730        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.98e+03    |\n",
      "| n_updates               | 1279422     |\n",
      "| policy_loss             | -411.237    |\n",
      "| qf1_loss                | 16.606804   |\n",
      "| qf2_loss                | 22.055641   |\n",
      "| time_elapsed            | 15364       |\n",
      "| total timesteps         | 1279521     |\n",
      "| value_loss              | 9.861782    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031907335 |\n",
      "| ent_coef_loss           | -11.359731  |\n",
      "| entropy                 | 14.316734   |\n",
      "| episodes                | 4740        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.98e+03    |\n",
      "| n_updates               | 1286531     |\n",
      "| policy_loss             | -416.3676   |\n",
      "| qf1_loss                | 19.008774   |\n",
      "| qf2_loss                | 12.709184   |\n",
      "| time_elapsed            | 15447       |\n",
      "| total timesteps         | 1286630     |\n",
      "| value_loss              | 8.140703    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029769951 |\n",
      "| ent_coef_loss           | 3.136643    |\n",
      "| entropy                 | 13.930703   |\n",
      "| episodes                | 4750        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 4.07e+03    |\n",
      "| n_updates               | 1292916     |\n",
      "| policy_loss             | -404.84576  |\n",
      "| qf1_loss                | 22.470522   |\n",
      "| qf2_loss                | 14.496952   |\n",
      "| time_elapsed            | 15527       |\n",
      "| total timesteps         | 1293015     |\n",
      "| value_loss              | 19.842743   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.027657155 |\n",
      "| ent_coef_loss           | -0.01214695 |\n",
      "| entropy                 | 14.339914   |\n",
      "| episodes                | 4760        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 4.23e+03    |\n",
      "| n_updates               | 1299861     |\n",
      "| policy_loss             | -423.03564  |\n",
      "| qf1_loss                | 8.367517    |\n",
      "| qf2_loss                | 12.607267   |\n",
      "| time_elapsed            | 15615       |\n",
      "| total timesteps         | 1299960     |\n",
      "| value_loss              | 13.585474   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028665552 |\n",
      "| ent_coef_loss           | -16.622063  |\n",
      "| entropy                 | 15.076967   |\n",
      "| episodes                | 4770        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 4.25e+03    |\n",
      "| n_updates               | 1308522     |\n",
      "| policy_loss             | -430.65967  |\n",
      "| qf1_loss                | 12.273869   |\n",
      "| qf2_loss                | 17.513058   |\n",
      "| time_elapsed            | 15745       |\n",
      "| total timesteps         | 1308621     |\n",
      "| value_loss              | 9.429866    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.027520694 |\n",
      "| ent_coef_loss           | 5.310293    |\n",
      "| entropy                 | 13.978738   |\n",
      "| episodes                | 4780        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 4.17e+03    |\n",
      "| n_updates               | 1316176     |\n",
      "| policy_loss             | -407.5349   |\n",
      "| qf1_loss                | 46.211594   |\n",
      "| qf2_loss                | 25.86856    |\n",
      "| time_elapsed            | 15860       |\n",
      "| total timesteps         | 1316275     |\n",
      "| value_loss              | 11.591336   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029565172 |\n",
      "| ent_coef_loss           | 11.197067   |\n",
      "| entropy                 | 14.570263   |\n",
      "| episodes                | 4790        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 4.12e+03    |\n",
      "| n_updates               | 1324154     |\n",
      "| policy_loss             | -405.64154  |\n",
      "| qf1_loss                | 38.416294   |\n",
      "| qf2_loss                | 44.326347   |\n",
      "| time_elapsed            | 15980       |\n",
      "| total timesteps         | 1324253     |\n",
      "| value_loss              | 9.931402    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028929535 |\n",
      "| ent_coef_loss           | -1.3951993  |\n",
      "| entropy                 | 14.732822   |\n",
      "| episodes                | 4800        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 4.26e+03    |\n",
      "| n_updates               | 1332000     |\n",
      "| policy_loss             | -419.2256   |\n",
      "| qf1_loss                | 24.50227    |\n",
      "| qf2_loss                | 21.618652   |\n",
      "| time_elapsed            | 16096       |\n",
      "| total timesteps         | 1332099     |\n",
      "| value_loss              | 10.828849   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028687019 |\n",
      "| ent_coef_loss           | -20.90469   |\n",
      "| entropy                 | 15.090248   |\n",
      "| episodes                | 4810        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 4.23e+03    |\n",
      "| n_updates               | 1340467     |\n",
      "| policy_loss             | -411.88998  |\n",
      "| qf1_loss                | 16.849611   |\n",
      "| qf2_loss                | 27.782314   |\n",
      "| time_elapsed            | 16218       |\n",
      "| total timesteps         | 1340566     |\n",
      "| value_loss              | 9.6488085   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030893821 |\n",
      "| ent_coef_loss           | 2.0187287   |\n",
      "| entropy                 | 14.762737   |\n",
      "| episodes                | 4820        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 4.2e+03     |\n",
      "| n_updates               | 1348624     |\n",
      "| policy_loss             | -423.39713  |\n",
      "| qf1_loss                | 26.353664   |\n",
      "| qf2_loss                | 23.610834   |\n",
      "| time_elapsed            | 16347       |\n",
      "| total timesteps         | 1348723     |\n",
      "| value_loss              | 16.155067   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03088525 |\n",
      "| ent_coef_loss           | -12.652441 |\n",
      "| entropy                 | 15.114635  |\n",
      "| episodes                | 4830       |\n",
      "| fps                     | 82         |\n",
      "| mean 100 episode reward | 4.09e+03   |\n",
      "| n_updates               | 1355107    |\n",
      "| policy_loss             | -437.64008 |\n",
      "| qf1_loss                | 9.0941     |\n",
      "| qf2_loss                | 6.1550093  |\n",
      "| time_elapsed            | 16438      |\n",
      "| total timesteps         | 1355206    |\n",
      "| value_loss              | 5.134454   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028774878 |\n",
      "| ent_coef_loss           | 4.676939    |\n",
      "| entropy                 | 14.067465   |\n",
      "| episodes                | 4840        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 3.94e+03    |\n",
      "| n_updates               | 1359486     |\n",
      "| policy_loss             | -424.0244   |\n",
      "| qf1_loss                | 25.958145   |\n",
      "| qf2_loss                | 18.685772   |\n",
      "| time_elapsed            | 16503       |\n",
      "| total timesteps         | 1359585     |\n",
      "| value_loss              | 18.698809   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029911466 |\n",
      "| ent_coef_loss           | -3.8033762  |\n",
      "| entropy                 | 14.883317   |\n",
      "| episodes                | 4850        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 3.93e+03    |\n",
      "| n_updates               | 1365878     |\n",
      "| policy_loss             | -430.06647  |\n",
      "| qf1_loss                | 21.402185   |\n",
      "| qf2_loss                | 20.463718   |\n",
      "| time_elapsed            | 16594       |\n",
      "| total timesteps         | 1365977     |\n",
      "| value_loss              | 9.409874    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028558193 |\n",
      "| ent_coef_loss           | -9.994448   |\n",
      "| entropy                 | 14.88106    |\n",
      "| episodes                | 4860        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 4e+03       |\n",
      "| n_updates               | 1374183     |\n",
      "| policy_loss             | -428.07928  |\n",
      "| qf1_loss                | 34.5451     |\n",
      "| qf2_loss                | 22.205969   |\n",
      "| time_elapsed            | 16700       |\n",
      "| total timesteps         | 1374282     |\n",
      "| value_loss              | 7.284384    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029112602 |\n",
      "| ent_coef_loss           | -6.5640965  |\n",
      "| entropy                 | 15.105557   |\n",
      "| episodes                | 4870        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 3.91e+03    |\n",
      "| n_updates               | 1381444     |\n",
      "| policy_loss             | -425.3202   |\n",
      "| qf1_loss                | 26.853909   |\n",
      "| qf2_loss                | 22.113792   |\n",
      "| time_elapsed            | 16789       |\n",
      "| total timesteps         | 1381543     |\n",
      "| value_loss              | 14.009164   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02692172 |\n",
      "| ent_coef_loss           | -7.3967843 |\n",
      "| entropy                 | 14.212481  |\n",
      "| episodes                | 4880       |\n",
      "| fps                     | 82         |\n",
      "| mean 100 episode reward | 3.74e+03   |\n",
      "| n_updates               | 1385839    |\n",
      "| policy_loss             | -431.55548 |\n",
      "| qf1_loss                | 5.5338163  |\n",
      "| qf2_loss                | 8.810286   |\n",
      "| time_elapsed            | 16836      |\n",
      "| total timesteps         | 1385938    |\n",
      "| value_loss              | 5.3006477  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02931157 |\n",
      "| ent_coef_loss           | -1.9252799 |\n",
      "| entropy                 | 14.5298    |\n",
      "| episodes                | 4890       |\n",
      "| fps                     | 82         |\n",
      "| mean 100 episode reward | 3.64e+03   |\n",
      "| n_updates               | 1391861    |\n",
      "| policy_loss             | -419.99942 |\n",
      "| qf1_loss                | 22.158312  |\n",
      "| qf2_loss                | 11.051484  |\n",
      "| time_elapsed            | 16900      |\n",
      "| total timesteps         | 1391960    |\n",
      "| value_loss              | 13.393807  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030838408 |\n",
      "| ent_coef_loss           | -3.907464   |\n",
      "| entropy                 | 14.418226   |\n",
      "| episodes                | 4900        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 3.66e+03    |\n",
      "| n_updates               | 1400097     |\n",
      "| policy_loss             | -431.39227  |\n",
      "| qf1_loss                | 13.4305315  |\n",
      "| qf2_loss                | 10.371884   |\n",
      "| time_elapsed            | 16989       |\n",
      "| total timesteps         | 1400196     |\n",
      "| value_loss              | 16.101444   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031158194 |\n",
      "| ent_coef_loss           | 1.2638628   |\n",
      "| entropy                 | 14.5897045  |\n",
      "| episodes                | 4910        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 3.67e+03    |\n",
      "| n_updates               | 1408784     |\n",
      "| policy_loss             | -423.9497   |\n",
      "| qf1_loss                | 23.648445   |\n",
      "| qf2_loss                | 8.721216    |\n",
      "| time_elapsed            | 17101       |\n",
      "| total timesteps         | 1408883     |\n",
      "| value_loss              | 15.425955   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.027770698 |\n",
      "| ent_coef_loss           | 15.756151   |\n",
      "| entropy                 | 14.048111   |\n",
      "| episodes                | 4920        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 3.44e+03    |\n",
      "| n_updates               | 1412674     |\n",
      "| policy_loss             | -394.95367  |\n",
      "| qf1_loss                | 21.43163    |\n",
      "| qf2_loss                | 25.225151   |\n",
      "| time_elapsed            | 17164       |\n",
      "| total timesteps         | 1412773     |\n",
      "| value_loss              | 15.375331   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028234681 |\n",
      "| ent_coef_loss           | -2.0055163  |\n",
      "| entropy                 | 14.255329   |\n",
      "| episodes                | 4930        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 3.51e+03    |\n",
      "| n_updates               | 1420473     |\n",
      "| policy_loss             | -424.27484  |\n",
      "| qf1_loss                | 30.558456   |\n",
      "| qf2_loss                | 27.52766    |\n",
      "| time_elapsed            | 17275       |\n",
      "| total timesteps         | 1420572     |\n",
      "| value_loss              | 20.259993   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029355194 |\n",
      "| ent_coef_loss           | 7.2815824   |\n",
      "| entropy                 | 14.181046   |\n",
      "| episodes                | 4940        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 3.78e+03    |\n",
      "| n_updates               | 1429836     |\n",
      "| policy_loss             | -392.38025  |\n",
      "| qf1_loss                | 20.920248   |\n",
      "| qf2_loss                | 19.255953   |\n",
      "| time_elapsed            | 17413       |\n",
      "| total timesteps         | 1429935     |\n",
      "| value_loss              | 23.018696   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.027849646 |\n",
      "| ent_coef_loss           | 16.995588   |\n",
      "| entropy                 | 13.534981   |\n",
      "| episodes                | 4950        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 3.84e+03    |\n",
      "| n_updates               | 1437063     |\n",
      "| policy_loss             | -400.14398  |\n",
      "| qf1_loss                | 25.95176    |\n",
      "| qf2_loss                | 22.867792   |\n",
      "| time_elapsed            | 17536       |\n",
      "| total timesteps         | 1437162     |\n",
      "| value_loss              | 12.761326   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.027199231 |\n",
      "| ent_coef_loss           | 14.929903   |\n",
      "| entropy                 | 14.32896    |\n",
      "| episodes                | 4960        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 3.83e+03    |\n",
      "| n_updates               | 1444980     |\n",
      "| policy_loss             | -419.27258  |\n",
      "| qf1_loss                | 32.744484   |\n",
      "| qf2_loss                | 19.555525   |\n",
      "| time_elapsed            | 17642       |\n",
      "| total timesteps         | 1445079     |\n",
      "| value_loss              | 18.097229   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.027234135 |\n",
      "| ent_coef_loss           | -3.9067469  |\n",
      "| entropy                 | 14.973588   |\n",
      "| episodes                | 4970        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 3.92e+03    |\n",
      "| n_updates               | 1453741     |\n",
      "| policy_loss             | -440.89343  |\n",
      "| qf1_loss                | 22.24014    |\n",
      "| qf2_loss                | 9.356161    |\n",
      "| time_elapsed            | 17772       |\n",
      "| total timesteps         | 1453840     |\n",
      "| value_loss              | 20.158588   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.026237981 |\n",
      "| ent_coef_loss           | -3.8440397  |\n",
      "| entropy                 | 13.617139   |\n",
      "| episodes                | 4980        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 3.98e+03    |\n",
      "| n_updates               | 1459381     |\n",
      "| policy_loss             | -432.10052  |\n",
      "| qf1_loss                | 44.174377   |\n",
      "| qf2_loss                | 36.564972   |\n",
      "| time_elapsed            | 17861       |\n",
      "| total timesteps         | 1459480     |\n",
      "| value_loss              | 18.31028    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.027638612 |\n",
      "| ent_coef_loss           | 2.84926     |\n",
      "| entropy                 | 14.459934   |\n",
      "| episodes                | 4990        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 4.02e+03    |\n",
      "| n_updates               | 1466356     |\n",
      "| policy_loss             | -418.74445  |\n",
      "| qf1_loss                | 23.572346   |\n",
      "| qf2_loss                | 25.96753    |\n",
      "| time_elapsed            | 17972       |\n",
      "| total timesteps         | 1466455     |\n",
      "| value_loss              | 12.668266   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.027442526 |\n",
      "| ent_coef_loss           | -0.5155716  |\n",
      "| entropy                 | 14.503395   |\n",
      "| episodes                | 5000        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 3.92e+03    |\n",
      "| n_updates               | 1472489     |\n",
      "| policy_loss             | -411.71277  |\n",
      "| qf1_loss                | 26.638527   |\n",
      "| qf2_loss                | 23.403843   |\n",
      "| time_elapsed            | 18071       |\n",
      "| total timesteps         | 1472588     |\n",
      "| value_loss              | 15.264112   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.026165871 |\n",
      "| ent_coef_loss           | -5.325344   |\n",
      "| entropy                 | 14.978943   |\n",
      "| episodes                | 5010        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 3.77e+03    |\n",
      "| n_updates               | 1478462     |\n",
      "| policy_loss             | -415.24664  |\n",
      "| qf1_loss                | 12.881838   |\n",
      "| qf2_loss                | 4.7037215   |\n",
      "| time_elapsed            | 18168       |\n",
      "| total timesteps         | 1478561     |\n",
      "| value_loss              | 8.373249    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.027464284 |\n",
      "| ent_coef_loss           | -7.2669535  |\n",
      "| entropy                 | 15.035132   |\n",
      "| episodes                | 5020        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 4.05e+03    |\n",
      "| n_updates               | 1487358     |\n",
      "| policy_loss             | -443.85168  |\n",
      "| qf1_loss                | 24.539875   |\n",
      "| qf2_loss                | 21.570902   |\n",
      "| time_elapsed            | 18310       |\n",
      "| total timesteps         | 1487457     |\n",
      "| value_loss              | 7.863242    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.027783923 |\n",
      "| ent_coef_loss           | -3.3183503  |\n",
      "| entropy                 | 14.84368    |\n",
      "| episodes                | 5030        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 4.01e+03    |\n",
      "| n_updates               | 1494289     |\n",
      "| policy_loss             | -426.43997  |\n",
      "| qf1_loss                | 20.904154   |\n",
      "| qf2_loss                | 31.372118   |\n",
      "| time_elapsed            | 18391       |\n",
      "| total timesteps         | 1494388     |\n",
      "| value_loss              | 26.665436   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029119253 |\n",
      "| ent_coef_loss           | -7.978      |\n",
      "| entropy                 | 15.151413   |\n",
      "| episodes                | 5040        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 3.79e+03    |\n",
      "| n_updates               | 1499554     |\n",
      "| policy_loss             | -430.7598   |\n",
      "| qf1_loss                | 8.593088    |\n",
      "| qf2_loss                | 7.9533772   |\n",
      "| time_elapsed            | 18446       |\n",
      "| total timesteps         | 1499653     |\n",
      "| value_loss              | 12.704058   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028081415 |\n",
      "| ent_coef_loss           | -15.316221  |\n",
      "| entropy                 | 14.456032   |\n",
      "| episodes                | 5050        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 3.9e+03     |\n",
      "| n_updates               | 1508718     |\n",
      "| policy_loss             | -446.16928  |\n",
      "| qf1_loss                | 38.730827   |\n",
      "| qf2_loss                | 26.78573    |\n",
      "| time_elapsed            | 18544       |\n",
      "| total timesteps         | 1508817     |\n",
      "| value_loss              | 14.101718   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029235898 |\n",
      "| ent_coef_loss           | -15.363142  |\n",
      "| entropy                 | 15.053864   |\n",
      "| episodes                | 5060        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 3.93e+03    |\n",
      "| n_updates               | 1517052     |\n",
      "| policy_loss             | -438.28143  |\n",
      "| qf1_loss                | 14.718515   |\n",
      "| qf2_loss                | 18.477757   |\n",
      "| time_elapsed            | 18632       |\n",
      "| total timesteps         | 1517151     |\n",
      "| value_loss              | 11.116659   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.027795438 |\n",
      "| ent_coef_loss           | -1.6932344  |\n",
      "| entropy                 | 14.18121    |\n",
      "| episodes                | 5070        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 3.79e+03    |\n",
      "| n_updates               | 1523216     |\n",
      "| policy_loss             | -432.23566  |\n",
      "| qf1_loss                | 19.22658    |\n",
      "| qf2_loss                | 10.887161   |\n",
      "| time_elapsed            | 18698       |\n",
      "| total timesteps         | 1523315     |\n",
      "| value_loss              | 11.653297   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.027761528 |\n",
      "| ent_coef_loss           | -11.949507  |\n",
      "| entropy                 | 15.105493   |\n",
      "| episodes                | 5080        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 3.84e+03    |\n",
      "| n_updates               | 1529659     |\n",
      "| policy_loss             | -444.05518  |\n",
      "| qf1_loss                | 7.627598    |\n",
      "| qf2_loss                | 6.6715155   |\n",
      "| time_elapsed            | 18767       |\n",
      "| total timesteps         | 1529758     |\n",
      "| value_loss              | 5.973584    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.026431212 |\n",
      "| ent_coef_loss           | -10.720377  |\n",
      "| entropy                 | 14.92044    |\n",
      "| episodes                | 5090        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 3.99e+03    |\n",
      "| n_updates               | 1539058     |\n",
      "| policy_loss             | -435.13574  |\n",
      "| qf1_loss                | 13.92595    |\n",
      "| qf2_loss                | 10.586875   |\n",
      "| time_elapsed            | 18866       |\n",
      "| total timesteps         | 1539157     |\n",
      "| value_loss              | 17.578753   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031511717 |\n",
      "| ent_coef_loss           | 1.1926198   |\n",
      "| entropy                 | 14.710289   |\n",
      "| episodes                | 5100        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 4.02e+03    |\n",
      "| n_updates               | 1545821     |\n",
      "| policy_loss             | -433.6376   |\n",
      "| qf1_loss                | 16.388191   |\n",
      "| qf2_loss                | 12.994824   |\n",
      "| time_elapsed            | 18938       |\n",
      "| total timesteps         | 1545920     |\n",
      "| value_loss              | 13.033691   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.0276202  |\n",
      "| ent_coef_loss           | 0.82931113 |\n",
      "| entropy                 | 14.159228  |\n",
      "| episodes                | 5110       |\n",
      "| fps                     | 81         |\n",
      "| mean 100 episode reward | 4.09e+03   |\n",
      "| n_updates               | 1552852    |\n",
      "| policy_loss             | -436.51703 |\n",
      "| qf1_loss                | 11.983243  |\n",
      "| qf2_loss                | 17.111895  |\n",
      "| time_elapsed            | 19012      |\n",
      "| total timesteps         | 1552951    |\n",
      "| value_loss              | 5.8416967  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028448496 |\n",
      "| ent_coef_loss           | 13.600281   |\n",
      "| entropy                 | 14.679515   |\n",
      "| episodes                | 5120        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 4.1e+03     |\n",
      "| n_updates               | 1561936     |\n",
      "| policy_loss             | -413.52957  |\n",
      "| qf1_loss                | 19.35       |\n",
      "| qf2_loss                | 13.077816   |\n",
      "| time_elapsed            | 19109       |\n",
      "| total timesteps         | 1562035     |\n",
      "| value_loss              | 19.32266    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.0301353  |\n",
      "| ent_coef_loss           | -2.9950337 |\n",
      "| entropy                 | 14.352768  |\n",
      "| episodes                | 5130       |\n",
      "| fps                     | 81         |\n",
      "| mean 100 episode reward | 4.06e+03   |\n",
      "| n_updates               | 1568395    |\n",
      "| policy_loss             | -454.2911  |\n",
      "| qf1_loss                | 30.45112   |\n",
      "| qf2_loss                | 31.994534  |\n",
      "| time_elapsed            | 19177      |\n",
      "| total timesteps         | 1568494    |\n",
      "| value_loss              | 28.456514  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02739143 |\n",
      "| ent_coef_loss           | -3.9665508 |\n",
      "| entropy                 | 13.674968  |\n",
      "| episodes                | 5140       |\n",
      "| fps                     | 81         |\n",
      "| mean 100 episode reward | 4.19e+03   |\n",
      "| n_updates               | 1575735    |\n",
      "| policy_loss             | -413.25836 |\n",
      "| qf1_loss                | 19.962688  |\n",
      "| qf2_loss                | 23.36056   |\n",
      "| time_elapsed            | 19255      |\n",
      "| total timesteps         | 1575834    |\n",
      "| value_loss              | 23.764755  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030355772 |\n",
      "| ent_coef_loss           | -1.3496177  |\n",
      "| entropy                 | 14.580101   |\n",
      "| episodes                | 5150        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 4.07e+03    |\n",
      "| n_updates               | 1582716     |\n",
      "| policy_loss             | -435.61145  |\n",
      "| qf1_loss                | 27.70811    |\n",
      "| qf2_loss                | 24.352325   |\n",
      "| time_elapsed            | 19328       |\n",
      "| total timesteps         | 1582815     |\n",
      "| value_loss              | 9.4441805   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029162627 |\n",
      "| ent_coef_loss           | 2.6322558   |\n",
      "| entropy                 | 14.549913   |\n",
      "| episodes                | 5160        |\n",
      "| fps                     | 81          |\n",
      "| mean 100 episode reward | 4.11e+03    |\n",
      "| n_updates               | 1591827     |\n",
      "| policy_loss             | -425.85724  |\n",
      "| qf1_loss                | 18.028362   |\n",
      "| qf2_loss                | 14.734481   |\n",
      "| time_elapsed            | 19425       |\n",
      "| total timesteps         | 1591926     |\n",
      "| value_loss              | 28.816761   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028674206 |\n",
      "| ent_coef_loss           | 5.8897862   |\n",
      "| entropy                 | 14.818251   |\n",
      "| episodes                | 5170        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 4.27e+03    |\n",
      "| n_updates               | 1600997     |\n",
      "| policy_loss             | -412.55637  |\n",
      "| qf1_loss                | 30.265223   |\n",
      "| qf2_loss                | 19.681135   |\n",
      "| time_elapsed            | 19522       |\n",
      "| total timesteps         | 1601096     |\n",
      "| value_loss              | 7.9886346   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031598084 |\n",
      "| ent_coef_loss           | 3.5222216   |\n",
      "| entropy                 | 14.168704   |\n",
      "| episodes                | 5180        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 4.42e+03    |\n",
      "| n_updates               | 1609954     |\n",
      "| policy_loss             | -431.9673   |\n",
      "| qf1_loss                | 40.96723    |\n",
      "| qf2_loss                | 21.241243   |\n",
      "| time_elapsed            | 19621       |\n",
      "| total timesteps         | 1610053     |\n",
      "| value_loss              | 20.294216   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028485378 |\n",
      "| ent_coef_loss           | -1.4538074  |\n",
      "| entropy                 | 14.535371   |\n",
      "| episodes                | 5190        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 4.35e+03    |\n",
      "| n_updates               | 1617990     |\n",
      "| policy_loss             | -424.69214  |\n",
      "| qf1_loss                | 13.636562   |\n",
      "| qf2_loss                | 14.962355   |\n",
      "| time_elapsed            | 19708       |\n",
      "| total timesteps         | 1618089     |\n",
      "| value_loss              | 20.31694    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028536223 |\n",
      "| ent_coef_loss           | 2.1669118   |\n",
      "| entropy                 | 14.326082   |\n",
      "| episodes                | 5200        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 4.36e+03    |\n",
      "| n_updates               | 1624792     |\n",
      "| policy_loss             | -429.1457   |\n",
      "| qf1_loss                | 15.3621855  |\n",
      "| qf2_loss                | 12.922678   |\n",
      "| time_elapsed            | 19780       |\n",
      "| total timesteps         | 1624891     |\n",
      "| value_loss              | 21.13757    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03022234 |\n",
      "| ent_coef_loss           | 7.232462   |\n",
      "| entropy                 | 13.993225  |\n",
      "| episodes                | 5210       |\n",
      "| fps                     | 82         |\n",
      "| mean 100 episode reward | 4.43e+03   |\n",
      "| n_updates               | 1633095    |\n",
      "| policy_loss             | -440.28934 |\n",
      "| qf1_loss                | 15.385001  |\n",
      "| qf2_loss                | 16.51794   |\n",
      "| time_elapsed            | 19869      |\n",
      "| total timesteps         | 1633194    |\n",
      "| value_loss              | 6.684456   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02793943 |\n",
      "| ent_coef_loss           | -3.0425763 |\n",
      "| entropy                 | 14.281975  |\n",
      "| episodes                | 5220       |\n",
      "| fps                     | 82         |\n",
      "| mean 100 episode reward | 4.25e+03   |\n",
      "| n_updates               | 1638874    |\n",
      "| policy_loss             | -431.43124 |\n",
      "| qf1_loss                | 6.030054   |\n",
      "| qf2_loss                | 15.032359  |\n",
      "| time_elapsed            | 19931      |\n",
      "| total timesteps         | 1638973    |\n",
      "| value_loss              | 11.195568  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028437505 |\n",
      "| ent_coef_loss           | 4.41158     |\n",
      "| entropy                 | 14.543958   |\n",
      "| episodes                | 5230        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 4.26e+03    |\n",
      "| n_updates               | 1645511     |\n",
      "| policy_loss             | -442.544    |\n",
      "| qf1_loss                | 19.019035   |\n",
      "| qf2_loss                | 54.390434   |\n",
      "| time_elapsed            | 20002       |\n",
      "| total timesteps         | 1645610     |\n",
      "| value_loss              | 23.705194   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028470298 |\n",
      "| ent_coef_loss           | 0.38507462  |\n",
      "| entropy                 | 14.941883   |\n",
      "| episodes                | 5240        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 4.18e+03    |\n",
      "| n_updates               | 1651271     |\n",
      "| policy_loss             | -437.38     |\n",
      "| qf1_loss                | 12.62315    |\n",
      "| qf2_loss                | 9.701993    |\n",
      "| time_elapsed            | 20063       |\n",
      "| total timesteps         | 1651370     |\n",
      "| value_loss              | 4.76409     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029036185 |\n",
      "| ent_coef_loss           | 3.8506784   |\n",
      "| entropy                 | 14.717987   |\n",
      "| episodes                | 5250        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 4.11e+03    |\n",
      "| n_updates               | 1656937     |\n",
      "| policy_loss             | -431.8553   |\n",
      "| qf1_loss                | 9.394657    |\n",
      "| qf2_loss                | 20.95409    |\n",
      "| time_elapsed            | 20123       |\n",
      "| total timesteps         | 1657036     |\n",
      "| value_loss              | 5.0079355   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.027322585 |\n",
      "| ent_coef_loss           | 9.422425    |\n",
      "| entropy                 | 13.355223   |\n",
      "| episodes                | 5260        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 4.07e+03    |\n",
      "| n_updates               | 1665283     |\n",
      "| policy_loss             | -421.4519   |\n",
      "| qf1_loss                | 8.137091    |\n",
      "| qf2_loss                | 15.678598   |\n",
      "| time_elapsed            | 20211       |\n",
      "| total timesteps         | 1665382     |\n",
      "| value_loss              | 9.288737    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028152412 |\n",
      "| ent_coef_loss           | -6.794527   |\n",
      "| entropy                 | 14.279665   |\n",
      "| episodes                | 5270        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 4e+03       |\n",
      "| n_updates               | 1673430     |\n",
      "| policy_loss             | -432.35165  |\n",
      "| qf1_loss                | 11.946665   |\n",
      "| qf2_loss                | 7.9017906   |\n",
      "| time_elapsed            | 20298       |\n",
      "| total timesteps         | 1673529     |\n",
      "| value_loss              | 8.249122    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.027855908 |\n",
      "| ent_coef_loss           | 9.666199    |\n",
      "| entropy                 | 13.751051   |\n",
      "| episodes                | 5280        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 3.86e+03    |\n",
      "| n_updates               | 1680050     |\n",
      "| policy_loss             | -417.6551   |\n",
      "| qf1_loss                | 11.557052   |\n",
      "| qf2_loss                | 23.009552   |\n",
      "| time_elapsed            | 20368       |\n",
      "| total timesteps         | 1680149     |\n",
      "| value_loss              | 21.974735   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.027753342 |\n",
      "| ent_coef_loss           | -3.477269   |\n",
      "| entropy                 | 14.266816   |\n",
      "| episodes                | 5290        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 3.86e+03    |\n",
      "| n_updates               | 1687935     |\n",
      "| policy_loss             | -432.45187  |\n",
      "| qf1_loss                | 11.663385   |\n",
      "| qf2_loss                | 25.817421   |\n",
      "| time_elapsed            | 20452       |\n",
      "| total timesteps         | 1688034     |\n",
      "| value_loss              | 8.901488    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.027218284 |\n",
      "| ent_coef_loss           | -12.695534  |\n",
      "| entropy                 | 14.531222   |\n",
      "| episodes                | 5300        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 3.95e+03    |\n",
      "| n_updates               | 1696388     |\n",
      "| policy_loss             | -442.1854   |\n",
      "| qf1_loss                | 39.010773   |\n",
      "| qf2_loss                | 37.700348   |\n",
      "| time_elapsed            | 20541       |\n",
      "| total timesteps         | 1696487     |\n",
      "| value_loss              | 10.010439   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.027425397 |\n",
      "| ent_coef_loss           | -3.522092   |\n",
      "| entropy                 | 14.715565   |\n",
      "| episodes                | 5310        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 3.89e+03    |\n",
      "| n_updates               | 1703649     |\n",
      "| policy_loss             | -419.81427  |\n",
      "| qf1_loss                | 18.584003   |\n",
      "| qf2_loss                | 15.464287   |\n",
      "| time_elapsed            | 20618       |\n",
      "| total timesteps         | 1703748     |\n",
      "| value_loss              | 7.7219276   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028719485 |\n",
      "| ent_coef_loss           | 4.491871    |\n",
      "| entropy                 | 14.895055   |\n",
      "| episodes                | 5320        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 3.84e+03    |\n",
      "| n_updates               | 1708712     |\n",
      "| policy_loss             | -429.49194  |\n",
      "| qf1_loss                | 40.51549    |\n",
      "| qf2_loss                | 16.647335   |\n",
      "| time_elapsed            | 20671       |\n",
      "| total timesteps         | 1708811     |\n",
      "| value_loss              | 9.501934    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029987907 |\n",
      "| ent_coef_loss           | -0.94289666 |\n",
      "| entropy                 | 14.423759   |\n",
      "| episodes                | 5330        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 3.84e+03    |\n",
      "| n_updates               | 1715251     |\n",
      "| policy_loss             | -439.30676  |\n",
      "| qf1_loss                | 11.228678   |\n",
      "| qf2_loss                | 12.767899   |\n",
      "| time_elapsed            | 20740       |\n",
      "| total timesteps         | 1715350     |\n",
      "| value_loss              | 3.6708817   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031042188 |\n",
      "| ent_coef_loss           | -1.7417643  |\n",
      "| entropy                 | 13.8299885  |\n",
      "| episodes                | 5340        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 3.76e+03    |\n",
      "| n_updates               | 1719784     |\n",
      "| policy_loss             | -420.516    |\n",
      "| qf1_loss                | 41.28412    |\n",
      "| qf2_loss                | 12.842125   |\n",
      "| time_elapsed            | 20789       |\n",
      "| total timesteps         | 1719883     |\n",
      "| value_loss              | 7.440008    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030456392 |\n",
      "| ent_coef_loss           | 7.4296513   |\n",
      "| entropy                 | 13.376277   |\n",
      "| episodes                | 5350        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 3.84e+03    |\n",
      "| n_updates               | 1727047     |\n",
      "| policy_loss             | -441.41824  |\n",
      "| qf1_loss                | 32.669914   |\n",
      "| qf2_loss                | 30.691265   |\n",
      "| time_elapsed            | 20866       |\n",
      "| total timesteps         | 1727146     |\n",
      "| value_loss              | 11.324757   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031069644 |\n",
      "| ent_coef_loss           | -7.999904   |\n",
      "| entropy                 | 14.075526   |\n",
      "| episodes                | 5360        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 3.62e+03    |\n",
      "| n_updates               | 1731351     |\n",
      "| policy_loss             | -437.6958   |\n",
      "| qf1_loss                | 692.12286   |\n",
      "| qf2_loss                | 585.5472    |\n",
      "| time_elapsed            | 20912       |\n",
      "| total timesteps         | 1731450     |\n",
      "| value_loss              | 19.124771   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03058573 |\n",
      "| ent_coef_loss           | 5.983846   |\n",
      "| entropy                 | 14.605041  |\n",
      "| episodes                | 5370       |\n",
      "| fps                     | 82         |\n",
      "| mean 100 episode reward | 3.65e+03   |\n",
      "| n_updates               | 1740049    |\n",
      "| policy_loss             | -429.3124  |\n",
      "| qf1_loss                | 15.6787815 |\n",
      "| qf2_loss                | 23.822819  |\n",
      "| time_elapsed            | 21008      |\n",
      "| total timesteps         | 1740148    |\n",
      "| value_loss              | 15.562279  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028879931 |\n",
      "| ent_coef_loss           | -2.9706044  |\n",
      "| entropy                 | 14.068977   |\n",
      "| episodes                | 5380        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 3.64e+03    |\n",
      "| n_updates               | 1746874     |\n",
      "| policy_loss             | -434.90973  |\n",
      "| qf1_loss                | 10.814505   |\n",
      "| qf2_loss                | 11.352846   |\n",
      "| time_elapsed            | 21089       |\n",
      "| total timesteps         | 1746973     |\n",
      "| value_loss              | 6.673716    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031185113 |\n",
      "| ent_coef_loss           | 4.209318    |\n",
      "| entropy                 | 14.542936   |\n",
      "| episodes                | 5390        |\n",
      "| fps                     | 82          |\n",
      "| mean 100 episode reward | 3.61e+03    |\n",
      "| n_updates               | 1754325     |\n",
      "| policy_loss             | -413.54474  |\n",
      "| qf1_loss                | 18.529375   |\n",
      "| qf2_loss                | 21.071365   |\n",
      "| time_elapsed            | 21170       |\n",
      "| total timesteps         | 1754424     |\n",
      "| value_loss              | 19.512653   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03154698 |\n",
      "| ent_coef_loss           | 1.3215375  |\n",
      "| entropy                 | 14.085138  |\n",
      "| episodes                | 5400       |\n",
      "| fps                     | 82         |\n",
      "| mean 100 episode reward | 3.58e+03   |\n",
      "| n_updates               | 1762314    |\n",
      "| policy_loss             | -433.77612 |\n",
      "| qf1_loss                | 23.917633  |\n",
      "| qf2_loss                | 8.712568   |\n",
      "| time_elapsed            | 21254      |\n",
      "| total timesteps         | 1762413    |\n",
      "| value_loss              | 14.228395  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03164945 |\n",
      "| ent_coef_loss           | 7.3349843  |\n",
      "| entropy                 | 13.28759   |\n",
      "| episodes                | 5410       |\n",
      "| fps                     | 82         |\n",
      "| mean 100 episode reward | 3.66e+03   |\n",
      "| n_updates               | 1771157    |\n",
      "| policy_loss             | -429.00803 |\n",
      "| qf1_loss                | 13.114708  |\n",
      "| qf2_loss                | 16.532442  |\n",
      "| time_elapsed            | 21348      |\n",
      "| total timesteps         | 1771256    |\n",
      "| value_loss              | 15.664197  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028652295 |\n",
      "| ent_coef_loss           | -8.18576    |\n",
      "| entropy                 | 14.181464   |\n",
      "| episodes                | 5420        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.89e+03    |\n",
      "| n_updates               | 1780325     |\n",
      "| policy_loss             | -434.42188  |\n",
      "| qf1_loss                | 9.782009    |\n",
      "| qf2_loss                | 8.85445     |\n",
      "| time_elapsed            | 21445       |\n",
      "| total timesteps         | 1780424     |\n",
      "| value_loss              | 7.4326897   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028613793 |\n",
      "| ent_coef_loss           | -10.090923  |\n",
      "| entropy                 | 15.066849   |\n",
      "| episodes                | 5430        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.91e+03    |\n",
      "| n_updates               | 1787156     |\n",
      "| policy_loss             | -429.58423  |\n",
      "| qf1_loss                | 18.861523   |\n",
      "| qf2_loss                | 25.470991   |\n",
      "| time_elapsed            | 21517       |\n",
      "| total timesteps         | 1787255     |\n",
      "| value_loss              | 15.906436   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028113268 |\n",
      "| ent_coef_loss           | -11.499125  |\n",
      "| entropy                 | 15.18391    |\n",
      "| episodes                | 5440        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.97e+03    |\n",
      "| n_updates               | 1792879     |\n",
      "| policy_loss             | -442.67853  |\n",
      "| qf1_loss                | 6.723777    |\n",
      "| qf2_loss                | 5.531251    |\n",
      "| time_elapsed            | 21577       |\n",
      "| total timesteps         | 1792978     |\n",
      "| value_loss              | 3.072418    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030488817 |\n",
      "| ent_coef_loss           | -7.155197   |\n",
      "| entropy                 | 14.536329   |\n",
      "| episodes                | 5450        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.96e+03    |\n",
      "| n_updates               | 1800019     |\n",
      "| policy_loss             | -442.13687  |\n",
      "| qf1_loss                | 6.7421293   |\n",
      "| qf2_loss                | 15.982632   |\n",
      "| time_elapsed            | 21652       |\n",
      "| total timesteps         | 1800118     |\n",
      "| value_loss              | 12.982727   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029562375 |\n",
      "| ent_coef_loss           | -8.325622   |\n",
      "| entropy                 | 14.843882   |\n",
      "| episodes                | 5460        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 4.13e+03    |\n",
      "| n_updates               | 1807358     |\n",
      "| policy_loss             | -426.10474  |\n",
      "| qf1_loss                | 20.069084   |\n",
      "| qf2_loss                | 41.152805   |\n",
      "| time_elapsed            | 21729       |\n",
      "| total timesteps         | 1807457     |\n",
      "| value_loss              | 20.710087   |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029370407 |\n",
      "| ent_coef_loss           | -0.60967827 |\n",
      "| entropy                 | 14.126799   |\n",
      "| episodes                | 5470        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.94e+03    |\n",
      "| n_updates               | 1812632     |\n",
      "| policy_loss             | -425.5194   |\n",
      "| qf1_loss                | 16.695164   |\n",
      "| qf2_loss                | 14.571318   |\n",
      "| time_elapsed            | 21784       |\n",
      "| total timesteps         | 1812731     |\n",
      "| value_loss              | 23.012783   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030695682 |\n",
      "| ent_coef_loss           | -0.45108318 |\n",
      "| entropy                 | 14.259212   |\n",
      "| episodes                | 5480        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.99e+03    |\n",
      "| n_updates               | 1820254     |\n",
      "| policy_loss             | -420.1197   |\n",
      "| qf1_loss                | 19.196781   |\n",
      "| qf2_loss                | 21.874556   |\n",
      "| time_elapsed            | 21864       |\n",
      "| total timesteps         | 1820353     |\n",
      "| value_loss              | 13.518612   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029180147 |\n",
      "| ent_coef_loss           | 2.1445749   |\n",
      "| entropy                 | 14.110508   |\n",
      "| episodes                | 5490        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 4.05e+03    |\n",
      "| n_updates               | 1828597     |\n",
      "| policy_loss             | -428.44223  |\n",
      "| qf1_loss                | 21.325165   |\n",
      "| qf2_loss                | 39.37571    |\n",
      "| time_elapsed            | 21952       |\n",
      "| total timesteps         | 1828696     |\n",
      "| value_loss              | 9.680168    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.027629368 |\n",
      "| ent_coef_loss           | -7.2829843  |\n",
      "| entropy                 | 13.940953   |\n",
      "| episodes                | 5500        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 4.09e+03    |\n",
      "| n_updates               | 1837269     |\n",
      "| policy_loss             | -428.14545  |\n",
      "| qf1_loss                | 33.593903   |\n",
      "| qf2_loss                | 21.794367   |\n",
      "| time_elapsed            | 22043       |\n",
      "| total timesteps         | 1837368     |\n",
      "| value_loss              | 9.649459    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030496495 |\n",
      "| ent_coef_loss           | 4.18402     |\n",
      "| entropy                 | 13.55598    |\n",
      "| episodes                | 5510        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 4.01e+03    |\n",
      "| n_updates               | 1844450     |\n",
      "| policy_loss             | -423.1313   |\n",
      "| qf1_loss                | 25.34929    |\n",
      "| qf2_loss                | 10.255416   |\n",
      "| time_elapsed            | 22119       |\n",
      "| total timesteps         | 1844549     |\n",
      "| value_loss              | 14.875849   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028803514 |\n",
      "| ent_coef_loss           | -7.855604   |\n",
      "| entropy                 | 14.273399   |\n",
      "| episodes                | 5520        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 3.95e+03    |\n",
      "| n_updates               | 1852347     |\n",
      "| policy_loss             | -429.52475  |\n",
      "| qf1_loss                | 19.6839     |\n",
      "| qf2_loss                | 10.089951   |\n",
      "| time_elapsed            | 22201       |\n",
      "| total timesteps         | 1852446     |\n",
      "| value_loss              | 12.083624   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029815149 |\n",
      "| ent_coef_loss           | -1.9189128  |\n",
      "| entropy                 | 14.302855   |\n",
      "| episodes                | 5530        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 4.04e+03    |\n",
      "| n_updates               | 1860823     |\n",
      "| policy_loss             | -424.88702  |\n",
      "| qf1_loss                | 40.043716   |\n",
      "| qf2_loss                | 35.19978    |\n",
      "| time_elapsed            | 22291       |\n",
      "| total timesteps         | 1860922     |\n",
      "| value_loss              | 22.743408   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.027763858 |\n",
      "| ent_coef_loss           | -3.9171305  |\n",
      "| entropy                 | 14.449324   |\n",
      "| episodes                | 5540        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 4.15e+03    |\n",
      "| n_updates               | 1868405     |\n",
      "| policy_loss             | -440.7514   |\n",
      "| qf1_loss                | 24.07923    |\n",
      "| qf2_loss                | 18.129671   |\n",
      "| time_elapsed            | 22370       |\n",
      "| total timesteps         | 1868504     |\n",
      "| value_loss              | 7.2116885   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029528625 |\n",
      "| ent_coef_loss           | -4.419806   |\n",
      "| entropy                 | 15.225439   |\n",
      "| episodes                | 5550        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 4.18e+03    |\n",
      "| n_updates               | 1875897     |\n",
      "| policy_loss             | -442.1637   |\n",
      "| qf1_loss                | 28.60773    |\n",
      "| qf2_loss                | 19.513805   |\n",
      "| time_elapsed            | 22449       |\n",
      "| total timesteps         | 1875996     |\n",
      "| value_loss              | 10.548169   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028221503 |\n",
      "| ent_coef_loss           | -10.916938  |\n",
      "| entropy                 | 14.177142   |\n",
      "| episodes                | 5560        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 4.14e+03    |\n",
      "| n_updates               | 1882467     |\n",
      "| policy_loss             | -442.74176  |\n",
      "| qf1_loss                | 13.910986   |\n",
      "| qf2_loss                | 17.798193   |\n",
      "| time_elapsed            | 22517       |\n",
      "| total timesteps         | 1882566     |\n",
      "| value_loss              | 17.756752   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02603171 |\n",
      "| ent_coef_loss           | -9.503414  |\n",
      "| entropy                 | 14.080562  |\n",
      "| episodes                | 5570       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 4.26e+03   |\n",
      "| n_updates               | 1889819    |\n",
      "| policy_loss             | -428.90692 |\n",
      "| qf1_loss                | 7.6489177  |\n",
      "| qf2_loss                | 7.8969893  |\n",
      "| time_elapsed            | 22594      |\n",
      "| total timesteps         | 1889918    |\n",
      "| value_loss              | 6.668939   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028879944 |\n",
      "| ent_coef_loss           | -0.22504735 |\n",
      "| entropy                 | 14.221369   |\n",
      "| episodes                | 5580        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 4.3e+03     |\n",
      "| n_updates               | 1898027     |\n",
      "| policy_loss             | -410.7528   |\n",
      "| qf1_loss                | 19.73468    |\n",
      "| qf2_loss                | 27.026783   |\n",
      "| time_elapsed            | 22680       |\n",
      "| total timesteps         | 1898126     |\n",
      "| value_loss              | 20.465288   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.033500884 |\n",
      "| ent_coef_loss           | -0.89444923 |\n",
      "| entropy                 | 14.575241   |\n",
      "| episodes                | 5590        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 4.37e+03    |\n",
      "| n_updates               | 1907462     |\n",
      "| policy_loss             | -420.22186  |\n",
      "| qf1_loss                | 13.195826   |\n",
      "| qf2_loss                | 13.10508    |\n",
      "| time_elapsed            | 22779       |\n",
      "| total timesteps         | 1907561     |\n",
      "| value_loss              | 9.700703    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02894218 |\n",
      "| ent_coef_loss           | -2.8412938 |\n",
      "| entropy                 | 15.157005  |\n",
      "| episodes                | 5600       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 4.37e+03   |\n",
      "| n_updates               | 1916039    |\n",
      "| policy_loss             | -436.90063 |\n",
      "| qf1_loss                | 15.057048  |\n",
      "| qf2_loss                | 10.85241   |\n",
      "| time_elapsed            | 22869      |\n",
      "| total timesteps         | 1916138    |\n",
      "| value_loss              | 7.080185   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.031102566 |\n",
      "| ent_coef_loss           | 0.67548156  |\n",
      "| entropy                 | 14.139357   |\n",
      "| episodes                | 5610        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 4.44e+03    |\n",
      "| n_updates               | 1924708     |\n",
      "| policy_loss             | -429.21298  |\n",
      "| qf1_loss                | 26.468697   |\n",
      "| qf2_loss                | 17.65601    |\n",
      "| time_elapsed            | 22960       |\n",
      "| total timesteps         | 1924807     |\n",
      "| value_loss              | 17.503347   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028990516 |\n",
      "| ent_coef_loss           | -7.431856   |\n",
      "| entropy                 | 13.188656   |\n",
      "| episodes                | 5620        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 4.53e+03    |\n",
      "| n_updates               | 1934156     |\n",
      "| policy_loss             | -441.12164  |\n",
      "| qf1_loss                | 9.5643835   |\n",
      "| qf2_loss                | 25.313332   |\n",
      "| time_elapsed            | 23059       |\n",
      "| total timesteps         | 1934255     |\n",
      "| value_loss              | 9.598647    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02880492 |\n",
      "| ent_coef_loss           | 5.2177224  |\n",
      "| entropy                 | 13.771379  |\n",
      "| episodes                | 5630       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 4.45e+03   |\n",
      "| n_updates               | 1941060    |\n",
      "| policy_loss             | -422.13687 |\n",
      "| qf1_loss                | 38.41042   |\n",
      "| qf2_loss                | 47.033062  |\n",
      "| time_elapsed            | 23131      |\n",
      "| total timesteps         | 1941159    |\n",
      "| value_loss              | 26.353107  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028711453 |\n",
      "| ent_coef_loss           | -1.2713827  |\n",
      "| entropy                 | 14.925286   |\n",
      "| episodes                | 5640        |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 4.47e+03    |\n",
      "| n_updates               | 1948985     |\n",
      "| policy_loss             | -432.74332  |\n",
      "| qf1_loss                | 11.217673   |\n",
      "| qf2_loss                | 8.852245    |\n",
      "| time_elapsed            | 23221       |\n",
      "| total timesteps         | 1949084     |\n",
      "| value_loss              | 15.504994   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.02762309 |\n",
      "| ent_coef_loss           | 5.850043   |\n",
      "| entropy                 | 13.584929  |\n",
      "| episodes                | 5650       |\n",
      "| fps                     | 83         |\n",
      "| mean 100 episode reward | 4.47e+03   |\n",
      "| n_updates               | 1956486    |\n",
      "| policy_loss             | -423.26508 |\n",
      "| qf1_loss                | 47.181435  |\n",
      "| qf2_loss                | 64.13574   |\n",
      "| time_elapsed            | 23302      |\n",
      "| total timesteps         | 1956585    |\n",
      "| value_loss              | 48.16774   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.028777286 |\n",
      "| ent_coef_loss           | 0.32543445  |\n",
      "| entropy                 | 15.33695    |\n",
      "| episodes                | 5660        |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 4.59e+03    |\n",
      "| n_updates               | 1965112     |\n",
      "| policy_loss             | -416.77814  |\n",
      "| qf1_loss                | 17.94247    |\n",
      "| qf2_loss                | 12.484608   |\n",
      "| time_elapsed            | 23393       |\n",
      "| total timesteps         | 1965211     |\n",
      "| value_loss              | 9.431281    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.029129695 |\n",
      "| ent_coef_loss           | 4.8580723   |\n",
      "| entropy                 | 14.034903   |\n",
      "| episodes                | 5670        |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 4.61e+03    |\n",
      "| n_updates               | 1972674     |\n",
      "| policy_loss             | -414.8836   |\n",
      "| qf1_loss                | 23.737051   |\n",
      "| qf2_loss                | 22.238724   |\n",
      "| time_elapsed            | 23473       |\n",
      "| total timesteps         | 1972773     |\n",
      "| value_loss              | 19.35762    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.030003497 |\n",
      "| ent_coef_loss           | 2.3435738   |\n",
      "| entropy                 | 14.388626   |\n",
      "| episodes                | 5680        |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 4.65e+03    |\n",
      "| n_updates               | 1981671     |\n",
      "| policy_loss             | -434.27258  |\n",
      "| qf1_loss                | 15.241843   |\n",
      "| qf2_loss                | 11.215733   |\n",
      "| time_elapsed            | 23568       |\n",
      "| total timesteps         | 1981770     |\n",
      "| value_loss              | 26.884335   |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.03015129 |\n",
      "| ent_coef_loss           | 2.9091327  |\n",
      "| entropy                 | 13.506798  |\n",
      "| episodes                | 5690       |\n",
      "| fps                     | 84         |\n",
      "| mean 100 episode reward | 4.49e+03   |\n",
      "| n_updates               | 1988143    |\n",
      "| policy_loss             | -412.13266 |\n",
      "| qf1_loss                | 48.854237  |\n",
      "| qf2_loss                | 26.085539  |\n",
      "| time_elapsed            | 23636      |\n",
      "| total timesteps         | 1988242    |\n",
      "| value_loss              | 9.660484   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.026770646 |\n",
      "| ent_coef_loss           | -2.968498   |\n",
      "| entropy                 | 14.392847   |\n",
      "| episodes                | 5700        |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 4.48e+03    |\n",
      "| n_updates               | 1996352     |\n",
      "| policy_loss             | -435.9751   |\n",
      "| qf1_loss                | 30.240345   |\n",
      "| qf2_loss                | 50.42679    |\n",
      "| time_elapsed            | 23723       |\n",
      "| total timesteps         | 1996451     |\n",
      "| value_loss              | 24.18204    |\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# TRAIN THE MODEL\n",
    "model.learn(total_timesteps=int(2e6), log_interval=10)\n",
    "model.save(\"humanoid_2M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading a model without an environment, this model cannot be trained until it has a valid environment.\n",
      "WARNING:tensorflow:From /home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:191: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:200: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/stable_baselines/sac/sac.py:142: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/stable_baselines/common/input.py:25: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/stable_baselines/sac/policies.py:194: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f073a6d2e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f073a6d2e50>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f073a6d2e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f073a6d2e50>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:From /home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/stable_baselines/common/tf_layers.py:57: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From /home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f0740230810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f0740230810>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f0740230810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f0740230810>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f0740223050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f0740223050>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f0740223050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f0740223050>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f073a6d2e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f073a6d2e50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f073a6d2e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f073a6d2e50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f073a6d2e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f073a6d2e50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f073a6d2e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f073a6d2e50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From /home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/stable_baselines/sac/policies.py:216: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f073a6ea390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f073a6ea390>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f073a6ea390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f073a6ea390>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f07383f8490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f07383f8490>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f07383f8490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f07383f8490>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f07384794d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f07384794d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f07384794d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f07384794d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f0740223590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f0740223590>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f0740223590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f0740223590>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f073a6ea4d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f073a6ea4d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f073a6ea4d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f073a6ea4d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f073a6ea4d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f073a6ea4d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f073a6ea4d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f073a6ea4d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f0738382510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f0738382510>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f0738382510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f0738382510>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f0738412110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f0738412110>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f0738412110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f0738412110>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f073828f550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f073828f550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f073828f550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f073828f550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f0738382510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f0738382510>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f0738382510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f0738382510>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f07383e41d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f07383e41d0>>: AttributeError: module 'gast' has no attribute 'Num'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f07383e41d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f07383e41d0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f0738382510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f0738382510>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f0738382510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f0738382510>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f0738304990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f0738304990>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f0738304990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f0738304990>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f0738300250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f0738300250>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f0738300250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f0738300250>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f0738455210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f0738455210>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f0738455210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f0738455210>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f07383525d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f07383525d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f07383525d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f07383525d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f073828f550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f073828f550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f073828f550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f073828f550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f0740223550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f0740223550>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f0740223550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f0740223550>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f0738455410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f0738455410>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f0738455410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f0738455410>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f0738455410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f0738455410>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f0738455410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f0738455410>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f0740223590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f0740223590>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f0740223590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f0740223590>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From /home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/stable_baselines/sac/sac.py:233: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/stable_baselines/sac/sac.py:296: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/stable_baselines/sac/sac.py:316: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "Creating window glfw\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3339: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# RUN THE SAVED MODEL\n",
    "env = gym.make('Humanoid-v2')\n",
    "model = SAC.load(\"humanoid_2M\")\n",
    "\n",
    "for _ in range(10):\n",
    "    obs = env.reset()\n",
    "    for _ in range(1000):\n",
    "        action, _states = model.predict(obs)\n",
    "        obs, rewards, dones, info = env.step(action)\n",
    "        env.render()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800\"\n",
       "            src=\"http://localhost:6006\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f849406fcd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid info file: '/tmp/.tensorboard-info/pid-38328.info'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/tensorboard/manager.py\", line 149, in _info_from_string\n",
      "    json_value = json.loads(info_string)\n",
      "  File \"/home/mike/anaconda3/envs/rl/lib/python3.7/json/__init__.py\", line 348, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/home/mike/anaconda3/envs/rl/lib/python3.7/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/home/mike/anaconda3/envs/rl/lib/python3.7/json/decoder.py\", line 355, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/tensorboard/manager.py\", line 316, in get_all\n",
      "    info = _info_from_string(contents)\n",
      "  File \"/home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/tensorboard/manager.py\", line 151, in _info_from_string\n",
      "    raise ValueError(\"invalid JSON: %r\" % (info_string,))\n",
      "ValueError: invalid JSON: ''\n"
     ]
    }
   ],
   "source": [
    "# DISPLAY THE RESULTS\n",
    "%tensorboard --logdir sac_humanoid_walk_tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task: Stand up from a flat beginning position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:191: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:200: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/stable_baselines/sac/sac.py:142: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/stable_baselines/common/input.py:25: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/stable_baselines/sac/policies.py:194: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8482bf8590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8482bf8590>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8482bf8590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8482bf8590>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:From /home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/stable_baselines/common/tf_layers.py:57: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From /home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8482bf8490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8482bf8490>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8482bf8490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8482bf8490>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f848ce911d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f848ce911d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f848ce911d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f848ce911d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f848ce914d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f848ce914d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f848ce914d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f848ce914d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f848ce914d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f848ce914d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f848ce914d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f848ce914d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From /home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/stable_baselines/sac/policies.py:216: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f848008c1d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f848008c1d0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f848008c1d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f848008c1d0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8480082510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8480082510>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8480082510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8480082510>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f84a8665ed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f84a8665ed0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f84a8665ed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f84a8665ed0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8482bf8c90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8482bf8c90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8482bf8c90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8482bf8c90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f84af4c1c10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f84af4c1c10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f84af4c1c10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f84af4c1c10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f84af4c1c10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f84af4c1c10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f84af4c1c10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f84af4c1c10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f848016df50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f848016df50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f848016df50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f848016df50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8482bf8490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8482bf8490>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8482bf8490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8482bf8490>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8468754650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8468754650>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8468754650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8468754650>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f84800e3ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f84800e3ad0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f84800e3ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f84800e3ad0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8480082390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8480082390>>: AttributeError: module 'gast' has no attribute 'Num'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8480082390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8480082390>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f848008c650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f848008c650>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f848008c650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f848008c650>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8480080ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8480080ad0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8480080ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8480080ad0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8468754650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8468754650>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8468754650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8468754650>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f84af4c1c10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f84af4c1c10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f84af4c1c10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f84af4c1c10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f84af4c1c10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f84af4c1c10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f84af4c1c10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f84af4c1c10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f84800e3410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f84800e3410>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f84800e3410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f84800e3410>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8480040210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8480040210>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8480040210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8480040210>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8482bf8490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8482bf8490>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8482bf8490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f8482bf8490>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f848000aa50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f848000aa50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f848000aa50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f848000aa50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f848000a090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f848000a090>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f848000a090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f848000a090>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From /home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/stable_baselines/sac/sac.py:233: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/stable_baselines/sac/sac.py:296: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/stable_baselines/sac/sac.py:316: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DEFINE THE ENVIRONMENT/MODEL WITH TUNED PARAMETERS\n",
    "env = gym.make('HumanoidStandup-v2')\n",
    "policy_kwargs = dict(layers=[256, 256])\n",
    "model = SAC(MlpPolicy, env, verbose=1, tensorboard_log=\"./sac_humanoid_standup_tensorboard/\", \n",
    "            policy_kwargs=policy_kwargs, buffer_size=1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/mike/anaconda3/envs/rl/lib/python3.7/site-packages/stable_baselines/common/base_class.py:1143: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.3715919  |\n",
      "| ent_coef_loss           | 1.0368845  |\n",
      "| entropy                 | 15.556219  |\n",
      "| episodes                | 10         |\n",
      "| fps                     | 72         |\n",
      "| mean 100 episode reward | 7.06e+04   |\n",
      "| n_updates               | 8901       |\n",
      "| policy_loss             | -2343.0728 |\n",
      "| qf1_loss                | 442.96002  |\n",
      "| qf2_loss                | 353.17847  |\n",
      "| time_elapsed            | 123        |\n",
      "| total timesteps         | 9000       |\n",
      "| value_loss              | 398.77277  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.6711767  |\n",
      "| ent_coef_loss           | 0.33287117 |\n",
      "| entropy                 | 15.5787325 |\n",
      "| episodes                | 20         |\n",
      "| fps                     | 81         |\n",
      "| mean 100 episode reward | 7.52e+04   |\n",
      "| n_updates               | 18901      |\n",
      "| policy_loss             | -4535.7314 |\n",
      "| qf1_loss                | 2131.247   |\n",
      "| qf2_loss                | 1931.5359  |\n",
      "| time_elapsed            | 234        |\n",
      "| total timesteps         | 19000      |\n",
      "| value_loss              | 1357.7815  |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ent_coef                | 0.7404186  |\n",
      "| ent_coef_loss           | 0.23721056 |\n",
      "| entropy                 | 15.481803  |\n",
      "| episodes                | 30         |\n",
      "| fps                     | 81         |\n",
      "| mean 100 episode reward | 8.04e+04   |\n",
      "| n_updates               | 28901      |\n",
      "| policy_loss             | -5633.621  |\n",
      "| qf1_loss                | 4343.631   |\n",
      "| qf2_loss                | 4476.461   |\n",
      "| time_elapsed            | 354        |\n",
      "| total timesteps         | 29000      |\n",
      "| value_loss              | 5531.1274  |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.7944754   |\n",
      "| ent_coef_loss           | -0.22849077 |\n",
      "| entropy                 | 15.390942   |\n",
      "| episodes                | 40          |\n",
      "| fps                     | 83          |\n",
      "| mean 100 episode reward | 7.88e+04    |\n",
      "| n_updates               | 38901       |\n",
      "| policy_loss             | -5579.257   |\n",
      "| qf1_loss                | 4988.739    |\n",
      "| qf2_loss                | 4873.195    |\n",
      "| time_elapsed            | 467         |\n",
      "| total timesteps         | 39000       |\n",
      "| value_loss              | 19163.492   |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.91131836  |\n",
      "| ent_coef_loss           | -0.04836991 |\n",
      "| entropy                 | 15.470493   |\n",
      "| episodes                | 50          |\n",
      "| fps                     | 84          |\n",
      "| mean 100 episode reward | 8.14e+04    |\n",
      "| n_updates               | 48901       |\n",
      "| policy_loss             | -6489.4336  |\n",
      "| qf1_loss                | 3632.4878   |\n",
      "| qf2_loss                | 4756.6567   |\n",
      "| time_elapsed            | 580         |\n",
      "| total timesteps         | 49000       |\n",
      "| value_loss              | 4223.5454   |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| current_lr              | 0.0003       |\n",
      "| ent_coef                | 0.9530886    |\n",
      "| ent_coef_loss           | -0.023826616 |\n",
      "| entropy                 | 15.43108     |\n",
      "| episodes                | 60           |\n",
      "| fps                     | 85           |\n",
      "| mean 100 episode reward | 8.12e+04     |\n",
      "| n_updates               | 58901        |\n",
      "| policy_loss             | -6070.8677   |\n",
      "| qf1_loss                | 3748.1333    |\n",
      "| qf2_loss                | 4197.015     |\n",
      "| time_elapsed            | 691          |\n",
      "| total timesteps         | 59000        |\n",
      "| value_loss              | 4184.997     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.9649788   |\n",
      "| ent_coef_loss           | 0.024068503 |\n",
      "| entropy                 | 15.278772   |\n",
      "| episodes                | 70          |\n",
      "| fps                     | 86          |\n",
      "| mean 100 episode reward | 8.31e+04    |\n",
      "| n_updates               | 68901       |\n",
      "| policy_loss             | -6521.9233  |\n",
      "| qf1_loss                | 12351.469   |\n",
      "| qf2_loss                | 11843.029   |\n",
      "| time_elapsed            | 799         |\n",
      "| total timesteps         | 69000       |\n",
      "| value_loss              | 4399.708    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 1.0225247   |\n",
      "| ent_coef_loss           | 0.024960719 |\n",
      "| entropy                 | 15.667633   |\n",
      "| episodes                | 80          |\n",
      "| fps                     | 85          |\n",
      "| mean 100 episode reward | 8.42e+04    |\n",
      "| n_updates               | 78901       |\n",
      "| policy_loss             | -5683.203   |\n",
      "| qf1_loss                | 6198.789    |\n",
      "| qf2_loss                | 7304.7393   |\n",
      "| time_elapsed            | 921         |\n",
      "| total timesteps         | 79000       |\n",
      "| value_loss              | 3003.3955   |\n",
      "-----------------------------------------\n",
      "--------------------------------------------\n",
      "| current_lr              | 0.0003         |\n",
      "| ent_coef                | 0.98686564     |\n",
      "| ent_coef_loss           | -0.00066134706 |\n",
      "| entropy                 | 15.527781      |\n",
      "| episodes                | 90             |\n",
      "| fps                     | 84             |\n",
      "| mean 100 episode reward | 8.53e+04       |\n",
      "| n_updates               | 88901          |\n",
      "| policy_loss             | -6058.24       |\n",
      "| qf1_loss                | 4870.6367      |\n",
      "| qf2_loss                | 3866.6895      |\n",
      "| time_elapsed            | 1057           |\n",
      "| total timesteps         | 89000          |\n",
      "| value_loss              | 1884.6318      |\n",
      "--------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# TRAIN THE MODEL\n",
    "model.learn(total_timesteps=int(2e6), log_interval=10)\n",
    "model.save(\"humanoid_standup_2M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THE SAVED MODEL\n",
    "env = gym.make('HumanoidStandup-v2')\n",
    "model = SAC.load(\"humanoid_standup_2M\")\n",
    "\n",
    "for _ in range(10):\n",
    "    obs = env.reset()\n",
    "    for _ in range(1000):\n",
    "        action, _states = model.predict(obs)\n",
    "        obs, rewards, dones, info = env.step(action)\n",
    "        env.render()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DISPLAY THE RESULTS\n",
    "%tensorboard --logdir sac_humanoid_standup_tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task: Teach a 'half-cheetah' a gait to run forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE THE ENVIRONMENT/MODEL WITH TUNED PARAMETERS\n",
    "env = gym.make('HalfCheetah-v2')\n",
    "policy_kwargs = dict(layers=[256, 256])\n",
    "model = SAC(MlpPolicy, env, verbose=1, tensorboard_log=\"./sac_half_cheetah_tensorboard/\", \n",
    "            policy_kwargs=policy_kwargs, buffer_size=1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN THE MODEL\n",
    "model.learn(total_timesteps=int(2e6), log_interval=10)\n",
    "model.save(\"half_cheetah_2M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THE SAVED MODEL\n",
    "env = gym.make('HumanoidStandup-v2')\n",
    "model = SAC.load(\"humanoid_standup_2M\")\n",
    "\n",
    "for _ in range(10):\n",
    "    obs = env.reset()\n",
    "    for _ in range(1000):\n",
    "        action, _states = model.predict(obs)\n",
    "        obs, rewards, dones, info = env.step(action)\n",
    "        env.render()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DISPLAY THE RESULTS\n",
    "%tensorboard --logdir sac_half_cheetah_tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task: Teach an 'ant-like' quadruped a gait to move forward "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE THE ENVIRONMENT/MODEL WITH TUNED PARAMETERS\n",
    "env = gym.make('Ant-v2')\n",
    "policy_kwargs = dict(layers=[256, 256])\n",
    "model = SAC(MlpPolicy, env, verbose=1, tensorboard_log=\"./sac_ant_tensorboard/\", \n",
    "            policy_kwargs=policy_kwargs, buffer_size=1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN THE MODEL\n",
    "model.learn(total_timesteps=int(2e6), log_interval=10)\n",
    "model.save(\"ant_2M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THE SAVED MODEL\n",
    "env = gym.make('Ant-v2')\n",
    "model = SAC.load(\"ant_2M\")\n",
    "\n",
    "for _ in range(10):\n",
    "    obs = env.reset()\n",
    "    for _ in range(1000):\n",
    "        action, _states = model.predict(obs)\n",
    "        obs, rewards, dones, info = env.step(action)\n",
    "        env.render()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DISPLAY THE RESULTS\n",
    "%tensorboard --logdir sac_ant_tensorboard"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
